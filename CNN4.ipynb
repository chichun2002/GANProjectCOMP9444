{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e14727-dad3-473e-8dc5-681309db07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from elpv_dataset.utils.elpv_reader import load_dataset\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122af98f-0610-4e33-b034-dfdf6643e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomVerticalFlip(0.5),\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "])\n",
    "\n",
    "transform_base = v2.Compose([\n",
    "    # v2.Grayscale(num_output_channels=3),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize((24,24), antialias=None),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46aaddd3-9e7b-48b1-9621-9cce321d41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELPV_Dataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        images, labels, types = load_dataset()\n",
    "        self.images = np.reshape(images, (np.shape(images)[0], np.shape(images)[1], np.shape(images)[2], 1))\n",
    "        \n",
    "        self.labels = (labels*3).astype(np.uint8)\n",
    "        self.types = types\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.images))\n",
    "\n",
    "data = ELPV_Dataset(transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a7226d-82da-482c-9c64-bce8e5493f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 1968 Validation Data: 656\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "val_size = int(len(data)*(1/4))\n",
    "train_size = len(data) - val_size\n",
    "print(f\"Training Data: {train_size} Validation Data: {val_size}\")\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(data,[train_size,val_size])\n",
    "\n",
    "label_tensor = torch.Tensor([label for (image, label) in train_data]).int()\n",
    "train_sampler = torch.utils.data.sampler.WeightedRandomSampler([(1/torch.bincount(label_tensor)[label].item()) for (image, label) in train_data],len(train_data))\n",
    "label_tensor = torch.Tensor([label for (image, label) in val_data]).int()\n",
    "val_sampler = torch.utils.data.sampler.WeightedRandomSampler([(1/torch.bincount(label_tensor)[label].item()) for (image, label) in val_data],len(val_data))\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for images, labels in val_dl:\n",
    "#     print(torch.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410debf8-4819-4571-8e6f-798fa33b9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "# i = np.random.randint(1,200)\n",
    "print(np.shape(data[0][0]))\n",
    "# print(data[i][0])\n",
    "# # images, labels, types = load_dataset()\n",
    "\n",
    "# # print(transform(images[0]))\n",
    "# plt.imshow(data[i][0].permute(1,2,0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d79d13-ff10-4473-81a9-2e60ea949005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1, 1, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(1, 2, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 2, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(2, 512, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 4, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(12,12),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(4,4),\n",
    "            nn.LogSoftmax(-1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output = self.network(x)\n",
    "        return output\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        multiplier = 4\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(1, 1*multiplier, (3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.block1 = self.block(1*multiplier,1*multiplier)\n",
    "        self.block2 = self.block(1*multiplier,1*multiplier)\n",
    "        self.block3 = self.block(1*multiplier,2*multiplier)\n",
    "        self.block4 = self.block(2*multiplier,2*multiplier)\n",
    "        self.block5 = self.block(2*multiplier,4*multiplier)\n",
    "        self.block6 = self.block(4*multiplier,4*multiplier)\n",
    "        self.block7 = self.block(4*multiplier,8*multiplier)\n",
    "        self.block8 = self.block(8*multiplier,8*multiplier)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.globalmaxpool = nn.AvgPool2d(2,2)\n",
    "        self.fc = nn.Linear(8*multiplier, 4)\n",
    "        self.lsf = nn.LogSoftmax(-1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout2d(0)\n",
    " \n",
    "    def block(self, input_channels, output_channels):\n",
    "        output = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_channels, output_channels, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def process_block(self, input, block, sample=None):\n",
    "        result = block(input)\n",
    "\n",
    "        if sample:\n",
    "            input = self.sample(input)\n",
    "        \n",
    "        output = self.relu(input + result)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def sample(self, input):\n",
    "        in_c = int(input.size()[1])\n",
    "        out_c = int(input.size()[1]*2)\n",
    "        upsample = nn.Conv2d(in_c, out_c, (3,3), padding=1)\n",
    "        upsample.to('cuda')\n",
    "        output = upsample(input)\n",
    "        return output\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input(x)\n",
    "        x = self.process_block(x, self.block1)\n",
    "        x = self.process_block(x, self.block2)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.process_block(x, self.block3, True)\n",
    "        x = self.process_block(x, self.block4)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.process_block(x, self.block5, True)\n",
    "        x = self.process_block(x, self.block6)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.process_block(x, self.block7, True)\n",
    "        x = self.process_block(x, self.block8)\n",
    "        x = self.globalmaxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.lsf(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f2bcac-5aee-4254-bbf8-e18f010756ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " # for i, (images, labels) in enumerate(train_dl):\n",
    "        \n",
    " #        plt.imshow(images[0].permute(1,2,0))\n",
    " #        plt.show()\n",
    " #        images = transform(images)\n",
    " #        plt.imshow(images[0].permute(1,2,0))\n",
    " #        plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e49b93-c4fe-4e95-848e-4070522f6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]/[5000], train_loss: 1.408400, train_acc: 26.27%, val_loss: 1.429100, val_acc: 7.68%\n",
      "Epoch [1]/[5000], train_loss: 1.358400, train_acc: 28.91%, val_loss: 1.524200, val_acc: 3.65%\n",
      "Epoch [2]/[5000], train_loss: 1.307200, train_acc: 34.38%, val_loss: 1.499000, val_acc: 8.98%\n",
      "Epoch [3]/[5000], train_loss: 1.270400, train_acc: 37.11%, val_loss: 1.363000, val_acc: 22.53%\n",
      "Epoch [4]/[5000], train_loss: 1.286700, train_acc: 37.26%, val_loss: 1.277400, val_acc: 30.86%\n",
      "Epoch [5]/[5000], train_loss: 1.241800, train_acc: 38.67%, val_loss: 1.339200, val_acc: 29.17%\n",
      "Epoch [6]/[5000], train_loss: 1.245600, train_acc: 37.94%, val_loss: 1.391700, val_acc: 28.39%\n",
      "Epoch [7]/[5000], train_loss: 1.227300, train_acc: 40.53%, val_loss: 1.292100, val_acc: 33.07%\n",
      "Epoch [8]/[5000], train_loss: 1.238100, train_acc: 38.57%, val_loss: 1.451100, val_acc: 20.18%\n",
      "Epoch [9]/[5000], train_loss: 1.232200, train_acc: 40.14%, val_loss: 1.109500, val_acc: 38.41%\n",
      "Epoch [10]/[5000], train_loss: 1.217600, train_acc: 39.36%, val_loss: 1.377500, val_acc: 16.28%\n",
      "Epoch [11]/[5000], train_loss: 1.227600, train_acc: 40.97%, val_loss: 1.292700, val_acc: 40.49%\n",
      "Epoch [12]/[5000], train_loss: 1.208000, train_acc: 41.55%, val_loss: 1.173500, val_acc: 44.79%\n",
      "Epoch [13]/[5000], train_loss: 1.205600, train_acc: 41.65%, val_loss: 1.440300, val_acc: 21.88%\n",
      "Epoch [14]/[5000], train_loss: 1.211500, train_acc: 42.14%, val_loss: 1.286400, val_acc: 30.08%\n",
      "Epoch [15]/[5000], train_loss: 1.205800, train_acc: 42.43%, val_loss: 1.374300, val_acc: 24.61%\n",
      "Epoch [16]/[5000], train_loss: 1.184300, train_acc: 44.14%, val_loss: 1.354400, val_acc: 38.54%\n",
      "Epoch [17]/[5000], train_loss: 1.210800, train_acc: 42.48%, val_loss: 1.265000, val_acc: 33.59%\n",
      "Epoch [18]/[5000], train_loss: 1.183800, train_acc: 44.34%, val_loss: 2.186100, val_acc: 22.92%\n",
      "Epoch [19]/[5000], train_loss: 1.202000, train_acc: 41.75%, val_loss: 1.259100, val_acc: 20.31%\n",
      "Epoch [20]/[5000], train_loss: 1.215200, train_acc: 41.36%, val_loss: 1.086300, val_acc: 44.27%\n",
      "Epoch [21]/[5000], train_loss: 1.190600, train_acc: 41.89%, val_loss: 1.201700, val_acc: 32.55%\n",
      "Epoch [22]/[5000], train_loss: 1.180900, train_acc: 42.53%, val_loss: 1.256600, val_acc: 29.69%\n",
      "Epoch [23]/[5000], train_loss: 1.183600, train_acc: 45.21%, val_loss: 1.305700, val_acc: 24.48%\n",
      "Epoch [24]/[5000], train_loss: 1.162600, train_acc: 44.97%, val_loss: 1.629100, val_acc: 29.69%\n",
      "Epoch [25]/[5000], train_loss: 1.151900, train_acc: 45.21%, val_loss: 1.261400, val_acc: 27.47%\n",
      "Epoch [26]/[5000], train_loss: 1.156800, train_acc: 46.58%, val_loss: 1.387100, val_acc: 20.83%\n",
      "Epoch [27]/[5000], train_loss: 1.150300, train_acc: 44.82%, val_loss: 1.229400, val_acc: 37.89%\n",
      "Epoch [28]/[5000], train_loss: 1.162200, train_acc: 45.12%, val_loss: 1.261900, val_acc: 34.51%\n",
      "Epoch [29]/[5000], train_loss: 1.174100, train_acc: 44.48%, val_loss: 1.309600, val_acc: 27.21%\n",
      "Epoch [30]/[5000], train_loss: 1.170500, train_acc: 44.87%, val_loss: 1.026700, val_acc: 41.28%\n",
      "Epoch [31]/[5000], train_loss: 1.156800, train_acc: 45.41%, val_loss: 1.334200, val_acc: 23.96%\n",
      "Epoch [32]/[5000], train_loss: 1.104000, train_acc: 47.90%, val_loss: 1.318400, val_acc: 31.90%\n",
      "Epoch [33]/[5000], train_loss: 1.117600, train_acc: 44.43%, val_loss: 1.181700, val_acc: 29.04%\n",
      "Epoch [34]/[5000], train_loss: 1.111000, train_acc: 47.51%, val_loss: 1.404300, val_acc: 34.77%\n",
      "Epoch [35]/[5000], train_loss: 1.120100, train_acc: 47.17%, val_loss: 1.195100, val_acc: 43.49%\n",
      "Epoch [36]/[5000], train_loss: 1.104900, train_acc: 46.39%, val_loss: 1.379000, val_acc: 25.00%\n",
      "Epoch [37]/[5000], train_loss: 1.092700, train_acc: 48.24%, val_loss: 1.375100, val_acc: 26.56%\n",
      "Epoch [38]/[5000], train_loss: 1.098200, train_acc: 48.93%, val_loss: 1.279200, val_acc: 37.24%\n",
      "Epoch [39]/[5000], train_loss: 1.077800, train_acc: 51.12%, val_loss: 1.319100, val_acc: 20.96%\n",
      "Epoch [40]/[5000], train_loss: 1.063200, train_acc: 50.54%, val_loss: 1.395700, val_acc: 23.57%\n",
      "Epoch [41]/[5000], train_loss: 1.056700, train_acc: 51.03%, val_loss: 1.256500, val_acc: 37.24%\n",
      "Epoch [42]/[5000], train_loss: 1.046600, train_acc: 51.12%, val_loss: 1.412400, val_acc: 30.99%\n",
      "Epoch [43]/[5000], train_loss: 1.071300, train_acc: 50.73%, val_loss: 1.441400, val_acc: 25.91%\n",
      "Epoch [44]/[5000], train_loss: 1.044400, train_acc: 53.08%, val_loss: 1.391200, val_acc: 29.04%\n",
      "Epoch [45]/[5000], train_loss: 1.060600, train_acc: 50.44%, val_loss: 1.377400, val_acc: 37.24%\n",
      "Epoch [46]/[5000], train_loss: 1.064100, train_acc: 50.54%, val_loss: 1.311700, val_acc: 29.04%\n",
      "Epoch [47]/[5000], train_loss: 1.036900, train_acc: 52.54%, val_loss: 1.517000, val_acc: 25.00%\n",
      "Epoch [48]/[5000], train_loss: 1.024800, train_acc: 53.61%, val_loss: 1.370400, val_acc: 29.56%\n",
      "Epoch [49]/[5000], train_loss: 0.982900, train_acc: 55.86%, val_loss: 1.364600, val_acc: 37.63%\n",
      "Epoch [50]/[5000], train_loss: 0.969900, train_acc: 56.45%, val_loss: 1.663600, val_acc: 20.18%\n",
      "Epoch [51]/[5000], train_loss: 0.984500, train_acc: 56.35%, val_loss: 1.607200, val_acc: 26.69%\n",
      "Epoch [52]/[5000], train_loss: 1.010400, train_acc: 55.08%, val_loss: 1.353400, val_acc: 31.38%\n",
      "Epoch [53]/[5000], train_loss: 1.001200, train_acc: 56.10%, val_loss: 1.331300, val_acc: 35.03%\n",
      "Epoch [54]/[5000], train_loss: 0.971700, train_acc: 55.42%, val_loss: 1.411600, val_acc: 34.11%\n",
      "Epoch [55]/[5000], train_loss: 0.944000, train_acc: 58.11%, val_loss: 1.384300, val_acc: 33.33%\n",
      "Epoch [56]/[5000], train_loss: 0.966900, train_acc: 56.25%, val_loss: 1.355800, val_acc: 33.07%\n",
      "Epoch [57]/[5000], train_loss: 0.943300, train_acc: 57.91%, val_loss: 1.342300, val_acc: 32.94%\n",
      "Epoch [58]/[5000], train_loss: 0.958600, train_acc: 57.08%, val_loss: 1.090600, val_acc: 49.35%\n",
      "Epoch [59]/[5000], train_loss: 0.942100, train_acc: 56.49%, val_loss: 1.748500, val_acc: 24.61%\n",
      "Epoch [60]/[5000], train_loss: 0.920500, train_acc: 59.57%, val_loss: 1.360400, val_acc: 35.42%\n",
      "Epoch [61]/[5000], train_loss: 0.948100, train_acc: 58.06%, val_loss: 1.500700, val_acc: 31.51%\n",
      "Epoch [62]/[5000], train_loss: 0.947300, train_acc: 58.45%, val_loss: 1.428700, val_acc: 27.47%\n",
      "Epoch [63]/[5000], train_loss: 0.933800, train_acc: 58.06%, val_loss: 1.270800, val_acc: 36.07%\n",
      "Epoch [64]/[5000], train_loss: 0.934100, train_acc: 58.50%, val_loss: 1.756000, val_acc: 22.53%\n",
      "Epoch [65]/[5000], train_loss: 0.878200, train_acc: 61.96%, val_loss: 1.196800, val_acc: 39.32%\n",
      "Epoch [66]/[5000], train_loss: 0.917500, train_acc: 58.45%, val_loss: 1.300100, val_acc: 37.11%\n",
      "Epoch [67]/[5000], train_loss: 0.844600, train_acc: 61.91%, val_loss: 1.233600, val_acc: 40.89%\n",
      "Epoch [68]/[5000], train_loss: 0.839600, train_acc: 62.70%, val_loss: 1.669900, val_acc: 29.30%\n",
      "Epoch [69]/[5000], train_loss: 0.877200, train_acc: 61.91%, val_loss: 1.226100, val_acc: 43.62%\n",
      "Epoch [70]/[5000], train_loss: 0.877800, train_acc: 59.62%, val_loss: 1.517100, val_acc: 26.95%\n",
      "Epoch [71]/[5000], train_loss: 0.898700, train_acc: 60.55%, val_loss: 1.439400, val_acc: 33.59%\n",
      "Epoch [72]/[5000], train_loss: 0.844900, train_acc: 63.38%, val_loss: 1.475100, val_acc: 32.29%\n",
      "Epoch [73]/[5000], train_loss: 0.853000, train_acc: 62.99%, val_loss: 1.396700, val_acc: 31.38%\n",
      "Epoch [74]/[5000], train_loss: 0.866300, train_acc: 61.62%, val_loss: 1.198100, val_acc: 37.50%\n",
      "Epoch [75]/[5000], train_loss: 0.848900, train_acc: 62.94%, val_loss: 1.173300, val_acc: 47.01%\n",
      "Epoch [76]/[5000], train_loss: 0.839800, train_acc: 62.45%, val_loss: 1.528300, val_acc: 29.56%\n",
      "Epoch [77]/[5000], train_loss: 0.826100, train_acc: 63.48%, val_loss: 1.060700, val_acc: 48.70%\n",
      "Epoch [78]/[5000], train_loss: 0.852900, train_acc: 61.91%, val_loss: 1.407500, val_acc: 39.06%\n",
      "Epoch [79]/[5000], train_loss: 0.828600, train_acc: 64.31%, val_loss: 1.329100, val_acc: 34.77%\n",
      "Epoch [80]/[5000], train_loss: 0.827500, train_acc: 62.79%, val_loss: 1.524200, val_acc: 31.77%\n",
      "Epoch [81]/[5000], train_loss: 0.822700, train_acc: 63.09%, val_loss: 1.117700, val_acc: 46.22%\n",
      "Epoch [82]/[5000], train_loss: 0.819900, train_acc: 64.06%, val_loss: 1.140900, val_acc: 44.53%\n",
      "Epoch [83]/[5000], train_loss: 0.773200, train_acc: 66.46%, val_loss: 1.329700, val_acc: 40.23%\n",
      "Epoch [84]/[5000], train_loss: 0.822100, train_acc: 63.72%, val_loss: 1.218200, val_acc: 47.40%\n",
      "Epoch [85]/[5000], train_loss: 0.818700, train_acc: 63.43%, val_loss: 1.174000, val_acc: 42.71%\n",
      "Epoch [86]/[5000], train_loss: 0.775400, train_acc: 66.31%, val_loss: 1.165400, val_acc: 43.10%\n",
      "Epoch [87]/[5000], train_loss: 0.771800, train_acc: 66.31%, val_loss: 1.461400, val_acc: 38.02%\n",
      "Epoch [88]/[5000], train_loss: 0.796600, train_acc: 64.99%, val_loss: 1.451000, val_acc: 29.04%\n",
      "Epoch [89]/[5000], train_loss: 0.744000, train_acc: 67.82%, val_loss: 1.141500, val_acc: 42.06%\n",
      "Epoch [90]/[5000], train_loss: 0.827000, train_acc: 63.87%, val_loss: 1.580100, val_acc: 29.95%\n",
      "Epoch [91]/[5000], train_loss: 0.776600, train_acc: 66.11%, val_loss: 1.197200, val_acc: 44.14%\n",
      "Epoch [92]/[5000], train_loss: 0.733900, train_acc: 68.07%, val_loss: 1.593700, val_acc: 31.25%\n",
      "Epoch [93]/[5000], train_loss: 0.806500, train_acc: 64.84%, val_loss: 1.184900, val_acc: 43.49%\n",
      "Epoch [94]/[5000], train_loss: 0.739300, train_acc: 67.53%, val_loss: 1.218900, val_acc: 40.10%\n",
      "Epoch [95]/[5000], train_loss: 0.727300, train_acc: 67.43%, val_loss: 1.450400, val_acc: 38.67%\n",
      "Epoch [96]/[5000], train_loss: 0.725900, train_acc: 67.92%, val_loss: 1.303800, val_acc: 43.23%\n",
      "Epoch [97]/[5000], train_loss: 0.761900, train_acc: 65.77%, val_loss: 1.385000, val_acc: 36.33%\n",
      "Epoch [98]/[5000], train_loss: 0.706200, train_acc: 67.82%, val_loss: 1.580700, val_acc: 28.65%\n",
      "Epoch [99]/[5000], train_loss: 0.720600, train_acc: 68.90%, val_loss: 1.578800, val_acc: 36.59%\n",
      "Epoch [100]/[5000], train_loss: 0.724100, train_acc: 67.19%, val_loss: 1.209100, val_acc: 39.71%\n",
      "Epoch [101]/[5000], train_loss: 0.719600, train_acc: 68.70%, val_loss: 1.269600, val_acc: 46.09%\n",
      "Epoch [102]/[5000], train_loss: 0.741500, train_acc: 68.80%, val_loss: 1.370000, val_acc: 40.36%\n",
      "Epoch [103]/[5000], train_loss: 0.742300, train_acc: 66.46%, val_loss: 1.314900, val_acc: 39.19%\n",
      "Epoch [104]/[5000], train_loss: 0.695200, train_acc: 68.99%, val_loss: 1.517600, val_acc: 32.29%\n",
      "Epoch [105]/[5000], train_loss: 0.707900, train_acc: 69.63%, val_loss: 1.479500, val_acc: 35.03%\n",
      "Epoch [106]/[5000], train_loss: 0.668300, train_acc: 70.07%, val_loss: 1.278400, val_acc: 41.80%\n",
      "Epoch [107]/[5000], train_loss: 0.678600, train_acc: 70.70%, val_loss: 1.231600, val_acc: 41.67%\n",
      "Epoch [108]/[5000], train_loss: 0.701800, train_acc: 68.31%, val_loss: 1.113100, val_acc: 51.17%\n",
      "Epoch [109]/[5000], train_loss: 0.672100, train_acc: 68.16%, val_loss: 1.568000, val_acc: 30.73%\n",
      "Epoch [110]/[5000], train_loss: 0.696900, train_acc: 68.99%, val_loss: 1.133500, val_acc: 43.10%\n",
      "Epoch [111]/[5000], train_loss: 0.662400, train_acc: 68.90%, val_loss: 1.097700, val_acc: 44.01%\n",
      "Epoch [112]/[5000], train_loss: 0.682600, train_acc: 70.95%, val_loss: 1.192100, val_acc: 49.22%\n",
      "Epoch [113]/[5000], train_loss: 0.696700, train_acc: 68.46%, val_loss: 1.749800, val_acc: 29.30%\n",
      "Epoch [114]/[5000], train_loss: 0.671100, train_acc: 68.75%, val_loss: 1.179500, val_acc: 47.79%\n",
      "Epoch [115]/[5000], train_loss: 0.666300, train_acc: 71.29%, val_loss: 1.316100, val_acc: 43.10%\n",
      "Epoch [116]/[5000], train_loss: 0.683800, train_acc: 69.34%, val_loss: 1.112400, val_acc: 49.87%\n",
      "Epoch [117]/[5000], train_loss: 0.659700, train_acc: 70.36%, val_loss: 1.089800, val_acc: 51.17%\n",
      "Epoch [118]/[5000], train_loss: 0.646100, train_acc: 71.92%, val_loss: 1.308000, val_acc: 47.92%\n",
      "Epoch [119]/[5000], train_loss: 0.629600, train_acc: 71.63%, val_loss: 1.807100, val_acc: 27.86%\n",
      "Epoch [120]/[5000], train_loss: 0.640000, train_acc: 70.36%, val_loss: 1.339700, val_acc: 39.45%\n",
      "Epoch [121]/[5000], train_loss: 0.619200, train_acc: 72.27%, val_loss: 1.377700, val_acc: 41.41%\n",
      "Epoch [122]/[5000], train_loss: 0.660800, train_acc: 71.04%, val_loss: 1.141400, val_acc: 48.44%\n",
      "Epoch [123]/[5000], train_loss: 0.645400, train_acc: 71.44%, val_loss: 1.417700, val_acc: 40.62%\n",
      "Epoch [124]/[5000], train_loss: 0.656600, train_acc: 70.70%, val_loss: 1.453200, val_acc: 41.67%\n",
      "Epoch [125]/[5000], train_loss: 0.629300, train_acc: 71.53%, val_loss: 1.568200, val_acc: 41.15%\n",
      "Epoch [126]/[5000], train_loss: 0.628700, train_acc: 71.19%, val_loss: 1.516800, val_acc: 40.36%\n",
      "Epoch [127]/[5000], train_loss: 0.598700, train_acc: 72.61%, val_loss: 1.428400, val_acc: 40.36%\n",
      "Epoch [128]/[5000], train_loss: 0.659500, train_acc: 70.46%, val_loss: 1.479000, val_acc: 43.88%\n",
      "Epoch [129]/[5000], train_loss: 0.602300, train_acc: 73.19%, val_loss: 1.154800, val_acc: 47.01%\n",
      "Epoch [130]/[5000], train_loss: 0.624600, train_acc: 72.56%, val_loss: 1.430300, val_acc: 41.54%\n",
      "Epoch [131]/[5000], train_loss: 0.597700, train_acc: 72.51%, val_loss: 1.157600, val_acc: 49.87%\n",
      "Epoch [132]/[5000], train_loss: 0.597700, train_acc: 72.51%, val_loss: 1.226800, val_acc: 44.27%\n",
      "Epoch [133]/[5000], train_loss: 0.598500, train_acc: 73.49%, val_loss: 1.547000, val_acc: 39.32%\n",
      "Epoch [134]/[5000], train_loss: 0.634300, train_acc: 71.04%, val_loss: 1.178600, val_acc: 49.35%\n",
      "Epoch [135]/[5000], train_loss: 0.611200, train_acc: 71.83%, val_loss: 1.264700, val_acc: 45.83%\n",
      "Epoch [136]/[5000], train_loss: 0.593300, train_acc: 73.10%, val_loss: 1.435700, val_acc: 37.76%\n",
      "Epoch [137]/[5000], train_loss: 0.561100, train_acc: 73.54%, val_loss: 1.556800, val_acc: 37.24%\n",
      "Epoch [138]/[5000], train_loss: 0.630300, train_acc: 71.97%, val_loss: 1.267800, val_acc: 45.57%\n",
      "Epoch [139]/[5000], train_loss: 0.599800, train_acc: 72.41%, val_loss: 1.333800, val_acc: 40.10%\n",
      "Epoch [140]/[5000], train_loss: 0.592600, train_acc: 73.54%, val_loss: 1.540000, val_acc: 35.16%\n",
      "Epoch [141]/[5000], train_loss: 0.582400, train_acc: 73.34%, val_loss: 1.561100, val_acc: 42.97%\n",
      "Epoch [142]/[5000], train_loss: 0.614600, train_acc: 72.36%, val_loss: 1.665400, val_acc: 34.90%\n",
      "Epoch [143]/[5000], train_loss: 0.535400, train_acc: 75.24%, val_loss: 1.327600, val_acc: 45.18%\n",
      "Epoch [144]/[5000], train_loss: 0.595600, train_acc: 72.80%, val_loss: 1.483000, val_acc: 36.33%\n",
      "Epoch [145]/[5000], train_loss: 0.578300, train_acc: 73.24%, val_loss: 1.314000, val_acc: 41.80%\n",
      "Epoch [146]/[5000], train_loss: 0.564200, train_acc: 73.88%, val_loss: 1.401800, val_acc: 40.23%\n",
      "Epoch [147]/[5000], train_loss: 0.536800, train_acc: 74.80%, val_loss: 1.636500, val_acc: 31.90%\n",
      "Epoch [148]/[5000], train_loss: 0.532200, train_acc: 75.68%, val_loss: 1.207800, val_acc: 48.57%\n",
      "Epoch [149]/[5000], train_loss: 0.544600, train_acc: 76.12%, val_loss: 1.268800, val_acc: 48.70%\n",
      "Epoch [150]/[5000], train_loss: 0.546000, train_acc: 75.54%, val_loss: 1.376300, val_acc: 42.71%\n",
      "Epoch [151]/[5000], train_loss: 0.530400, train_acc: 76.22%, val_loss: 1.494500, val_acc: 38.93%\n",
      "Epoch [152]/[5000], train_loss: 0.546900, train_acc: 75.05%, val_loss: 1.343100, val_acc: 47.27%\n",
      "Epoch [153]/[5000], train_loss: 0.626900, train_acc: 72.02%, val_loss: 1.338500, val_acc: 39.32%\n",
      "Epoch [154]/[5000], train_loss: 0.552100, train_acc: 75.24%, val_loss: 1.402200, val_acc: 42.32%\n",
      "Epoch [155]/[5000], train_loss: 0.540300, train_acc: 75.15%, val_loss: 1.259400, val_acc: 43.49%\n",
      "Epoch [156]/[5000], train_loss: 0.543900, train_acc: 75.00%, val_loss: 1.365800, val_acc: 48.70%\n",
      "Epoch [157]/[5000], train_loss: 0.558100, train_acc: 73.78%, val_loss: 1.200600, val_acc: 48.70%\n",
      "Epoch [158]/[5000], train_loss: 0.579600, train_acc: 73.93%, val_loss: 1.268900, val_acc: 52.08%\n",
      "Epoch [159]/[5000], train_loss: 0.563100, train_acc: 74.32%, val_loss: 1.334100, val_acc: 46.22%\n",
      "Epoch [160]/[5000], train_loss: 0.541400, train_acc: 74.22%, val_loss: 1.478200, val_acc: 44.53%\n",
      "Epoch [161]/[5000], train_loss: 0.559800, train_acc: 73.88%, val_loss: 1.334300, val_acc: 44.53%\n",
      "Epoch [162]/[5000], train_loss: 0.516800, train_acc: 75.98%, val_loss: 1.479800, val_acc: 41.67%\n",
      "Epoch [163]/[5000], train_loss: 0.509500, train_acc: 76.86%, val_loss: 1.232100, val_acc: 48.05%\n",
      "Epoch [164]/[5000], train_loss: 0.514300, train_acc: 76.12%, val_loss: 1.215500, val_acc: 49.22%\n",
      "Epoch [165]/[5000], train_loss: 0.517700, train_acc: 74.71%, val_loss: 1.340900, val_acc: 48.70%\n",
      "Epoch [166]/[5000], train_loss: 0.567400, train_acc: 74.02%, val_loss: 1.333900, val_acc: 50.00%\n",
      "Epoch [167]/[5000], train_loss: 0.537500, train_acc: 75.29%, val_loss: 1.176600, val_acc: 48.96%\n",
      "Epoch [168]/[5000], train_loss: 0.526700, train_acc: 75.29%, val_loss: 1.484800, val_acc: 38.28%\n",
      "Epoch [169]/[5000], train_loss: 0.524900, train_acc: 75.54%, val_loss: 1.345800, val_acc: 45.05%\n",
      "Epoch [170]/[5000], train_loss: 0.511000, train_acc: 76.86%, val_loss: 1.422300, val_acc: 47.53%\n",
      "Epoch [171]/[5000], train_loss: 0.533800, train_acc: 76.42%, val_loss: 1.395300, val_acc: 45.31%\n",
      "Epoch [172]/[5000], train_loss: 0.495900, train_acc: 76.46%, val_loss: 1.275800, val_acc: 44.40%\n",
      "Epoch [173]/[5000], train_loss: 0.510800, train_acc: 76.27%, val_loss: 1.243800, val_acc: 50.13%\n",
      "Epoch [174]/[5000], train_loss: 0.499400, train_acc: 76.27%, val_loss: 1.467900, val_acc: 40.76%\n",
      "Epoch [175]/[5000], train_loss: 0.450800, train_acc: 78.22%, val_loss: 1.229600, val_acc: 44.92%\n",
      "Epoch [176]/[5000], train_loss: 0.479700, train_acc: 77.29%, val_loss: 1.462800, val_acc: 36.85%\n",
      "Epoch [177]/[5000], train_loss: 0.540300, train_acc: 75.78%, val_loss: 1.549000, val_acc: 45.96%\n",
      "Epoch [178]/[5000], train_loss: 0.543700, train_acc: 74.85%, val_loss: 1.663700, val_acc: 33.07%\n",
      "Epoch [179]/[5000], train_loss: 0.504200, train_acc: 77.29%, val_loss: 1.542600, val_acc: 42.19%\n",
      "Epoch [180]/[5000], train_loss: 0.544800, train_acc: 75.68%, val_loss: 1.347100, val_acc: 46.22%\n",
      "Epoch [181]/[5000], train_loss: 0.541300, train_acc: 74.76%, val_loss: 1.535000, val_acc: 47.79%\n",
      "Epoch [182]/[5000], train_loss: 0.512200, train_acc: 76.17%, val_loss: 1.171000, val_acc: 47.92%\n",
      "Epoch [183]/[5000], train_loss: 0.527600, train_acc: 75.83%, val_loss: 1.230200, val_acc: 50.13%\n",
      "Epoch [184]/[5000], train_loss: 0.498600, train_acc: 76.66%, val_loss: 1.260200, val_acc: 50.52%\n",
      "Epoch [185]/[5000], train_loss: 0.477100, train_acc: 77.10%, val_loss: 1.555300, val_acc: 41.93%\n",
      "Epoch [186]/[5000], train_loss: 0.462000, train_acc: 77.44%, val_loss: 1.587700, val_acc: 43.62%\n",
      "Epoch [187]/[5000], train_loss: 0.449900, train_acc: 78.61%, val_loss: 1.322300, val_acc: 47.40%\n",
      "Epoch [188]/[5000], train_loss: 0.468000, train_acc: 77.83%, val_loss: 1.428400, val_acc: 43.88%\n",
      "Epoch [189]/[5000], train_loss: 0.440100, train_acc: 79.15%, val_loss: 1.484000, val_acc: 44.14%\n",
      "Epoch [190]/[5000], train_loss: 0.502500, train_acc: 77.10%, val_loss: 1.356700, val_acc: 43.23%\n",
      "Epoch [191]/[5000], train_loss: 0.457400, train_acc: 78.56%, val_loss: 1.342300, val_acc: 44.40%\n",
      "Epoch [192]/[5000], train_loss: 0.482200, train_acc: 77.25%, val_loss: 1.405200, val_acc: 46.22%\n",
      "Epoch [193]/[5000], train_loss: 0.479400, train_acc: 77.34%, val_loss: 1.191900, val_acc: 50.39%\n",
      "Epoch [194]/[5000], train_loss: 0.488000, train_acc: 77.49%, val_loss: 1.343100, val_acc: 51.43%\n",
      "Epoch [195]/[5000], train_loss: 0.498000, train_acc: 77.05%, val_loss: 1.398100, val_acc: 47.79%\n",
      "Epoch [196]/[5000], train_loss: 0.477100, train_acc: 77.59%, val_loss: 1.291600, val_acc: 47.14%\n",
      "Epoch [197]/[5000], train_loss: 0.444000, train_acc: 79.39%, val_loss: 1.560900, val_acc: 42.58%\n",
      "Epoch [198]/[5000], train_loss: 0.439300, train_acc: 79.98%, val_loss: 1.255700, val_acc: 54.04%\n",
      "Epoch [199]/[5000], train_loss: 0.457000, train_acc: 79.39%, val_loss: 1.467600, val_acc: 47.79%\n",
      "Epoch [200]/[5000], train_loss: 0.527600, train_acc: 75.59%, val_loss: 1.651200, val_acc: 42.45%\n",
      "Epoch [201]/[5000], train_loss: 0.485000, train_acc: 77.93%, val_loss: 1.276800, val_acc: 52.99%\n",
      "Epoch [202]/[5000], train_loss: 0.480800, train_acc: 76.95%, val_loss: 1.351700, val_acc: 45.57%\n",
      "Epoch [203]/[5000], train_loss: 0.428300, train_acc: 79.88%, val_loss: 1.243400, val_acc: 53.39%\n",
      "Epoch [204]/[5000], train_loss: 0.505600, train_acc: 76.90%, val_loss: 1.472400, val_acc: 47.53%\n",
      "Epoch [205]/[5000], train_loss: 0.505600, train_acc: 76.17%, val_loss: 1.226500, val_acc: 50.26%\n",
      "Epoch [206]/[5000], train_loss: 0.465700, train_acc: 77.69%, val_loss: 1.527900, val_acc: 46.09%\n",
      "Epoch [207]/[5000], train_loss: 0.473600, train_acc: 77.69%, val_loss: 1.339500, val_acc: 50.00%\n",
      "Epoch [208]/[5000], train_loss: 0.435400, train_acc: 79.25%, val_loss: 1.662400, val_acc: 44.01%\n",
      "Epoch [209]/[5000], train_loss: 0.453300, train_acc: 79.00%, val_loss: 1.237000, val_acc: 50.78%\n",
      "Epoch [210]/[5000], train_loss: 0.404000, train_acc: 80.37%, val_loss: 1.587100, val_acc: 41.15%\n",
      "Epoch [211]/[5000], train_loss: 0.462600, train_acc: 77.73%, val_loss: 1.587200, val_acc: 45.05%\n",
      "Epoch [212]/[5000], train_loss: 0.444800, train_acc: 77.88%, val_loss: 1.397400, val_acc: 47.53%\n",
      "Epoch [213]/[5000], train_loss: 0.443100, train_acc: 79.20%, val_loss: 1.310400, val_acc: 45.57%\n",
      "Epoch [214]/[5000], train_loss: 0.474600, train_acc: 77.98%, val_loss: 1.424700, val_acc: 44.66%\n",
      "Epoch [215]/[5000], train_loss: 0.453000, train_acc: 78.52%, val_loss: 1.471200, val_acc: 45.83%\n",
      "Epoch [216]/[5000], train_loss: 0.445700, train_acc: 78.12%, val_loss: 1.522700, val_acc: 44.14%\n",
      "Epoch [217]/[5000], train_loss: 0.405900, train_acc: 79.54%, val_loss: 1.265500, val_acc: 52.34%\n",
      "Epoch [218]/[5000], train_loss: 0.429700, train_acc: 79.20%, val_loss: 1.292000, val_acc: 49.09%\n",
      "Epoch [219]/[5000], train_loss: 0.417000, train_acc: 79.79%, val_loss: 1.391400, val_acc: 46.35%\n",
      "Epoch [220]/[5000], train_loss: 0.426000, train_acc: 79.74%, val_loss: 1.588400, val_acc: 46.09%\n",
      "Epoch [221]/[5000], train_loss: 0.435600, train_acc: 78.03%, val_loss: 1.384400, val_acc: 52.08%\n",
      "Epoch [222]/[5000], train_loss: 0.446900, train_acc: 79.10%, val_loss: 1.477500, val_acc: 46.48%\n",
      "Epoch [223]/[5000], train_loss: 0.413200, train_acc: 79.79%, val_loss: 1.434000, val_acc: 44.66%\n",
      "Epoch [224]/[5000], train_loss: 0.410900, train_acc: 80.47%, val_loss: 1.412100, val_acc: 47.40%\n",
      "Epoch [225]/[5000], train_loss: 0.436800, train_acc: 79.64%, val_loss: 1.294300, val_acc: 52.73%\n",
      "Epoch [226]/[5000], train_loss: 0.427000, train_acc: 80.22%, val_loss: 1.407800, val_acc: 50.39%\n",
      "Epoch [227]/[5000], train_loss: 0.481700, train_acc: 77.00%, val_loss: 1.557700, val_acc: 43.10%\n",
      "Epoch [228]/[5000], train_loss: 0.437100, train_acc: 79.00%, val_loss: 1.757100, val_acc: 45.96%\n",
      "Epoch [229]/[5000], train_loss: 0.433800, train_acc: 79.15%, val_loss: 1.194000, val_acc: 53.91%\n",
      "Epoch [230]/[5000], train_loss: 0.425500, train_acc: 79.74%, val_loss: 1.372000, val_acc: 47.01%\n",
      "Epoch [231]/[5000], train_loss: 0.443600, train_acc: 79.64%, val_loss: 1.326300, val_acc: 48.96%\n",
      "Epoch [232]/[5000], train_loss: 0.423500, train_acc: 79.64%, val_loss: 1.596500, val_acc: 41.28%\n",
      "Epoch [233]/[5000], train_loss: 0.452800, train_acc: 78.61%, val_loss: 1.493100, val_acc: 48.57%\n",
      "Epoch [234]/[5000], train_loss: 0.432100, train_acc: 79.88%, val_loss: 1.630600, val_acc: 43.75%\n",
      "Epoch [235]/[5000], train_loss: 0.457400, train_acc: 78.61%, val_loss: 1.660100, val_acc: 42.45%\n",
      "Epoch [236]/[5000], train_loss: 0.399400, train_acc: 81.05%, val_loss: 1.320000, val_acc: 50.26%\n",
      "Epoch [237]/[5000], train_loss: 0.396100, train_acc: 80.81%, val_loss: 1.477200, val_acc: 45.18%\n",
      "Epoch [238]/[5000], train_loss: 0.426700, train_acc: 79.10%, val_loss: 1.274600, val_acc: 54.82%\n",
      "Epoch [239]/[5000], train_loss: 0.405600, train_acc: 81.25%, val_loss: 1.516100, val_acc: 46.61%\n",
      "Epoch [240]/[5000], train_loss: 0.424000, train_acc: 79.69%, val_loss: 1.283700, val_acc: 51.95%\n",
      "Epoch [241]/[5000], train_loss: 0.428000, train_acc: 79.35%, val_loss: 1.408000, val_acc: 47.27%\n",
      "Epoch [242]/[5000], train_loss: 0.408200, train_acc: 80.52%, val_loss: 1.234400, val_acc: 54.17%\n",
      "Epoch [243]/[5000], train_loss: 0.398800, train_acc: 81.05%, val_loss: 1.484700, val_acc: 43.23%\n",
      "Epoch [244]/[5000], train_loss: 0.394200, train_acc: 80.62%, val_loss: 1.617800, val_acc: 47.01%\n",
      "Epoch [245]/[5000], train_loss: 0.432900, train_acc: 79.88%, val_loss: 1.662100, val_acc: 52.73%\n",
      "Epoch [246]/[5000], train_loss: 0.423800, train_acc: 79.49%, val_loss: 1.353900, val_acc: 42.58%\n",
      "Epoch [247]/[5000], train_loss: 0.432600, train_acc: 80.03%, val_loss: 1.267900, val_acc: 47.01%\n",
      "Epoch [248]/[5000], train_loss: 0.462700, train_acc: 78.03%, val_loss: 1.337300, val_acc: 54.30%\n",
      "Epoch [249]/[5000], train_loss: 0.425100, train_acc: 79.83%, val_loss: 1.407500, val_acc: 47.14%\n",
      "Epoch [250]/[5000], train_loss: 0.416000, train_acc: 79.74%, val_loss: 1.239400, val_acc: 46.35%\n",
      "Epoch [251]/[5000], train_loss: 0.389900, train_acc: 80.13%, val_loss: 1.305700, val_acc: 48.83%\n",
      "Epoch [252]/[5000], train_loss: 0.379400, train_acc: 80.91%, val_loss: 1.306800, val_acc: 51.95%\n",
      "Epoch [253]/[5000], train_loss: 0.403100, train_acc: 81.30%, val_loss: 1.631200, val_acc: 49.48%\n",
      "Epoch [254]/[5000], train_loss: 0.376800, train_acc: 81.59%, val_loss: 1.376400, val_acc: 45.83%\n",
      "Epoch [255]/[5000], train_loss: 0.371000, train_acc: 81.30%, val_loss: 1.562900, val_acc: 42.84%\n",
      "Epoch [256]/[5000], train_loss: 0.394400, train_acc: 80.96%, val_loss: 1.481400, val_acc: 47.01%\n",
      "Epoch [257]/[5000], train_loss: 0.397800, train_acc: 80.22%, val_loss: 1.596300, val_acc: 48.18%\n",
      "Epoch [258]/[5000], train_loss: 0.337400, train_acc: 82.96%, val_loss: 1.460000, val_acc: 46.35%\n",
      "Epoch [259]/[5000], train_loss: 0.396400, train_acc: 80.81%, val_loss: 1.497900, val_acc: 48.05%\n",
      "Epoch [260]/[5000], train_loss: 0.392900, train_acc: 81.25%, val_loss: 1.395900, val_acc: 47.27%\n",
      "Epoch [261]/[5000], train_loss: 0.400700, train_acc: 81.20%, val_loss: 1.624800, val_acc: 46.22%\n",
      "Epoch [262]/[5000], train_loss: 0.393500, train_acc: 80.32%, val_loss: 1.522700, val_acc: 45.31%\n",
      "Epoch [263]/[5000], train_loss: 0.382600, train_acc: 81.15%, val_loss: 1.349500, val_acc: 50.39%\n",
      "Epoch [264]/[5000], train_loss: 0.359900, train_acc: 82.76%, val_loss: 1.707100, val_acc: 37.37%\n",
      "Epoch [265]/[5000], train_loss: 0.407500, train_acc: 80.37%, val_loss: 1.419000, val_acc: 49.48%\n",
      "Epoch [266]/[5000], train_loss: 0.374900, train_acc: 82.03%, val_loss: 1.629500, val_acc: 44.14%\n",
      "Epoch [267]/[5000], train_loss: 0.409500, train_acc: 80.86%, val_loss: 1.251200, val_acc: 51.30%\n",
      "Epoch [268]/[5000], train_loss: 0.348300, train_acc: 82.71%, val_loss: 1.627800, val_acc: 46.22%\n",
      "Epoch [269]/[5000], train_loss: 0.341400, train_acc: 82.47%, val_loss: 1.499000, val_acc: 48.44%\n",
      "Epoch [270]/[5000], train_loss: 0.384400, train_acc: 81.79%, val_loss: 1.452000, val_acc: 48.31%\n",
      "Epoch [271]/[5000], train_loss: 0.376600, train_acc: 81.25%, val_loss: 1.662700, val_acc: 39.84%\n",
      "Epoch [272]/[5000], train_loss: 0.391500, train_acc: 80.47%, val_loss: 1.481400, val_acc: 52.47%\n",
      "Epoch [273]/[5000], train_loss: 0.365200, train_acc: 82.13%, val_loss: 1.533500, val_acc: 44.40%\n",
      "Epoch [274]/[5000], train_loss: 0.368300, train_acc: 81.79%, val_loss: 1.490400, val_acc: 48.44%\n",
      "Epoch [275]/[5000], train_loss: 0.357500, train_acc: 81.49%, val_loss: 1.469700, val_acc: 50.26%\n",
      "Epoch [276]/[5000], train_loss: 0.384400, train_acc: 80.96%, val_loss: 1.475100, val_acc: 43.75%\n",
      "Epoch [277]/[5000], train_loss: 0.380000, train_acc: 81.84%, val_loss: 1.464100, val_acc: 51.43%\n",
      "Epoch [278]/[5000], train_loss: 0.399200, train_acc: 80.22%, val_loss: 1.661700, val_acc: 42.97%\n",
      "Epoch [279]/[5000], train_loss: 0.415700, train_acc: 79.74%, val_loss: 1.418500, val_acc: 49.48%\n",
      "Epoch [280]/[5000], train_loss: 0.373700, train_acc: 81.01%, val_loss: 1.579100, val_acc: 41.41%\n",
      "Epoch [281]/[5000], train_loss: 0.402800, train_acc: 80.76%, val_loss: 1.418000, val_acc: 45.05%\n",
      "Epoch [282]/[5000], train_loss: 0.375900, train_acc: 81.20%, val_loss: 1.324900, val_acc: 53.65%\n",
      "Epoch [283]/[5000], train_loss: 0.390900, train_acc: 80.37%, val_loss: 1.521000, val_acc: 49.48%\n",
      "Epoch [284]/[5000], train_loss: 0.335700, train_acc: 83.20%, val_loss: 1.305500, val_acc: 52.99%\n",
      "Epoch [285]/[5000], train_loss: 0.363300, train_acc: 81.88%, val_loss: 1.465500, val_acc: 53.52%\n",
      "Epoch [286]/[5000], train_loss: 0.356900, train_acc: 82.37%, val_loss: 1.421500, val_acc: 49.35%\n",
      "Epoch [287]/[5000], train_loss: 0.360800, train_acc: 82.67%, val_loss: 1.590700, val_acc: 48.18%\n",
      "Epoch [288]/[5000], train_loss: 0.384600, train_acc: 80.52%, val_loss: 1.257100, val_acc: 51.69%\n",
      "Epoch [289]/[5000], train_loss: 0.346500, train_acc: 82.67%, val_loss: 1.283000, val_acc: 48.57%\n",
      "Epoch [290]/[5000], train_loss: 0.371300, train_acc: 82.28%, val_loss: 1.334200, val_acc: 54.30%\n",
      "Epoch [291]/[5000], train_loss: 0.385000, train_acc: 80.86%, val_loss: 1.768800, val_acc: 41.02%\n",
      "Epoch [292]/[5000], train_loss: 0.365000, train_acc: 82.47%, val_loss: 1.359900, val_acc: 44.14%\n",
      "Epoch [293]/[5000], train_loss: 0.388300, train_acc: 81.40%, val_loss: 1.508300, val_acc: 47.53%\n",
      "Epoch [294]/[5000], train_loss: 0.353300, train_acc: 82.47%, val_loss: 1.330800, val_acc: 52.73%\n",
      "Epoch [295]/[5000], train_loss: 0.385500, train_acc: 81.64%, val_loss: 1.435500, val_acc: 53.78%\n",
      "Epoch [296]/[5000], train_loss: 0.366200, train_acc: 81.20%, val_loss: 1.529400, val_acc: 46.09%\n",
      "Epoch [297]/[5000], train_loss: 0.358300, train_acc: 81.79%, val_loss: 1.432700, val_acc: 49.87%\n",
      "Epoch [298]/[5000], train_loss: 0.337000, train_acc: 83.84%, val_loss: 1.460500, val_acc: 52.86%\n",
      "Epoch [299]/[5000], train_loss: 0.354000, train_acc: 82.28%, val_loss: 1.373700, val_acc: 48.70%\n",
      "Epoch [300]/[5000], train_loss: 0.359900, train_acc: 82.81%, val_loss: 1.532300, val_acc: 47.01%\n",
      "Epoch [301]/[5000], train_loss: 0.344200, train_acc: 82.57%, val_loss: 1.656300, val_acc: 44.27%\n",
      "Epoch [302]/[5000], train_loss: 0.327000, train_acc: 83.40%, val_loss: 1.447600, val_acc: 44.27%\n",
      "Epoch [303]/[5000], train_loss: 0.328200, train_acc: 83.94%, val_loss: 1.465900, val_acc: 50.13%\n",
      "Epoch [304]/[5000], train_loss: 0.323300, train_acc: 83.20%, val_loss: 1.614500, val_acc: 44.66%\n",
      "Epoch [305]/[5000], train_loss: 0.360400, train_acc: 82.08%, val_loss: 1.593300, val_acc: 52.34%\n",
      "Epoch [306]/[5000], train_loss: 0.343100, train_acc: 82.96%, val_loss: 1.742600, val_acc: 45.70%\n",
      "Epoch [307]/[5000], train_loss: 0.355500, train_acc: 82.91%, val_loss: 1.605100, val_acc: 53.52%\n",
      "Epoch [308]/[5000], train_loss: 0.353100, train_acc: 82.18%, val_loss: 1.420500, val_acc: 52.08%\n",
      "Epoch [309]/[5000], train_loss: 0.348600, train_acc: 82.08%, val_loss: 1.408600, val_acc: 51.30%\n",
      "Epoch [310]/[5000], train_loss: 0.331200, train_acc: 83.54%, val_loss: 1.567400, val_acc: 46.74%\n",
      "Epoch [311]/[5000], train_loss: 0.377800, train_acc: 81.54%, val_loss: 1.525300, val_acc: 46.61%\n",
      "Epoch [312]/[5000], train_loss: 0.344400, train_acc: 82.86%, val_loss: 1.619500, val_acc: 46.09%\n",
      "Epoch [313]/[5000], train_loss: 0.323400, train_acc: 83.11%, val_loss: 1.559700, val_acc: 45.57%\n",
      "Epoch [314]/[5000], train_loss: 0.394500, train_acc: 81.54%, val_loss: 1.522400, val_acc: 43.36%\n",
      "Epoch [315]/[5000], train_loss: 0.364600, train_acc: 82.08%, val_loss: 1.532200, val_acc: 49.61%\n",
      "Epoch [316]/[5000], train_loss: 0.345900, train_acc: 83.06%, val_loss: 1.439300, val_acc: 52.86%\n",
      "Epoch [317]/[5000], train_loss: 0.320700, train_acc: 84.23%, val_loss: 1.574000, val_acc: 48.57%\n",
      "Epoch [318]/[5000], train_loss: 0.335700, train_acc: 83.64%, val_loss: 1.651400, val_acc: 47.92%\n",
      "Epoch [319]/[5000], train_loss: 0.329500, train_acc: 83.74%, val_loss: 1.639400, val_acc: 45.70%\n",
      "Epoch [320]/[5000], train_loss: 0.326000, train_acc: 83.64%, val_loss: 1.709900, val_acc: 47.27%\n",
      "Epoch [321]/[5000], train_loss: 0.306600, train_acc: 84.03%, val_loss: 1.379800, val_acc: 54.43%\n",
      "Epoch [322]/[5000], train_loss: 0.328800, train_acc: 83.35%, val_loss: 1.739700, val_acc: 42.32%\n",
      "Epoch [323]/[5000], train_loss: 0.316100, train_acc: 83.25%, val_loss: 1.606200, val_acc: 44.79%\n",
      "Epoch [324]/[5000], train_loss: 0.331400, train_acc: 82.32%, val_loss: 1.273000, val_acc: 54.30%\n",
      "Epoch [325]/[5000], train_loss: 0.319700, train_acc: 83.84%, val_loss: 1.528700, val_acc: 47.66%\n",
      "Epoch [326]/[5000], train_loss: 0.342900, train_acc: 82.57%, val_loss: 1.685300, val_acc: 54.56%\n",
      "Epoch [327]/[5000], train_loss: 0.366800, train_acc: 82.32%, val_loss: 1.821900, val_acc: 42.45%\n",
      "Epoch [328]/[5000], train_loss: 0.339600, train_acc: 83.25%, val_loss: 1.500200, val_acc: 52.86%\n",
      "Epoch [329]/[5000], train_loss: 0.359200, train_acc: 81.79%, val_loss: 1.730500, val_acc: 47.27%\n",
      "Epoch [330]/[5000], train_loss: 0.338600, train_acc: 83.40%, val_loss: 1.392600, val_acc: 52.08%\n",
      "Epoch [331]/[5000], train_loss: 0.361900, train_acc: 81.98%, val_loss: 1.471800, val_acc: 47.53%\n",
      "Epoch [332]/[5000], train_loss: 0.339200, train_acc: 82.91%, val_loss: 1.292400, val_acc: 51.82%\n",
      "Epoch [333]/[5000], train_loss: 0.314300, train_acc: 83.74%, val_loss: 1.557600, val_acc: 51.82%\n",
      "Epoch [334]/[5000], train_loss: 0.310100, train_acc: 84.08%, val_loss: 1.364600, val_acc: 51.95%\n",
      "Epoch [335]/[5000], train_loss: 0.330300, train_acc: 83.11%, val_loss: 1.736200, val_acc: 50.13%\n",
      "Epoch [336]/[5000], train_loss: 0.337500, train_acc: 83.11%, val_loss: 1.558000, val_acc: 44.92%\n",
      "Epoch [337]/[5000], train_loss: 0.329300, train_acc: 84.42%, val_loss: 1.532800, val_acc: 49.87%\n",
      "Epoch [338]/[5000], train_loss: 0.337500, train_acc: 84.08%, val_loss: 1.483500, val_acc: 51.95%\n",
      "Epoch [339]/[5000], train_loss: 0.301100, train_acc: 85.21%, val_loss: 1.546800, val_acc: 48.31%\n",
      "Epoch [340]/[5000], train_loss: 0.311300, train_acc: 84.67%, val_loss: 1.433200, val_acc: 51.30%\n",
      "Epoch [341]/[5000], train_loss: 0.294700, train_acc: 84.86%, val_loss: 1.479700, val_acc: 50.78%\n",
      "Epoch [342]/[5000], train_loss: 0.318900, train_acc: 84.47%, val_loss: 1.477000, val_acc: 51.82%\n",
      "Epoch [343]/[5000], train_loss: 0.308900, train_acc: 84.13%, val_loss: 1.572300, val_acc: 46.09%\n",
      "Epoch [344]/[5000], train_loss: 0.369300, train_acc: 80.66%, val_loss: 1.453000, val_acc: 48.18%\n",
      "Epoch [345]/[5000], train_loss: 0.325600, train_acc: 83.98%, val_loss: 1.685100, val_acc: 48.05%\n",
      "Epoch [346]/[5000], train_loss: 0.329000, train_acc: 83.74%, val_loss: 1.523300, val_acc: 54.43%\n",
      "Epoch [347]/[5000], train_loss: 0.349500, train_acc: 82.52%, val_loss: 1.577700, val_acc: 51.30%\n",
      "Epoch [348]/[5000], train_loss: 0.343000, train_acc: 83.11%, val_loss: 1.564100, val_acc: 46.88%\n",
      "Epoch [349]/[5000], train_loss: 0.321900, train_acc: 83.45%, val_loss: 1.690400, val_acc: 48.18%\n",
      "Epoch [350]/[5000], train_loss: 0.368500, train_acc: 82.23%, val_loss: 1.650300, val_acc: 44.27%\n",
      "Epoch [351]/[5000], train_loss: 0.318800, train_acc: 84.38%, val_loss: 1.611800, val_acc: 48.57%\n",
      "Epoch [352]/[5000], train_loss: 0.323300, train_acc: 83.54%, val_loss: 1.489400, val_acc: 44.79%\n",
      "Epoch [353]/[5000], train_loss: 0.313600, train_acc: 83.94%, val_loss: 1.496300, val_acc: 48.31%\n",
      "Epoch [354]/[5000], train_loss: 0.308300, train_acc: 84.18%, val_loss: 1.487900, val_acc: 53.12%\n",
      "Epoch [355]/[5000], train_loss: 0.312100, train_acc: 83.98%, val_loss: 1.772100, val_acc: 47.79%\n",
      "Epoch [356]/[5000], train_loss: 0.298200, train_acc: 85.35%, val_loss: 1.489200, val_acc: 49.61%\n",
      "Epoch [357]/[5000], train_loss: 0.289100, train_acc: 85.11%, val_loss: 1.463900, val_acc: 48.96%\n",
      "Epoch [358]/[5000], train_loss: 0.283400, train_acc: 84.77%, val_loss: 1.560400, val_acc: 46.09%\n",
      "Epoch [359]/[5000], train_loss: 0.291400, train_acc: 84.23%, val_loss: 1.505600, val_acc: 51.17%\n",
      "Epoch [360]/[5000], train_loss: 0.292200, train_acc: 84.86%, val_loss: 1.511300, val_acc: 55.08%\n",
      "Epoch [361]/[5000], train_loss: 0.296000, train_acc: 85.06%, val_loss: 1.783800, val_acc: 46.35%\n",
      "Epoch [362]/[5000], train_loss: 0.301100, train_acc: 85.06%, val_loss: 1.368700, val_acc: 52.08%\n",
      "Epoch [363]/[5000], train_loss: 0.290200, train_acc: 85.40%, val_loss: 1.562400, val_acc: 47.14%\n",
      "Epoch [364]/[5000], train_loss: 0.301200, train_acc: 84.77%, val_loss: 1.825100, val_acc: 46.61%\n",
      "Epoch [365]/[5000], train_loss: 0.320700, train_acc: 83.25%, val_loss: 1.692600, val_acc: 50.91%\n",
      "Epoch [366]/[5000], train_loss: 0.303400, train_acc: 84.67%, val_loss: 1.712600, val_acc: 44.40%\n",
      "Epoch [367]/[5000], train_loss: 0.373400, train_acc: 82.62%, val_loss: 2.096600, val_acc: 39.84%\n",
      "Epoch [368]/[5000], train_loss: 0.367000, train_acc: 83.20%, val_loss: 1.714300, val_acc: 48.83%\n",
      "Epoch [369]/[5000], train_loss: 0.325400, train_acc: 82.67%, val_loss: 1.426900, val_acc: 53.39%\n",
      "Epoch [370]/[5000], train_loss: 0.304400, train_acc: 85.35%, val_loss: 1.505500, val_acc: 48.05%\n",
      "Epoch [371]/[5000], train_loss: 0.287300, train_acc: 85.94%, val_loss: 1.560500, val_acc: 45.05%\n",
      "Epoch [372]/[5000], train_loss: 0.312700, train_acc: 83.69%, val_loss: 1.464800, val_acc: 51.17%\n",
      "Epoch [373]/[5000], train_loss: 0.278900, train_acc: 85.84%, val_loss: 1.514600, val_acc: 47.79%\n",
      "Epoch [374]/[5000], train_loss: 0.308200, train_acc: 83.30%, val_loss: 1.538900, val_acc: 48.83%\n",
      "Epoch [375]/[5000], train_loss: 0.296700, train_acc: 84.47%, val_loss: 1.493400, val_acc: 42.45%\n",
      "Epoch [376]/[5000], train_loss: 0.307200, train_acc: 84.91%, val_loss: 1.527000, val_acc: 49.48%\n",
      "Epoch [377]/[5000], train_loss: 0.322900, train_acc: 84.67%, val_loss: 1.865500, val_acc: 44.14%\n",
      "Epoch [378]/[5000], train_loss: 0.321200, train_acc: 83.25%, val_loss: 1.853000, val_acc: 49.35%\n",
      "Epoch [379]/[5000], train_loss: 0.309500, train_acc: 85.16%, val_loss: 1.783700, val_acc: 51.56%\n",
      "Epoch [380]/[5000], train_loss: 0.303900, train_acc: 84.57%, val_loss: 1.458500, val_acc: 52.34%\n",
      "Epoch [381]/[5000], train_loss: 0.254600, train_acc: 86.08%, val_loss: 1.589600, val_acc: 50.26%\n",
      "Epoch [382]/[5000], train_loss: 0.282900, train_acc: 85.89%, val_loss: 1.740400, val_acc: 47.01%\n",
      "Epoch [383]/[5000], train_loss: 0.278500, train_acc: 85.84%, val_loss: 1.978800, val_acc: 47.01%\n",
      "Epoch [384]/[5000], train_loss: 0.338700, train_acc: 83.50%, val_loss: 1.535600, val_acc: 53.78%\n",
      "Epoch [385]/[5000], train_loss: 0.262100, train_acc: 86.33%, val_loss: 1.813200, val_acc: 49.48%\n",
      "Epoch [386]/[5000], train_loss: 0.262800, train_acc: 85.79%, val_loss: 1.612100, val_acc: 47.79%\n",
      "Epoch [387]/[5000], train_loss: 0.291300, train_acc: 83.59%, val_loss: 1.529200, val_acc: 51.30%\n",
      "Epoch [388]/[5000], train_loss: 0.283500, train_acc: 85.01%, val_loss: 1.642600, val_acc: 50.26%\n",
      "Epoch [389]/[5000], train_loss: 0.275600, train_acc: 85.06%, val_loss: 1.698900, val_acc: 48.44%\n",
      "Epoch [390]/[5000], train_loss: 0.288600, train_acc: 84.91%, val_loss: 1.576200, val_acc: 47.79%\n",
      "Epoch [391]/[5000], train_loss: 0.289300, train_acc: 85.35%, val_loss: 1.573200, val_acc: 49.22%\n",
      "Epoch [392]/[5000], train_loss: 0.301400, train_acc: 85.55%, val_loss: 1.606900, val_acc: 49.35%\n",
      "Epoch [393]/[5000], train_loss: 0.273700, train_acc: 85.60%, val_loss: 1.571100, val_acc: 49.61%\n",
      "Epoch [394]/[5000], train_loss: 0.274300, train_acc: 85.94%, val_loss: 1.706900, val_acc: 42.45%\n",
      "Epoch [395]/[5000], train_loss: 0.281400, train_acc: 84.96%, val_loss: 1.668800, val_acc: 51.69%\n",
      "Epoch [396]/[5000], train_loss: 0.298000, train_acc: 85.01%, val_loss: 1.695900, val_acc: 47.66%\n",
      "Epoch [397]/[5000], train_loss: 0.304400, train_acc: 85.06%, val_loss: 1.757700, val_acc: 44.40%\n",
      "Epoch [398]/[5000], train_loss: 0.345800, train_acc: 83.11%, val_loss: 1.858400, val_acc: 43.36%\n",
      "Epoch [399]/[5000], train_loss: 0.317400, train_acc: 84.03%, val_loss: 1.864000, val_acc: 53.12%\n",
      "Epoch [400]/[5000], train_loss: 0.322300, train_acc: 83.98%, val_loss: 1.544000, val_acc: 48.57%\n",
      "Epoch [401]/[5000], train_loss: 0.307400, train_acc: 84.18%, val_loss: 1.423900, val_acc: 50.65%\n",
      "Epoch [402]/[5000], train_loss: 0.304300, train_acc: 84.23%, val_loss: 1.513300, val_acc: 52.99%\n",
      "Epoch [403]/[5000], train_loss: 0.311100, train_acc: 84.91%, val_loss: 1.502900, val_acc: 50.26%\n",
      "Epoch [404]/[5000], train_loss: 0.297600, train_acc: 85.11%, val_loss: 1.697400, val_acc: 47.14%\n",
      "Epoch [405]/[5000], train_loss: 0.283300, train_acc: 85.35%, val_loss: 1.499800, val_acc: 45.70%\n",
      "Epoch [406]/[5000], train_loss: 0.268500, train_acc: 86.04%, val_loss: 1.575600, val_acc: 50.26%\n",
      "Epoch [407]/[5000], train_loss: 0.279400, train_acc: 86.08%, val_loss: 1.473800, val_acc: 50.78%\n",
      "Epoch [408]/[5000], train_loss: 0.283000, train_acc: 85.55%, val_loss: 1.618200, val_acc: 47.27%\n",
      "Epoch [409]/[5000], train_loss: 0.322300, train_acc: 83.45%, val_loss: 1.626200, val_acc: 47.27%\n",
      "Epoch [410]/[5000], train_loss: 0.306000, train_acc: 85.45%, val_loss: 1.696600, val_acc: 44.14%\n",
      "Epoch [411]/[5000], train_loss: 0.279900, train_acc: 85.45%, val_loss: 1.634800, val_acc: 48.44%\n",
      "Epoch [412]/[5000], train_loss: 0.253700, train_acc: 86.38%, val_loss: 1.616100, val_acc: 51.82%\n",
      "Epoch [413]/[5000], train_loss: 0.266900, train_acc: 85.94%, val_loss: 1.559900, val_acc: 50.78%\n",
      "Epoch [414]/[5000], train_loss: 0.291600, train_acc: 84.47%, val_loss: 1.593600, val_acc: 48.70%\n",
      "Epoch [415]/[5000], train_loss: 0.254500, train_acc: 85.60%, val_loss: 1.680300, val_acc: 46.74%\n",
      "Epoch [416]/[5000], train_loss: 0.276300, train_acc: 85.84%, val_loss: 1.682000, val_acc: 46.35%\n",
      "Epoch [417]/[5000], train_loss: 0.284000, train_acc: 85.25%, val_loss: 1.723300, val_acc: 52.60%\n",
      "Epoch [418]/[5000], train_loss: 0.294400, train_acc: 85.79%, val_loss: 2.042300, val_acc: 46.22%\n",
      "Epoch [419]/[5000], train_loss: 0.280400, train_acc: 84.86%, val_loss: 1.561900, val_acc: 50.39%\n",
      "Epoch [420]/[5000], train_loss: 0.247000, train_acc: 86.91%, val_loss: 1.391500, val_acc: 50.65%\n",
      "Epoch [421]/[5000], train_loss: 0.223200, train_acc: 87.30%, val_loss: 1.474500, val_acc: 54.17%\n",
      "Epoch [422]/[5000], train_loss: 0.261000, train_acc: 85.79%, val_loss: 1.838100, val_acc: 47.53%\n",
      "Epoch [423]/[5000], train_loss: 0.251300, train_acc: 86.82%, val_loss: 1.656300, val_acc: 49.09%\n",
      "Epoch [424]/[5000], train_loss: 0.258400, train_acc: 85.55%, val_loss: 1.576000, val_acc: 49.22%\n",
      "Epoch [425]/[5000], train_loss: 0.258900, train_acc: 86.57%, val_loss: 1.862400, val_acc: 48.96%\n",
      "Epoch [426]/[5000], train_loss: 0.253200, train_acc: 86.18%, val_loss: 1.871500, val_acc: 46.48%\n",
      "Epoch [427]/[5000], train_loss: 0.272400, train_acc: 85.25%, val_loss: 1.990100, val_acc: 46.48%\n",
      "Epoch [428]/[5000], train_loss: 0.249300, train_acc: 86.38%, val_loss: 1.706600, val_acc: 51.95%\n",
      "Epoch [429]/[5000], train_loss: 0.284300, train_acc: 85.84%, val_loss: 1.829400, val_acc: 45.44%\n",
      "Epoch [430]/[5000], train_loss: 0.346200, train_acc: 82.86%, val_loss: 1.763400, val_acc: 45.96%\n",
      "Epoch [431]/[5000], train_loss: 0.305200, train_acc: 85.50%, val_loss: 1.660700, val_acc: 49.87%\n",
      "Epoch [432]/[5000], train_loss: 0.270200, train_acc: 85.35%, val_loss: 1.379900, val_acc: 48.70%\n",
      "Epoch [433]/[5000], train_loss: 0.307100, train_acc: 84.42%, val_loss: 1.646400, val_acc: 45.31%\n",
      "Epoch [434]/[5000], train_loss: 0.316100, train_acc: 84.42%, val_loss: 1.858700, val_acc: 44.14%\n",
      "Epoch [435]/[5000], train_loss: 0.267000, train_acc: 86.13%, val_loss: 1.697900, val_acc: 51.69%\n",
      "Epoch [436]/[5000], train_loss: 0.288400, train_acc: 85.25%, val_loss: 1.837900, val_acc: 50.00%\n",
      "Epoch [437]/[5000], train_loss: 0.286300, train_acc: 85.40%, val_loss: 1.869300, val_acc: 43.88%\n",
      "Epoch [438]/[5000], train_loss: 0.267100, train_acc: 85.64%, val_loss: 1.479700, val_acc: 49.48%\n",
      "Epoch [439]/[5000], train_loss: 0.261500, train_acc: 85.84%, val_loss: 1.597800, val_acc: 52.08%\n",
      "Epoch [440]/[5000], train_loss: 0.302900, train_acc: 85.45%, val_loss: 1.766700, val_acc: 50.00%\n",
      "Epoch [441]/[5000], train_loss: 0.273100, train_acc: 85.60%, val_loss: 1.854300, val_acc: 49.09%\n",
      "Epoch [442]/[5000], train_loss: 0.250000, train_acc: 86.52%, val_loss: 1.605300, val_acc: 48.83%\n",
      "Epoch [443]/[5000], train_loss: 0.262900, train_acc: 86.77%, val_loss: 1.599800, val_acc: 49.22%\n",
      "Epoch [444]/[5000], train_loss: 0.240200, train_acc: 86.82%, val_loss: 1.423200, val_acc: 50.78%\n",
      "Epoch [445]/[5000], train_loss: 0.270100, train_acc: 84.91%, val_loss: 1.625800, val_acc: 50.65%\n",
      "Epoch [446]/[5000], train_loss: 0.254400, train_acc: 86.28%, val_loss: 1.679900, val_acc: 49.35%\n",
      "Epoch [447]/[5000], train_loss: 0.258800, train_acc: 87.65%, val_loss: 1.732300, val_acc: 47.27%\n",
      "Epoch [448]/[5000], train_loss: 0.274200, train_acc: 86.47%, val_loss: 1.717000, val_acc: 51.04%\n",
      "Epoch [449]/[5000], train_loss: 0.279800, train_acc: 85.25%, val_loss: 1.769200, val_acc: 49.61%\n",
      "Epoch [450]/[5000], train_loss: 0.300200, train_acc: 85.45%, val_loss: 1.440000, val_acc: 49.35%\n",
      "Epoch [451]/[5000], train_loss: 0.274500, train_acc: 85.60%, val_loss: 1.679000, val_acc: 51.17%\n",
      "Epoch [452]/[5000], train_loss: 0.269500, train_acc: 85.94%, val_loss: 1.876500, val_acc: 47.79%\n",
      "Epoch [453]/[5000], train_loss: 0.229000, train_acc: 87.26%, val_loss: 1.846900, val_acc: 43.75%\n",
      "Epoch [454]/[5000], train_loss: 0.228800, train_acc: 87.16%, val_loss: 1.758400, val_acc: 46.48%\n",
      "Epoch [455]/[5000], train_loss: 0.226500, train_acc: 87.94%, val_loss: 1.762500, val_acc: 51.95%\n",
      "Epoch [456]/[5000], train_loss: 0.234600, train_acc: 87.26%, val_loss: 1.711800, val_acc: 50.78%\n",
      "Epoch [457]/[5000], train_loss: 0.220200, train_acc: 87.79%, val_loss: 1.643300, val_acc: 50.52%\n",
      "Epoch [458]/[5000], train_loss: 0.213400, train_acc: 88.33%, val_loss: 1.500800, val_acc: 51.69%\n",
      "Epoch [459]/[5000], train_loss: 0.201100, train_acc: 88.92%, val_loss: 1.810900, val_acc: 50.65%\n",
      "Epoch [460]/[5000], train_loss: 0.234100, train_acc: 87.01%, val_loss: 1.579800, val_acc: 56.12%\n",
      "Epoch [461]/[5000], train_loss: 0.251300, train_acc: 87.11%, val_loss: 1.793800, val_acc: 45.83%\n",
      "Epoch [462]/[5000], train_loss: 0.251600, train_acc: 86.04%, val_loss: 1.734600, val_acc: 52.73%\n",
      "Epoch [463]/[5000], train_loss: 0.264700, train_acc: 86.47%, val_loss: 1.522800, val_acc: 50.00%\n",
      "Epoch [464]/[5000], train_loss: 0.240600, train_acc: 87.74%, val_loss: 1.891900, val_acc: 47.14%\n",
      "Epoch [465]/[5000], train_loss: 0.270700, train_acc: 86.33%, val_loss: 1.593000, val_acc: 53.39%\n",
      "Epoch [466]/[5000], train_loss: 0.273600, train_acc: 85.84%, val_loss: 1.715000, val_acc: 49.74%\n",
      "Epoch [467]/[5000], train_loss: 0.272600, train_acc: 86.52%, val_loss: 1.643000, val_acc: 54.82%\n",
      "Epoch [468]/[5000], train_loss: 0.244300, train_acc: 86.08%, val_loss: 1.552200, val_acc: 51.43%\n",
      "Epoch [469]/[5000], train_loss: 0.246100, train_acc: 86.47%, val_loss: 1.648300, val_acc: 50.52%\n",
      "Epoch [470]/[5000], train_loss: 0.248500, train_acc: 87.11%, val_loss: 1.701600, val_acc: 49.48%\n",
      "Epoch [471]/[5000], train_loss: 0.246000, train_acc: 86.18%, val_loss: 1.916700, val_acc: 46.35%\n",
      "Epoch [472]/[5000], train_loss: 0.216800, train_acc: 88.77%, val_loss: 1.936500, val_acc: 50.39%\n",
      "Epoch [473]/[5000], train_loss: 0.219000, train_acc: 87.55%, val_loss: 1.850500, val_acc: 46.61%\n",
      "Epoch [474]/[5000], train_loss: 0.226100, train_acc: 87.35%, val_loss: 1.628400, val_acc: 51.56%\n",
      "Epoch [475]/[5000], train_loss: 0.244400, train_acc: 86.52%, val_loss: 1.431500, val_acc: 48.96%\n",
      "Epoch [476]/[5000], train_loss: 0.263700, train_acc: 86.28%, val_loss: 1.473000, val_acc: 50.39%\n",
      "Epoch [477]/[5000], train_loss: 0.253600, train_acc: 86.43%, val_loss: 1.729300, val_acc: 52.47%\n",
      "Epoch [478]/[5000], train_loss: 0.269800, train_acc: 86.52%, val_loss: 1.759500, val_acc: 48.96%\n",
      "Epoch [479]/[5000], train_loss: 0.239200, train_acc: 87.01%, val_loss: 1.596600, val_acc: 52.08%\n",
      "Epoch [480]/[5000], train_loss: 0.229700, train_acc: 87.60%, val_loss: 1.532500, val_acc: 48.44%\n",
      "Epoch [481]/[5000], train_loss: 0.229200, train_acc: 87.60%, val_loss: 1.675500, val_acc: 48.31%\n",
      "Epoch [482]/[5000], train_loss: 0.270400, train_acc: 85.64%, val_loss: 1.936700, val_acc: 47.14%\n",
      "Epoch [483]/[5000], train_loss: 0.284600, train_acc: 85.40%, val_loss: 1.650900, val_acc: 52.34%\n",
      "Epoch [484]/[5000], train_loss: 0.278900, train_acc: 85.45%, val_loss: 1.982900, val_acc: 47.14%\n",
      "Epoch [485]/[5000], train_loss: 0.263900, train_acc: 86.62%, val_loss: 1.504800, val_acc: 50.52%\n",
      "Epoch [486]/[5000], train_loss: 0.275200, train_acc: 85.21%, val_loss: 1.569800, val_acc: 51.82%\n",
      "Epoch [487]/[5000], train_loss: 0.252400, train_acc: 86.82%, val_loss: 1.553100, val_acc: 49.48%\n",
      "Epoch [488]/[5000], train_loss: 0.237600, train_acc: 87.55%, val_loss: 1.889400, val_acc: 48.18%\n",
      "Epoch [489]/[5000], train_loss: 0.235500, train_acc: 86.62%, val_loss: 1.612300, val_acc: 51.30%\n",
      "Epoch [490]/[5000], train_loss: 0.228800, train_acc: 87.21%, val_loss: 1.638700, val_acc: 51.82%\n",
      "Epoch [491]/[5000], train_loss: 0.246700, train_acc: 86.33%, val_loss: 1.713300, val_acc: 50.13%\n",
      "Epoch [492]/[5000], train_loss: 0.239300, train_acc: 87.45%, val_loss: 1.590900, val_acc: 50.26%\n",
      "Epoch [493]/[5000], train_loss: 0.266700, train_acc: 86.08%, val_loss: 1.672000, val_acc: 50.78%\n",
      "Epoch [494]/[5000], train_loss: 0.247800, train_acc: 86.77%, val_loss: 1.864000, val_acc: 49.74%\n",
      "Epoch [495]/[5000], train_loss: 0.220300, train_acc: 87.65%, val_loss: 1.896100, val_acc: 50.52%\n",
      "Epoch [496]/[5000], train_loss: 0.252000, train_acc: 87.35%, val_loss: 1.748700, val_acc: 47.79%\n",
      "Epoch [497]/[5000], train_loss: 0.260700, train_acc: 87.01%, val_loss: 1.576000, val_acc: 52.08%\n",
      "Epoch [498]/[5000], train_loss: 0.266800, train_acc: 85.45%, val_loss: 2.000600, val_acc: 40.36%\n",
      "Epoch [499]/[5000], train_loss: 0.244200, train_acc: 87.35%, val_loss: 1.647300, val_acc: 52.08%\n",
      "Epoch [500]/[5000], train_loss: 0.240000, train_acc: 87.40%, val_loss: 1.603700, val_acc: 50.91%\n",
      "Epoch [501]/[5000], train_loss: 0.256600, train_acc: 87.50%, val_loss: 1.639000, val_acc: 54.43%\n",
      "Epoch [502]/[5000], train_loss: 0.305300, train_acc: 84.91%, val_loss: 1.992100, val_acc: 49.22%\n",
      "Epoch [503]/[5000], train_loss: 0.238900, train_acc: 86.77%, val_loss: 1.598300, val_acc: 48.57%\n",
      "Epoch [504]/[5000], train_loss: 0.235500, train_acc: 87.30%, val_loss: 1.877700, val_acc: 51.17%\n",
      "Epoch [505]/[5000], train_loss: 0.242700, train_acc: 85.84%, val_loss: 1.952000, val_acc: 47.66%\n",
      "Epoch [506]/[5000], train_loss: 0.241100, train_acc: 86.91%, val_loss: 1.677600, val_acc: 51.04%\n",
      "Epoch [507]/[5000], train_loss: 0.240000, train_acc: 86.82%, val_loss: 1.844100, val_acc: 51.43%\n",
      "Epoch [508]/[5000], train_loss: 0.201300, train_acc: 89.21%, val_loss: 1.875600, val_acc: 49.87%\n",
      "Epoch [509]/[5000], train_loss: 0.216200, train_acc: 88.28%, val_loss: 2.119600, val_acc: 50.00%\n",
      "Epoch [510]/[5000], train_loss: 0.220000, train_acc: 87.94%, val_loss: 1.779700, val_acc: 50.13%\n",
      "Epoch [511]/[5000], train_loss: 0.228700, train_acc: 86.33%, val_loss: 1.866200, val_acc: 47.53%\n",
      "Epoch [512]/[5000], train_loss: 0.213800, train_acc: 88.38%, val_loss: 1.804900, val_acc: 52.73%\n",
      "Epoch [513]/[5000], train_loss: 0.215200, train_acc: 88.92%, val_loss: 1.936600, val_acc: 49.48%\n",
      "Epoch [514]/[5000], train_loss: 0.281100, train_acc: 86.28%, val_loss: 1.765300, val_acc: 53.52%\n",
      "Epoch [515]/[5000], train_loss: 0.228900, train_acc: 88.13%, val_loss: 1.766500, val_acc: 48.57%\n",
      "Epoch [516]/[5000], train_loss: 0.215000, train_acc: 88.13%, val_loss: 1.790300, val_acc: 49.22%\n",
      "Epoch [517]/[5000], train_loss: 0.229000, train_acc: 87.55%, val_loss: 1.728800, val_acc: 48.70%\n",
      "Epoch [518]/[5000], train_loss: 0.232000, train_acc: 87.35%, val_loss: 1.800600, val_acc: 53.91%\n",
      "Epoch [519]/[5000], train_loss: 0.240300, train_acc: 86.96%, val_loss: 1.965100, val_acc: 50.91%\n",
      "Epoch [520]/[5000], train_loss: 0.221200, train_acc: 87.89%, val_loss: 1.755600, val_acc: 48.44%\n",
      "Epoch [521]/[5000], train_loss: 0.241500, train_acc: 86.87%, val_loss: 1.623900, val_acc: 49.48%\n",
      "Epoch [522]/[5000], train_loss: 0.230100, train_acc: 87.84%, val_loss: 1.943800, val_acc: 53.78%\n",
      "Epoch [523]/[5000], train_loss: 0.241500, train_acc: 87.45%, val_loss: 1.775400, val_acc: 49.74%\n",
      "Epoch [524]/[5000], train_loss: 0.215800, train_acc: 88.38%, val_loss: 1.918900, val_acc: 48.05%\n",
      "Epoch [525]/[5000], train_loss: 0.238600, train_acc: 87.40%, val_loss: 1.697400, val_acc: 50.78%\n",
      "Epoch [526]/[5000], train_loss: 0.211300, train_acc: 88.72%, val_loss: 1.869400, val_acc: 49.22%\n",
      "Epoch [527]/[5000], train_loss: 0.246600, train_acc: 86.57%, val_loss: 1.880900, val_acc: 50.65%\n",
      "Epoch [528]/[5000], train_loss: 0.228800, train_acc: 87.84%, val_loss: 1.895900, val_acc: 49.22%\n",
      "Epoch [529]/[5000], train_loss: 0.222800, train_acc: 87.79%, val_loss: 1.740900, val_acc: 48.83%\n",
      "Epoch [530]/[5000], train_loss: 0.236600, train_acc: 87.50%, val_loss: 1.723800, val_acc: 50.00%\n",
      "Epoch [531]/[5000], train_loss: 0.238900, train_acc: 87.65%, val_loss: 1.835300, val_acc: 48.57%\n",
      "Epoch [532]/[5000], train_loss: 0.214200, train_acc: 88.48%, val_loss: 2.154000, val_acc: 46.09%\n",
      "Epoch [533]/[5000], train_loss: 0.225200, train_acc: 87.30%, val_loss: 1.761600, val_acc: 51.82%\n",
      "Epoch [534]/[5000], train_loss: 0.228800, train_acc: 87.01%, val_loss: 1.618300, val_acc: 51.82%\n",
      "Epoch [535]/[5000], train_loss: 0.205400, train_acc: 88.53%, val_loss: 1.607100, val_acc: 49.48%\n",
      "Epoch [536]/[5000], train_loss: 0.236700, train_acc: 87.45%, val_loss: 1.529600, val_acc: 50.65%\n",
      "Epoch [537]/[5000], train_loss: 0.213500, train_acc: 87.74%, val_loss: 1.829300, val_acc: 50.65%\n",
      "Epoch [538]/[5000], train_loss: 0.223800, train_acc: 87.65%, val_loss: 1.647100, val_acc: 48.57%\n",
      "Epoch [539]/[5000], train_loss: 0.223700, train_acc: 88.18%, val_loss: 1.588900, val_acc: 51.56%\n",
      "Epoch [540]/[5000], train_loss: 0.232200, train_acc: 87.50%, val_loss: 1.922700, val_acc: 53.12%\n",
      "Epoch [541]/[5000], train_loss: 0.234700, train_acc: 87.16%, val_loss: 2.073500, val_acc: 42.71%\n",
      "Epoch [542]/[5000], train_loss: 0.228000, train_acc: 87.79%, val_loss: 1.826700, val_acc: 53.26%\n",
      "Epoch [543]/[5000], train_loss: 0.234600, train_acc: 87.40%, val_loss: 1.702400, val_acc: 50.00%\n",
      "Epoch [544]/[5000], train_loss: 0.239000, train_acc: 86.96%, val_loss: 1.675300, val_acc: 51.82%\n",
      "Epoch [545]/[5000], train_loss: 0.227000, train_acc: 88.04%, val_loss: 1.755100, val_acc: 47.40%\n",
      "Epoch [546]/[5000], train_loss: 0.235600, train_acc: 87.55%, val_loss: 1.674300, val_acc: 51.43%\n",
      "Epoch [547]/[5000], train_loss: 0.214300, train_acc: 88.62%, val_loss: 2.199100, val_acc: 47.27%\n",
      "Epoch [548]/[5000], train_loss: 0.211900, train_acc: 88.82%, val_loss: 1.816900, val_acc: 49.48%\n",
      "Epoch [549]/[5000], train_loss: 0.250300, train_acc: 87.11%, val_loss: 1.775700, val_acc: 57.42%\n",
      "Epoch [550]/[5000], train_loss: 0.263100, train_acc: 86.57%, val_loss: 2.058700, val_acc: 48.18%\n",
      "Epoch [551]/[5000], train_loss: 0.221500, train_acc: 88.04%, val_loss: 1.747100, val_acc: 45.18%\n",
      "Epoch [552]/[5000], train_loss: 0.230700, train_acc: 88.18%, val_loss: 2.126800, val_acc: 48.44%\n",
      "Epoch [553]/[5000], train_loss: 0.222500, train_acc: 88.33%, val_loss: 1.800700, val_acc: 53.12%\n",
      "Epoch [554]/[5000], train_loss: 0.197600, train_acc: 87.89%, val_loss: 1.667700, val_acc: 53.65%\n",
      "Epoch [555]/[5000], train_loss: 0.245700, train_acc: 86.96%, val_loss: 1.790200, val_acc: 52.99%\n",
      "Epoch [556]/[5000], train_loss: 0.267000, train_acc: 85.69%, val_loss: 2.024300, val_acc: 46.88%\n",
      "Epoch [557]/[5000], train_loss: 0.255800, train_acc: 87.21%, val_loss: 1.606400, val_acc: 50.26%\n",
      "Epoch [558]/[5000], train_loss: 0.239700, train_acc: 87.30%, val_loss: 1.557100, val_acc: 49.61%\n",
      "Epoch [559]/[5000], train_loss: 0.195000, train_acc: 88.72%, val_loss: 1.579200, val_acc: 52.47%\n",
      "Epoch [560]/[5000], train_loss: 0.203800, train_acc: 88.82%, val_loss: 1.833100, val_acc: 46.48%\n",
      "Epoch [561]/[5000], train_loss: 0.193300, train_acc: 89.11%, val_loss: 1.868500, val_acc: 53.39%\n",
      "Epoch [562]/[5000], train_loss: 0.206600, train_acc: 88.33%, val_loss: 1.508000, val_acc: 51.82%\n",
      "Epoch [563]/[5000], train_loss: 0.192200, train_acc: 88.96%, val_loss: 1.711300, val_acc: 49.74%\n",
      "Epoch [564]/[5000], train_loss: 0.203200, train_acc: 88.77%, val_loss: 1.831300, val_acc: 50.00%\n",
      "Epoch [565]/[5000], train_loss: 0.234500, train_acc: 88.04%, val_loss: 1.850300, val_acc: 49.48%\n",
      "Epoch [566]/[5000], train_loss: 0.206500, train_acc: 88.09%, val_loss: 1.678400, val_acc: 49.22%\n",
      "Epoch [567]/[5000], train_loss: 0.217300, train_acc: 88.23%, val_loss: 1.700900, val_acc: 52.08%\n",
      "Epoch [568]/[5000], train_loss: 0.196400, train_acc: 88.67%, val_loss: 1.917300, val_acc: 52.34%\n",
      "Epoch [569]/[5000], train_loss: 0.203400, train_acc: 89.31%, val_loss: 1.622200, val_acc: 49.61%\n",
      "Epoch [570]/[5000], train_loss: 0.204600, train_acc: 88.77%, val_loss: 1.778300, val_acc: 52.34%\n",
      "Epoch [571]/[5000], train_loss: 0.222600, train_acc: 87.89%, val_loss: 1.881900, val_acc: 54.43%\n",
      "Epoch [572]/[5000], train_loss: 0.224100, train_acc: 87.01%, val_loss: 2.066700, val_acc: 50.00%\n",
      "Epoch [573]/[5000], train_loss: 0.195700, train_acc: 88.18%, val_loss: 1.803100, val_acc: 51.43%\n",
      "Epoch [574]/[5000], train_loss: 0.199000, train_acc: 89.36%, val_loss: 2.112400, val_acc: 52.60%\n",
      "Epoch [575]/[5000], train_loss: 0.223600, train_acc: 88.18%, val_loss: 1.755200, val_acc: 52.60%\n",
      "Epoch [576]/[5000], train_loss: 0.230800, train_acc: 87.70%, val_loss: 1.608200, val_acc: 50.52%\n",
      "Epoch [577]/[5000], train_loss: 0.237800, train_acc: 87.55%, val_loss: 1.720900, val_acc: 52.73%\n",
      "Epoch [578]/[5000], train_loss: 0.214700, train_acc: 88.62%, val_loss: 1.852800, val_acc: 51.30%\n",
      "Epoch [579]/[5000], train_loss: 0.253300, train_acc: 88.09%, val_loss: 1.968100, val_acc: 45.83%\n",
      "Epoch [580]/[5000], train_loss: 0.227700, train_acc: 87.84%, val_loss: 1.701300, val_acc: 52.21%\n",
      "Epoch [581]/[5000], train_loss: 0.238400, train_acc: 86.77%, val_loss: 1.739700, val_acc: 48.96%\n",
      "Epoch [582]/[5000], train_loss: 0.218600, train_acc: 88.18%, val_loss: 1.795400, val_acc: 50.26%\n",
      "Epoch [583]/[5000], train_loss: 0.201500, train_acc: 87.99%, val_loss: 1.582100, val_acc: 52.73%\n",
      "Epoch [584]/[5000], train_loss: 0.209700, train_acc: 87.99%, val_loss: 1.591700, val_acc: 51.82%\n",
      "Epoch [585]/[5000], train_loss: 0.186700, train_acc: 89.40%, val_loss: 1.810400, val_acc: 50.26%\n",
      "Epoch [586]/[5000], train_loss: 0.207800, train_acc: 88.62%, val_loss: 1.519700, val_acc: 55.47%\n",
      "Epoch [587]/[5000], train_loss: 0.213300, train_acc: 88.67%, val_loss: 1.902100, val_acc: 49.87%\n",
      "Epoch [588]/[5000], train_loss: 0.186000, train_acc: 89.84%, val_loss: 1.793800, val_acc: 52.99%\n",
      "Epoch [589]/[5000], train_loss: 0.179000, train_acc: 89.31%, val_loss: 1.688500, val_acc: 49.74%\n",
      "Epoch [590]/[5000], train_loss: 0.175500, train_acc: 89.70%, val_loss: 1.895100, val_acc: 49.61%\n",
      "Epoch [591]/[5000], train_loss: 0.225100, train_acc: 87.74%, val_loss: 2.220900, val_acc: 53.78%\n",
      "Epoch [592]/[5000], train_loss: 0.188000, train_acc: 89.75%, val_loss: 1.691800, val_acc: 47.27%\n",
      "Epoch [593]/[5000], train_loss: 0.211900, train_acc: 87.40%, val_loss: 1.952800, val_acc: 51.30%\n",
      "Epoch [594]/[5000], train_loss: 0.214500, train_acc: 87.94%, val_loss: 1.882700, val_acc: 53.52%\n",
      "Epoch [595]/[5000], train_loss: 0.242000, train_acc: 88.04%, val_loss: 1.886100, val_acc: 49.87%\n",
      "Epoch [596]/[5000], train_loss: 0.247500, train_acc: 86.91%, val_loss: 1.723400, val_acc: 49.61%\n",
      "Epoch [597]/[5000], train_loss: 0.224300, train_acc: 88.04%, val_loss: 1.752900, val_acc: 52.21%\n",
      "Epoch [598]/[5000], train_loss: 0.205000, train_acc: 88.43%, val_loss: 1.811000, val_acc: 48.31%\n",
      "Epoch [599]/[5000], train_loss: 0.210400, train_acc: 88.33%, val_loss: 1.690300, val_acc: 52.34%\n",
      "Epoch [600]/[5000], train_loss: 0.204400, train_acc: 88.67%, val_loss: 1.601900, val_acc: 53.39%\n",
      "Epoch [601]/[5000], train_loss: 0.185000, train_acc: 88.33%, val_loss: 1.798500, val_acc: 52.08%\n",
      "Epoch [602]/[5000], train_loss: 0.189400, train_acc: 88.77%, val_loss: 1.990200, val_acc: 51.30%\n",
      "Epoch [603]/[5000], train_loss: 0.202900, train_acc: 88.67%, val_loss: 2.198500, val_acc: 54.95%\n",
      "Epoch [604]/[5000], train_loss: 0.191000, train_acc: 88.96%, val_loss: 1.873700, val_acc: 52.73%\n",
      "Epoch [605]/[5000], train_loss: 0.245200, train_acc: 88.04%, val_loss: 1.615600, val_acc: 51.69%\n",
      "Epoch [606]/[5000], train_loss: 0.223100, train_acc: 87.94%, val_loss: 1.990500, val_acc: 47.40%\n",
      "Epoch [607]/[5000], train_loss: 0.262400, train_acc: 86.77%, val_loss: 2.151000, val_acc: 46.09%\n",
      "Epoch [608]/[5000], train_loss: 0.213800, train_acc: 88.87%, val_loss: 1.538700, val_acc: 52.73%\n",
      "Epoch [609]/[5000], train_loss: 0.194900, train_acc: 89.06%, val_loss: 1.560800, val_acc: 53.12%\n",
      "Epoch [610]/[5000], train_loss: 0.196000, train_acc: 88.72%, val_loss: 2.130500, val_acc: 52.47%\n",
      "Epoch [611]/[5000], train_loss: 0.229700, train_acc: 87.70%, val_loss: 1.691800, val_acc: 49.74%\n",
      "Epoch [612]/[5000], train_loss: 0.200900, train_acc: 88.77%, val_loss: 1.923500, val_acc: 53.26%\n",
      "Epoch [613]/[5000], train_loss: 0.195100, train_acc: 88.87%, val_loss: 2.074400, val_acc: 49.48%\n",
      "Epoch [614]/[5000], train_loss: 0.185500, train_acc: 89.40%, val_loss: 1.836400, val_acc: 50.13%\n",
      "Epoch [615]/[5000], train_loss: 0.184900, train_acc: 89.45%, val_loss: 1.716600, val_acc: 50.78%\n",
      "Epoch [616]/[5000], train_loss: 0.203800, train_acc: 89.50%, val_loss: 1.831400, val_acc: 50.65%\n",
      "Epoch [617]/[5000], train_loss: 0.207500, train_acc: 88.96%, val_loss: 1.809900, val_acc: 52.73%\n",
      "Epoch [618]/[5000], train_loss: 0.187300, train_acc: 89.36%, val_loss: 1.846900, val_acc: 47.79%\n",
      "Epoch [619]/[5000], train_loss: 0.202600, train_acc: 88.77%, val_loss: 1.860400, val_acc: 51.17%\n",
      "Epoch [620]/[5000], train_loss: 0.231300, train_acc: 87.89%, val_loss: 1.908100, val_acc: 51.69%\n",
      "Epoch [621]/[5000], train_loss: 0.223800, train_acc: 87.50%, val_loss: 1.700900, val_acc: 52.86%\n",
      "Epoch [622]/[5000], train_loss: 0.208900, train_acc: 88.67%, val_loss: 2.127800, val_acc: 52.86%\n",
      "Epoch [623]/[5000], train_loss: 0.220600, train_acc: 87.89%, val_loss: 1.956400, val_acc: 48.31%\n",
      "Epoch [624]/[5000], train_loss: 0.211700, train_acc: 88.28%, val_loss: 1.826200, val_acc: 51.69%\n",
      "Epoch [625]/[5000], train_loss: 0.190700, train_acc: 89.79%, val_loss: 1.982900, val_acc: 51.30%\n",
      "Epoch [626]/[5000], train_loss: 0.198300, train_acc: 89.06%, val_loss: 2.089600, val_acc: 54.04%\n",
      "Epoch [627]/[5000], train_loss: 0.181200, train_acc: 89.26%, val_loss: 1.968900, val_acc: 51.82%\n",
      "Epoch [628]/[5000], train_loss: 0.170500, train_acc: 89.65%, val_loss: 1.636800, val_acc: 52.34%\n",
      "Epoch [629]/[5000], train_loss: 0.180600, train_acc: 89.70%, val_loss: 1.807300, val_acc: 51.82%\n",
      "Epoch [630]/[5000], train_loss: 0.167000, train_acc: 90.62%, val_loss: 1.802900, val_acc: 53.91%\n",
      "Epoch [631]/[5000], train_loss: 0.193000, train_acc: 89.70%, val_loss: 1.874100, val_acc: 48.18%\n",
      "Epoch [632]/[5000], train_loss: 0.194900, train_acc: 89.31%, val_loss: 1.941000, val_acc: 53.39%\n",
      "Epoch [633]/[5000], train_loss: 0.204600, train_acc: 89.11%, val_loss: 1.706400, val_acc: 48.18%\n",
      "Epoch [634]/[5000], train_loss: 0.196100, train_acc: 88.62%, val_loss: 1.646300, val_acc: 54.82%\n",
      "Epoch [635]/[5000], train_loss: 0.174300, train_acc: 89.01%, val_loss: 1.859400, val_acc: 47.66%\n",
      "Epoch [636]/[5000], train_loss: 0.172100, train_acc: 89.55%, val_loss: 1.872800, val_acc: 51.17%\n",
      "Epoch [637]/[5000], train_loss: 0.195000, train_acc: 89.11%, val_loss: 1.939000, val_acc: 50.65%\n",
      "Epoch [638]/[5000], train_loss: 0.184400, train_acc: 89.16%, val_loss: 1.610700, val_acc: 51.82%\n",
      "Epoch [639]/[5000], train_loss: 0.173900, train_acc: 89.45%, val_loss: 2.144900, val_acc: 45.57%\n",
      "Epoch [640]/[5000], train_loss: 0.187100, train_acc: 89.94%, val_loss: 1.802500, val_acc: 50.13%\n",
      "Epoch [641]/[5000], train_loss: 0.198800, train_acc: 88.67%, val_loss: 1.894400, val_acc: 50.78%\n",
      "Epoch [642]/[5000], train_loss: 0.171200, train_acc: 89.89%, val_loss: 1.818700, val_acc: 52.73%\n",
      "Epoch [643]/[5000], train_loss: 0.218400, train_acc: 88.09%, val_loss: 1.765600, val_acc: 48.05%\n",
      "Epoch [644]/[5000], train_loss: 0.204300, train_acc: 88.77%, val_loss: 1.678500, val_acc: 52.86%\n",
      "Epoch [645]/[5000], train_loss: 0.195200, train_acc: 88.18%, val_loss: 2.057600, val_acc: 45.31%\n",
      "Epoch [646]/[5000], train_loss: 0.181500, train_acc: 89.40%, val_loss: 1.995300, val_acc: 51.04%\n",
      "Epoch [647]/[5000], train_loss: 0.170300, train_acc: 89.75%, val_loss: 1.643700, val_acc: 54.69%\n",
      "Epoch [648]/[5000], train_loss: 0.187000, train_acc: 89.11%, val_loss: 1.964100, val_acc: 51.17%\n",
      "Epoch [649]/[5000], train_loss: 0.172400, train_acc: 89.45%, val_loss: 1.843800, val_acc: 51.17%\n",
      "Epoch [650]/[5000], train_loss: 0.172000, train_acc: 89.50%, val_loss: 1.645500, val_acc: 55.86%\n",
      "Epoch [651]/[5000], train_loss: 0.164200, train_acc: 90.19%, val_loss: 1.993200, val_acc: 54.30%\n",
      "Epoch [652]/[5000], train_loss: 0.199100, train_acc: 88.92%, val_loss: 1.766300, val_acc: 48.57%\n",
      "Epoch [653]/[5000], train_loss: 0.187100, train_acc: 89.26%, val_loss: 2.021500, val_acc: 53.52%\n",
      "Epoch [654]/[5000], train_loss: 0.178800, train_acc: 88.96%, val_loss: 1.925100, val_acc: 49.61%\n",
      "Epoch [655]/[5000], train_loss: 0.177700, train_acc: 89.31%, val_loss: 2.004500, val_acc: 49.35%\n",
      "Epoch [656]/[5000], train_loss: 0.181800, train_acc: 90.14%, val_loss: 1.619400, val_acc: 53.26%\n",
      "Epoch [657]/[5000], train_loss: 0.168000, train_acc: 90.58%, val_loss: 1.761300, val_acc: 53.52%\n",
      "Epoch [658]/[5000], train_loss: 0.181100, train_acc: 88.67%, val_loss: 1.755500, val_acc: 51.69%\n",
      "Epoch [659]/[5000], train_loss: 0.233300, train_acc: 86.91%, val_loss: 1.685400, val_acc: 49.87%\n",
      "Epoch [660]/[5000], train_loss: 0.205800, train_acc: 88.13%, val_loss: 1.823100, val_acc: 53.78%\n",
      "Epoch [661]/[5000], train_loss: 0.175800, train_acc: 89.75%, val_loss: 1.836600, val_acc: 52.86%\n",
      "Epoch [662]/[5000], train_loss: 0.197100, train_acc: 88.57%, val_loss: 1.874500, val_acc: 48.96%\n",
      "Epoch [663]/[5000], train_loss: 0.163400, train_acc: 90.28%, val_loss: 2.025800, val_acc: 51.30%\n",
      "Epoch [664]/[5000], train_loss: 0.213300, train_acc: 88.28%, val_loss: 1.965100, val_acc: 52.47%\n",
      "Epoch [665]/[5000], train_loss: 0.178200, train_acc: 89.40%, val_loss: 1.744700, val_acc: 52.86%\n",
      "Epoch [666]/[5000], train_loss: 0.179800, train_acc: 89.55%, val_loss: 1.707400, val_acc: 54.82%\n",
      "Epoch [667]/[5000], train_loss: 0.174200, train_acc: 89.45%, val_loss: 1.930800, val_acc: 50.00%\n",
      "Epoch [668]/[5000], train_loss: 0.159400, train_acc: 90.62%, val_loss: 1.866700, val_acc: 51.82%\n",
      "Epoch [669]/[5000], train_loss: 0.173100, train_acc: 90.04%, val_loss: 1.674900, val_acc: 51.56%\n",
      "Epoch [670]/[5000], train_loss: 0.187900, train_acc: 89.70%, val_loss: 1.780500, val_acc: 53.26%\n",
      "Epoch [671]/[5000], train_loss: 0.185100, train_acc: 89.89%, val_loss: 1.955100, val_acc: 47.92%\n",
      "Epoch [672]/[5000], train_loss: 0.194500, train_acc: 88.72%, val_loss: 1.945200, val_acc: 51.82%\n",
      "Epoch [673]/[5000], train_loss: 0.171200, train_acc: 89.75%, val_loss: 1.759800, val_acc: 55.08%\n",
      "Epoch [674]/[5000], train_loss: 0.191600, train_acc: 89.16%, val_loss: 2.073900, val_acc: 48.70%\n",
      "Epoch [675]/[5000], train_loss: 0.173300, train_acc: 89.60%, val_loss: 1.735700, val_acc: 51.04%\n",
      "Epoch [676]/[5000], train_loss: 0.187900, train_acc: 89.36%, val_loss: 2.426600, val_acc: 51.82%\n",
      "Epoch [677]/[5000], train_loss: 0.183300, train_acc: 89.89%, val_loss: 2.113800, val_acc: 50.00%\n",
      "Epoch [678]/[5000], train_loss: 0.177300, train_acc: 89.60%, val_loss: 1.735800, val_acc: 53.26%\n",
      "Epoch [679]/[5000], train_loss: 0.185000, train_acc: 89.79%, val_loss: 1.786300, val_acc: 52.99%\n",
      "Epoch [680]/[5000], train_loss: 0.184800, train_acc: 89.26%, val_loss: 2.151400, val_acc: 53.12%\n",
      "Epoch [681]/[5000], train_loss: 0.166100, train_acc: 90.28%, val_loss: 1.652400, val_acc: 51.04%\n",
      "Epoch [682]/[5000], train_loss: 0.188600, train_acc: 88.96%, val_loss: 1.751800, val_acc: 49.87%\n",
      "Epoch [683]/[5000], train_loss: 0.167100, train_acc: 90.14%, val_loss: 1.995500, val_acc: 51.43%\n",
      "Epoch [684]/[5000], train_loss: 0.165900, train_acc: 90.28%, val_loss: 1.726900, val_acc: 54.95%\n",
      "Epoch [685]/[5000], train_loss: 0.170500, train_acc: 89.84%, val_loss: 2.257100, val_acc: 51.56%\n",
      "Epoch [686]/[5000], train_loss: 0.198400, train_acc: 88.43%, val_loss: 1.710800, val_acc: 52.47%\n",
      "Epoch [687]/[5000], train_loss: 0.205600, train_acc: 88.04%, val_loss: 1.939500, val_acc: 45.05%\n",
      "Epoch [688]/[5000], train_loss: 0.197800, train_acc: 88.92%, val_loss: 2.242200, val_acc: 49.74%\n",
      "Epoch [689]/[5000], train_loss: 0.197200, train_acc: 88.28%, val_loss: 1.790500, val_acc: 53.78%\n",
      "Epoch [690]/[5000], train_loss: 0.195400, train_acc: 88.67%, val_loss: 1.881200, val_acc: 45.44%\n",
      "Epoch [691]/[5000], train_loss: 0.195100, train_acc: 89.55%, val_loss: 1.811300, val_acc: 53.12%\n",
      "Epoch [692]/[5000], train_loss: 0.186900, train_acc: 89.50%, val_loss: 1.941500, val_acc: 54.69%\n",
      "Epoch [693]/[5000], train_loss: 0.202900, train_acc: 89.40%, val_loss: 1.959000, val_acc: 50.91%\n",
      "Epoch [694]/[5000], train_loss: 0.167500, train_acc: 89.99%, val_loss: 1.926300, val_acc: 52.73%\n",
      "Epoch [695]/[5000], train_loss: 0.181200, train_acc: 89.70%, val_loss: 1.698900, val_acc: 51.82%\n",
      "Epoch [696]/[5000], train_loss: 0.176100, train_acc: 89.01%, val_loss: 1.742700, val_acc: 52.60%\n",
      "Epoch [697]/[5000], train_loss: 0.174100, train_acc: 90.09%, val_loss: 1.840300, val_acc: 51.82%\n",
      "Epoch [698]/[5000], train_loss: 0.181300, train_acc: 89.55%, val_loss: 2.093400, val_acc: 52.99%\n",
      "Epoch [699]/[5000], train_loss: 0.154900, train_acc: 90.67%, val_loss: 1.856200, val_acc: 50.91%\n",
      "Epoch [700]/[5000], train_loss: 0.151600, train_acc: 90.43%, val_loss: 1.775200, val_acc: 55.08%\n",
      "Epoch [701]/[5000], train_loss: 0.163200, train_acc: 89.89%, val_loss: 1.694000, val_acc: 52.86%\n",
      "Epoch [702]/[5000], train_loss: 0.169700, train_acc: 90.04%, val_loss: 1.937300, val_acc: 52.60%\n",
      "Epoch [703]/[5000], train_loss: 0.147600, train_acc: 90.82%, val_loss: 1.850400, val_acc: 49.87%\n",
      "Epoch [704]/[5000], train_loss: 0.163300, train_acc: 90.67%, val_loss: 1.814300, val_acc: 52.08%\n",
      "Epoch [705]/[5000], train_loss: 0.164600, train_acc: 89.36%, val_loss: 1.847000, val_acc: 52.99%\n",
      "Epoch [706]/[5000], train_loss: 0.173900, train_acc: 90.28%, val_loss: 2.298600, val_acc: 47.66%\n",
      "Epoch [707]/[5000], train_loss: 0.158900, train_acc: 90.53%, val_loss: 1.965000, val_acc: 48.05%\n",
      "Epoch [708]/[5000], train_loss: 0.140500, train_acc: 90.92%, val_loss: 1.871200, val_acc: 48.44%\n",
      "Epoch [709]/[5000], train_loss: 0.185000, train_acc: 89.36%, val_loss: 1.944700, val_acc: 50.52%\n",
      "Epoch [710]/[5000], train_loss: 0.194500, train_acc: 88.67%, val_loss: 2.137700, val_acc: 48.05%\n",
      "Epoch [711]/[5000], train_loss: 0.217100, train_acc: 88.38%, val_loss: 1.997900, val_acc: 54.82%\n",
      "Epoch [712]/[5000], train_loss: 0.193300, train_acc: 88.67%, val_loss: 1.850800, val_acc: 49.48%\n",
      "Epoch [713]/[5000], train_loss: 0.195200, train_acc: 89.31%, val_loss: 1.753600, val_acc: 52.08%\n",
      "Epoch [714]/[5000], train_loss: 0.171400, train_acc: 89.84%, val_loss: 1.903100, val_acc: 48.96%\n",
      "Epoch [715]/[5000], train_loss: 0.187500, train_acc: 89.01%, val_loss: 1.858300, val_acc: 51.56%\n",
      "Epoch [716]/[5000], train_loss: 0.155900, train_acc: 89.89%, val_loss: 1.917300, val_acc: 53.39%\n",
      "Epoch [717]/[5000], train_loss: 0.149100, train_acc: 91.11%, val_loss: 1.786700, val_acc: 52.21%\n",
      "Epoch [718]/[5000], train_loss: 0.174000, train_acc: 89.84%, val_loss: 1.823400, val_acc: 54.82%\n",
      "Epoch [719]/[5000], train_loss: 0.184900, train_acc: 89.36%, val_loss: 1.826300, val_acc: 51.69%\n",
      "Epoch [720]/[5000], train_loss: 0.215900, train_acc: 88.13%, val_loss: 1.890700, val_acc: 51.30%\n",
      "Epoch [721]/[5000], train_loss: 0.185200, train_acc: 89.79%, val_loss: 1.816800, val_acc: 48.96%\n",
      "Epoch [722]/[5000], train_loss: 0.166200, train_acc: 89.89%, val_loss: 1.890700, val_acc: 53.39%\n",
      "Epoch [723]/[5000], train_loss: 0.192600, train_acc: 88.57%, val_loss: 2.034000, val_acc: 52.60%\n",
      "Epoch [724]/[5000], train_loss: 0.146500, train_acc: 91.31%, val_loss: 1.591100, val_acc: 54.17%\n",
      "Epoch [725]/[5000], train_loss: 0.178900, train_acc: 89.94%, val_loss: 1.710600, val_acc: 53.26%\n",
      "Epoch [726]/[5000], train_loss: 0.148800, train_acc: 91.21%, val_loss: 1.914200, val_acc: 52.08%\n",
      "Epoch [727]/[5000], train_loss: 0.201300, train_acc: 88.48%, val_loss: 2.048300, val_acc: 52.73%\n",
      "Epoch [728]/[5000], train_loss: 0.190900, train_acc: 89.01%, val_loss: 1.752100, val_acc: 52.08%\n",
      "Epoch [729]/[5000], train_loss: 0.176000, train_acc: 90.28%, val_loss: 1.818600, val_acc: 50.78%\n",
      "Epoch [730]/[5000], train_loss: 0.160900, train_acc: 90.14%, val_loss: 1.891000, val_acc: 54.82%\n",
      "Epoch [731]/[5000], train_loss: 0.123100, train_acc: 91.65%, val_loss: 2.172700, val_acc: 48.44%\n",
      "Epoch [732]/[5000], train_loss: 0.151000, train_acc: 90.82%, val_loss: 1.974000, val_acc: 50.52%\n",
      "Epoch [733]/[5000], train_loss: 0.217300, train_acc: 88.87%, val_loss: 2.016600, val_acc: 47.14%\n",
      "Epoch [734]/[5000], train_loss: 0.184400, train_acc: 89.11%, val_loss: 1.952900, val_acc: 46.88%\n",
      "Epoch [735]/[5000], train_loss: 0.199900, train_acc: 88.67%, val_loss: 1.714500, val_acc: 53.12%\n",
      "Epoch [736]/[5000], train_loss: 0.197300, train_acc: 89.50%, val_loss: 1.899900, val_acc: 49.74%\n",
      "Epoch [737]/[5000], train_loss: 0.173800, train_acc: 89.50%, val_loss: 2.144600, val_acc: 52.34%\n",
      "Epoch [738]/[5000], train_loss: 0.200800, train_acc: 88.53%, val_loss: 1.754500, val_acc: 52.73%\n",
      "Epoch [739]/[5000], train_loss: 0.158500, train_acc: 90.67%, val_loss: 2.044500, val_acc: 50.26%\n",
      "Epoch [740]/[5000], train_loss: 0.187200, train_acc: 89.16%, val_loss: 1.677000, val_acc: 54.56%\n",
      "Epoch [741]/[5000], train_loss: 0.134600, train_acc: 91.41%, val_loss: 1.926900, val_acc: 53.52%\n",
      "Epoch [742]/[5000], train_loss: 0.148700, train_acc: 90.53%, val_loss: 1.726000, val_acc: 52.86%\n",
      "Epoch [743]/[5000], train_loss: 0.160000, train_acc: 89.94%, val_loss: 1.814600, val_acc: 50.65%\n",
      "Epoch [744]/[5000], train_loss: 0.161000, train_acc: 90.72%, val_loss: 1.854800, val_acc: 50.52%\n",
      "Epoch [745]/[5000], train_loss: 0.156900, train_acc: 90.48%, val_loss: 2.136600, val_acc: 52.47%\n",
      "Epoch [746]/[5000], train_loss: 0.151200, train_acc: 90.97%, val_loss: 2.054000, val_acc: 48.96%\n",
      "Epoch [747]/[5000], train_loss: 0.154200, train_acc: 90.92%, val_loss: 1.991000, val_acc: 53.39%\n",
      "Epoch [748]/[5000], train_loss: 0.137100, train_acc: 90.82%, val_loss: 1.799400, val_acc: 52.08%\n",
      "Epoch [749]/[5000], train_loss: 0.150100, train_acc: 90.92%, val_loss: 2.237400, val_acc: 48.83%\n",
      "Epoch [750]/[5000], train_loss: 0.174800, train_acc: 89.50%, val_loss: 1.881500, val_acc: 51.43%\n",
      "Epoch [751]/[5000], train_loss: 0.156600, train_acc: 90.53%, val_loss: 2.324200, val_acc: 52.34%\n",
      "Epoch [752]/[5000], train_loss: 0.175700, train_acc: 90.04%, val_loss: 1.979600, val_acc: 43.88%\n",
      "Epoch [753]/[5000], train_loss: 0.192500, train_acc: 89.06%, val_loss: 1.862000, val_acc: 49.48%\n",
      "Epoch [754]/[5000], train_loss: 0.210300, train_acc: 88.77%, val_loss: 1.959200, val_acc: 51.43%\n",
      "Epoch [755]/[5000], train_loss: 0.192000, train_acc: 90.28%, val_loss: 1.664200, val_acc: 55.73%\n",
      "Epoch [756]/[5000], train_loss: 0.190000, train_acc: 89.21%, val_loss: 1.868100, val_acc: 52.73%\n",
      "Epoch [757]/[5000], train_loss: 0.166300, train_acc: 89.55%, val_loss: 2.076700, val_acc: 53.52%\n",
      "Epoch [758]/[5000], train_loss: 0.134200, train_acc: 91.36%, val_loss: 1.786500, val_acc: 53.52%\n",
      "Epoch [759]/[5000], train_loss: 0.145200, train_acc: 90.67%, val_loss: 2.159000, val_acc: 49.48%\n",
      "Epoch [760]/[5000], train_loss: 0.152900, train_acc: 90.87%, val_loss: 1.811200, val_acc: 53.39%\n",
      "Epoch [761]/[5000], train_loss: 0.139200, train_acc: 91.02%, val_loss: 1.812800, val_acc: 51.95%\n",
      "Epoch [762]/[5000], train_loss: 0.130400, train_acc: 91.65%, val_loss: 1.881000, val_acc: 50.39%\n",
      "Epoch [763]/[5000], train_loss: 0.175300, train_acc: 89.99%, val_loss: 1.903700, val_acc: 53.52%\n",
      "Epoch [764]/[5000], train_loss: 0.135100, train_acc: 90.72%, val_loss: 1.691800, val_acc: 49.61%\n",
      "Epoch [765]/[5000], train_loss: 0.155200, train_acc: 90.87%, val_loss: 1.797500, val_acc: 52.73%\n",
      "Epoch [766]/[5000], train_loss: 0.194500, train_acc: 89.45%, val_loss: 1.930100, val_acc: 52.86%\n",
      "Epoch [767]/[5000], train_loss: 0.160200, train_acc: 90.53%, val_loss: 2.151100, val_acc: 48.05%\n",
      "Epoch [768]/[5000], train_loss: 0.166100, train_acc: 90.14%, val_loss: 1.983800, val_acc: 49.22%\n",
      "Epoch [769]/[5000], train_loss: 0.177400, train_acc: 89.99%, val_loss: 2.213400, val_acc: 50.52%\n",
      "Epoch [770]/[5000], train_loss: 0.196600, train_acc: 89.79%, val_loss: 1.995200, val_acc: 53.39%\n",
      "Epoch [771]/[5000], train_loss: 0.212300, train_acc: 88.04%, val_loss: 2.002800, val_acc: 50.39%\n",
      "Epoch [772]/[5000], train_loss: 0.188300, train_acc: 89.26%, val_loss: 2.054700, val_acc: 51.43%\n",
      "Epoch [773]/[5000], train_loss: 0.184800, train_acc: 89.99%, val_loss: 1.901300, val_acc: 51.82%\n",
      "Epoch [774]/[5000], train_loss: 0.169200, train_acc: 90.09%, val_loss: 1.744900, val_acc: 50.13%\n",
      "Epoch [775]/[5000], train_loss: 0.177400, train_acc: 89.65%, val_loss: 1.732000, val_acc: 51.82%\n",
      "Epoch [776]/[5000], train_loss: 0.153300, train_acc: 90.09%, val_loss: 1.898200, val_acc: 51.95%\n",
      "Epoch [777]/[5000], train_loss: 0.153900, train_acc: 89.94%, val_loss: 1.816800, val_acc: 54.30%\n",
      "Epoch [778]/[5000], train_loss: 0.136900, train_acc: 90.82%, val_loss: 1.996600, val_acc: 52.47%\n",
      "Epoch [779]/[5000], train_loss: 0.144100, train_acc: 90.67%, val_loss: 1.775600, val_acc: 51.56%\n",
      "Epoch [780]/[5000], train_loss: 0.150200, train_acc: 90.58%, val_loss: 1.685100, val_acc: 53.52%\n",
      "Epoch [781]/[5000], train_loss: 0.136600, train_acc: 90.97%, val_loss: 2.008100, val_acc: 54.69%\n",
      "Epoch [782]/[5000], train_loss: 0.163900, train_acc: 90.09%, val_loss: 1.986200, val_acc: 49.74%\n",
      "Epoch [783]/[5000], train_loss: 0.155600, train_acc: 90.33%, val_loss: 2.058000, val_acc: 52.60%\n",
      "Epoch [784]/[5000], train_loss: 0.172700, train_acc: 89.45%, val_loss: 1.905800, val_acc: 52.34%\n",
      "Epoch [785]/[5000], train_loss: 0.177600, train_acc: 89.84%, val_loss: 1.929600, val_acc: 50.39%\n",
      "Epoch [786]/[5000], train_loss: 0.162200, train_acc: 89.89%, val_loss: 2.130200, val_acc: 51.56%\n",
      "Epoch [787]/[5000], train_loss: 0.159300, train_acc: 89.65%, val_loss: 1.610800, val_acc: 52.08%\n",
      "Epoch [788]/[5000], train_loss: 0.160300, train_acc: 90.28%, val_loss: 1.912900, val_acc: 50.26%\n",
      "Epoch [789]/[5000], train_loss: 0.166400, train_acc: 90.09%, val_loss: 1.918400, val_acc: 50.91%\n",
      "Epoch [790]/[5000], train_loss: 0.205700, train_acc: 89.26%, val_loss: 1.969100, val_acc: 52.86%\n",
      "Epoch [791]/[5000], train_loss: 0.170600, train_acc: 89.70%, val_loss: 1.804400, val_acc: 50.26%\n",
      "Epoch [792]/[5000], train_loss: 0.170900, train_acc: 90.04%, val_loss: 1.793700, val_acc: 56.12%\n",
      "Epoch [793]/[5000], train_loss: 0.144700, train_acc: 91.11%, val_loss: 1.755000, val_acc: 54.30%\n",
      "Epoch [794]/[5000], train_loss: 0.156200, train_acc: 90.67%, val_loss: 1.830000, val_acc: 51.04%\n",
      "Epoch [795]/[5000], train_loss: 0.154700, train_acc: 90.97%, val_loss: 1.986100, val_acc: 50.65%\n",
      "Epoch [796]/[5000], train_loss: 0.168200, train_acc: 90.58%, val_loss: 1.974500, val_acc: 50.91%\n",
      "Epoch [797]/[5000], train_loss: 0.140500, train_acc: 90.62%, val_loss: 1.946900, val_acc: 51.82%\n",
      "Epoch [798]/[5000], train_loss: 0.145800, train_acc: 90.43%, val_loss: 1.825300, val_acc: 45.83%\n",
      "Epoch [799]/[5000], train_loss: 0.228900, train_acc: 87.84%, val_loss: 2.063500, val_acc: 53.91%\n",
      "Epoch [800]/[5000], train_loss: 0.193800, train_acc: 89.06%, val_loss: 1.747200, val_acc: 51.30%\n",
      "Epoch [801]/[5000], train_loss: 0.191100, train_acc: 89.40%, val_loss: 1.885800, val_acc: 52.73%\n",
      "Epoch [802]/[5000], train_loss: 0.170500, train_acc: 89.75%, val_loss: 1.872000, val_acc: 50.00%\n",
      "Epoch [803]/[5000], train_loss: 0.146400, train_acc: 90.77%, val_loss: 1.603000, val_acc: 52.34%\n",
      "Epoch [804]/[5000], train_loss: 0.128600, train_acc: 91.75%, val_loss: 1.904200, val_acc: 52.34%\n",
      "Epoch [805]/[5000], train_loss: 0.156400, train_acc: 89.84%, val_loss: 1.721000, val_acc: 54.69%\n",
      "Epoch [806]/[5000], train_loss: 0.147800, train_acc: 90.62%, val_loss: 1.604200, val_acc: 53.65%\n",
      "Epoch [807]/[5000], train_loss: 0.176100, train_acc: 89.45%, val_loss: 1.853500, val_acc: 54.17%\n",
      "Epoch [808]/[5000], train_loss: 0.172300, train_acc: 89.31%, val_loss: 1.859400, val_acc: 54.69%\n",
      "Epoch [809]/[5000], train_loss: 0.128300, train_acc: 91.06%, val_loss: 1.761800, val_acc: 54.43%\n",
      "Epoch [810]/[5000], train_loss: 0.140500, train_acc: 90.82%, val_loss: 2.076900, val_acc: 56.38%\n",
      "Epoch [811]/[5000], train_loss: 0.145400, train_acc: 91.26%, val_loss: 1.866700, val_acc: 52.86%\n",
      "Epoch [812]/[5000], train_loss: 0.164300, train_acc: 89.75%, val_loss: 2.351800, val_acc: 47.66%\n",
      "Epoch [813]/[5000], train_loss: 0.167600, train_acc: 90.14%, val_loss: 1.926400, val_acc: 50.91%\n",
      "Epoch [814]/[5000], train_loss: 0.177700, train_acc: 89.99%, val_loss: 1.813800, val_acc: 50.78%\n",
      "Epoch [815]/[5000], train_loss: 0.145200, train_acc: 90.48%, val_loss: 1.725100, val_acc: 55.34%\n",
      "Epoch [816]/[5000], train_loss: 0.142400, train_acc: 90.72%, val_loss: 1.874100, val_acc: 52.21%\n",
      "Epoch [817]/[5000], train_loss: 0.163400, train_acc: 90.28%, val_loss: 1.851500, val_acc: 53.65%\n",
      "Epoch [818]/[5000], train_loss: 0.145600, train_acc: 90.82%, val_loss: 1.717300, val_acc: 53.52%\n",
      "Epoch [819]/[5000], train_loss: 0.150400, train_acc: 90.53%, val_loss: 1.982000, val_acc: 52.99%\n",
      "Epoch [820]/[5000], train_loss: 0.143500, train_acc: 90.82%, val_loss: 2.005100, val_acc: 51.82%\n",
      "Epoch [821]/[5000], train_loss: 0.135200, train_acc: 91.02%, val_loss: 2.126900, val_acc: 52.73%\n",
      "Epoch [822]/[5000], train_loss: 0.130200, train_acc: 91.46%, val_loss: 2.158200, val_acc: 53.65%\n",
      "Epoch [823]/[5000], train_loss: 0.164400, train_acc: 90.38%, val_loss: 1.977400, val_acc: 52.86%\n",
      "Epoch [824]/[5000], train_loss: 0.141700, train_acc: 91.02%, val_loss: 2.191800, val_acc: 51.17%\n",
      "Epoch [825]/[5000], train_loss: 0.129300, train_acc: 91.41%, val_loss: 1.830400, val_acc: 51.43%\n",
      "Epoch [826]/[5000], train_loss: 0.126300, train_acc: 92.38%, val_loss: 2.520000, val_acc: 53.78%\n",
      "Epoch [827]/[5000], train_loss: 0.171900, train_acc: 89.84%, val_loss: 1.856600, val_acc: 51.82%\n",
      "Epoch [828]/[5000], train_loss: 0.141200, train_acc: 90.97%, val_loss: 2.384900, val_acc: 49.61%\n",
      "Epoch [829]/[5000], train_loss: 0.160800, train_acc: 90.72%, val_loss: 1.898400, val_acc: 50.91%\n",
      "Epoch [830]/[5000], train_loss: 0.177300, train_acc: 89.36%, val_loss: 1.733600, val_acc: 52.73%\n",
      "Epoch [831]/[5000], train_loss: 0.151800, train_acc: 90.77%, val_loss: 2.219100, val_acc: 50.78%\n",
      "Epoch [832]/[5000], train_loss: 0.172900, train_acc: 90.23%, val_loss: 2.024800, val_acc: 51.82%\n",
      "Epoch [833]/[5000], train_loss: 0.150300, train_acc: 90.14%, val_loss: 2.077000, val_acc: 47.92%\n",
      "Epoch [834]/[5000], train_loss: 0.134000, train_acc: 91.70%, val_loss: 1.636400, val_acc: 53.26%\n",
      "Epoch [835]/[5000], train_loss: 0.142800, train_acc: 90.67%, val_loss: 2.191000, val_acc: 50.65%\n",
      "Epoch [836]/[5000], train_loss: 0.164300, train_acc: 89.94%, val_loss: 1.948000, val_acc: 50.91%\n",
      "Epoch [837]/[5000], train_loss: 0.159200, train_acc: 90.48%, val_loss: 1.948300, val_acc: 50.91%\n",
      "Epoch [838]/[5000], train_loss: 0.147200, train_acc: 90.58%, val_loss: 1.755700, val_acc: 53.26%\n",
      "Epoch [839]/[5000], train_loss: 0.156700, train_acc: 90.82%, val_loss: 2.121200, val_acc: 52.47%\n",
      "Epoch [840]/[5000], train_loss: 0.162000, train_acc: 89.79%, val_loss: 2.034600, val_acc: 46.48%\n",
      "Epoch [841]/[5000], train_loss: 0.135900, train_acc: 90.67%, val_loss: 1.908100, val_acc: 50.39%\n",
      "Epoch [842]/[5000], train_loss: 0.131500, train_acc: 91.85%, val_loss: 2.151800, val_acc: 51.82%\n",
      "Epoch [843]/[5000], train_loss: 0.173600, train_acc: 89.94%, val_loss: 2.137600, val_acc: 46.48%\n",
      "Epoch [844]/[5000], train_loss: 0.199200, train_acc: 88.72%, val_loss: 1.979800, val_acc: 54.69%\n",
      "Epoch [845]/[5000], train_loss: 0.151300, train_acc: 89.79%, val_loss: 2.268300, val_acc: 50.65%\n",
      "Epoch [846]/[5000], train_loss: 0.142800, train_acc: 90.82%, val_loss: 1.652600, val_acc: 50.65%\n",
      "Epoch [847]/[5000], train_loss: 0.130200, train_acc: 91.89%, val_loss: 1.856400, val_acc: 50.52%\n",
      "Epoch [848]/[5000], train_loss: 0.135000, train_acc: 91.26%, val_loss: 1.693900, val_acc: 52.99%\n",
      "Epoch [849]/[5000], train_loss: 0.123200, train_acc: 91.65%, val_loss: 1.867500, val_acc: 51.95%\n",
      "Epoch [850]/[5000], train_loss: 0.132600, train_acc: 91.41%, val_loss: 2.006100, val_acc: 52.34%\n",
      "Epoch [851]/[5000], train_loss: 0.124900, train_acc: 91.11%, val_loss: 2.173900, val_acc: 51.69%\n",
      "Epoch [852]/[5000], train_loss: 0.121200, train_acc: 92.09%, val_loss: 1.993100, val_acc: 51.95%\n",
      "Epoch [853]/[5000], train_loss: 0.120000, train_acc: 91.70%, val_loss: 2.102300, val_acc: 55.99%\n",
      "Epoch [854]/[5000], train_loss: 0.132200, train_acc: 91.65%, val_loss: 2.244600, val_acc: 51.95%\n",
      "Epoch [855]/[5000], train_loss: 0.134000, train_acc: 91.21%, val_loss: 2.619000, val_acc: 47.27%\n",
      "Epoch [856]/[5000], train_loss: 0.156600, train_acc: 90.43%, val_loss: 1.921700, val_acc: 50.78%\n",
      "Epoch [857]/[5000], train_loss: 0.178600, train_acc: 89.89%, val_loss: 1.922000, val_acc: 52.47%\n",
      "Epoch [858]/[5000], train_loss: 0.180900, train_acc: 90.14%, val_loss: 2.217800, val_acc: 51.95%\n",
      "Epoch [859]/[5000], train_loss: 0.149200, train_acc: 90.23%, val_loss: 2.150900, val_acc: 51.69%\n",
      "Epoch [860]/[5000], train_loss: 0.163100, train_acc: 90.53%, val_loss: 1.875200, val_acc: 50.00%\n",
      "Epoch [861]/[5000], train_loss: 0.140100, train_acc: 91.36%, val_loss: 1.709500, val_acc: 54.56%\n",
      "Epoch [862]/[5000], train_loss: 0.141000, train_acc: 91.36%, val_loss: 2.075300, val_acc: 50.26%\n",
      "Epoch [863]/[5000], train_loss: 0.128300, train_acc: 91.65%, val_loss: 2.072800, val_acc: 55.60%\n",
      "Epoch [864]/[5000], train_loss: 0.139800, train_acc: 90.97%, val_loss: 1.910200, val_acc: 55.73%\n",
      "Epoch [865]/[5000], train_loss: 0.184500, train_acc: 89.36%, val_loss: 2.189600, val_acc: 52.86%\n",
      "Epoch [866]/[5000], train_loss: 0.165500, train_acc: 89.84%, val_loss: 1.862900, val_acc: 48.31%\n",
      "Epoch [867]/[5000], train_loss: 0.136900, train_acc: 91.46%, val_loss: 1.873500, val_acc: 52.73%\n",
      "Epoch [868]/[5000], train_loss: 0.154400, train_acc: 90.67%, val_loss: 2.138000, val_acc: 53.91%\n",
      "Epoch [869]/[5000], train_loss: 0.155500, train_acc: 90.53%, val_loss: 1.987300, val_acc: 50.39%\n",
      "Epoch [870]/[5000], train_loss: 0.144200, train_acc: 91.21%, val_loss: 2.040400, val_acc: 52.21%\n",
      "Epoch [871]/[5000], train_loss: 0.145400, train_acc: 91.31%, val_loss: 2.033500, val_acc: 55.21%\n",
      "Epoch [872]/[5000], train_loss: 0.131900, train_acc: 91.50%, val_loss: 2.118100, val_acc: 49.22%\n",
      "Epoch [873]/[5000], train_loss: 0.141100, train_acc: 91.16%, val_loss: 1.856700, val_acc: 57.55%\n",
      "Epoch [874]/[5000], train_loss: 0.123200, train_acc: 91.36%, val_loss: 1.854500, val_acc: 55.73%\n",
      "Epoch [875]/[5000], train_loss: 0.133200, train_acc: 91.36%, val_loss: 1.895800, val_acc: 54.17%\n",
      "Epoch [876]/[5000], train_loss: 0.151500, train_acc: 90.92%, val_loss: 2.015700, val_acc: 52.21%\n",
      "Epoch [877]/[5000], train_loss: 0.161900, train_acc: 90.53%, val_loss: 2.001800, val_acc: 51.17%\n",
      "Epoch [878]/[5000], train_loss: 0.143100, train_acc: 90.97%, val_loss: 1.926000, val_acc: 50.13%\n",
      "Epoch [879]/[5000], train_loss: 0.165800, train_acc: 89.75%, val_loss: 1.773200, val_acc: 53.12%\n",
      "Epoch [880]/[5000], train_loss: 0.172100, train_acc: 90.62%, val_loss: 2.040500, val_acc: 50.78%\n",
      "Epoch [881]/[5000], train_loss: 0.129500, train_acc: 91.65%, val_loss: 2.217000, val_acc: 50.00%\n",
      "Epoch [882]/[5000], train_loss: 0.153600, train_acc: 89.99%, val_loss: 2.372200, val_acc: 50.52%\n",
      "Epoch [883]/[5000], train_loss: 0.161700, train_acc: 89.75%, val_loss: 1.768900, val_acc: 52.60%\n",
      "Epoch [884]/[5000], train_loss: 0.130700, train_acc: 91.11%, val_loss: 1.912200, val_acc: 55.21%\n",
      "Epoch [885]/[5000], train_loss: 0.128700, train_acc: 91.70%, val_loss: 2.221900, val_acc: 45.83%\n",
      "Epoch [886]/[5000], train_loss: 0.133900, train_acc: 91.55%, val_loss: 2.190400, val_acc: 49.87%\n",
      "Epoch [887]/[5000], train_loss: 0.154000, train_acc: 90.82%, val_loss: 1.879000, val_acc: 50.26%\n",
      "Epoch [888]/[5000], train_loss: 0.180800, train_acc: 90.04%, val_loss: 2.194100, val_acc: 52.08%\n",
      "Epoch [889]/[5000], train_loss: 0.177700, train_acc: 90.09%, val_loss: 2.226600, val_acc: 50.78%\n",
      "Epoch [890]/[5000], train_loss: 0.185800, train_acc: 89.75%, val_loss: 1.876600, val_acc: 53.65%\n",
      "Epoch [891]/[5000], train_loss: 0.172300, train_acc: 89.89%, val_loss: 1.879000, val_acc: 50.39%\n",
      "Epoch [892]/[5000], train_loss: 0.169400, train_acc: 89.75%, val_loss: 2.003900, val_acc: 50.52%\n",
      "Epoch [893]/[5000], train_loss: 0.190700, train_acc: 89.11%, val_loss: 1.921900, val_acc: 55.21%\n",
      "Epoch [894]/[5000], train_loss: 0.161400, train_acc: 90.28%, val_loss: 1.833700, val_acc: 48.83%\n",
      "Epoch [895]/[5000], train_loss: 0.126300, train_acc: 91.60%, val_loss: 1.908500, val_acc: 52.21%\n",
      "Epoch [896]/[5000], train_loss: 0.125200, train_acc: 91.60%, val_loss: 2.062200, val_acc: 48.57%\n",
      "Epoch [897]/[5000], train_loss: 0.130400, train_acc: 91.16%, val_loss: 1.925000, val_acc: 49.61%\n",
      "Epoch [898]/[5000], train_loss: 0.157500, train_acc: 90.92%, val_loss: 2.371200, val_acc: 50.13%\n",
      "Epoch [899]/[5000], train_loss: 0.156500, train_acc: 90.19%, val_loss: 2.097900, val_acc: 50.65%\n",
      "Epoch [900]/[5000], train_loss: 0.165800, train_acc: 90.53%, val_loss: 1.645000, val_acc: 51.04%\n",
      "Epoch [901]/[5000], train_loss: 0.165200, train_acc: 90.53%, val_loss: 1.870100, val_acc: 51.82%\n",
      "Epoch [902]/[5000], train_loss: 0.172000, train_acc: 90.23%, val_loss: 1.954000, val_acc: 54.43%\n",
      "Epoch [903]/[5000], train_loss: 0.145200, train_acc: 90.19%, val_loss: 1.959300, val_acc: 52.21%\n",
      "Epoch [904]/[5000], train_loss: 0.120700, train_acc: 91.94%, val_loss: 1.904500, val_acc: 53.12%\n",
      "Epoch [905]/[5000], train_loss: 0.124000, train_acc: 91.75%, val_loss: 2.071300, val_acc: 52.60%\n",
      "Epoch [906]/[5000], train_loss: 0.116900, train_acc: 91.70%, val_loss: 1.942300, val_acc: 51.43%\n",
      "Epoch [907]/[5000], train_loss: 0.116600, train_acc: 91.89%, val_loss: 2.147000, val_acc: 53.52%\n",
      "Epoch [908]/[5000], train_loss: 0.132900, train_acc: 91.99%, val_loss: 2.105600, val_acc: 55.47%\n",
      "Epoch [909]/[5000], train_loss: 0.134900, train_acc: 91.46%, val_loss: 2.184500, val_acc: 51.30%\n",
      "Epoch [910]/[5000], train_loss: 0.137000, train_acc: 91.50%, val_loss: 1.980100, val_acc: 53.65%\n",
      "Epoch [911]/[5000], train_loss: 0.133900, train_acc: 91.06%, val_loss: 2.365500, val_acc: 50.52%\n",
      "Epoch [912]/[5000], train_loss: 0.176400, train_acc: 89.84%, val_loss: 2.289000, val_acc: 51.30%\n",
      "Epoch [913]/[5000], train_loss: 0.125400, train_acc: 91.85%, val_loss: 2.026900, val_acc: 55.60%\n",
      "Epoch [914]/[5000], train_loss: 0.153200, train_acc: 90.58%, val_loss: 2.065000, val_acc: 48.31%\n",
      "Epoch [915]/[5000], train_loss: 0.152100, train_acc: 90.67%, val_loss: 1.905800, val_acc: 51.43%\n",
      "Epoch [916]/[5000], train_loss: 0.148500, train_acc: 90.72%, val_loss: 1.909400, val_acc: 52.47%\n",
      "Epoch [917]/[5000], train_loss: 0.146600, train_acc: 91.36%, val_loss: 1.912000, val_acc: 54.43%\n",
      "Epoch [918]/[5000], train_loss: 0.127900, train_acc: 91.36%, val_loss: 2.508400, val_acc: 50.00%\n",
      "Epoch [919]/[5000], train_loss: 0.133800, train_acc: 91.11%, val_loss: 1.887100, val_acc: 52.34%\n",
      "Epoch [920]/[5000], train_loss: 0.139200, train_acc: 90.92%, val_loss: 1.976400, val_acc: 55.08%\n",
      "Epoch [921]/[5000], train_loss: 0.130600, train_acc: 92.29%, val_loss: 2.018100, val_acc: 54.30%\n",
      "Epoch [922]/[5000], train_loss: 0.114900, train_acc: 92.48%, val_loss: 2.156100, val_acc: 52.34%\n",
      "Epoch [923]/[5000], train_loss: 0.121100, train_acc: 91.26%, val_loss: 2.133100, val_acc: 51.04%\n",
      "Epoch [924]/[5000], train_loss: 0.109700, train_acc: 91.89%, val_loss: 2.078200, val_acc: 49.35%\n",
      "Epoch [925]/[5000], train_loss: 0.104200, train_acc: 92.53%, val_loss: 2.861600, val_acc: 51.04%\n",
      "Epoch [926]/[5000], train_loss: 0.115400, train_acc: 92.09%, val_loss: 2.068600, val_acc: 51.30%\n",
      "Epoch [927]/[5000], train_loss: 0.128400, train_acc: 91.46%, val_loss: 2.111300, val_acc: 56.51%\n",
      "Epoch [928]/[5000], train_loss: 0.133000, train_acc: 91.50%, val_loss: 2.157500, val_acc: 51.56%\n",
      "Epoch [929]/[5000], train_loss: 0.119300, train_acc: 91.80%, val_loss: 1.966800, val_acc: 54.43%\n",
      "Epoch [930]/[5000], train_loss: 0.126900, train_acc: 91.55%, val_loss: 2.546100, val_acc: 50.39%\n",
      "Epoch [931]/[5000], train_loss: 0.149600, train_acc: 90.19%, val_loss: 2.302400, val_acc: 51.95%\n",
      "Epoch [932]/[5000], train_loss: 0.154000, train_acc: 90.23%, val_loss: 2.184900, val_acc: 50.91%\n",
      "Epoch [933]/[5000], train_loss: 0.146700, train_acc: 91.31%, val_loss: 2.031700, val_acc: 53.65%\n",
      "Epoch [934]/[5000], train_loss: 0.143500, train_acc: 91.06%, val_loss: 2.147600, val_acc: 48.57%\n",
      "Epoch [935]/[5000], train_loss: 0.142900, train_acc: 90.82%, val_loss: 2.575000, val_acc: 48.70%\n",
      "Epoch [936]/[5000], train_loss: 0.106300, train_acc: 92.68%, val_loss: 1.979500, val_acc: 52.73%\n",
      "Epoch [937]/[5000], train_loss: 0.141100, train_acc: 91.31%, val_loss: 1.921500, val_acc: 52.86%\n",
      "Epoch [938]/[5000], train_loss: 0.147100, train_acc: 90.43%, val_loss: 2.005500, val_acc: 51.95%\n",
      "Epoch [939]/[5000], train_loss: 0.153700, train_acc: 91.06%, val_loss: 1.835100, val_acc: 54.17%\n",
      "Epoch [940]/[5000], train_loss: 0.144000, train_acc: 91.46%, val_loss: 2.358700, val_acc: 51.30%\n",
      "Epoch [941]/[5000], train_loss: 0.130700, train_acc: 91.16%, val_loss: 2.104900, val_acc: 48.31%\n",
      "Epoch [942]/[5000], train_loss: 0.116200, train_acc: 91.89%, val_loss: 2.073600, val_acc: 48.05%\n",
      "Epoch [943]/[5000], train_loss: 0.124400, train_acc: 91.65%, val_loss: 2.609100, val_acc: 49.74%\n",
      "Epoch [944]/[5000], train_loss: 0.109200, train_acc: 91.99%, val_loss: 2.016300, val_acc: 52.08%\n",
      "Epoch [945]/[5000], train_loss: 0.136800, train_acc: 91.80%, val_loss: 2.339400, val_acc: 53.52%\n",
      "Epoch [946]/[5000], train_loss: 0.118500, train_acc: 91.85%, val_loss: 2.054700, val_acc: 49.22%\n",
      "Epoch [947]/[5000], train_loss: 0.133600, train_acc: 91.75%, val_loss: 2.281700, val_acc: 49.74%\n",
      "Epoch [948]/[5000], train_loss: 0.126000, train_acc: 91.70%, val_loss: 2.408200, val_acc: 53.65%\n",
      "Epoch [949]/[5000], train_loss: 0.161100, train_acc: 90.38%, val_loss: 2.162200, val_acc: 51.82%\n",
      "Epoch [950]/[5000], train_loss: 0.152400, train_acc: 90.77%, val_loss: 2.014300, val_acc: 53.12%\n",
      "Epoch [951]/[5000], train_loss: 0.117300, train_acc: 92.09%, val_loss: 1.979100, val_acc: 50.13%\n",
      "Epoch [952]/[5000], train_loss: 0.134300, train_acc: 91.41%, val_loss: 2.137900, val_acc: 53.91%\n",
      "Epoch [953]/[5000], train_loss: 0.123800, train_acc: 91.80%, val_loss: 2.203400, val_acc: 52.60%\n",
      "Epoch [954]/[5000], train_loss: 0.128600, train_acc: 91.50%, val_loss: 2.131700, val_acc: 52.21%\n",
      "Epoch [955]/[5000], train_loss: 0.120000, train_acc: 91.99%, val_loss: 1.776600, val_acc: 52.47%\n",
      "Epoch [956]/[5000], train_loss: 0.166900, train_acc: 89.70%, val_loss: 2.031900, val_acc: 50.91%\n",
      "Epoch [957]/[5000], train_loss: 0.143800, train_acc: 90.97%, val_loss: 1.924900, val_acc: 55.08%\n",
      "Epoch [958]/[5000], train_loss: 0.147300, train_acc: 90.77%, val_loss: 1.844000, val_acc: 53.12%\n",
      "Epoch [959]/[5000], train_loss: 0.140200, train_acc: 91.21%, val_loss: 2.118500, val_acc: 52.21%\n",
      "Epoch [960]/[5000], train_loss: 0.107800, train_acc: 92.43%, val_loss: 1.948900, val_acc: 54.56%\n",
      "Epoch [961]/[5000], train_loss: 0.115500, train_acc: 92.19%, val_loss: 1.980800, val_acc: 54.69%\n",
      "Epoch [962]/[5000], train_loss: 0.122100, train_acc: 92.09%, val_loss: 2.204300, val_acc: 55.73%\n",
      "Epoch [963]/[5000], train_loss: 0.130700, train_acc: 91.02%, val_loss: 2.156400, val_acc: 53.52%\n",
      "Epoch [964]/[5000], train_loss: 0.121800, train_acc: 91.60%, val_loss: 2.121100, val_acc: 53.39%\n",
      "Epoch [965]/[5000], train_loss: 0.136800, train_acc: 91.11%, val_loss: 1.890200, val_acc: 54.30%\n",
      "Epoch [966]/[5000], train_loss: 0.133600, train_acc: 91.36%, val_loss: 2.125100, val_acc: 51.04%\n",
      "Epoch [967]/[5000], train_loss: 0.126300, train_acc: 91.02%, val_loss: 2.308300, val_acc: 52.47%\n",
      "Epoch [968]/[5000], train_loss: 0.126300, train_acc: 91.65%, val_loss: 2.015500, val_acc: 53.91%\n",
      "Epoch [969]/[5000], train_loss: 0.141800, train_acc: 90.62%, val_loss: 2.005100, val_acc: 49.35%\n",
      "Epoch [970]/[5000], train_loss: 0.132300, train_acc: 91.60%, val_loss: 2.471400, val_acc: 47.79%\n",
      "Epoch [971]/[5000], train_loss: 0.117900, train_acc: 92.14%, val_loss: 2.344400, val_acc: 48.44%\n",
      "Epoch [972]/[5000], train_loss: 0.100100, train_acc: 92.43%, val_loss: 2.344200, val_acc: 52.60%\n",
      "Epoch [973]/[5000], train_loss: 0.128600, train_acc: 91.26%, val_loss: 2.198800, val_acc: 49.09%\n",
      "Epoch [974]/[5000], train_loss: 0.143500, train_acc: 90.97%, val_loss: 2.145900, val_acc: 54.43%\n",
      "Epoch [975]/[5000], train_loss: 0.139300, train_acc: 91.02%, val_loss: 1.939500, val_acc: 52.34%\n",
      "Epoch [976]/[5000], train_loss: 0.105400, train_acc: 92.29%, val_loss: 2.225600, val_acc: 48.83%\n",
      "Epoch [977]/[5000], train_loss: 0.133900, train_acc: 91.60%, val_loss: 2.113100, val_acc: 54.69%\n",
      "Epoch [978]/[5000], train_loss: 0.117000, train_acc: 91.99%, val_loss: 2.383000, val_acc: 52.08%\n",
      "Epoch [979]/[5000], train_loss: 0.132200, train_acc: 91.02%, val_loss: 2.093100, val_acc: 51.43%\n",
      "Epoch [980]/[5000], train_loss: 0.153500, train_acc: 90.82%, val_loss: 2.158300, val_acc: 49.22%\n",
      "Epoch [981]/[5000], train_loss: 0.115500, train_acc: 92.24%, val_loss: 2.249200, val_acc: 49.61%\n",
      "Epoch [982]/[5000], train_loss: 0.108800, train_acc: 92.29%, val_loss: 2.022600, val_acc: 49.74%\n",
      "Epoch [983]/[5000], train_loss: 0.115200, train_acc: 92.29%, val_loss: 2.072800, val_acc: 52.60%\n",
      "Epoch [984]/[5000], train_loss: 0.127200, train_acc: 91.06%, val_loss: 2.231300, val_acc: 52.60%\n",
      "Epoch [985]/[5000], train_loss: 0.148400, train_acc: 90.92%, val_loss: 2.345700, val_acc: 50.91%\n",
      "Epoch [986]/[5000], train_loss: 0.131800, train_acc: 91.26%, val_loss: 2.311300, val_acc: 51.82%\n",
      "Epoch [987]/[5000], train_loss: 0.166700, train_acc: 90.87%, val_loss: 2.349000, val_acc: 52.99%\n",
      "Epoch [988]/[5000], train_loss: 0.141800, train_acc: 90.48%, val_loss: 2.491000, val_acc: 49.74%\n",
      "Epoch [989]/[5000], train_loss: 0.163600, train_acc: 89.55%, val_loss: 2.098200, val_acc: 52.47%\n",
      "Epoch [990]/[5000], train_loss: 0.148100, train_acc: 91.46%, val_loss: 2.352400, val_acc: 54.69%\n",
      "Epoch [991]/[5000], train_loss: 0.124500, train_acc: 91.36%, val_loss: 2.278900, val_acc: 50.65%\n",
      "Epoch [992]/[5000], train_loss: 0.154500, train_acc: 90.67%, val_loss: 2.240300, val_acc: 51.43%\n",
      "Epoch [993]/[5000], train_loss: 0.165300, train_acc: 90.33%, val_loss: 2.061000, val_acc: 52.34%\n",
      "Epoch [994]/[5000], train_loss: 0.157500, train_acc: 90.87%, val_loss: 1.830000, val_acc: 52.99%\n",
      "Epoch [995]/[5000], train_loss: 0.132200, train_acc: 91.21%, val_loss: 2.117700, val_acc: 51.82%\n",
      "Epoch [996]/[5000], train_loss: 0.150800, train_acc: 90.33%, val_loss: 2.212200, val_acc: 49.09%\n",
      "Epoch [997]/[5000], train_loss: 0.127000, train_acc: 91.41%, val_loss: 2.107400, val_acc: 53.91%\n",
      "Epoch [998]/[5000], train_loss: 0.105600, train_acc: 92.43%, val_loss: 1.969000, val_acc: 49.61%\n",
      "Epoch [999]/[5000], train_loss: 0.111700, train_acc: 92.77%, val_loss: 2.159000, val_acc: 51.56%\n",
      "Epoch [1000]/[5000], train_loss: 0.098200, train_acc: 92.77%, val_loss: 1.891000, val_acc: 49.87%\n",
      "Epoch [1001]/[5000], train_loss: 0.134100, train_acc: 91.70%, val_loss: 2.138100, val_acc: 54.95%\n",
      "Epoch [1002]/[5000], train_loss: 0.109900, train_acc: 92.09%, val_loss: 2.250000, val_acc: 50.00%\n",
      "Epoch [1003]/[5000], train_loss: 0.127800, train_acc: 91.55%, val_loss: 2.416600, val_acc: 49.22%\n",
      "Epoch [1004]/[5000], train_loss: 0.145100, train_acc: 90.58%, val_loss: 2.414500, val_acc: 55.60%\n",
      "Epoch [1005]/[5000], train_loss: 0.113400, train_acc: 91.94%, val_loss: 2.221300, val_acc: 52.47%\n",
      "Epoch [1006]/[5000], train_loss: 0.113600, train_acc: 91.70%, val_loss: 2.258100, val_acc: 51.56%\n",
      "Epoch [1007]/[5000], train_loss: 0.115600, train_acc: 92.29%, val_loss: 2.212600, val_acc: 52.47%\n",
      "Epoch [1008]/[5000], train_loss: 0.115800, train_acc: 91.75%, val_loss: 2.340700, val_acc: 49.22%\n",
      "Epoch [1009]/[5000], train_loss: 0.100500, train_acc: 92.38%, val_loss: 2.336400, val_acc: 53.12%\n",
      "Epoch [1010]/[5000], train_loss: 0.129100, train_acc: 91.36%, val_loss: 2.414100, val_acc: 51.69%\n",
      "Epoch [1011]/[5000], train_loss: 0.137500, train_acc: 90.92%, val_loss: 2.303100, val_acc: 49.74%\n",
      "Epoch [1012]/[5000], train_loss: 0.106600, train_acc: 91.85%, val_loss: 2.153200, val_acc: 54.43%\n",
      "Epoch [1013]/[5000], train_loss: 0.113500, train_acc: 91.99%, val_loss: 2.040300, val_acc: 50.52%\n",
      "Epoch [1014]/[5000], train_loss: 0.144500, train_acc: 91.06%, val_loss: 2.353800, val_acc: 52.99%\n",
      "Epoch [1015]/[5000], train_loss: 0.143400, train_acc: 90.38%, val_loss: 2.018100, val_acc: 54.17%\n",
      "Epoch [1016]/[5000], train_loss: 0.142100, train_acc: 90.97%, val_loss: 2.408400, val_acc: 48.31%\n",
      "Epoch [1017]/[5000], train_loss: 0.110000, train_acc: 92.14%, val_loss: 2.222700, val_acc: 49.74%\n",
      "Epoch [1018]/[5000], train_loss: 0.151600, train_acc: 91.55%, val_loss: 2.410700, val_acc: 52.99%\n",
      "Epoch [1019]/[5000], train_loss: 0.141300, train_acc: 91.06%, val_loss: 2.183000, val_acc: 52.73%\n",
      "Epoch [1020]/[5000], train_loss: 0.094700, train_acc: 92.87%, val_loss: 2.273600, val_acc: 51.69%\n",
      "Epoch [1021]/[5000], train_loss: 0.113100, train_acc: 91.99%, val_loss: 1.867300, val_acc: 52.73%\n",
      "Epoch [1022]/[5000], train_loss: 0.115300, train_acc: 92.09%, val_loss: 2.169200, val_acc: 52.73%\n",
      "Epoch [1023]/[5000], train_loss: 0.102500, train_acc: 92.63%, val_loss: 2.284400, val_acc: 52.60%\n",
      "Epoch [1024]/[5000], train_loss: 0.122400, train_acc: 91.94%, val_loss: 2.173700, val_acc: 56.64%\n",
      "Epoch [1025]/[5000], train_loss: 0.116000, train_acc: 92.38%, val_loss: 2.312500, val_acc: 52.47%\n",
      "Epoch [1026]/[5000], train_loss: 0.107500, train_acc: 92.72%, val_loss: 1.998300, val_acc: 50.26%\n",
      "Epoch [1027]/[5000], train_loss: 0.085200, train_acc: 93.12%, val_loss: 2.492300, val_acc: 54.17%\n",
      "Epoch [1028]/[5000], train_loss: 0.094200, train_acc: 92.68%, val_loss: 2.205500, val_acc: 51.95%\n",
      "Epoch [1029]/[5000], train_loss: 0.106200, train_acc: 92.82%, val_loss: 2.172000, val_acc: 52.73%\n",
      "Epoch [1030]/[5000], train_loss: 0.096500, train_acc: 92.68%, val_loss: 1.987000, val_acc: 54.43%\n",
      "Epoch [1031]/[5000], train_loss: 0.088000, train_acc: 93.55%, val_loss: 2.128500, val_acc: 54.43%\n",
      "Epoch [1032]/[5000], train_loss: 0.094400, train_acc: 92.43%, val_loss: 2.373700, val_acc: 53.12%\n",
      "Epoch [1033]/[5000], train_loss: 0.121600, train_acc: 91.94%, val_loss: 2.340700, val_acc: 50.65%\n",
      "Epoch [1034]/[5000], train_loss: 0.157000, train_acc: 90.48%, val_loss: 2.239000, val_acc: 49.35%\n",
      "Epoch [1035]/[5000], train_loss: 0.154300, train_acc: 91.16%, val_loss: 2.175400, val_acc: 52.60%\n",
      "Epoch [1036]/[5000], train_loss: 0.120700, train_acc: 91.55%, val_loss: 2.273200, val_acc: 54.04%\n",
      "Epoch [1037]/[5000], train_loss: 0.131300, train_acc: 91.70%, val_loss: 2.222800, val_acc: 51.82%\n",
      "Epoch [1038]/[5000], train_loss: 0.142000, train_acc: 91.21%, val_loss: 2.242700, val_acc: 50.78%\n",
      "Epoch [1039]/[5000], train_loss: 0.138200, train_acc: 91.21%, val_loss: 2.088700, val_acc: 50.13%\n",
      "Epoch [1040]/[5000], train_loss: 0.102900, train_acc: 92.19%, val_loss: 2.068100, val_acc: 52.73%\n",
      "Epoch [1041]/[5000], train_loss: 0.113500, train_acc: 91.70%, val_loss: 2.329700, val_acc: 52.08%\n",
      "Epoch [1042]/[5000], train_loss: 0.139200, train_acc: 91.60%, val_loss: 1.928700, val_acc: 51.17%\n",
      "Epoch [1043]/[5000], train_loss: 0.124100, train_acc: 91.26%, val_loss: 2.111700, val_acc: 50.78%\n",
      "Epoch [1044]/[5000], train_loss: 0.111600, train_acc: 91.75%, val_loss: 2.320800, val_acc: 48.96%\n",
      "Epoch [1045]/[5000], train_loss: 0.116300, train_acc: 91.89%, val_loss: 2.184700, val_acc: 53.78%\n",
      "Epoch [1046]/[5000], train_loss: 0.119600, train_acc: 92.04%, val_loss: 2.435000, val_acc: 49.74%\n",
      "Epoch [1047]/[5000], train_loss: 0.128600, train_acc: 91.16%, val_loss: 2.399700, val_acc: 49.87%\n",
      "Epoch [1048]/[5000], train_loss: 0.133400, train_acc: 92.04%, val_loss: 1.973200, val_acc: 52.08%\n",
      "Epoch [1049]/[5000], train_loss: 0.092200, train_acc: 92.87%, val_loss: 2.408500, val_acc: 49.22%\n",
      "Epoch [1050]/[5000], train_loss: 0.139500, train_acc: 90.72%, val_loss: 2.519900, val_acc: 51.04%\n",
      "Epoch [1051]/[5000], train_loss: 0.134800, train_acc: 90.92%, val_loss: 2.195300, val_acc: 50.52%\n",
      "Epoch [1052]/[5000], train_loss: 0.098100, train_acc: 92.43%, val_loss: 2.111600, val_acc: 51.95%\n",
      "Epoch [1053]/[5000], train_loss: 0.099800, train_acc: 91.75%, val_loss: 2.033300, val_acc: 53.78%\n",
      "Epoch [1054]/[5000], train_loss: 0.101300, train_acc: 92.87%, val_loss: 2.233800, val_acc: 54.04%\n",
      "Epoch [1055]/[5000], train_loss: 0.100500, train_acc: 92.43%, val_loss: 2.341100, val_acc: 53.78%\n",
      "Epoch [1056]/[5000], train_loss: 0.100700, train_acc: 92.43%, val_loss: 2.386700, val_acc: 50.39%\n",
      "Epoch [1057]/[5000], train_loss: 0.089000, train_acc: 92.82%, val_loss: 2.430700, val_acc: 53.39%\n",
      "Epoch [1058]/[5000], train_loss: 0.102400, train_acc: 92.33%, val_loss: 3.100000, val_acc: 49.09%\n",
      "Epoch [1059]/[5000], train_loss: 0.119900, train_acc: 91.80%, val_loss: 2.172600, val_acc: 54.69%\n",
      "Epoch [1060]/[5000], train_loss: 0.122400, train_acc: 92.04%, val_loss: 2.115700, val_acc: 51.56%\n",
      "Epoch [1061]/[5000], train_loss: 0.145600, train_acc: 90.92%, val_loss: 2.071800, val_acc: 50.65%\n",
      "Epoch [1062]/[5000], train_loss: 0.110800, train_acc: 92.14%, val_loss: 2.206900, val_acc: 48.96%\n",
      "Epoch [1063]/[5000], train_loss: 0.134300, train_acc: 91.55%, val_loss: 2.142400, val_acc: 54.30%\n",
      "Epoch [1064]/[5000], train_loss: 0.116900, train_acc: 91.85%, val_loss: 2.298500, val_acc: 51.04%\n",
      "Epoch [1065]/[5000], train_loss: 0.123400, train_acc: 91.75%, val_loss: 2.381700, val_acc: 54.56%\n",
      "Epoch [1066]/[5000], train_loss: 0.116900, train_acc: 91.99%, val_loss: 1.927600, val_acc: 52.47%\n",
      "Epoch [1067]/[5000], train_loss: 0.093500, train_acc: 93.21%, val_loss: 2.210700, val_acc: 50.39%\n",
      "Epoch [1068]/[5000], train_loss: 0.112100, train_acc: 91.89%, val_loss: 2.162200, val_acc: 52.08%\n",
      "Epoch [1069]/[5000], train_loss: 0.101200, train_acc: 92.72%, val_loss: 2.334800, val_acc: 56.51%\n",
      "Epoch [1070]/[5000], train_loss: 0.115100, train_acc: 92.19%, val_loss: 2.102100, val_acc: 55.47%\n",
      "Epoch [1071]/[5000], train_loss: 0.120800, train_acc: 91.26%, val_loss: 2.063700, val_acc: 50.91%\n",
      "Epoch [1072]/[5000], train_loss: 0.125200, train_acc: 91.41%, val_loss: 2.545500, val_acc: 52.99%\n",
      "Epoch [1073]/[5000], train_loss: 0.133800, train_acc: 91.26%, val_loss: 2.106600, val_acc: 50.26%\n",
      "Epoch [1074]/[5000], train_loss: 0.129800, train_acc: 91.31%, val_loss: 2.373400, val_acc: 52.60%\n",
      "Epoch [1075]/[5000], train_loss: 0.099600, train_acc: 92.04%, val_loss: 2.301700, val_acc: 52.60%\n",
      "Epoch [1076]/[5000], train_loss: 0.133700, train_acc: 91.89%, val_loss: 2.514100, val_acc: 52.99%\n",
      "Epoch [1077]/[5000], train_loss: 0.113600, train_acc: 92.53%, val_loss: 2.146700, val_acc: 51.56%\n",
      "Epoch [1078]/[5000], train_loss: 0.097200, train_acc: 92.87%, val_loss: 2.426900, val_acc: 54.30%\n",
      "Epoch [1079]/[5000], train_loss: 0.084300, train_acc: 92.58%, val_loss: 2.210700, val_acc: 51.17%\n",
      "Epoch [1080]/[5000], train_loss: 0.112100, train_acc: 92.33%, val_loss: 2.203800, val_acc: 51.17%\n",
      "Epoch [1081]/[5000], train_loss: 0.133100, train_acc: 91.31%, val_loss: 2.002000, val_acc: 53.26%\n",
      "Epoch [1082]/[5000], train_loss: 0.114900, train_acc: 91.75%, val_loss: 1.986700, val_acc: 54.04%\n",
      "Epoch [1083]/[5000], train_loss: 0.131200, train_acc: 91.75%, val_loss: 1.950400, val_acc: 56.51%\n",
      "Epoch [1084]/[5000], train_loss: 0.108300, train_acc: 92.19%, val_loss: 2.199400, val_acc: 53.26%\n",
      "Epoch [1085]/[5000], train_loss: 0.120000, train_acc: 91.99%, val_loss: 2.310200, val_acc: 54.30%\n",
      "Epoch [1086]/[5000], train_loss: 0.143600, train_acc: 90.92%, val_loss: 2.272900, val_acc: 52.34%\n",
      "Epoch [1087]/[5000], train_loss: 0.123500, train_acc: 91.50%, val_loss: 2.156900, val_acc: 53.78%\n",
      "Epoch [1088]/[5000], train_loss: 0.125800, train_acc: 91.31%, val_loss: 2.096300, val_acc: 50.26%\n",
      "Epoch [1089]/[5000], train_loss: 0.108600, train_acc: 92.38%, val_loss: 2.229600, val_acc: 51.30%\n",
      "Epoch [1090]/[5000], train_loss: 0.118400, train_acc: 92.14%, val_loss: 2.067100, val_acc: 54.95%\n",
      "Epoch [1091]/[5000], train_loss: 0.114200, train_acc: 91.55%, val_loss: 2.110500, val_acc: 52.86%\n",
      "Epoch [1092]/[5000], train_loss: 0.129000, train_acc: 91.06%, val_loss: 2.432300, val_acc: 52.73%\n",
      "Epoch [1093]/[5000], train_loss: 0.104600, train_acc: 92.19%, val_loss: 2.235200, val_acc: 54.56%\n",
      "Epoch [1094]/[5000], train_loss: 0.109500, train_acc: 92.38%, val_loss: 2.256400, val_acc: 52.60%\n",
      "Epoch [1095]/[5000], train_loss: 0.115200, train_acc: 92.19%, val_loss: 2.213000, val_acc: 52.47%\n",
      "Epoch [1096]/[5000], train_loss: 0.109000, train_acc: 92.43%, val_loss: 2.105700, val_acc: 54.56%\n",
      "Epoch [1097]/[5000], train_loss: 0.097800, train_acc: 92.63%, val_loss: 2.206500, val_acc: 52.73%\n",
      "Epoch [1098]/[5000], train_loss: 0.135200, train_acc: 91.26%, val_loss: 2.492400, val_acc: 52.73%\n",
      "Epoch [1099]/[5000], train_loss: 0.120700, train_acc: 91.99%, val_loss: 2.315100, val_acc: 51.17%\n",
      "Epoch [1100]/[5000], train_loss: 0.095100, train_acc: 92.43%, val_loss: 2.106500, val_acc: 53.65%\n",
      "Epoch [1101]/[5000], train_loss: 0.101000, train_acc: 92.82%, val_loss: 2.112500, val_acc: 53.78%\n",
      "Epoch [1102]/[5000], train_loss: 0.107000, train_acc: 92.24%, val_loss: 2.419900, val_acc: 52.47%\n",
      "Epoch [1103]/[5000], train_loss: 0.107600, train_acc: 92.38%, val_loss: 2.529900, val_acc: 52.60%\n",
      "Epoch [1104]/[5000], train_loss: 0.111000, train_acc: 92.14%, val_loss: 2.469700, val_acc: 48.70%\n",
      "Epoch [1105]/[5000], train_loss: 0.115900, train_acc: 92.09%, val_loss: 2.500000, val_acc: 53.39%\n",
      "Epoch [1106]/[5000], train_loss: 0.108200, train_acc: 91.99%, val_loss: 2.381100, val_acc: 50.13%\n",
      "Epoch [1107]/[5000], train_loss: 0.119900, train_acc: 91.65%, val_loss: 2.416300, val_acc: 52.34%\n",
      "Epoch [1108]/[5000], train_loss: 0.127400, train_acc: 91.65%, val_loss: 2.148400, val_acc: 51.04%\n",
      "Epoch [1109]/[5000], train_loss: 0.131900, train_acc: 91.70%, val_loss: 1.940200, val_acc: 50.91%\n",
      "Epoch [1110]/[5000], train_loss: 0.120100, train_acc: 91.70%, val_loss: 2.391100, val_acc: 50.13%\n",
      "Epoch [1111]/[5000], train_loss: 0.121800, train_acc: 91.75%, val_loss: 2.193800, val_acc: 49.35%\n",
      "Epoch [1112]/[5000], train_loss: 0.119000, train_acc: 92.58%, val_loss: 2.208600, val_acc: 51.30%\n",
      "Epoch [1113]/[5000], train_loss: 0.103000, train_acc: 92.77%, val_loss: 2.142000, val_acc: 51.95%\n",
      "Epoch [1114]/[5000], train_loss: 0.109400, train_acc: 92.19%, val_loss: 2.202400, val_acc: 52.86%\n",
      "Epoch [1115]/[5000], train_loss: 0.098700, train_acc: 92.09%, val_loss: 2.009600, val_acc: 51.69%\n",
      "Epoch [1116]/[5000], train_loss: 0.110800, train_acc: 92.29%, val_loss: 2.193700, val_acc: 51.69%\n",
      "Epoch [1117]/[5000], train_loss: 0.107800, train_acc: 92.24%, val_loss: 2.405700, val_acc: 52.47%\n",
      "Epoch [1118]/[5000], train_loss: 0.112200, train_acc: 92.43%, val_loss: 2.286900, val_acc: 50.65%\n",
      "Epoch [1119]/[5000], train_loss: 0.112900, train_acc: 91.85%, val_loss: 2.201900, val_acc: 53.52%\n",
      "Epoch [1120]/[5000], train_loss: 0.089200, train_acc: 92.72%, val_loss: 2.117600, val_acc: 49.74%\n",
      "Epoch [1121]/[5000], train_loss: 0.105300, train_acc: 92.43%, val_loss: 2.447800, val_acc: 52.99%\n",
      "Epoch [1122]/[5000], train_loss: 0.128300, train_acc: 91.21%, val_loss: 2.407600, val_acc: 50.52%\n",
      "Epoch [1123]/[5000], train_loss: 0.125600, train_acc: 91.31%, val_loss: 2.281900, val_acc: 54.43%\n",
      "Epoch [1124]/[5000], train_loss: 0.111500, train_acc: 91.65%, val_loss: 2.135100, val_acc: 51.56%\n",
      "Epoch [1125]/[5000], train_loss: 0.083700, train_acc: 92.87%, val_loss: 2.482600, val_acc: 49.61%\n",
      "Epoch [1126]/[5000], train_loss: 0.106200, train_acc: 92.14%, val_loss: 2.415800, val_acc: 51.04%\n",
      "Epoch [1127]/[5000], train_loss: 0.103700, train_acc: 92.77%, val_loss: 2.234900, val_acc: 54.30%\n",
      "Epoch [1128]/[5000], train_loss: 0.117400, train_acc: 91.75%, val_loss: 2.229200, val_acc: 52.47%\n",
      "Epoch [1129]/[5000], train_loss: 0.109400, train_acc: 92.14%, val_loss: 2.482400, val_acc: 51.04%\n",
      "Epoch [1130]/[5000], train_loss: 0.143000, train_acc: 90.58%, val_loss: 2.327400, val_acc: 48.70%\n",
      "Epoch [1131]/[5000], train_loss: 0.135000, train_acc: 91.65%, val_loss: 2.378600, val_acc: 52.34%\n",
      "Epoch [1132]/[5000], train_loss: 0.121000, train_acc: 91.94%, val_loss: 2.151400, val_acc: 51.30%\n",
      "Epoch [1133]/[5000], train_loss: 0.136900, train_acc: 91.46%, val_loss: 2.009500, val_acc: 52.60%\n",
      "Epoch [1134]/[5000], train_loss: 0.103800, train_acc: 92.29%, val_loss: 2.048000, val_acc: 54.43%\n",
      "Epoch [1135]/[5000], train_loss: 0.095200, train_acc: 93.12%, val_loss: 2.250400, val_acc: 50.39%\n",
      "Epoch [1136]/[5000], train_loss: 0.108400, train_acc: 92.38%, val_loss: 1.991000, val_acc: 54.04%\n",
      "Epoch [1137]/[5000], train_loss: 0.117200, train_acc: 92.14%, val_loss: 2.173100, val_acc: 55.21%\n",
      "Epoch [1138]/[5000], train_loss: 0.145400, train_acc: 90.92%, val_loss: 2.379300, val_acc: 50.78%\n",
      "Epoch [1139]/[5000], train_loss: 0.115900, train_acc: 91.60%, val_loss: 2.157300, val_acc: 50.13%\n",
      "Epoch [1140]/[5000], train_loss: 0.105500, train_acc: 92.72%, val_loss: 2.241800, val_acc: 52.47%\n",
      "Epoch [1141]/[5000], train_loss: 0.108500, train_acc: 92.53%, val_loss: 2.311700, val_acc: 50.26%\n",
      "Epoch [1142]/[5000], train_loss: 0.147400, train_acc: 91.16%, val_loss: 2.294800, val_acc: 50.00%\n",
      "Epoch [1143]/[5000], train_loss: 0.125300, train_acc: 91.99%, val_loss: 2.267500, val_acc: 52.08%\n",
      "Epoch [1144]/[5000], train_loss: 0.115100, train_acc: 91.94%, val_loss: 2.026200, val_acc: 53.12%\n",
      "Epoch [1145]/[5000], train_loss: 0.106400, train_acc: 92.09%, val_loss: 1.995100, val_acc: 53.65%\n",
      "Epoch [1146]/[5000], train_loss: 0.110900, train_acc: 91.85%, val_loss: 2.013500, val_acc: 53.26%\n",
      "Epoch [1147]/[5000], train_loss: 0.102000, train_acc: 92.24%, val_loss: 2.425100, val_acc: 50.26%\n",
      "Epoch [1148]/[5000], train_loss: 0.087200, train_acc: 92.82%, val_loss: 2.265200, val_acc: 50.78%\n",
      "Epoch [1149]/[5000], train_loss: 0.088000, train_acc: 92.87%, val_loss: 2.310600, val_acc: 52.21%\n",
      "Epoch [1150]/[5000], train_loss: 0.098500, train_acc: 92.53%, val_loss: 2.882600, val_acc: 48.44%\n",
      "Epoch [1151]/[5000], train_loss: 0.093600, train_acc: 93.12%, val_loss: 2.382900, val_acc: 54.43%\n",
      "Epoch [1152]/[5000], train_loss: 0.122400, train_acc: 91.55%, val_loss: 2.043400, val_acc: 54.82%\n",
      "Epoch [1153]/[5000], train_loss: 0.093900, train_acc: 92.68%, val_loss: 2.147600, val_acc: 53.65%\n",
      "Epoch [1154]/[5000], train_loss: 0.115200, train_acc: 91.89%, val_loss: 2.229500, val_acc: 51.04%\n",
      "Epoch [1155]/[5000], train_loss: 0.129700, train_acc: 91.26%, val_loss: 2.091200, val_acc: 50.13%\n",
      "Epoch [1156]/[5000], train_loss: 0.101300, train_acc: 92.09%, val_loss: 2.043900, val_acc: 53.78%\n",
      "Epoch [1157]/[5000], train_loss: 0.085800, train_acc: 92.72%, val_loss: 2.475000, val_acc: 53.78%\n",
      "Epoch [1158]/[5000], train_loss: 0.100500, train_acc: 92.87%, val_loss: 2.121300, val_acc: 52.47%\n",
      "Epoch [1159]/[5000], train_loss: 0.085500, train_acc: 92.97%, val_loss: 2.081000, val_acc: 52.99%\n",
      "Epoch [1160]/[5000], train_loss: 0.083400, train_acc: 93.07%, val_loss: 2.139600, val_acc: 54.17%\n",
      "Epoch [1161]/[5000], train_loss: 0.077100, train_acc: 93.16%, val_loss: 2.455200, val_acc: 51.43%\n",
      "Epoch [1162]/[5000], train_loss: 0.095200, train_acc: 93.46%, val_loss: 2.288200, val_acc: 51.69%\n",
      "Epoch [1163]/[5000], train_loss: 0.083300, train_acc: 93.12%, val_loss: 2.465400, val_acc: 54.95%\n",
      "Epoch [1164]/[5000], train_loss: 0.100700, train_acc: 92.68%, val_loss: 2.468100, val_acc: 53.65%\n",
      "Epoch [1165]/[5000], train_loss: 0.092900, train_acc: 92.97%, val_loss: 2.117200, val_acc: 52.08%\n",
      "Epoch [1166]/[5000], train_loss: 0.075900, train_acc: 93.41%, val_loss: 2.313900, val_acc: 50.39%\n",
      "Epoch [1167]/[5000], train_loss: 0.080400, train_acc: 93.26%, val_loss: 1.921600, val_acc: 52.86%\n",
      "Epoch [1168]/[5000], train_loss: 0.076500, train_acc: 93.26%, val_loss: 2.399900, val_acc: 53.52%\n",
      "Epoch [1169]/[5000], train_loss: 0.088100, train_acc: 93.07%, val_loss: 2.534400, val_acc: 51.17%\n",
      "Epoch [1170]/[5000], train_loss: 0.102500, train_acc: 92.24%, val_loss: 2.370900, val_acc: 55.47%\n",
      "Epoch [1171]/[5000], train_loss: 0.103000, train_acc: 92.24%, val_loss: 2.429900, val_acc: 52.34%\n",
      "Epoch [1172]/[5000], train_loss: 0.114300, train_acc: 92.29%, val_loss: 2.397800, val_acc: 53.78%\n",
      "Epoch [1173]/[5000], train_loss: 0.128800, train_acc: 91.41%, val_loss: 2.139900, val_acc: 52.86%\n",
      "Epoch [1174]/[5000], train_loss: 0.143900, train_acc: 91.02%, val_loss: 2.241500, val_acc: 50.91%\n",
      "Epoch [1175]/[5000], train_loss: 0.112900, train_acc: 92.38%, val_loss: 2.309800, val_acc: 53.39%\n",
      "Epoch [1176]/[5000], train_loss: 0.127300, train_acc: 91.65%, val_loss: 2.295500, val_acc: 55.34%\n",
      "Epoch [1177]/[5000], train_loss: 0.160500, train_acc: 90.77%, val_loss: 2.477100, val_acc: 51.04%\n",
      "Epoch [1178]/[5000], train_loss: 0.125800, train_acc: 91.75%, val_loss: 2.544600, val_acc: 51.17%\n",
      "Epoch [1179]/[5000], train_loss: 0.133500, train_acc: 91.60%, val_loss: 2.599500, val_acc: 52.60%\n",
      "Epoch [1180]/[5000], train_loss: 0.090100, train_acc: 92.72%, val_loss: 2.338900, val_acc: 52.47%\n",
      "Epoch [1181]/[5000], train_loss: 0.089000, train_acc: 93.16%, val_loss: 2.151800, val_acc: 54.56%\n",
      "Epoch [1182]/[5000], train_loss: 0.107100, train_acc: 92.43%, val_loss: 2.610300, val_acc: 52.73%\n",
      "Epoch [1183]/[5000], train_loss: 0.094600, train_acc: 92.77%, val_loss: 2.165700, val_acc: 55.08%\n",
      "Epoch [1184]/[5000], train_loss: 0.083100, train_acc: 93.02%, val_loss: 2.218100, val_acc: 51.56%\n",
      "Epoch [1185]/[5000], train_loss: 0.088600, train_acc: 93.02%, val_loss: 2.165200, val_acc: 56.25%\n",
      "Epoch [1186]/[5000], train_loss: 0.104000, train_acc: 92.53%, val_loss: 2.564800, val_acc: 54.43%\n",
      "Epoch [1187]/[5000], train_loss: 0.091600, train_acc: 92.82%, val_loss: 2.411900, val_acc: 54.82%\n",
      "Epoch [1188]/[5000], train_loss: 0.095600, train_acc: 93.12%, val_loss: 2.944400, val_acc: 54.30%\n",
      "Epoch [1189]/[5000], train_loss: 0.099200, train_acc: 92.68%, val_loss: 2.257500, val_acc: 54.43%\n",
      "Epoch [1190]/[5000], train_loss: 0.108900, train_acc: 92.38%, val_loss: 2.085300, val_acc: 52.60%\n",
      "Epoch [1191]/[5000], train_loss: 0.113900, train_acc: 92.14%, val_loss: 2.368100, val_acc: 52.47%\n",
      "Epoch [1192]/[5000], train_loss: 0.098800, train_acc: 92.77%, val_loss: 2.892000, val_acc: 53.91%\n",
      "Epoch [1193]/[5000], train_loss: 0.099000, train_acc: 92.92%, val_loss: 2.441000, val_acc: 53.91%\n",
      "Epoch [1194]/[5000], train_loss: 0.083600, train_acc: 92.92%, val_loss: 2.129500, val_acc: 50.65%\n",
      "Epoch [1195]/[5000], train_loss: 0.093700, train_acc: 92.43%, val_loss: 2.707300, val_acc: 52.73%\n",
      "Epoch [1196]/[5000], train_loss: 0.105900, train_acc: 92.24%, val_loss: 3.162000, val_acc: 52.21%\n",
      "Epoch [1197]/[5000], train_loss: 0.107900, train_acc: 92.68%, val_loss: 2.280800, val_acc: 50.13%\n",
      "Epoch [1198]/[5000], train_loss: 0.105200, train_acc: 92.63%, val_loss: 2.282800, val_acc: 51.82%\n",
      "Epoch [1199]/[5000], train_loss: 0.106600, train_acc: 92.24%, val_loss: 2.478500, val_acc: 52.08%\n",
      "Epoch [1200]/[5000], train_loss: 0.097700, train_acc: 92.43%, val_loss: 2.514100, val_acc: 50.91%\n",
      "Epoch [1201]/[5000], train_loss: 0.098200, train_acc: 92.77%, val_loss: 2.154400, val_acc: 53.65%\n",
      "Epoch [1202]/[5000], train_loss: 0.102000, train_acc: 92.09%, val_loss: 2.186100, val_acc: 53.65%\n",
      "Epoch [1203]/[5000], train_loss: 0.096500, train_acc: 92.92%, val_loss: 2.165300, val_acc: 53.39%\n",
      "Epoch [1204]/[5000], train_loss: 0.116800, train_acc: 92.04%, val_loss: 2.726500, val_acc: 52.73%\n",
      "Epoch [1205]/[5000], train_loss: 0.095100, train_acc: 92.43%, val_loss: 2.718100, val_acc: 52.47%\n",
      "Epoch [1206]/[5000], train_loss: 0.092700, train_acc: 92.48%, val_loss: 2.675300, val_acc: 53.91%\n",
      "Epoch [1207]/[5000], train_loss: 0.112400, train_acc: 91.75%, val_loss: 2.335600, val_acc: 51.69%\n",
      "Epoch [1208]/[5000], train_loss: 0.145800, train_acc: 91.60%, val_loss: 2.404100, val_acc: 48.31%\n",
      "Epoch [1209]/[5000], train_loss: 0.122100, train_acc: 92.19%, val_loss: 2.260400, val_acc: 50.52%\n",
      "Epoch [1210]/[5000], train_loss: 0.131300, train_acc: 91.16%, val_loss: 2.557300, val_acc: 53.12%\n",
      "Epoch [1211]/[5000], train_loss: 0.124700, train_acc: 91.26%, val_loss: 2.109000, val_acc: 53.12%\n",
      "Epoch [1212]/[5000], train_loss: 0.104900, train_acc: 92.09%, val_loss: 2.039200, val_acc: 55.47%\n",
      "Epoch [1213]/[5000], train_loss: 0.092100, train_acc: 92.43%, val_loss: 2.495300, val_acc: 52.21%\n",
      "Epoch [1214]/[5000], train_loss: 0.077200, train_acc: 93.51%, val_loss: 2.334200, val_acc: 52.99%\n",
      "Epoch [1215]/[5000], train_loss: 0.105200, train_acc: 91.89%, val_loss: 2.172800, val_acc: 52.47%\n",
      "Epoch [1216]/[5000], train_loss: 0.078800, train_acc: 93.26%, val_loss: 2.261400, val_acc: 52.47%\n",
      "Epoch [1217]/[5000], train_loss: 0.123900, train_acc: 91.89%, val_loss: 2.316800, val_acc: 53.78%\n",
      "Epoch [1218]/[5000], train_loss: 0.133200, train_acc: 91.50%, val_loss: 2.524700, val_acc: 46.48%\n",
      "Epoch [1219]/[5000], train_loss: 0.116800, train_acc: 91.50%, val_loss: 2.440000, val_acc: 52.47%\n",
      "Epoch [1220]/[5000], train_loss: 0.120000, train_acc: 92.19%, val_loss: 2.649300, val_acc: 49.74%\n",
      "Epoch [1221]/[5000], train_loss: 0.119000, train_acc: 92.09%, val_loss: 2.280600, val_acc: 54.04%\n",
      "Epoch [1222]/[5000], train_loss: 0.109000, train_acc: 92.09%, val_loss: 2.287500, val_acc: 49.61%\n",
      "Epoch [1223]/[5000], train_loss: 0.104300, train_acc: 92.58%, val_loss: 2.450600, val_acc: 51.30%\n",
      "Epoch [1224]/[5000], train_loss: 0.105700, train_acc: 92.43%, val_loss: 2.599200, val_acc: 48.05%\n",
      "Epoch [1225]/[5000], train_loss: 0.091200, train_acc: 92.87%, val_loss: 2.250600, val_acc: 52.86%\n",
      "Epoch [1226]/[5000], train_loss: 0.097200, train_acc: 92.48%, val_loss: 2.210900, val_acc: 53.52%\n",
      "Epoch [1227]/[5000], train_loss: 0.092700, train_acc: 92.87%, val_loss: 2.453900, val_acc: 51.56%\n",
      "Epoch [1228]/[5000], train_loss: 0.109200, train_acc: 92.19%, val_loss: 2.478700, val_acc: 50.39%\n",
      "Epoch [1229]/[5000], train_loss: 0.143400, train_acc: 91.36%, val_loss: 2.280000, val_acc: 54.56%\n",
      "Epoch [1230]/[5000], train_loss: 0.120500, train_acc: 92.14%, val_loss: 2.247900, val_acc: 54.04%\n",
      "Epoch [1231]/[5000], train_loss: 0.138600, train_acc: 91.06%, val_loss: 2.407400, val_acc: 50.26%\n",
      "Epoch [1232]/[5000], train_loss: 0.110700, train_acc: 92.04%, val_loss: 1.964900, val_acc: 54.43%\n",
      "Epoch [1233]/[5000], train_loss: 0.121100, train_acc: 91.70%, val_loss: 2.293800, val_acc: 49.48%\n",
      "Epoch [1234]/[5000], train_loss: 0.119500, train_acc: 91.80%, val_loss: 2.186700, val_acc: 53.78%\n",
      "Epoch [1235]/[5000], train_loss: 0.104700, train_acc: 92.43%, val_loss: 2.335800, val_acc: 50.00%\n",
      "Epoch [1236]/[5000], train_loss: 0.104000, train_acc: 92.38%, val_loss: 2.546300, val_acc: 50.65%\n",
      "Epoch [1237]/[5000], train_loss: 0.104800, train_acc: 92.87%, val_loss: 2.077100, val_acc: 53.65%\n",
      "Epoch [1238]/[5000], train_loss: 0.119100, train_acc: 91.94%, val_loss: 2.111300, val_acc: 52.34%\n",
      "Epoch [1239]/[5000], train_loss: 0.103800, train_acc: 92.97%, val_loss: 2.163700, val_acc: 51.17%\n",
      "Epoch [1240]/[5000], train_loss: 0.097600, train_acc: 92.92%, val_loss: 2.174200, val_acc: 53.12%\n",
      "Epoch [1241]/[5000], train_loss: 0.086100, train_acc: 93.31%, val_loss: 2.022100, val_acc: 53.65%\n",
      "Epoch [1242]/[5000], train_loss: 0.091400, train_acc: 92.87%, val_loss: 2.373000, val_acc: 52.73%\n",
      "Epoch [1243]/[5000], train_loss: 0.115200, train_acc: 92.09%, val_loss: 2.032700, val_acc: 56.38%\n",
      "Epoch [1244]/[5000], train_loss: 0.078900, train_acc: 93.46%, val_loss: 2.284600, val_acc: 49.61%\n",
      "Epoch [1245]/[5000], train_loss: 0.105500, train_acc: 92.72%, val_loss: 1.949300, val_acc: 51.43%\n",
      "Epoch [1246]/[5000], train_loss: 0.148800, train_acc: 90.87%, val_loss: 2.461900, val_acc: 50.26%\n",
      "Epoch [1247]/[5000], train_loss: 0.099600, train_acc: 92.43%, val_loss: 2.428400, val_acc: 49.09%\n",
      "Epoch [1248]/[5000], train_loss: 0.117700, train_acc: 91.80%, val_loss: 2.242400, val_acc: 52.47%\n",
      "Epoch [1249]/[5000], train_loss: 0.108000, train_acc: 92.09%, val_loss: 2.138900, val_acc: 52.08%\n",
      "Epoch [1250]/[5000], train_loss: 0.087100, train_acc: 93.36%, val_loss: 2.229000, val_acc: 52.21%\n",
      "Epoch [1251]/[5000], train_loss: 0.117200, train_acc: 92.14%, val_loss: 2.257200, val_acc: 49.35%\n",
      "Epoch [1252]/[5000], train_loss: 0.164700, train_acc: 89.89%, val_loss: 2.127000, val_acc: 51.17%\n",
      "Epoch [1253]/[5000], train_loss: 0.118600, train_acc: 91.89%, val_loss: 2.276000, val_acc: 50.39%\n",
      "Epoch [1254]/[5000], train_loss: 0.166200, train_acc: 90.87%, val_loss: 2.408900, val_acc: 51.43%\n",
      "Epoch [1255]/[5000], train_loss: 0.106300, train_acc: 92.33%, val_loss: 2.108300, val_acc: 50.13%\n",
      "Epoch [1256]/[5000], train_loss: 0.114000, train_acc: 91.99%, val_loss: 1.904200, val_acc: 54.30%\n",
      "Epoch [1257]/[5000], train_loss: 0.112200, train_acc: 91.85%, val_loss: 2.110900, val_acc: 53.39%\n",
      "Epoch [1258]/[5000], train_loss: 0.096600, train_acc: 92.58%, val_loss: 2.094100, val_acc: 54.30%\n",
      "Epoch [1259]/[5000], train_loss: 0.091500, train_acc: 92.63%, val_loss: 2.156900, val_acc: 53.78%\n",
      "Epoch [1260]/[5000], train_loss: 0.093800, train_acc: 92.92%, val_loss: 2.122700, val_acc: 55.99%\n",
      "Epoch [1261]/[5000], train_loss: 0.107500, train_acc: 92.09%, val_loss: 2.276300, val_acc: 52.47%\n",
      "Epoch [1262]/[5000], train_loss: 0.092000, train_acc: 92.92%, val_loss: 2.313900, val_acc: 54.56%\n",
      "Epoch [1263]/[5000], train_loss: 0.118700, train_acc: 91.80%, val_loss: 2.204500, val_acc: 51.30%\n",
      "Epoch [1264]/[5000], train_loss: 0.134500, train_acc: 91.41%, val_loss: 2.209600, val_acc: 52.60%\n",
      "Epoch [1265]/[5000], train_loss: 0.084700, train_acc: 92.92%, val_loss: 2.167000, val_acc: 48.83%\n",
      "Epoch [1266]/[5000], train_loss: 0.094300, train_acc: 92.58%, val_loss: 2.057000, val_acc: 50.91%\n",
      "Epoch [1267]/[5000], train_loss: 0.105000, train_acc: 92.58%, val_loss: 2.225100, val_acc: 53.65%\n",
      "Epoch [1268]/[5000], train_loss: 0.099500, train_acc: 92.58%, val_loss: 1.976300, val_acc: 51.56%\n",
      "Epoch [1269]/[5000], train_loss: 0.112400, train_acc: 92.63%, val_loss: 2.114600, val_acc: 56.25%\n",
      "Epoch [1270]/[5000], train_loss: 0.110000, train_acc: 92.53%, val_loss: 2.363300, val_acc: 49.22%\n",
      "Epoch [1271]/[5000], train_loss: 0.101300, train_acc: 92.29%, val_loss: 2.211600, val_acc: 53.91%\n",
      "Epoch [1272]/[5000], train_loss: 0.106300, train_acc: 92.09%, val_loss: 2.058200, val_acc: 55.47%\n",
      "Epoch [1273]/[5000], train_loss: 0.089700, train_acc: 92.92%, val_loss: 2.504400, val_acc: 53.26%\n",
      "Epoch [1274]/[5000], train_loss: 0.088800, train_acc: 92.82%, val_loss: 2.366000, val_acc: 51.30%\n",
      "Epoch [1275]/[5000], train_loss: 0.074900, train_acc: 93.70%, val_loss: 2.234800, val_acc: 52.86%\n",
      "Epoch [1276]/[5000], train_loss: 0.077500, train_acc: 93.31%, val_loss: 2.806100, val_acc: 53.26%\n",
      "Epoch [1277]/[5000], train_loss: 0.093300, train_acc: 93.26%, val_loss: 2.347400, val_acc: 52.73%\n",
      "Epoch [1278]/[5000], train_loss: 0.082500, train_acc: 92.92%, val_loss: 2.405300, val_acc: 54.30%\n",
      "Epoch [1279]/[5000], train_loss: 0.078000, train_acc: 93.12%, val_loss: 2.414700, val_acc: 52.73%\n",
      "Epoch [1280]/[5000], train_loss: 0.079700, train_acc: 93.51%, val_loss: 1.873600, val_acc: 53.91%\n",
      "Epoch [1281]/[5000], train_loss: 0.100000, train_acc: 92.63%, val_loss: 2.346400, val_acc: 50.91%\n",
      "Epoch [1282]/[5000], train_loss: 0.085800, train_acc: 93.41%, val_loss: 2.312500, val_acc: 55.21%\n",
      "Epoch [1283]/[5000], train_loss: 0.084100, train_acc: 92.97%, val_loss: 2.237400, val_acc: 48.83%\n",
      "Epoch [1284]/[5000], train_loss: 0.084400, train_acc: 93.12%, val_loss: 2.647900, val_acc: 51.43%\n",
      "Epoch [1285]/[5000], train_loss: 0.095400, train_acc: 92.68%, val_loss: 2.529400, val_acc: 52.86%\n",
      "Epoch [1286]/[5000], train_loss: 0.089800, train_acc: 93.12%, val_loss: 2.425300, val_acc: 52.21%\n",
      "Epoch [1287]/[5000], train_loss: 0.122200, train_acc: 91.85%, val_loss: 2.114700, val_acc: 54.56%\n",
      "Epoch [1288]/[5000], train_loss: 0.094800, train_acc: 92.43%, val_loss: 2.287600, val_acc: 52.60%\n",
      "Epoch [1289]/[5000], train_loss: 0.081900, train_acc: 93.31%, val_loss: 2.653400, val_acc: 48.96%\n",
      "Epoch [1290]/[5000], train_loss: 0.122500, train_acc: 91.80%, val_loss: 2.183200, val_acc: 54.04%\n",
      "Epoch [1291]/[5000], train_loss: 0.095300, train_acc: 92.87%, val_loss: 2.261000, val_acc: 54.56%\n",
      "Epoch [1292]/[5000], train_loss: 0.078800, train_acc: 93.36%, val_loss: 2.857900, val_acc: 51.04%\n",
      "Epoch [1293]/[5000], train_loss: 0.107000, train_acc: 92.58%, val_loss: 2.616700, val_acc: 50.13%\n",
      "Epoch [1294]/[5000], train_loss: 0.108600, train_acc: 91.99%, val_loss: 2.400100, val_acc: 54.95%\n",
      "Epoch [1295]/[5000], train_loss: 0.099700, train_acc: 92.29%, val_loss: 2.452900, val_acc: 45.44%\n",
      "Epoch [1296]/[5000], train_loss: 0.088700, train_acc: 92.68%, val_loss: 2.442800, val_acc: 51.82%\n",
      "Epoch [1297]/[5000], train_loss: 0.075700, train_acc: 93.12%, val_loss: 2.126700, val_acc: 49.87%\n",
      "Epoch [1298]/[5000], train_loss: 0.092100, train_acc: 92.58%, val_loss: 2.104100, val_acc: 53.78%\n",
      "Epoch [1299]/[5000], train_loss: 0.091000, train_acc: 92.53%, val_loss: 2.651400, val_acc: 53.91%\n",
      "Epoch [1300]/[5000], train_loss: 0.075100, train_acc: 92.87%, val_loss: 2.436800, val_acc: 56.64%\n",
      "Epoch [1301]/[5000], train_loss: 0.068600, train_acc: 93.26%, val_loss: 2.487700, val_acc: 52.08%\n",
      "Epoch [1302]/[5000], train_loss: 0.069200, train_acc: 93.70%, val_loss: 2.377100, val_acc: 53.78%\n",
      "Epoch [1303]/[5000], train_loss: 0.099100, train_acc: 92.97%, val_loss: 2.397100, val_acc: 53.12%\n",
      "Epoch [1304]/[5000], train_loss: 0.098600, train_acc: 92.48%, val_loss: 2.743600, val_acc: 48.18%\n",
      "Epoch [1305]/[5000], train_loss: 0.105800, train_acc: 92.14%, val_loss: 2.182200, val_acc: 51.95%\n",
      "Epoch [1306]/[5000], train_loss: 0.110500, train_acc: 93.12%, val_loss: 2.261500, val_acc: 48.83%\n",
      "Epoch [1307]/[5000], train_loss: 0.106200, train_acc: 92.29%, val_loss: 2.284400, val_acc: 51.82%\n",
      "Epoch [1308]/[5000], train_loss: 0.076200, train_acc: 93.46%, val_loss: 2.649800, val_acc: 50.65%\n",
      "Epoch [1309]/[5000], train_loss: 0.070600, train_acc: 93.65%, val_loss: 2.091800, val_acc: 53.12%\n",
      "Epoch [1310]/[5000], train_loss: 0.090500, train_acc: 93.31%, val_loss: 2.216800, val_acc: 53.39%\n",
      "Epoch [1311]/[5000], train_loss: 0.082500, train_acc: 93.02%, val_loss: 2.364900, val_acc: 51.56%\n",
      "Epoch [1312]/[5000], train_loss: 0.082300, train_acc: 93.21%, val_loss: 2.247900, val_acc: 52.86%\n",
      "Epoch [1313]/[5000], train_loss: 0.102200, train_acc: 92.68%, val_loss: 2.525900, val_acc: 53.12%\n",
      "Epoch [1314]/[5000], train_loss: 0.111300, train_acc: 92.24%, val_loss: 2.487300, val_acc: 53.39%\n",
      "Epoch [1315]/[5000], train_loss: 0.123200, train_acc: 91.50%, val_loss: 2.139100, val_acc: 52.73%\n",
      "Epoch [1316]/[5000], train_loss: 0.105300, train_acc: 92.53%, val_loss: 2.204100, val_acc: 54.30%\n",
      "Epoch [1317]/[5000], train_loss: 0.107700, train_acc: 92.14%, val_loss: 2.683300, val_acc: 53.12%\n",
      "Epoch [1318]/[5000], train_loss: 0.111700, train_acc: 92.24%, val_loss: 2.068600, val_acc: 54.69%\n",
      "Epoch [1319]/[5000], train_loss: 0.107500, train_acc: 93.16%, val_loss: 2.097700, val_acc: 53.78%\n",
      "Epoch [1320]/[5000], train_loss: 0.089400, train_acc: 92.87%, val_loss: 2.606100, val_acc: 53.39%\n",
      "Epoch [1321]/[5000], train_loss: 0.102000, train_acc: 92.43%, val_loss: 2.493700, val_acc: 51.17%\n",
      "Epoch [1322]/[5000], train_loss: 0.082700, train_acc: 93.02%, val_loss: 2.124200, val_acc: 53.12%\n",
      "Epoch [1323]/[5000], train_loss: 0.092100, train_acc: 92.53%, val_loss: 2.311300, val_acc: 52.99%\n",
      "Epoch [1324]/[5000], train_loss: 0.099500, train_acc: 92.43%, val_loss: 2.592200, val_acc: 51.69%\n",
      "Epoch [1325]/[5000], train_loss: 0.110400, train_acc: 92.48%, val_loss: 2.149200, val_acc: 52.73%\n",
      "Epoch [1326]/[5000], train_loss: 0.110500, train_acc: 92.38%, val_loss: 2.199100, val_acc: 51.56%\n",
      "Epoch [1327]/[5000], train_loss: 0.129600, train_acc: 92.19%, val_loss: 2.251700, val_acc: 50.13%\n",
      "Epoch [1328]/[5000], train_loss: 0.115900, train_acc: 92.14%, val_loss: 2.667900, val_acc: 53.65%\n",
      "Epoch [1329]/[5000], train_loss: 0.112900, train_acc: 92.43%, val_loss: 2.297300, val_acc: 50.00%\n",
      "Epoch [1330]/[5000], train_loss: 0.122400, train_acc: 91.60%, val_loss: 2.102700, val_acc: 50.91%\n",
      "Epoch [1331]/[5000], train_loss: 0.102500, train_acc: 92.33%, val_loss: 2.149000, val_acc: 51.17%\n",
      "Epoch [1332]/[5000], train_loss: 0.088100, train_acc: 92.97%, val_loss: 2.463500, val_acc: 51.69%\n",
      "Epoch [1333]/[5000], train_loss: 0.064400, train_acc: 93.95%, val_loss: 2.212800, val_acc: 55.86%\n",
      "Epoch [1334]/[5000], train_loss: 0.076300, train_acc: 93.41%, val_loss: 2.432100, val_acc: 51.95%\n",
      "Epoch [1335]/[5000], train_loss: 0.070800, train_acc: 93.46%, val_loss: 2.753600, val_acc: 51.95%\n",
      "Epoch [1336]/[5000], train_loss: 0.074700, train_acc: 93.26%, val_loss: 2.204400, val_acc: 52.47%\n",
      "Epoch [1337]/[5000], train_loss: 0.083800, train_acc: 92.82%, val_loss: 2.273000, val_acc: 54.43%\n",
      "Epoch [1338]/[5000], train_loss: 0.098500, train_acc: 92.29%, val_loss: 2.266000, val_acc: 52.08%\n",
      "Epoch [1339]/[5000], train_loss: 0.086300, train_acc: 93.16%, val_loss: 2.294400, val_acc: 51.17%\n",
      "Epoch [1340]/[5000], train_loss: 0.089900, train_acc: 92.97%, val_loss: 2.313500, val_acc: 52.08%\n",
      "Epoch [1341]/[5000], train_loss: 0.094200, train_acc: 92.63%, val_loss: 2.979300, val_acc: 50.65%\n",
      "Epoch [1342]/[5000], train_loss: 0.080800, train_acc: 93.46%, val_loss: 2.298100, val_acc: 54.95%\n",
      "Epoch [1343]/[5000], train_loss: 0.091200, train_acc: 92.72%, val_loss: 2.150700, val_acc: 53.65%\n",
      "Epoch [1344]/[5000], train_loss: 0.090700, train_acc: 93.36%, val_loss: 2.749000, val_acc: 49.22%\n",
      "Epoch [1345]/[5000], train_loss: 0.122700, train_acc: 92.33%, val_loss: 2.459400, val_acc: 53.12%\n",
      "Epoch [1346]/[5000], train_loss: 0.110900, train_acc: 92.33%, val_loss: 2.458900, val_acc: 50.91%\n",
      "Epoch [1347]/[5000], train_loss: 0.100900, train_acc: 92.48%, val_loss: 2.285000, val_acc: 50.26%\n",
      "Epoch [1348]/[5000], train_loss: 0.118600, train_acc: 92.58%, val_loss: 2.362100, val_acc: 50.52%\n",
      "Epoch [1349]/[5000], train_loss: 0.157900, train_acc: 90.77%, val_loss: 2.263700, val_acc: 50.13%\n",
      "Epoch [1350]/[5000], train_loss: 0.126500, train_acc: 91.85%, val_loss: 2.202700, val_acc: 52.73%\n",
      "Epoch [1351]/[5000], train_loss: 0.113600, train_acc: 91.75%, val_loss: 2.880700, val_acc: 50.00%\n",
      "Epoch [1352]/[5000], train_loss: 0.111000, train_acc: 92.63%, val_loss: 2.152100, val_acc: 51.04%\n",
      "Epoch [1353]/[5000], train_loss: 0.111500, train_acc: 92.24%, val_loss: 1.883800, val_acc: 54.95%\n",
      "Epoch [1354]/[5000], train_loss: 0.094800, train_acc: 92.43%, val_loss: 2.197700, val_acc: 52.73%\n",
      "Epoch [1355]/[5000], train_loss: 0.096000, train_acc: 92.29%, val_loss: 2.313600, val_acc: 53.65%\n",
      "Epoch [1356]/[5000], train_loss: 0.077000, train_acc: 93.90%, val_loss: 2.038100, val_acc: 53.78%\n",
      "Epoch [1357]/[5000], train_loss: 0.092100, train_acc: 93.21%, val_loss: 2.400700, val_acc: 54.17%\n",
      "Epoch [1358]/[5000], train_loss: 0.093100, train_acc: 92.68%, val_loss: 2.399400, val_acc: 52.08%\n",
      "Epoch [1359]/[5000], train_loss: 0.126500, train_acc: 91.55%, val_loss: 2.261600, val_acc: 52.73%\n",
      "Epoch [1360]/[5000], train_loss: 0.114200, train_acc: 91.60%, val_loss: 2.402800, val_acc: 53.78%\n",
      "Epoch [1361]/[5000], train_loss: 0.111300, train_acc: 92.38%, val_loss: 2.126400, val_acc: 52.86%\n",
      "Epoch [1362]/[5000], train_loss: 0.098800, train_acc: 92.58%, val_loss: 2.245000, val_acc: 51.95%\n",
      "Epoch [1363]/[5000], train_loss: 0.092000, train_acc: 93.02%, val_loss: 2.528400, val_acc: 52.08%\n",
      "Epoch [1364]/[5000], train_loss: 0.094000, train_acc: 92.68%, val_loss: 2.260200, val_acc: 52.99%\n",
      "Epoch [1365]/[5000], train_loss: 0.098700, train_acc: 92.48%, val_loss: 2.222400, val_acc: 54.56%\n",
      "Epoch [1366]/[5000], train_loss: 0.079900, train_acc: 93.60%, val_loss: 2.424400, val_acc: 54.43%\n",
      "Epoch [1367]/[5000], train_loss: 0.102200, train_acc: 92.72%, val_loss: 2.123300, val_acc: 52.73%\n",
      "Epoch [1368]/[5000], train_loss: 0.084900, train_acc: 92.87%, val_loss: 2.587100, val_acc: 53.65%\n",
      "Epoch [1369]/[5000], train_loss: 0.125600, train_acc: 91.41%, val_loss: 2.121900, val_acc: 52.99%\n",
      "Epoch [1370]/[5000], train_loss: 0.101400, train_acc: 92.92%, val_loss: 2.282800, val_acc: 52.21%\n",
      "Epoch [1371]/[5000], train_loss: 0.091100, train_acc: 93.12%, val_loss: 2.252400, val_acc: 53.78%\n",
      "Epoch [1372]/[5000], train_loss: 0.084900, train_acc: 92.97%, val_loss: 2.518600, val_acc: 51.56%\n",
      "Epoch [1373]/[5000], train_loss: 0.092200, train_acc: 92.87%, val_loss: 2.573800, val_acc: 53.26%\n",
      "Epoch [1374]/[5000], train_loss: 0.106700, train_acc: 92.24%, val_loss: 2.488200, val_acc: 55.34%\n",
      "Epoch [1375]/[5000], train_loss: 0.085700, train_acc: 92.82%, val_loss: 2.128600, val_acc: 52.47%\n",
      "Epoch [1376]/[5000], train_loss: 0.107000, train_acc: 92.38%, val_loss: 2.488100, val_acc: 52.21%\n",
      "Epoch [1377]/[5000], train_loss: 0.085000, train_acc: 93.21%, val_loss: 2.351300, val_acc: 52.60%\n",
      "Epoch [1378]/[5000], train_loss: 0.086200, train_acc: 93.31%, val_loss: 2.216300, val_acc: 53.91%\n",
      "Epoch [1379]/[5000], train_loss: 0.055400, train_acc: 94.19%, val_loss: 2.334300, val_acc: 54.69%\n",
      "Epoch [1380]/[5000], train_loss: 0.079000, train_acc: 93.95%, val_loss: 2.246500, val_acc: 51.30%\n",
      "Epoch [1381]/[5000], train_loss: 0.117600, train_acc: 92.04%, val_loss: 2.208500, val_acc: 52.99%\n",
      "Epoch [1382]/[5000], train_loss: 0.111500, train_acc: 91.75%, val_loss: 2.318700, val_acc: 55.99%\n",
      "Epoch [1383]/[5000], train_loss: 0.077200, train_acc: 93.16%, val_loss: 2.599500, val_acc: 53.91%\n",
      "Epoch [1384]/[5000], train_loss: 0.090700, train_acc: 92.82%, val_loss: 2.383000, val_acc: 51.17%\n",
      "Epoch [1385]/[5000], train_loss: 0.069600, train_acc: 93.90%, val_loss: 2.206300, val_acc: 55.08%\n",
      "Epoch [1386]/[5000], train_loss: 0.103600, train_acc: 92.48%, val_loss: 2.398600, val_acc: 53.52%\n",
      "Epoch [1387]/[5000], train_loss: 0.089700, train_acc: 92.97%, val_loss: 2.474400, val_acc: 52.21%\n",
      "Epoch [1388]/[5000], train_loss: 0.098700, train_acc: 92.43%, val_loss: 2.314800, val_acc: 52.99%\n",
      "Epoch [1389]/[5000], train_loss: 0.095200, train_acc: 92.82%, val_loss: 2.341200, val_acc: 51.69%\n",
      "Epoch [1390]/[5000], train_loss: 0.107800, train_acc: 92.19%, val_loss: 2.200600, val_acc: 51.82%\n",
      "Epoch [1391]/[5000], train_loss: 0.092500, train_acc: 93.12%, val_loss: 2.433400, val_acc: 48.83%\n",
      "Epoch [1392]/[5000], train_loss: 0.103400, train_acc: 92.68%, val_loss: 2.461000, val_acc: 56.51%\n",
      "Epoch [1393]/[5000], train_loss: 0.089500, train_acc: 93.12%, val_loss: 2.399000, val_acc: 54.04%\n",
      "Epoch [1394]/[5000], train_loss: 0.095500, train_acc: 92.53%, val_loss: 2.378300, val_acc: 53.78%\n",
      "Epoch [1395]/[5000], train_loss: 0.081500, train_acc: 93.31%, val_loss: 2.270400, val_acc: 55.73%\n",
      "Epoch [1396]/[5000], train_loss: 0.076500, train_acc: 93.46%, val_loss: 2.161800, val_acc: 54.30%\n",
      "Epoch [1397]/[5000], train_loss: 0.057900, train_acc: 93.99%, val_loss: 2.433300, val_acc: 53.65%\n",
      "Epoch [1398]/[5000], train_loss: 0.066600, train_acc: 93.99%, val_loss: 2.128300, val_acc: 53.52%\n",
      "Epoch [1399]/[5000], train_loss: 0.067600, train_acc: 93.95%, val_loss: 2.363000, val_acc: 51.56%\n",
      "Epoch [1400]/[5000], train_loss: 0.087300, train_acc: 93.16%, val_loss: 2.776100, val_acc: 54.95%\n",
      "Epoch [1401]/[5000], train_loss: 0.075400, train_acc: 93.26%, val_loss: 2.391300, val_acc: 53.65%\n",
      "Epoch [1402]/[5000], train_loss: 0.077000, train_acc: 93.16%, val_loss: 2.497800, val_acc: 52.47%\n",
      "Epoch [1403]/[5000], train_loss: 0.064300, train_acc: 93.65%, val_loss: 2.406700, val_acc: 53.12%\n",
      "Epoch [1404]/[5000], train_loss: 0.069500, train_acc: 93.80%, val_loss: 2.479600, val_acc: 54.04%\n",
      "Epoch [1405]/[5000], train_loss: 0.091900, train_acc: 92.58%, val_loss: 2.403700, val_acc: 51.69%\n",
      "Epoch [1406]/[5000], train_loss: 0.095400, train_acc: 93.12%, val_loss: 2.214600, val_acc: 51.82%\n",
      "Epoch [1407]/[5000], train_loss: 0.120200, train_acc: 92.24%, val_loss: 2.449000, val_acc: 51.30%\n",
      "Epoch [1408]/[5000], train_loss: 0.083800, train_acc: 92.97%, val_loss: 2.313200, val_acc: 53.52%\n",
      "Epoch [1409]/[5000], train_loss: 0.088600, train_acc: 92.72%, val_loss: 2.489600, val_acc: 50.65%\n",
      "Epoch [1410]/[5000], train_loss: 0.114700, train_acc: 92.04%, val_loss: 2.342800, val_acc: 53.39%\n",
      "Epoch [1411]/[5000], train_loss: 0.084300, train_acc: 92.82%, val_loss: 2.432900, val_acc: 53.52%\n",
      "Epoch [1412]/[5000], train_loss: 0.074300, train_acc: 93.51%, val_loss: 2.268100, val_acc: 51.56%\n",
      "Epoch [1413]/[5000], train_loss: 0.081100, train_acc: 93.02%, val_loss: 2.430900, val_acc: 52.34%\n",
      "Epoch [1414]/[5000], train_loss: 0.073800, train_acc: 93.70%, val_loss: 2.231800, val_acc: 52.34%\n",
      "Epoch [1415]/[5000], train_loss: 0.064300, train_acc: 93.65%, val_loss: 2.192200, val_acc: 53.39%\n",
      "Epoch [1416]/[5000], train_loss: 0.081600, train_acc: 93.21%, val_loss: 2.679400, val_acc: 53.91%\n",
      "Epoch [1417]/[5000], train_loss: 0.095700, train_acc: 92.92%, val_loss: 2.356600, val_acc: 50.91%\n",
      "Epoch [1418]/[5000], train_loss: 0.098100, train_acc: 92.87%, val_loss: 2.340300, val_acc: 54.82%\n",
      "Epoch [1419]/[5000], train_loss: 0.110000, train_acc: 92.58%, val_loss: 2.152300, val_acc: 53.26%\n",
      "Epoch [1420]/[5000], train_loss: 0.100300, train_acc: 92.14%, val_loss: 2.469600, val_acc: 51.82%\n",
      "Epoch [1421]/[5000], train_loss: 0.123100, train_acc: 91.46%, val_loss: 2.522100, val_acc: 51.56%\n",
      "Epoch [1422]/[5000], train_loss: 0.108000, train_acc: 92.29%, val_loss: 2.055000, val_acc: 56.51%\n",
      "Epoch [1423]/[5000], train_loss: 0.074400, train_acc: 93.07%, val_loss: 2.384900, val_acc: 55.08%\n",
      "Epoch [1424]/[5000], train_loss: 0.071200, train_acc: 93.60%, val_loss: 2.140700, val_acc: 54.04%\n",
      "Epoch [1425]/[5000], train_loss: 0.083600, train_acc: 93.55%, val_loss: 2.364500, val_acc: 51.82%\n",
      "Epoch [1426]/[5000], train_loss: 0.077700, train_acc: 93.51%, val_loss: 2.312800, val_acc: 51.56%\n",
      "Epoch [1427]/[5000], train_loss: 0.073600, train_acc: 93.65%, val_loss: 2.485600, val_acc: 48.96%\n",
      "Epoch [1428]/[5000], train_loss: 0.090200, train_acc: 92.92%, val_loss: 2.559300, val_acc: 56.25%\n",
      "Epoch [1429]/[5000], train_loss: 0.072700, train_acc: 93.46%, val_loss: 2.334200, val_acc: 50.52%\n",
      "Epoch [1430]/[5000], train_loss: 0.069800, train_acc: 93.21%, val_loss: 2.932000, val_acc: 51.30%\n",
      "Epoch [1431]/[5000], train_loss: 0.078700, train_acc: 93.31%, val_loss: 2.403300, val_acc: 55.73%\n",
      "Epoch [1432]/[5000], train_loss: 0.068200, train_acc: 93.65%, val_loss: 2.341100, val_acc: 55.47%\n",
      "Epoch [1433]/[5000], train_loss: 0.069300, train_acc: 93.60%, val_loss: 2.402500, val_acc: 53.12%\n",
      "Epoch [1434]/[5000], train_loss: 0.066400, train_acc: 93.21%, val_loss: 2.530000, val_acc: 51.95%\n",
      "Epoch [1435]/[5000], train_loss: 0.086500, train_acc: 93.12%, val_loss: 2.909700, val_acc: 53.26%\n",
      "Epoch [1436]/[5000], train_loss: 0.060300, train_acc: 93.85%, val_loss: 2.405500, val_acc: 52.60%\n",
      "Epoch [1437]/[5000], train_loss: 0.080700, train_acc: 93.02%, val_loss: 2.450900, val_acc: 56.51%\n",
      "Epoch [1438]/[5000], train_loss: 0.089900, train_acc: 92.87%, val_loss: 2.421500, val_acc: 52.60%\n",
      "Epoch [1439]/[5000], train_loss: 0.085200, train_acc: 93.36%, val_loss: 2.676900, val_acc: 53.12%\n",
      "Epoch [1440]/[5000], train_loss: 0.088400, train_acc: 92.97%, val_loss: 2.214000, val_acc: 53.26%\n",
      "Epoch [1441]/[5000], train_loss: 0.110400, train_acc: 92.09%, val_loss: 2.304500, val_acc: 51.69%\n",
      "Epoch [1442]/[5000], train_loss: 0.099600, train_acc: 92.87%, val_loss: 2.518300, val_acc: 51.43%\n",
      "Epoch [1443]/[5000], train_loss: 0.086000, train_acc: 93.26%, val_loss: 2.506800, val_acc: 50.39%\n",
      "Epoch [1444]/[5000], train_loss: 0.085700, train_acc: 92.68%, val_loss: 2.731000, val_acc: 56.51%\n",
      "Epoch [1445]/[5000], train_loss: 0.088600, train_acc: 93.46%, val_loss: 2.570400, val_acc: 55.34%\n",
      "Epoch [1446]/[5000], train_loss: 0.068500, train_acc: 93.90%, val_loss: 2.247000, val_acc: 51.04%\n",
      "Epoch [1447]/[5000], train_loss: 0.076600, train_acc: 93.51%, val_loss: 2.712300, val_acc: 52.60%\n",
      "Epoch [1448]/[5000], train_loss: 0.115300, train_acc: 91.75%, val_loss: 2.596100, val_acc: 55.21%\n",
      "Epoch [1449]/[5000], train_loss: 0.098900, train_acc: 92.38%, val_loss: 2.423700, val_acc: 51.17%\n",
      "Epoch [1450]/[5000], train_loss: 0.078000, train_acc: 93.46%, val_loss: 2.518300, val_acc: 53.91%\n",
      "Epoch [1451]/[5000], train_loss: 0.080700, train_acc: 92.72%, val_loss: 2.465600, val_acc: 51.82%\n",
      "Epoch [1452]/[5000], train_loss: 0.087400, train_acc: 93.02%, val_loss: 2.368400, val_acc: 50.26%\n",
      "Epoch [1453]/[5000], train_loss: 0.080300, train_acc: 93.21%, val_loss: 2.691800, val_acc: 48.70%\n",
      "Epoch [1454]/[5000], train_loss: 0.079200, train_acc: 93.07%, val_loss: 2.617600, val_acc: 53.26%\n",
      "Epoch [1455]/[5000], train_loss: 0.092300, train_acc: 93.07%, val_loss: 2.754700, val_acc: 52.47%\n",
      "Epoch [1456]/[5000], train_loss: 0.122700, train_acc: 92.29%, val_loss: 2.369700, val_acc: 54.95%\n",
      "Epoch [1457]/[5000], train_loss: 0.098200, train_acc: 93.02%, val_loss: 2.242000, val_acc: 53.52%\n",
      "Epoch [1458]/[5000], train_loss: 0.074700, train_acc: 93.02%, val_loss: 2.579300, val_acc: 48.31%\n",
      "Epoch [1459]/[5000], train_loss: 0.085400, train_acc: 93.21%, val_loss: 2.719800, val_acc: 49.48%\n",
      "Epoch [1460]/[5000], train_loss: 0.098200, train_acc: 92.53%, val_loss: 2.413400, val_acc: 54.56%\n",
      "Epoch [1461]/[5000], train_loss: 0.094400, train_acc: 92.77%, val_loss: 2.209100, val_acc: 51.04%\n",
      "Epoch [1462]/[5000], train_loss: 0.084300, train_acc: 93.16%, val_loss: 2.434100, val_acc: 51.30%\n",
      "Epoch [1463]/[5000], train_loss: 0.092500, train_acc: 93.26%, val_loss: 2.791600, val_acc: 53.78%\n",
      "Epoch [1464]/[5000], train_loss: 0.090300, train_acc: 92.97%, val_loss: 2.405300, val_acc: 52.99%\n",
      "Epoch [1465]/[5000], train_loss: 0.084400, train_acc: 92.68%, val_loss: 2.560700, val_acc: 55.21%\n",
      "Epoch [1466]/[5000], train_loss: 0.089800, train_acc: 93.02%, val_loss: 2.535800, val_acc: 49.87%\n",
      "Epoch [1467]/[5000], train_loss: 0.091200, train_acc: 93.46%, val_loss: 2.673300, val_acc: 49.74%\n",
      "Epoch [1468]/[5000], train_loss: 0.112600, train_acc: 91.75%, val_loss: 2.651800, val_acc: 54.43%\n",
      "Epoch [1469]/[5000], train_loss: 0.118600, train_acc: 92.68%, val_loss: 2.739000, val_acc: 50.91%\n",
      "Epoch [1470]/[5000], train_loss: 0.086400, train_acc: 92.92%, val_loss: 2.444900, val_acc: 50.39%\n",
      "Epoch [1471]/[5000], train_loss: 0.111900, train_acc: 92.58%, val_loss: 2.544800, val_acc: 52.73%\n",
      "Epoch [1472]/[5000], train_loss: 0.176900, train_acc: 90.33%, val_loss: 2.583300, val_acc: 46.48%\n",
      "Epoch [1473]/[5000], train_loss: 0.150900, train_acc: 90.87%, val_loss: 2.340700, val_acc: 53.52%\n",
      "Epoch [1474]/[5000], train_loss: 0.131900, train_acc: 91.50%, val_loss: 2.023600, val_acc: 53.78%\n",
      "Epoch [1475]/[5000], train_loss: 0.122500, train_acc: 91.65%, val_loss: 2.375500, val_acc: 53.91%\n",
      "Epoch [1476]/[5000], train_loss: 0.103800, train_acc: 92.43%, val_loss: 2.411900, val_acc: 51.17%\n",
      "Epoch [1477]/[5000], train_loss: 0.079800, train_acc: 93.31%, val_loss: 2.660800, val_acc: 49.74%\n",
      "Epoch [1478]/[5000], train_loss: 0.100300, train_acc: 92.82%, val_loss: 2.536000, val_acc: 49.22%\n",
      "Epoch [1479]/[5000], train_loss: 0.092600, train_acc: 92.48%, val_loss: 2.038400, val_acc: 52.86%\n",
      "Epoch [1480]/[5000], train_loss: 0.089700, train_acc: 93.12%, val_loss: 1.998500, val_acc: 55.21%\n",
      "Epoch [1481]/[5000], train_loss: 0.076200, train_acc: 93.46%, val_loss: 2.663500, val_acc: 51.30%\n",
      "Epoch [1482]/[5000], train_loss: 0.059400, train_acc: 94.09%, val_loss: 2.441400, val_acc: 51.82%\n",
      "Epoch [1483]/[5000], train_loss: 0.084200, train_acc: 93.51%, val_loss: 2.103500, val_acc: 53.26%\n",
      "Epoch [1484]/[5000], train_loss: 0.083900, train_acc: 92.92%, val_loss: 2.544400, val_acc: 51.43%\n",
      "Epoch [1485]/[5000], train_loss: 0.098900, train_acc: 93.02%, val_loss: 2.583600, val_acc: 54.56%\n",
      "Epoch [1486]/[5000], train_loss: 0.098200, train_acc: 92.29%, val_loss: 2.730800, val_acc: 50.78%\n",
      "Epoch [1487]/[5000], train_loss: 0.097200, train_acc: 93.07%, val_loss: 2.251100, val_acc: 53.12%\n",
      "Epoch [1488]/[5000], train_loss: 0.091100, train_acc: 92.92%, val_loss: 2.346800, val_acc: 54.04%\n",
      "Epoch [1489]/[5000], train_loss: 0.087500, train_acc: 92.82%, val_loss: 2.222700, val_acc: 51.82%\n",
      "Epoch [1490]/[5000], train_loss: 0.121000, train_acc: 92.24%, val_loss: 2.630200, val_acc: 52.86%\n",
      "Epoch [1491]/[5000], train_loss: 0.113400, train_acc: 92.43%, val_loss: 2.282900, val_acc: 51.04%\n",
      "Epoch [1492]/[5000], train_loss: 0.080600, train_acc: 93.51%, val_loss: 2.376900, val_acc: 52.86%\n",
      "Epoch [1493]/[5000], train_loss: 0.085500, train_acc: 93.46%, val_loss: 2.081000, val_acc: 54.95%\n",
      "Epoch [1494]/[5000], train_loss: 0.103700, train_acc: 92.97%, val_loss: 2.211800, val_acc: 53.78%\n",
      "Epoch [1495]/[5000], train_loss: 0.092500, train_acc: 93.41%, val_loss: 2.377300, val_acc: 52.73%\n",
      "Epoch [1496]/[5000], train_loss: 0.080300, train_acc: 93.21%, val_loss: 2.480300, val_acc: 52.99%\n",
      "Epoch [1497]/[5000], train_loss: 0.080700, train_acc: 93.41%, val_loss: 2.373300, val_acc: 52.34%\n",
      "Epoch [1498]/[5000], train_loss: 0.076900, train_acc: 93.36%, val_loss: 2.389300, val_acc: 52.99%\n",
      "Epoch [1499]/[5000], train_loss: 0.084100, train_acc: 92.77%, val_loss: 2.517400, val_acc: 52.21%\n",
      "Epoch [1500]/[5000], train_loss: 0.074700, train_acc: 93.26%, val_loss: 2.459900, val_acc: 51.04%\n",
      "Epoch [1501]/[5000], train_loss: 0.054600, train_acc: 94.38%, val_loss: 2.497900, val_acc: 53.39%\n",
      "Epoch [1502]/[5000], train_loss: 0.067400, train_acc: 93.55%, val_loss: 2.285900, val_acc: 53.91%\n",
      "Epoch [1503]/[5000], train_loss: 0.073300, train_acc: 93.60%, val_loss: 2.469700, val_acc: 50.00%\n",
      "Epoch [1504]/[5000], train_loss: 0.060900, train_acc: 93.95%, val_loss: 2.673600, val_acc: 51.17%\n",
      "Epoch [1505]/[5000], train_loss: 0.105300, train_acc: 92.53%, val_loss: 2.388600, val_acc: 50.26%\n",
      "Epoch [1506]/[5000], train_loss: 0.087300, train_acc: 93.46%, val_loss: 2.489700, val_acc: 52.47%\n",
      "Epoch [1507]/[5000], train_loss: 0.101900, train_acc: 92.58%, val_loss: 2.157200, val_acc: 52.34%\n",
      "Epoch [1508]/[5000], train_loss: 0.080300, train_acc: 92.97%, val_loss: 2.317100, val_acc: 54.56%\n",
      "Epoch [1509]/[5000], train_loss: 0.086300, train_acc: 92.53%, val_loss: 2.433100, val_acc: 54.69%\n",
      "Epoch [1510]/[5000], train_loss: 0.096200, train_acc: 93.31%, val_loss: 2.472300, val_acc: 53.26%\n",
      "Epoch [1511]/[5000], train_loss: 0.117300, train_acc: 91.89%, val_loss: 2.379800, val_acc: 54.69%\n",
      "Epoch [1512]/[5000], train_loss: 0.092800, train_acc: 92.82%, val_loss: 2.221900, val_acc: 52.73%\n",
      "Epoch [1513]/[5000], train_loss: 0.102300, train_acc: 92.48%, val_loss: 2.744200, val_acc: 49.22%\n",
      "Epoch [1514]/[5000], train_loss: 0.120400, train_acc: 91.70%, val_loss: 2.436400, val_acc: 51.43%\n",
      "Epoch [1515]/[5000], train_loss: 0.139500, train_acc: 90.53%, val_loss: 2.353700, val_acc: 54.82%\n",
      "Epoch [1516]/[5000], train_loss: 0.116400, train_acc: 91.65%, val_loss: 2.540400, val_acc: 52.73%\n",
      "Epoch [1517]/[5000], train_loss: 0.113000, train_acc: 91.80%, val_loss: 2.122800, val_acc: 51.69%\n",
      "Epoch [1518]/[5000], train_loss: 0.091800, train_acc: 92.24%, val_loss: 2.339800, val_acc: 55.86%\n",
      "Epoch [1519]/[5000], train_loss: 0.083000, train_acc: 93.41%, val_loss: 2.589600, val_acc: 51.04%\n",
      "Epoch [1520]/[5000], train_loss: 0.083700, train_acc: 93.55%, val_loss: 2.377900, val_acc: 54.69%\n",
      "Epoch [1521]/[5000], train_loss: 0.092200, train_acc: 92.68%, val_loss: 2.241600, val_acc: 54.17%\n",
      "Epoch [1522]/[5000], train_loss: 0.083400, train_acc: 93.21%, val_loss: 2.227700, val_acc: 53.78%\n",
      "Epoch [1523]/[5000], train_loss: 0.068000, train_acc: 94.09%, val_loss: 2.404300, val_acc: 54.69%\n",
      "Epoch [1524]/[5000], train_loss: 0.067900, train_acc: 93.80%, val_loss: 2.820800, val_acc: 52.47%\n",
      "Epoch [1525]/[5000], train_loss: 0.088300, train_acc: 92.68%, val_loss: 2.322000, val_acc: 54.95%\n",
      "Epoch [1526]/[5000], train_loss: 0.075800, train_acc: 93.51%, val_loss: 2.366600, val_acc: 54.04%\n",
      "Epoch [1527]/[5000], train_loss: 0.072800, train_acc: 93.41%, val_loss: 2.042500, val_acc: 55.73%\n",
      "Epoch [1528]/[5000], train_loss: 0.081800, train_acc: 93.41%, val_loss: 2.350700, val_acc: 54.56%\n",
      "Epoch [1529]/[5000], train_loss: 0.070400, train_acc: 93.70%, val_loss: 2.530500, val_acc: 50.65%\n",
      "Epoch [1530]/[5000], train_loss: 0.063800, train_acc: 93.90%, val_loss: 2.563500, val_acc: 54.95%\n",
      "Epoch [1531]/[5000], train_loss: 0.068300, train_acc: 93.41%, val_loss: 2.302200, val_acc: 53.78%\n",
      "Epoch [1532]/[5000], train_loss: 0.062200, train_acc: 93.80%, val_loss: 2.604300, val_acc: 51.17%\n",
      "Epoch [1533]/[5000], train_loss: 0.075300, train_acc: 92.87%, val_loss: 2.858300, val_acc: 52.47%\n",
      "Epoch [1534]/[5000], train_loss: 0.062600, train_acc: 93.95%, val_loss: 2.249100, val_acc: 52.21%\n",
      "Epoch [1535]/[5000], train_loss: 0.083100, train_acc: 93.12%, val_loss: 2.486600, val_acc: 53.52%\n",
      "Epoch [1536]/[5000], train_loss: 0.118300, train_acc: 92.33%, val_loss: 2.297000, val_acc: 51.95%\n",
      "Epoch [1537]/[5000], train_loss: 0.138800, train_acc: 91.46%, val_loss: 2.676200, val_acc: 53.26%\n",
      "Epoch [1538]/[5000], train_loss: 0.122800, train_acc: 91.94%, val_loss: 2.972700, val_acc: 51.95%\n",
      "Epoch [1539]/[5000], train_loss: 0.095500, train_acc: 92.87%, val_loss: 2.361400, val_acc: 52.60%\n",
      "Epoch [1540]/[5000], train_loss: 0.105200, train_acc: 92.72%, val_loss: 2.271400, val_acc: 50.26%\n",
      "Epoch [1541]/[5000], train_loss: 0.079300, train_acc: 93.26%, val_loss: 2.147300, val_acc: 53.52%\n",
      "Epoch [1542]/[5000], train_loss: 0.080100, train_acc: 93.26%, val_loss: 2.463400, val_acc: 53.39%\n",
      "Epoch [1543]/[5000], train_loss: 0.081400, train_acc: 93.21%, val_loss: 2.674800, val_acc: 53.91%\n",
      "Epoch [1544]/[5000], train_loss: 0.081200, train_acc: 93.55%, val_loss: 2.193900, val_acc: 54.56%\n",
      "Epoch [1545]/[5000], train_loss: 0.088100, train_acc: 92.82%, val_loss: 2.849200, val_acc: 52.86%\n",
      "Epoch [1546]/[5000], train_loss: 0.110900, train_acc: 92.72%, val_loss: 2.369100, val_acc: 53.39%\n",
      "Epoch [1547]/[5000], train_loss: 0.080000, train_acc: 93.51%, val_loss: 2.312500, val_acc: 47.66%\n",
      "Epoch [1548]/[5000], train_loss: 0.072500, train_acc: 93.46%, val_loss: 2.301900, val_acc: 53.52%\n",
      "Epoch [1549]/[5000], train_loss: 0.069600, train_acc: 93.41%, val_loss: 2.124100, val_acc: 53.52%\n",
      "Epoch [1550]/[5000], train_loss: 0.086000, train_acc: 93.12%, val_loss: 2.409600, val_acc: 55.60%\n",
      "Epoch [1551]/[5000], train_loss: 0.067000, train_acc: 93.70%, val_loss: 2.540500, val_acc: 50.00%\n",
      "Epoch [1552]/[5000], train_loss: 0.077200, train_acc: 93.26%, val_loss: 2.268800, val_acc: 53.12%\n",
      "Epoch [1553]/[5000], train_loss: 0.067400, train_acc: 93.75%, val_loss: 2.514000, val_acc: 54.04%\n",
      "Epoch [1554]/[5000], train_loss: 0.078100, train_acc: 93.55%, val_loss: 2.380400, val_acc: 52.47%\n",
      "Epoch [1555]/[5000], train_loss: 0.098500, train_acc: 91.85%, val_loss: 2.777800, val_acc: 54.82%\n",
      "Epoch [1556]/[5000], train_loss: 0.091600, train_acc: 92.92%, val_loss: 2.313200, val_acc: 49.09%\n",
      "Epoch [1557]/[5000], train_loss: 0.093700, train_acc: 93.07%, val_loss: 2.256900, val_acc: 54.17%\n",
      "Epoch [1558]/[5000], train_loss: 0.069800, train_acc: 93.60%, val_loss: 2.426200, val_acc: 52.21%\n",
      "Epoch [1559]/[5000], train_loss: 0.084500, train_acc: 93.02%, val_loss: 2.515800, val_acc: 52.34%\n",
      "Epoch [1560]/[5000], train_loss: 0.069900, train_acc: 93.55%, val_loss: 2.294200, val_acc: 53.26%\n",
      "Epoch [1561]/[5000], train_loss: 0.074400, train_acc: 93.85%, val_loss: 2.499000, val_acc: 53.39%\n",
      "Epoch [1562]/[5000], train_loss: 0.066700, train_acc: 93.85%, val_loss: 2.314400, val_acc: 52.47%\n",
      "Epoch [1563]/[5000], train_loss: 0.064600, train_acc: 93.55%, val_loss: 2.548000, val_acc: 53.65%\n",
      "Epoch [1564]/[5000], train_loss: 0.049600, train_acc: 94.48%, val_loss: 2.443900, val_acc: 51.04%\n",
      "Epoch [1565]/[5000], train_loss: 0.054900, train_acc: 93.99%, val_loss: 2.187800, val_acc: 55.08%\n",
      "Epoch [1566]/[5000], train_loss: 0.066000, train_acc: 94.34%, val_loss: 2.871500, val_acc: 55.47%\n",
      "Epoch [1567]/[5000], train_loss: 0.094300, train_acc: 92.92%, val_loss: 2.486600, val_acc: 52.99%\n",
      "Epoch [1568]/[5000], train_loss: 0.084200, train_acc: 93.36%, val_loss: 2.318200, val_acc: 56.12%\n",
      "Epoch [1569]/[5000], train_loss: 0.085800, train_acc: 92.87%, val_loss: 2.392800, val_acc: 53.65%\n",
      "Epoch [1570]/[5000], train_loss: 0.108200, train_acc: 92.48%, val_loss: 2.367900, val_acc: 49.87%\n",
      "Epoch [1571]/[5000], train_loss: 0.067500, train_acc: 93.46%, val_loss: 2.235800, val_acc: 52.99%\n",
      "Epoch [1572]/[5000], train_loss: 0.077400, train_acc: 93.07%, val_loss: 2.295400, val_acc: 50.52%\n",
      "Epoch [1573]/[5000], train_loss: 0.066800, train_acc: 93.90%, val_loss: 2.513000, val_acc: 53.78%\n",
      "Epoch [1574]/[5000], train_loss: 0.064000, train_acc: 93.90%, val_loss: 2.598000, val_acc: 53.39%\n",
      "Epoch [1575]/[5000], train_loss: 0.073600, train_acc: 93.60%, val_loss: 2.566600, val_acc: 55.34%\n",
      "Epoch [1576]/[5000], train_loss: 0.081800, train_acc: 93.46%, val_loss: 2.503100, val_acc: 54.95%\n",
      "Epoch [1577]/[5000], train_loss: 0.086400, train_acc: 92.97%, val_loss: 2.102300, val_acc: 54.04%\n",
      "Epoch [1578]/[5000], train_loss: 0.076400, train_acc: 93.16%, val_loss: 2.276100, val_acc: 54.04%\n",
      "Epoch [1579]/[5000], train_loss: 0.061900, train_acc: 94.09%, val_loss: 2.577900, val_acc: 54.17%\n",
      "Epoch [1580]/[5000], train_loss: 0.077300, train_acc: 93.07%, val_loss: 2.558700, val_acc: 54.56%\n",
      "Epoch [1581]/[5000], train_loss: 0.074500, train_acc: 93.99%, val_loss: 2.156700, val_acc: 56.90%\n",
      "Epoch [1582]/[5000], train_loss: 0.078400, train_acc: 93.26%, val_loss: 2.940300, val_acc: 51.30%\n",
      "Epoch [1583]/[5000], train_loss: 0.096000, train_acc: 92.97%, val_loss: 2.579100, val_acc: 47.92%\n",
      "Epoch [1584]/[5000], train_loss: 0.082100, train_acc: 92.97%, val_loss: 2.191000, val_acc: 51.82%\n",
      "Epoch [1585]/[5000], train_loss: 0.089000, train_acc: 93.02%, val_loss: 2.493600, val_acc: 51.95%\n",
      "Epoch [1586]/[5000], train_loss: 0.077700, train_acc: 93.75%, val_loss: 2.371600, val_acc: 56.51%\n",
      "Epoch [1587]/[5000], train_loss: 0.089100, train_acc: 93.21%, val_loss: 2.305100, val_acc: 52.73%\n",
      "Epoch [1588]/[5000], train_loss: 0.094000, train_acc: 92.92%, val_loss: 2.508500, val_acc: 53.65%\n",
      "Epoch [1589]/[5000], train_loss: 0.110600, train_acc: 91.89%, val_loss: 2.151000, val_acc: 52.99%\n",
      "Epoch [1590]/[5000], train_loss: 0.102900, train_acc: 92.53%, val_loss: 2.327800, val_acc: 55.08%\n",
      "Epoch [1591]/[5000], train_loss: 0.104600, train_acc: 91.94%, val_loss: 2.374300, val_acc: 52.34%\n",
      "Epoch [1592]/[5000], train_loss: 0.110400, train_acc: 91.89%, val_loss: 2.127800, val_acc: 54.95%\n",
      "Epoch [1593]/[5000], train_loss: 0.087700, train_acc: 92.77%, val_loss: 2.466500, val_acc: 53.65%\n",
      "Epoch [1594]/[5000], train_loss: 0.087600, train_acc: 92.68%, val_loss: 2.342600, val_acc: 52.73%\n",
      "Epoch [1595]/[5000], train_loss: 0.083300, train_acc: 93.41%, val_loss: 2.371000, val_acc: 53.12%\n",
      "Epoch [1596]/[5000], train_loss: 0.084200, train_acc: 93.16%, val_loss: 2.453500, val_acc: 52.21%\n",
      "Epoch [1597]/[5000], train_loss: 0.069600, train_acc: 93.55%, val_loss: 2.186600, val_acc: 54.04%\n",
      "Epoch [1598]/[5000], train_loss: 0.080900, train_acc: 93.16%, val_loss: 2.404000, val_acc: 54.30%\n",
      "Epoch [1599]/[5000], train_loss: 0.082800, train_acc: 92.92%, val_loss: 2.642800, val_acc: 53.52%\n",
      "Epoch [1600]/[5000], train_loss: 0.060700, train_acc: 94.04%, val_loss: 2.253300, val_acc: 55.60%\n",
      "Epoch [1601]/[5000], train_loss: 0.070700, train_acc: 93.55%, val_loss: 2.516400, val_acc: 53.12%\n",
      "Epoch [1602]/[5000], train_loss: 0.083500, train_acc: 93.07%, val_loss: 2.439700, val_acc: 53.39%\n",
      "Epoch [1603]/[5000], train_loss: 0.073500, train_acc: 93.75%, val_loss: 2.294200, val_acc: 55.47%\n",
      "Epoch [1604]/[5000], train_loss: 0.078500, train_acc: 93.80%, val_loss: 2.659100, val_acc: 53.65%\n",
      "Epoch [1605]/[5000], train_loss: 0.079200, train_acc: 93.16%, val_loss: 2.763200, val_acc: 53.65%\n",
      "Epoch [1606]/[5000], train_loss: 0.091600, train_acc: 93.02%, val_loss: 2.741600, val_acc: 55.99%\n",
      "Epoch [1607]/[5000], train_loss: 0.065800, train_acc: 94.34%, val_loss: 2.390200, val_acc: 54.95%\n",
      "Epoch [1608]/[5000], train_loss: 0.097500, train_acc: 92.92%, val_loss: 2.677900, val_acc: 51.04%\n",
      "Epoch [1609]/[5000], train_loss: 0.100100, train_acc: 93.12%, val_loss: 2.473800, val_acc: 53.65%\n",
      "Epoch [1610]/[5000], train_loss: 0.120200, train_acc: 91.70%, val_loss: 2.565900, val_acc: 51.04%\n",
      "Epoch [1611]/[5000], train_loss: 0.115700, train_acc: 91.80%, val_loss: 2.487400, val_acc: 54.82%\n",
      "Epoch [1612]/[5000], train_loss: 0.102800, train_acc: 92.48%, val_loss: 2.144100, val_acc: 54.69%\n",
      "Epoch [1613]/[5000], train_loss: 0.103100, train_acc: 92.63%, val_loss: 2.566300, val_acc: 54.04%\n",
      "Epoch [1614]/[5000], train_loss: 0.111000, train_acc: 92.29%, val_loss: 2.335200, val_acc: 51.82%\n",
      "Epoch [1615]/[5000], train_loss: 0.088400, train_acc: 93.16%, val_loss: 2.293900, val_acc: 55.34%\n",
      "Epoch [1616]/[5000], train_loss: 0.092400, train_acc: 93.12%, val_loss: 2.558000, val_acc: 54.82%\n",
      "Epoch [1617]/[5000], train_loss: 0.064600, train_acc: 93.70%, val_loss: 2.448300, val_acc: 54.04%\n",
      "Epoch [1618]/[5000], train_loss: 0.072600, train_acc: 93.41%, val_loss: 2.566700, val_acc: 51.82%\n",
      "Epoch [1619]/[5000], train_loss: 0.071200, train_acc: 93.55%, val_loss: 2.851400, val_acc: 56.64%\n",
      "Epoch [1620]/[5000], train_loss: 0.066800, train_acc: 93.51%, val_loss: 2.312200, val_acc: 51.95%\n",
      "Epoch [1621]/[5000], train_loss: 0.065900, train_acc: 94.09%, val_loss: 2.643800, val_acc: 54.04%\n",
      "Epoch [1622]/[5000], train_loss: 0.061400, train_acc: 93.75%, val_loss: 2.751000, val_acc: 53.12%\n",
      "Epoch [1623]/[5000], train_loss: 0.069700, train_acc: 93.95%, val_loss: 2.593900, val_acc: 55.34%\n",
      "Epoch [1624]/[5000], train_loss: 0.061600, train_acc: 94.19%, val_loss: 2.451500, val_acc: 53.39%\n",
      "Epoch [1625]/[5000], train_loss: 0.057700, train_acc: 94.34%, val_loss: 2.442400, val_acc: 52.86%\n",
      "Epoch [1626]/[5000], train_loss: 0.078900, train_acc: 93.65%, val_loss: 2.524400, val_acc: 55.21%\n",
      "Epoch [1627]/[5000], train_loss: 0.060700, train_acc: 94.24%, val_loss: 2.462300, val_acc: 54.04%\n",
      "Epoch [1628]/[5000], train_loss: 0.075500, train_acc: 93.51%, val_loss: 2.870900, val_acc: 52.99%\n",
      "Epoch [1629]/[5000], train_loss: 0.071300, train_acc: 93.36%, val_loss: 2.415000, val_acc: 48.83%\n",
      "Epoch [1630]/[5000], train_loss: 0.069700, train_acc: 93.46%, val_loss: 2.263900, val_acc: 51.95%\n",
      "Epoch [1631]/[5000], train_loss: 0.062600, train_acc: 93.75%, val_loss: 2.459400, val_acc: 55.34%\n",
      "Epoch [1632]/[5000], train_loss: 0.076700, train_acc: 93.55%, val_loss: 2.510800, val_acc: 53.12%\n",
      "Epoch [1633]/[5000], train_loss: 0.067100, train_acc: 93.99%, val_loss: 2.551100, val_acc: 52.34%\n",
      "Epoch [1634]/[5000], train_loss: 0.063700, train_acc: 93.46%, val_loss: 2.573000, val_acc: 54.95%\n",
      "Epoch [1635]/[5000], train_loss: 0.073100, train_acc: 93.65%, val_loss: 2.713100, val_acc: 55.08%\n",
      "Epoch [1636]/[5000], train_loss: 0.074700, train_acc: 93.99%, val_loss: 2.557800, val_acc: 53.52%\n",
      "Epoch [1637]/[5000], train_loss: 0.081300, train_acc: 93.07%, val_loss: 2.628500, val_acc: 52.47%\n",
      "Epoch [1638]/[5000], train_loss: 0.074400, train_acc: 94.04%, val_loss: 2.646000, val_acc: 53.91%\n",
      "Epoch [1639]/[5000], train_loss: 0.068900, train_acc: 93.60%, val_loss: 2.298500, val_acc: 54.43%\n",
      "Epoch [1640]/[5000], train_loss: 0.082100, train_acc: 93.55%, val_loss: 2.645100, val_acc: 57.16%\n",
      "Epoch [1641]/[5000], train_loss: 0.069900, train_acc: 93.90%, val_loss: 2.449100, val_acc: 54.95%\n",
      "Epoch [1642]/[5000], train_loss: 0.120100, train_acc: 91.89%, val_loss: 2.552500, val_acc: 54.82%\n",
      "Epoch [1643]/[5000], train_loss: 0.068900, train_acc: 93.31%, val_loss: 2.838400, val_acc: 50.78%\n",
      "Epoch [1644]/[5000], train_loss: 0.072700, train_acc: 93.16%, val_loss: 2.352800, val_acc: 55.08%\n",
      "Epoch [1645]/[5000], train_loss: 0.074700, train_acc: 93.41%, val_loss: 2.738200, val_acc: 52.60%\n",
      "Epoch [1646]/[5000], train_loss: 0.058300, train_acc: 93.90%, val_loss: 2.330700, val_acc: 53.12%\n",
      "Epoch [1647]/[5000], train_loss: 0.072800, train_acc: 93.41%, val_loss: 2.560200, val_acc: 54.17%\n",
      "Epoch [1648]/[5000], train_loss: 0.069800, train_acc: 93.60%, val_loss: 2.550900, val_acc: 53.39%\n",
      "Epoch [1649]/[5000], train_loss: 0.096500, train_acc: 92.53%, val_loss: 2.518400, val_acc: 52.21%\n",
      "Epoch [1650]/[5000], train_loss: 0.094800, train_acc: 93.02%, val_loss: 2.572000, val_acc: 51.69%\n",
      "Epoch [1651]/[5000], train_loss: 0.077700, train_acc: 93.21%, val_loss: 2.604300, val_acc: 51.82%\n",
      "Epoch [1652]/[5000], train_loss: 0.102000, train_acc: 92.63%, val_loss: 2.516800, val_acc: 53.65%\n",
      "Epoch [1653]/[5000], train_loss: 0.088700, train_acc: 92.87%, val_loss: 2.225300, val_acc: 52.73%\n",
      "Epoch [1654]/[5000], train_loss: 0.072400, train_acc: 93.31%, val_loss: 2.637900, val_acc: 51.43%\n",
      "Epoch [1655]/[5000], train_loss: 0.072800, train_acc: 93.31%, val_loss: 2.560600, val_acc: 53.52%\n",
      "Epoch [1656]/[5000], train_loss: 0.093400, train_acc: 93.02%, val_loss: 2.582600, val_acc: 52.86%\n",
      "Epoch [1657]/[5000], train_loss: 0.097800, train_acc: 92.33%, val_loss: 2.984800, val_acc: 52.60%\n",
      "Epoch [1658]/[5000], train_loss: 0.087300, train_acc: 93.07%, val_loss: 2.548100, val_acc: 53.39%\n",
      "Epoch [1659]/[5000], train_loss: 0.107000, train_acc: 92.29%, val_loss: 2.632100, val_acc: 52.08%\n",
      "Epoch [1660]/[5000], train_loss: 0.089400, train_acc: 92.68%, val_loss: 2.502700, val_acc: 53.52%\n",
      "Epoch [1661]/[5000], train_loss: 0.069600, train_acc: 93.99%, val_loss: 2.434800, val_acc: 52.99%\n",
      "Epoch [1662]/[5000], train_loss: 0.088300, train_acc: 92.87%, val_loss: 2.418900, val_acc: 54.82%\n",
      "Epoch [1663]/[5000], train_loss: 0.075900, train_acc: 93.99%, val_loss: 2.330700, val_acc: 53.12%\n",
      "Epoch [1664]/[5000], train_loss: 0.083900, train_acc: 93.85%, val_loss: 2.636000, val_acc: 52.60%\n",
      "Epoch [1665]/[5000], train_loss: 0.112600, train_acc: 92.53%, val_loss: 2.310100, val_acc: 50.91%\n",
      "Epoch [1666]/[5000], train_loss: 0.133600, train_acc: 92.09%, val_loss: 2.376900, val_acc: 51.43%\n",
      "Epoch [1667]/[5000], train_loss: 0.095100, train_acc: 93.07%, val_loss: 2.436900, val_acc: 50.13%\n",
      "Epoch [1668]/[5000], train_loss: 0.118400, train_acc: 91.75%, val_loss: 2.162200, val_acc: 49.09%\n",
      "Epoch [1669]/[5000], train_loss: 0.120300, train_acc: 91.46%, val_loss: 2.762700, val_acc: 50.39%\n",
      "Epoch [1670]/[5000], train_loss: 0.137800, train_acc: 91.55%, val_loss: 2.253100, val_acc: 52.08%\n",
      "Epoch [1671]/[5000], train_loss: 0.077000, train_acc: 93.41%, val_loss: 2.461900, val_acc: 53.12%\n",
      "Epoch [1672]/[5000], train_loss: 0.070500, train_acc: 93.75%, val_loss: 2.226900, val_acc: 54.04%\n",
      "Epoch [1673]/[5000], train_loss: 0.085300, train_acc: 92.87%, val_loss: 2.354800, val_acc: 51.56%\n",
      "Epoch [1674]/[5000], train_loss: 0.086000, train_acc: 92.82%, val_loss: 2.390400, val_acc: 51.17%\n",
      "Epoch [1675]/[5000], train_loss: 0.083000, train_acc: 92.82%, val_loss: 2.354900, val_acc: 50.13%\n",
      "Epoch [1676]/[5000], train_loss: 0.080900, train_acc: 93.26%, val_loss: 2.327000, val_acc: 54.82%\n",
      "Epoch [1677]/[5000], train_loss: 0.082100, train_acc: 93.21%, val_loss: 2.400600, val_acc: 54.43%\n",
      "Epoch [1678]/[5000], train_loss: 0.091700, train_acc: 92.58%, val_loss: 2.197000, val_acc: 55.73%\n",
      "Epoch [1679]/[5000], train_loss: 0.060300, train_acc: 93.65%, val_loss: 2.560900, val_acc: 56.90%\n",
      "Epoch [1680]/[5000], train_loss: 0.060800, train_acc: 93.85%, val_loss: 2.332400, val_acc: 51.17%\n",
      "Epoch [1681]/[5000], train_loss: 0.067400, train_acc: 93.41%, val_loss: 2.107500, val_acc: 55.47%\n",
      "Epoch [1682]/[5000], train_loss: 0.055700, train_acc: 94.24%, val_loss: 3.276700, val_acc: 52.21%\n",
      "Epoch [1683]/[5000], train_loss: 0.051900, train_acc: 94.04%, val_loss: 2.548400, val_acc: 54.69%\n",
      "Epoch [1684]/[5000], train_loss: 0.064200, train_acc: 93.99%, val_loss: 2.306700, val_acc: 54.69%\n",
      "Epoch [1685]/[5000], train_loss: 0.057900, train_acc: 94.24%, val_loss: 2.444500, val_acc: 51.82%\n",
      "Epoch [1686]/[5000], train_loss: 0.071200, train_acc: 93.31%, val_loss: 2.312700, val_acc: 53.91%\n",
      "Epoch [1687]/[5000], train_loss: 0.069800, train_acc: 93.70%, val_loss: 2.553400, val_acc: 51.82%\n",
      "Epoch [1688]/[5000], train_loss: 0.074800, train_acc: 93.55%, val_loss: 2.207800, val_acc: 54.95%\n",
      "Epoch [1689]/[5000], train_loss: 0.083000, train_acc: 93.31%, val_loss: 2.203600, val_acc: 54.43%\n",
      "Epoch [1690]/[5000], train_loss: 0.089800, train_acc: 92.92%, val_loss: 2.788400, val_acc: 54.43%\n",
      "Epoch [1691]/[5000], train_loss: 0.087700, train_acc: 93.02%, val_loss: 2.503100, val_acc: 51.69%\n",
      "Epoch [1692]/[5000], train_loss: 0.066900, train_acc: 93.70%, val_loss: 2.226800, val_acc: 54.17%\n",
      "Epoch [1693]/[5000], train_loss: 0.081300, train_acc: 93.41%, val_loss: 2.548300, val_acc: 55.47%\n",
      "Epoch [1694]/[5000], train_loss: 0.073500, train_acc: 93.26%, val_loss: 2.454300, val_acc: 49.09%\n",
      "Epoch [1695]/[5000], train_loss: 0.081700, train_acc: 93.26%, val_loss: 2.395600, val_acc: 51.69%\n",
      "Epoch [1696]/[5000], train_loss: 0.083500, train_acc: 92.97%, val_loss: 2.520200, val_acc: 54.69%\n",
      "Epoch [1697]/[5000], train_loss: 0.070700, train_acc: 93.55%, val_loss: 2.568100, val_acc: 53.65%\n",
      "Epoch [1698]/[5000], train_loss: 0.062500, train_acc: 94.09%, val_loss: 2.704000, val_acc: 54.30%\n",
      "Epoch [1699]/[5000], train_loss: 0.051500, train_acc: 94.78%, val_loss: 2.377900, val_acc: 54.56%\n",
      "Epoch [1700]/[5000], train_loss: 0.042100, train_acc: 94.34%, val_loss: 2.601400, val_acc: 52.21%\n",
      "Epoch [1701]/[5000], train_loss: 0.044100, train_acc: 94.58%, val_loss: 2.337100, val_acc: 54.43%\n",
      "Epoch [1702]/[5000], train_loss: 0.060500, train_acc: 94.14%, val_loss: 2.570300, val_acc: 55.08%\n",
      "Epoch [1703]/[5000], train_loss: 0.056300, train_acc: 94.53%, val_loss: 2.173000, val_acc: 53.78%\n",
      "Epoch [1704]/[5000], train_loss: 0.099500, train_acc: 92.68%, val_loss: 2.456300, val_acc: 53.78%\n",
      "Epoch [1705]/[5000], train_loss: 0.094700, train_acc: 92.92%, val_loss: 2.686300, val_acc: 54.17%\n",
      "Epoch [1706]/[5000], train_loss: 0.110500, train_acc: 92.09%, val_loss: 2.502800, val_acc: 52.60%\n",
      "Epoch [1707]/[5000], train_loss: 0.105600, train_acc: 92.14%, val_loss: 2.678400, val_acc: 52.60%\n",
      "Epoch [1708]/[5000], train_loss: 0.119100, train_acc: 91.99%, val_loss: 2.777900, val_acc: 51.04%\n",
      "Epoch [1709]/[5000], train_loss: 0.094700, train_acc: 92.87%, val_loss: 2.730800, val_acc: 54.30%\n",
      "Epoch [1710]/[5000], train_loss: 0.107100, train_acc: 92.58%, val_loss: 2.725800, val_acc: 52.21%\n",
      "Epoch [1711]/[5000], train_loss: 0.112800, train_acc: 92.29%, val_loss: 2.428000, val_acc: 51.69%\n",
      "Epoch [1712]/[5000], train_loss: 0.094000, train_acc: 92.87%, val_loss: 2.133600, val_acc: 54.17%\n",
      "Epoch [1713]/[5000], train_loss: 0.068700, train_acc: 93.60%, val_loss: 2.400700, val_acc: 55.08%\n",
      "Epoch [1714]/[5000], train_loss: 0.086700, train_acc: 93.41%, val_loss: 2.181900, val_acc: 54.82%\n",
      "Epoch [1715]/[5000], train_loss: 0.081100, train_acc: 93.07%, val_loss: 2.492600, val_acc: 52.86%\n",
      "Epoch [1716]/[5000], train_loss: 0.078700, train_acc: 93.31%, val_loss: 2.320800, val_acc: 55.73%\n",
      "Epoch [1717]/[5000], train_loss: 0.093000, train_acc: 93.02%, val_loss: 2.525200, val_acc: 53.39%\n",
      "Epoch [1718]/[5000], train_loss: 0.084700, train_acc: 93.16%, val_loss: 2.709300, val_acc: 55.60%\n",
      "Epoch [1719]/[5000], train_loss: 0.070800, train_acc: 93.36%, val_loss: 2.353900, val_acc: 52.34%\n",
      "Epoch [1720]/[5000], train_loss: 0.073800, train_acc: 93.85%, val_loss: 2.273300, val_acc: 53.12%\n",
      "Epoch [1721]/[5000], train_loss: 0.061300, train_acc: 94.24%, val_loss: 2.525600, val_acc: 54.30%\n",
      "Epoch [1722]/[5000], train_loss: 0.068100, train_acc: 93.55%, val_loss: 2.299800, val_acc: 54.17%\n",
      "Epoch [1723]/[5000], train_loss: 0.058900, train_acc: 94.04%, val_loss: 2.929100, val_acc: 53.39%\n",
      "Epoch [1724]/[5000], train_loss: 0.054300, train_acc: 94.14%, val_loss: 2.961100, val_acc: 54.82%\n",
      "Epoch [1725]/[5000], train_loss: 0.058800, train_acc: 93.90%, val_loss: 2.541700, val_acc: 52.08%\n",
      "Epoch [1726]/[5000], train_loss: 0.056800, train_acc: 93.65%, val_loss: 2.354500, val_acc: 50.78%\n",
      "Epoch [1727]/[5000], train_loss: 0.057600, train_acc: 93.90%, val_loss: 2.332800, val_acc: 55.47%\n",
      "Epoch [1728]/[5000], train_loss: 0.064900, train_acc: 93.99%, val_loss: 2.249700, val_acc: 55.47%\n",
      "Epoch [1729]/[5000], train_loss: 0.070000, train_acc: 93.60%, val_loss: 2.341400, val_acc: 49.74%\n",
      "Epoch [1730]/[5000], train_loss: 0.108200, train_acc: 92.53%, val_loss: 2.934600, val_acc: 51.56%\n",
      "Epoch [1731]/[5000], train_loss: 0.100700, train_acc: 92.48%, val_loss: 2.554200, val_acc: 48.96%\n",
      "Epoch [1732]/[5000], train_loss: 0.111300, train_acc: 92.14%, val_loss: 2.260500, val_acc: 56.64%\n",
      "Epoch [1733]/[5000], train_loss: 0.090700, train_acc: 92.82%, val_loss: 2.255800, val_acc: 52.34%\n",
      "Epoch [1734]/[5000], train_loss: 0.073300, train_acc: 93.60%, val_loss: 2.294700, val_acc: 51.95%\n",
      "Epoch [1735]/[5000], train_loss: 0.052100, train_acc: 94.14%, val_loss: 2.428200, val_acc: 53.91%\n",
      "Epoch [1736]/[5000], train_loss: 0.072700, train_acc: 93.80%, val_loss: 2.641800, val_acc: 53.12%\n",
      "Epoch [1737]/[5000], train_loss: 0.064800, train_acc: 93.95%, val_loss: 2.577500, val_acc: 54.30%\n",
      "Epoch [1738]/[5000], train_loss: 0.090900, train_acc: 93.07%, val_loss: 2.510000, val_acc: 51.43%\n",
      "Epoch [1739]/[5000], train_loss: 0.088100, train_acc: 92.77%, val_loss: 2.596800, val_acc: 52.08%\n",
      "Epoch [1740]/[5000], train_loss: 0.065400, train_acc: 94.19%, val_loss: 2.463900, val_acc: 53.39%\n",
      "Epoch [1741]/[5000], train_loss: 0.066800, train_acc: 93.75%, val_loss: 2.542700, val_acc: 53.91%\n",
      "Epoch [1742]/[5000], train_loss: 0.068600, train_acc: 93.36%, val_loss: 2.549300, val_acc: 53.52%\n",
      "Epoch [1743]/[5000], train_loss: 0.050300, train_acc: 94.43%, val_loss: 2.397600, val_acc: 54.82%\n",
      "Epoch [1744]/[5000], train_loss: 0.072200, train_acc: 93.80%, val_loss: 2.482100, val_acc: 53.26%\n",
      "Epoch [1745]/[5000], train_loss: 0.078600, train_acc: 93.51%, val_loss: 2.306200, val_acc: 53.39%\n",
      "Epoch [1746]/[5000], train_loss: 0.091400, train_acc: 93.16%, val_loss: 2.711500, val_acc: 53.78%\n",
      "Epoch [1747]/[5000], train_loss: 0.089300, train_acc: 92.82%, val_loss: 2.625900, val_acc: 54.04%\n",
      "Epoch [1748]/[5000], train_loss: 0.069900, train_acc: 93.60%, val_loss: 2.319600, val_acc: 52.21%\n",
      "Epoch [1749]/[5000], train_loss: 0.095700, train_acc: 92.72%, val_loss: 2.448200, val_acc: 51.04%\n",
      "Epoch [1750]/[5000], train_loss: 0.090500, train_acc: 93.02%, val_loss: 2.936400, val_acc: 50.78%\n",
      "Epoch [1751]/[5000], train_loss: 0.068100, train_acc: 94.09%, val_loss: 2.408000, val_acc: 53.91%\n",
      "Epoch [1752]/[5000], train_loss: 0.064200, train_acc: 93.90%, val_loss: 2.331400, val_acc: 52.34%\n",
      "Epoch [1753]/[5000], train_loss: 0.074700, train_acc: 93.65%, val_loss: 2.366900, val_acc: 53.91%\n",
      "Epoch [1754]/[5000], train_loss: 0.062700, train_acc: 94.29%, val_loss: 2.451300, val_acc: 54.82%\n",
      "Epoch [1755]/[5000], train_loss: 0.058900, train_acc: 93.95%, val_loss: 2.399500, val_acc: 53.12%\n",
      "Epoch [1756]/[5000], train_loss: 0.059000, train_acc: 93.99%, val_loss: 2.789300, val_acc: 52.73%\n",
      "Epoch [1757]/[5000], train_loss: 0.077800, train_acc: 93.75%, val_loss: 2.397100, val_acc: 53.78%\n",
      "Epoch [1758]/[5000], train_loss: 0.074000, train_acc: 93.55%, val_loss: 2.696800, val_acc: 53.52%\n",
      "Epoch [1759]/[5000], train_loss: 0.068200, train_acc: 93.70%, val_loss: 2.584500, val_acc: 54.69%\n",
      "Epoch [1760]/[5000], train_loss: 0.072700, train_acc: 93.21%, val_loss: 2.324800, val_acc: 52.08%\n",
      "Epoch [1761]/[5000], train_loss: 0.073900, train_acc: 93.80%, val_loss: 2.834200, val_acc: 53.78%\n",
      "Epoch [1762]/[5000], train_loss: 0.079400, train_acc: 93.36%, val_loss: 2.574600, val_acc: 55.08%\n",
      "Epoch [1763]/[5000], train_loss: 0.081600, train_acc: 93.46%, val_loss: 2.333800, val_acc: 54.43%\n",
      "Epoch [1764]/[5000], train_loss: 0.076300, train_acc: 93.41%, val_loss: 2.208900, val_acc: 53.26%\n",
      "Epoch [1765]/[5000], train_loss: 0.093000, train_acc: 92.63%, val_loss: 2.335600, val_acc: 55.34%\n",
      "Epoch [1766]/[5000], train_loss: 0.079000, train_acc: 93.26%, val_loss: 2.333500, val_acc: 53.65%\n",
      "Epoch [1767]/[5000], train_loss: 0.094400, train_acc: 93.07%, val_loss: 2.565000, val_acc: 53.12%\n",
      "Epoch [1768]/[5000], train_loss: 0.111100, train_acc: 92.72%, val_loss: 2.564600, val_acc: 55.21%\n",
      "Epoch [1769]/[5000], train_loss: 0.086900, train_acc: 93.60%, val_loss: 2.646400, val_acc: 54.82%\n",
      "Epoch [1770]/[5000], train_loss: 0.092300, train_acc: 92.82%, val_loss: 2.774100, val_acc: 53.12%\n",
      "Epoch [1771]/[5000], train_loss: 0.081700, train_acc: 93.31%, val_loss: 2.228000, val_acc: 53.52%\n",
      "Epoch [1772]/[5000], train_loss: 0.072200, train_acc: 93.26%, val_loss: 2.547700, val_acc: 55.86%\n",
      "Epoch [1773]/[5000], train_loss: 0.071700, train_acc: 93.41%, val_loss: 2.695700, val_acc: 51.17%\n",
      "Epoch [1774]/[5000], train_loss: 0.064700, train_acc: 94.04%, val_loss: 2.688100, val_acc: 56.38%\n",
      "Epoch [1775]/[5000], train_loss: 0.055900, train_acc: 94.04%, val_loss: 2.327600, val_acc: 53.39%\n",
      "Epoch [1776]/[5000], train_loss: 0.059400, train_acc: 94.38%, val_loss: 2.354700, val_acc: 52.60%\n",
      "Epoch [1777]/[5000], train_loss: 0.055800, train_acc: 94.09%, val_loss: 2.634800, val_acc: 52.21%\n",
      "Epoch [1778]/[5000], train_loss: 0.069800, train_acc: 93.70%, val_loss: 2.427100, val_acc: 52.99%\n",
      "Epoch [1779]/[5000], train_loss: 0.051200, train_acc: 94.43%, val_loss: 2.455500, val_acc: 52.86%\n",
      "Epoch [1780]/[5000], train_loss: 0.068000, train_acc: 93.85%, val_loss: 2.549500, val_acc: 52.60%\n",
      "Epoch [1781]/[5000], train_loss: 0.065300, train_acc: 93.75%, val_loss: 2.605700, val_acc: 53.26%\n",
      "Epoch [1782]/[5000], train_loss: 0.082000, train_acc: 93.12%, val_loss: 2.438000, val_acc: 53.39%\n",
      "Epoch [1783]/[5000], train_loss: 0.043700, train_acc: 94.68%, val_loss: 2.313600, val_acc: 53.52%\n",
      "Epoch [1784]/[5000], train_loss: 0.067800, train_acc: 93.46%, val_loss: 2.240800, val_acc: 54.17%\n",
      "Epoch [1785]/[5000], train_loss: 0.055100, train_acc: 94.58%, val_loss: 2.424000, val_acc: 52.60%\n",
      "Epoch [1786]/[5000], train_loss: 0.055400, train_acc: 94.14%, val_loss: 2.354700, val_acc: 55.60%\n",
      "Epoch [1787]/[5000], train_loss: 0.060400, train_acc: 93.99%, val_loss: 2.504200, val_acc: 53.78%\n",
      "Epoch [1788]/[5000], train_loss: 0.078800, train_acc: 93.95%, val_loss: 2.391900, val_acc: 51.69%\n",
      "Epoch [1789]/[5000], train_loss: 0.054500, train_acc: 94.43%, val_loss: 2.476900, val_acc: 55.60%\n",
      "Epoch [1790]/[5000], train_loss: 0.057700, train_acc: 93.99%, val_loss: 2.171000, val_acc: 54.82%\n",
      "Epoch [1791]/[5000], train_loss: 0.062100, train_acc: 93.99%, val_loss: 2.908100, val_acc: 53.65%\n",
      "Epoch [1792]/[5000], train_loss: 0.055500, train_acc: 94.14%, val_loss: 2.339300, val_acc: 55.60%\n",
      "Epoch [1793]/[5000], train_loss: 0.055600, train_acc: 94.09%, val_loss: 2.486800, val_acc: 55.21%\n",
      "Epoch [1794]/[5000], train_loss: 0.049100, train_acc: 94.38%, val_loss: 2.416000, val_acc: 56.64%\n",
      "Epoch [1795]/[5000], train_loss: 0.052300, train_acc: 94.34%, val_loss: 2.680100, val_acc: 54.04%\n",
      "Epoch [1796]/[5000], train_loss: 0.066300, train_acc: 93.95%, val_loss: 2.744200, val_acc: 54.82%\n",
      "Epoch [1797]/[5000], train_loss: 0.061700, train_acc: 93.80%, val_loss: 2.648500, val_acc: 55.08%\n",
      "Epoch [1798]/[5000], train_loss: 0.064300, train_acc: 93.90%, val_loss: 2.374000, val_acc: 50.78%\n",
      "Epoch [1799]/[5000], train_loss: 0.088400, train_acc: 92.87%, val_loss: 3.129300, val_acc: 52.73%\n",
      "Epoch [1800]/[5000], train_loss: 0.102700, train_acc: 92.68%, val_loss: 2.460000, val_acc: 56.90%\n",
      "Epoch [1801]/[5000], train_loss: 0.080300, train_acc: 93.46%, val_loss: 2.619700, val_acc: 52.73%\n",
      "Epoch [1802]/[5000], train_loss: 0.080400, train_acc: 93.95%, val_loss: 2.384300, val_acc: 52.21%\n",
      "Epoch [1803]/[5000], train_loss: 0.063400, train_acc: 93.65%, val_loss: 2.576500, val_acc: 53.12%\n",
      "Epoch [1804]/[5000], train_loss: 0.083600, train_acc: 93.31%, val_loss: 2.144600, val_acc: 56.38%\n",
      "Epoch [1805]/[5000], train_loss: 0.062500, train_acc: 93.65%, val_loss: 2.324300, val_acc: 54.30%\n",
      "Epoch [1806]/[5000], train_loss: 0.063600, train_acc: 93.99%, val_loss: 2.691700, val_acc: 51.69%\n",
      "Epoch [1807]/[5000], train_loss: 0.080500, train_acc: 93.36%, val_loss: 2.331400, val_acc: 55.34%\n",
      "Epoch [1808]/[5000], train_loss: 0.073700, train_acc: 93.75%, val_loss: 2.738500, val_acc: 56.12%\n",
      "Epoch [1809]/[5000], train_loss: 0.055800, train_acc: 94.43%, val_loss: 2.374200, val_acc: 56.38%\n",
      "Epoch [1810]/[5000], train_loss: 0.084400, train_acc: 93.07%, val_loss: 2.359400, val_acc: 54.30%\n",
      "Epoch [1811]/[5000], train_loss: 0.071500, train_acc: 93.36%, val_loss: 2.555700, val_acc: 54.30%\n",
      "Epoch [1812]/[5000], train_loss: 0.070400, train_acc: 93.65%, val_loss: 2.229800, val_acc: 53.78%\n",
      "Epoch [1813]/[5000], train_loss: 0.081500, train_acc: 93.12%, val_loss: 2.560600, val_acc: 52.34%\n",
      "Epoch [1814]/[5000], train_loss: 0.100800, train_acc: 92.38%, val_loss: 2.857200, val_acc: 52.21%\n",
      "Epoch [1815]/[5000], train_loss: 0.116600, train_acc: 92.58%, val_loss: 2.293700, val_acc: 51.43%\n",
      "Epoch [1816]/[5000], train_loss: 0.118000, train_acc: 92.48%, val_loss: 2.778200, val_acc: 51.43%\n",
      "Epoch [1817]/[5000], train_loss: 0.094200, train_acc: 93.02%, val_loss: 2.660100, val_acc: 54.95%\n",
      "Epoch [1818]/[5000], train_loss: 0.095800, train_acc: 93.21%, val_loss: 2.380600, val_acc: 53.39%\n",
      "Epoch [1819]/[5000], train_loss: 0.081700, train_acc: 93.46%, val_loss: 2.767900, val_acc: 55.08%\n",
      "Epoch [1820]/[5000], train_loss: 0.075200, train_acc: 93.31%, val_loss: 2.170500, val_acc: 54.56%\n",
      "Epoch [1821]/[5000], train_loss: 0.072500, train_acc: 93.70%, val_loss: 2.695700, val_acc: 52.73%\n",
      "Epoch [1822]/[5000], train_loss: 0.095700, train_acc: 92.92%, val_loss: 2.458200, val_acc: 51.69%\n",
      "Epoch [1823]/[5000], train_loss: 0.081600, train_acc: 93.31%, val_loss: 2.640100, val_acc: 55.73%\n",
      "Epoch [1824]/[5000], train_loss: 0.087800, train_acc: 92.63%, val_loss: 2.341500, val_acc: 51.82%\n",
      "Epoch [1825]/[5000], train_loss: 0.105000, train_acc: 92.48%, val_loss: 2.862500, val_acc: 51.43%\n",
      "Epoch [1826]/[5000], train_loss: 0.116800, train_acc: 92.24%, val_loss: 2.082400, val_acc: 51.17%\n",
      "Epoch [1827]/[5000], train_loss: 0.102200, train_acc: 92.43%, val_loss: 2.754100, val_acc: 51.69%\n",
      "Epoch [1828]/[5000], train_loss: 0.092800, train_acc: 92.43%, val_loss: 2.535400, val_acc: 52.60%\n",
      "Epoch [1829]/[5000], train_loss: 0.087300, train_acc: 92.72%, val_loss: 2.298200, val_acc: 52.34%\n",
      "Epoch [1830]/[5000], train_loss: 0.075200, train_acc: 93.21%, val_loss: 2.467300, val_acc: 55.60%\n",
      "Epoch [1831]/[5000], train_loss: 0.073900, train_acc: 93.75%, val_loss: 2.161200, val_acc: 53.12%\n",
      "Epoch [1832]/[5000], train_loss: 0.077700, train_acc: 93.26%, val_loss: 2.393800, val_acc: 55.34%\n",
      "Epoch [1833]/[5000], train_loss: 0.066800, train_acc: 94.09%, val_loss: 2.595700, val_acc: 53.12%\n",
      "Epoch [1834]/[5000], train_loss: 0.050400, train_acc: 94.34%, val_loss: 2.351400, val_acc: 56.12%\n",
      "Epoch [1835]/[5000], train_loss: 0.067200, train_acc: 93.60%, val_loss: 2.577100, val_acc: 55.86%\n",
      "Epoch [1836]/[5000], train_loss: 0.066200, train_acc: 93.41%, val_loss: 2.413700, val_acc: 53.91%\n",
      "Epoch [1837]/[5000], train_loss: 0.043600, train_acc: 94.68%, val_loss: 2.224700, val_acc: 56.51%\n",
      "Epoch [1838]/[5000], train_loss: 0.050200, train_acc: 94.38%, val_loss: 2.698500, val_acc: 54.56%\n",
      "Epoch [1839]/[5000], train_loss: 0.048400, train_acc: 94.38%, val_loss: 2.274200, val_acc: 52.86%\n",
      "Epoch [1840]/[5000], train_loss: 0.054800, train_acc: 94.53%, val_loss: 2.405900, val_acc: 53.65%\n",
      "Epoch [1841]/[5000], train_loss: 0.052000, train_acc: 94.34%, val_loss: 2.381400, val_acc: 56.38%\n",
      "Epoch [1842]/[5000], train_loss: 0.046900, train_acc: 94.68%, val_loss: 3.064400, val_acc: 55.47%\n",
      "Epoch [1843]/[5000], train_loss: 0.049300, train_acc: 94.43%, val_loss: 2.453800, val_acc: 53.52%\n",
      "Epoch [1844]/[5000], train_loss: 0.057800, train_acc: 94.09%, val_loss: 2.314300, val_acc: 53.65%\n",
      "Epoch [1845]/[5000], train_loss: 0.057800, train_acc: 94.34%, val_loss: 3.035200, val_acc: 53.12%\n",
      "Epoch [1846]/[5000], train_loss: 0.050200, train_acc: 94.43%, val_loss: 2.537000, val_acc: 55.99%\n",
      "Epoch [1847]/[5000], train_loss: 0.067200, train_acc: 93.70%, val_loss: 2.562900, val_acc: 54.56%\n",
      "Epoch [1848]/[5000], train_loss: 0.051800, train_acc: 94.34%, val_loss: 2.558100, val_acc: 52.34%\n",
      "Epoch [1849]/[5000], train_loss: 0.071900, train_acc: 93.41%, val_loss: 3.094800, val_acc: 54.95%\n",
      "Epoch [1850]/[5000], train_loss: 0.057900, train_acc: 94.09%, val_loss: 2.534200, val_acc: 52.08%\n",
      "Epoch [1851]/[5000], train_loss: 0.085700, train_acc: 93.31%, val_loss: 2.686900, val_acc: 53.52%\n",
      "Epoch [1852]/[5000], train_loss: 0.083300, train_acc: 93.31%, val_loss: 2.723800, val_acc: 52.73%\n",
      "Epoch [1853]/[5000], train_loss: 0.077300, train_acc: 93.31%, val_loss: 2.619700, val_acc: 51.30%\n",
      "Epoch [1854]/[5000], train_loss: 0.069200, train_acc: 93.51%, val_loss: 2.926900, val_acc: 52.34%\n",
      "Epoch [1855]/[5000], train_loss: 0.062400, train_acc: 93.46%, val_loss: 2.651400, val_acc: 52.99%\n",
      "Epoch [1856]/[5000], train_loss: 0.077100, train_acc: 93.51%, val_loss: 2.414600, val_acc: 53.12%\n",
      "Epoch [1857]/[5000], train_loss: 0.084700, train_acc: 93.12%, val_loss: 2.434400, val_acc: 50.39%\n",
      "Epoch [1858]/[5000], train_loss: 0.076600, train_acc: 92.92%, val_loss: 2.504100, val_acc: 55.60%\n",
      "Epoch [1859]/[5000], train_loss: 0.060200, train_acc: 94.24%, val_loss: 2.469800, val_acc: 53.91%\n",
      "Epoch [1860]/[5000], train_loss: 0.048600, train_acc: 94.68%, val_loss: 2.570200, val_acc: 53.91%\n",
      "Epoch [1861]/[5000], train_loss: 0.054500, train_acc: 94.43%, val_loss: 2.363500, val_acc: 53.39%\n",
      "Epoch [1862]/[5000], train_loss: 0.053700, train_acc: 94.38%, val_loss: 2.734800, val_acc: 51.82%\n",
      "Epoch [1863]/[5000], train_loss: 0.052200, train_acc: 94.29%, val_loss: 2.397700, val_acc: 55.47%\n",
      "Epoch [1864]/[5000], train_loss: 0.084300, train_acc: 93.12%, val_loss: 2.607700, val_acc: 51.56%\n",
      "Epoch [1865]/[5000], train_loss: 0.078400, train_acc: 93.12%, val_loss: 2.439700, val_acc: 51.04%\n",
      "Epoch [1866]/[5000], train_loss: 0.107900, train_acc: 92.68%, val_loss: 2.249700, val_acc: 53.91%\n",
      "Epoch [1867]/[5000], train_loss: 0.099100, train_acc: 93.46%, val_loss: 2.723000, val_acc: 53.39%\n",
      "Epoch [1868]/[5000], train_loss: 0.091900, train_acc: 93.02%, val_loss: 2.296100, val_acc: 55.47%\n",
      "Epoch [1869]/[5000], train_loss: 0.082400, train_acc: 92.63%, val_loss: 2.546200, val_acc: 52.73%\n",
      "Epoch [1870]/[5000], train_loss: 0.071500, train_acc: 93.90%, val_loss: 2.517600, val_acc: 54.56%\n",
      "Epoch [1871]/[5000], train_loss: 0.092000, train_acc: 93.21%, val_loss: 2.814700, val_acc: 51.30%\n",
      "Epoch [1872]/[5000], train_loss: 0.097700, train_acc: 92.53%, val_loss: 2.513900, val_acc: 54.17%\n",
      "Epoch [1873]/[5000], train_loss: 0.081800, train_acc: 93.31%, val_loss: 2.549800, val_acc: 56.64%\n",
      "Epoch [1874]/[5000], train_loss: 0.074500, train_acc: 93.60%, val_loss: 2.961600, val_acc: 51.17%\n",
      "Epoch [1875]/[5000], train_loss: 0.080600, train_acc: 93.07%, val_loss: 2.751400, val_acc: 53.12%\n",
      "Epoch [1876]/[5000], train_loss: 0.073500, train_acc: 93.41%, val_loss: 2.643100, val_acc: 51.30%\n",
      "Epoch [1877]/[5000], train_loss: 0.067600, train_acc: 93.65%, val_loss: 2.644700, val_acc: 53.12%\n",
      "Epoch [1878]/[5000], train_loss: 0.083400, train_acc: 93.75%, val_loss: 2.266600, val_acc: 52.60%\n",
      "Epoch [1879]/[5000], train_loss: 0.060600, train_acc: 93.99%, val_loss: 2.729100, val_acc: 50.91%\n",
      "Epoch [1880]/[5000], train_loss: 0.079000, train_acc: 93.31%, val_loss: 2.614900, val_acc: 54.04%\n",
      "Epoch [1881]/[5000], train_loss: 0.078200, train_acc: 93.21%, val_loss: 2.355100, val_acc: 54.82%\n",
      "Epoch [1882]/[5000], train_loss: 0.077700, train_acc: 93.85%, val_loss: 2.342300, val_acc: 53.39%\n",
      "Epoch [1883]/[5000], train_loss: 0.068400, train_acc: 93.80%, val_loss: 2.592700, val_acc: 50.13%\n",
      "Epoch [1884]/[5000], train_loss: 0.083200, train_acc: 93.51%, val_loss: 2.471900, val_acc: 55.60%\n",
      "Epoch [1885]/[5000], train_loss: 0.057200, train_acc: 94.29%, val_loss: 2.992300, val_acc: 55.08%\n",
      "Epoch [1886]/[5000], train_loss: 0.066000, train_acc: 93.55%, val_loss: 2.392500, val_acc: 52.99%\n",
      "Epoch [1887]/[5000], train_loss: 0.057400, train_acc: 93.95%, val_loss: 2.282700, val_acc: 54.04%\n",
      "Epoch [1888]/[5000], train_loss: 0.055100, train_acc: 94.38%, val_loss: 2.680100, val_acc: 54.04%\n",
      "Epoch [1889]/[5000], train_loss: 0.042500, train_acc: 94.38%, val_loss: 2.444600, val_acc: 54.04%\n",
      "Epoch [1890]/[5000], train_loss: 0.048000, train_acc: 94.38%, val_loss: 2.523300, val_acc: 54.04%\n",
      "Epoch [1891]/[5000], train_loss: 0.060300, train_acc: 94.14%, val_loss: 2.378900, val_acc: 55.08%\n",
      "Epoch [1892]/[5000], train_loss: 0.073300, train_acc: 93.41%, val_loss: 2.684600, val_acc: 53.52%\n",
      "Epoch [1893]/[5000], train_loss: 0.086800, train_acc: 93.51%, val_loss: 2.320200, val_acc: 53.65%\n",
      "Epoch [1894]/[5000], train_loss: 0.078900, train_acc: 93.51%, val_loss: 2.554200, val_acc: 51.30%\n",
      "Epoch [1895]/[5000], train_loss: 0.094300, train_acc: 93.16%, val_loss: 2.710300, val_acc: 49.48%\n",
      "Epoch [1896]/[5000], train_loss: 0.096400, train_acc: 92.77%, val_loss: 2.639600, val_acc: 50.26%\n",
      "Epoch [1897]/[5000], train_loss: 0.067600, train_acc: 93.85%, val_loss: 2.646000, val_acc: 52.60%\n",
      "Epoch [1898]/[5000], train_loss: 0.051200, train_acc: 94.43%, val_loss: 2.614900, val_acc: 53.78%\n",
      "Epoch [1899]/[5000], train_loss: 0.060300, train_acc: 93.95%, val_loss: 3.015200, val_acc: 54.04%\n",
      "Epoch [1900]/[5000], train_loss: 0.069000, train_acc: 93.70%, val_loss: 2.996100, val_acc: 51.56%\n",
      "Epoch [1901]/[5000], train_loss: 0.059000, train_acc: 94.43%, val_loss: 2.456400, val_acc: 55.21%\n",
      "Epoch [1902]/[5000], train_loss: 0.049900, train_acc: 93.95%, val_loss: 2.311200, val_acc: 54.30%\n",
      "Epoch [1903]/[5000], train_loss: 0.050100, train_acc: 94.48%, val_loss: 2.656700, val_acc: 53.39%\n",
      "Epoch [1904]/[5000], train_loss: 0.039400, train_acc: 94.82%, val_loss: 2.734900, val_acc: 55.99%\n",
      "Epoch [1905]/[5000], train_loss: 0.062100, train_acc: 93.95%, val_loss: 2.845900, val_acc: 52.60%\n",
      "Epoch [1906]/[5000], train_loss: 0.069300, train_acc: 94.19%, val_loss: 2.598700, val_acc: 50.39%\n",
      "Epoch [1907]/[5000], train_loss: 0.081200, train_acc: 93.36%, val_loss: 2.722600, val_acc: 52.86%\n",
      "Epoch [1908]/[5000], train_loss: 0.076000, train_acc: 93.65%, val_loss: 2.702000, val_acc: 51.56%\n",
      "Epoch [1909]/[5000], train_loss: 0.050900, train_acc: 94.34%, val_loss: 2.482300, val_acc: 55.86%\n",
      "Epoch [1910]/[5000], train_loss: 0.048600, train_acc: 94.34%, val_loss: 2.641800, val_acc: 53.65%\n",
      "Epoch [1911]/[5000], train_loss: 0.056900, train_acc: 93.85%, val_loss: 2.691900, val_acc: 57.03%\n",
      "Epoch [1912]/[5000], train_loss: 0.054100, train_acc: 94.29%, val_loss: 2.403000, val_acc: 55.60%\n",
      "Epoch [1913]/[5000], train_loss: 0.038000, train_acc: 94.53%, val_loss: 2.415900, val_acc: 57.94%\n",
      "Epoch [1914]/[5000], train_loss: 0.038800, train_acc: 94.78%, val_loss: 2.341200, val_acc: 54.04%\n",
      "Epoch [1915]/[5000], train_loss: 0.045800, train_acc: 94.48%, val_loss: 2.479900, val_acc: 54.04%\n",
      "Epoch [1916]/[5000], train_loss: 0.043700, train_acc: 94.48%, val_loss: 2.396900, val_acc: 52.99%\n",
      "Epoch [1917]/[5000], train_loss: 0.087200, train_acc: 93.21%, val_loss: 2.322600, val_acc: 54.43%\n",
      "Epoch [1918]/[5000], train_loss: 0.057500, train_acc: 93.80%, val_loss: 3.249400, val_acc: 53.12%\n",
      "Epoch [1919]/[5000], train_loss: 0.076000, train_acc: 93.16%, val_loss: 2.715500, val_acc: 52.73%\n",
      "Epoch [1920]/[5000], train_loss: 0.064500, train_acc: 93.65%, val_loss: 2.808600, val_acc: 51.95%\n",
      "Epoch [1921]/[5000], train_loss: 0.072400, train_acc: 93.75%, val_loss: 2.793900, val_acc: 56.12%\n",
      "Epoch [1922]/[5000], train_loss: 0.068100, train_acc: 93.60%, val_loss: 2.729200, val_acc: 54.69%\n",
      "Epoch [1923]/[5000], train_loss: 0.067600, train_acc: 93.36%, val_loss: 2.594800, val_acc: 50.39%\n",
      "Epoch [1924]/[5000], train_loss: 0.080700, train_acc: 93.36%, val_loss: 2.829200, val_acc: 55.73%\n",
      "Epoch [1925]/[5000], train_loss: 0.075100, train_acc: 93.41%, val_loss: 2.551300, val_acc: 50.39%\n",
      "Epoch [1926]/[5000], train_loss: 0.104200, train_acc: 92.72%, val_loss: 2.707200, val_acc: 52.60%\n",
      "Epoch [1927]/[5000], train_loss: 0.105600, train_acc: 92.72%, val_loss: 2.715700, val_acc: 53.78%\n",
      "Epoch [1928]/[5000], train_loss: 0.074300, train_acc: 93.70%, val_loss: 2.552800, val_acc: 50.39%\n",
      "Epoch [1929]/[5000], train_loss: 0.054700, train_acc: 94.29%, val_loss: 2.917300, val_acc: 54.17%\n",
      "Epoch [1930]/[5000], train_loss: 0.071600, train_acc: 93.55%, val_loss: 2.743800, val_acc: 52.60%\n",
      "Epoch [1931]/[5000], train_loss: 0.058900, train_acc: 94.34%, val_loss: 2.718000, val_acc: 54.30%\n",
      "Epoch [1932]/[5000], train_loss: 0.062000, train_acc: 93.65%, val_loss: 2.506200, val_acc: 53.12%\n",
      "Epoch [1933]/[5000], train_loss: 0.055700, train_acc: 93.75%, val_loss: 2.743600, val_acc: 55.21%\n",
      "Epoch [1934]/[5000], train_loss: 0.084900, train_acc: 93.36%, val_loss: 2.537200, val_acc: 51.30%\n",
      "Epoch [1935]/[5000], train_loss: 0.085800, train_acc: 93.12%, val_loss: 2.638800, val_acc: 53.26%\n",
      "Epoch [1936]/[5000], train_loss: 0.088300, train_acc: 93.02%, val_loss: 2.759500, val_acc: 52.08%\n",
      "Epoch [1937]/[5000], train_loss: 0.088300, train_acc: 93.26%, val_loss: 2.336600, val_acc: 50.78%\n",
      "Epoch [1938]/[5000], train_loss: 0.068100, train_acc: 93.99%, val_loss: 2.434400, val_acc: 56.77%\n",
      "Epoch [1939]/[5000], train_loss: 0.057800, train_acc: 94.24%, val_loss: 2.395300, val_acc: 52.86%\n",
      "Epoch [1940]/[5000], train_loss: 0.071400, train_acc: 93.65%, val_loss: 2.487800, val_acc: 52.47%\n",
      "Epoch [1941]/[5000], train_loss: 0.074400, train_acc: 93.46%, val_loss: 2.664500, val_acc: 51.95%\n",
      "Epoch [1942]/[5000], train_loss: 0.051900, train_acc: 94.09%, val_loss: 2.339200, val_acc: 55.47%\n",
      "Epoch [1943]/[5000], train_loss: 0.063500, train_acc: 93.99%, val_loss: 2.201200, val_acc: 54.56%\n",
      "Epoch [1944]/[5000], train_loss: 0.092000, train_acc: 93.16%, val_loss: 2.487700, val_acc: 53.39%\n",
      "Epoch [1945]/[5000], train_loss: 0.077300, train_acc: 93.41%, val_loss: 2.449400, val_acc: 54.43%\n",
      "Epoch [1946]/[5000], train_loss: 0.095700, train_acc: 92.82%, val_loss: 2.300900, val_acc: 53.91%\n",
      "Epoch [1947]/[5000], train_loss: 0.089800, train_acc: 93.07%, val_loss: 2.633700, val_acc: 54.30%\n",
      "Epoch [1948]/[5000], train_loss: 0.102000, train_acc: 92.53%, val_loss: 2.506200, val_acc: 53.52%\n",
      "Epoch [1949]/[5000], train_loss: 0.078500, train_acc: 93.12%, val_loss: 2.393200, val_acc: 54.04%\n",
      "Epoch [1950]/[5000], train_loss: 0.076500, train_acc: 93.21%, val_loss: 2.386700, val_acc: 57.42%\n",
      "Epoch [1951]/[5000], train_loss: 0.062500, train_acc: 94.09%, val_loss: 2.382200, val_acc: 52.34%\n",
      "Epoch [1952]/[5000], train_loss: 0.067200, train_acc: 93.90%, val_loss: 2.378700, val_acc: 53.91%\n",
      "Epoch [1953]/[5000], train_loss: 0.068800, train_acc: 93.95%, val_loss: 2.508000, val_acc: 54.04%\n",
      "Epoch [1954]/[5000], train_loss: 0.050800, train_acc: 94.09%, val_loss: 2.239200, val_acc: 52.60%\n",
      "Epoch [1955]/[5000], train_loss: 0.054700, train_acc: 93.99%, val_loss: 2.659500, val_acc: 55.08%\n",
      "Epoch [1956]/[5000], train_loss: 0.056800, train_acc: 94.09%, val_loss: 2.624800, val_acc: 50.78%\n",
      "Epoch [1957]/[5000], train_loss: 0.053400, train_acc: 94.24%, val_loss: 2.643600, val_acc: 55.99%\n",
      "Epoch [1958]/[5000], train_loss: 0.059900, train_acc: 93.99%, val_loss: 2.337600, val_acc: 53.65%\n",
      "Epoch [1959]/[5000], train_loss: 0.057600, train_acc: 94.04%, val_loss: 2.775900, val_acc: 55.34%\n",
      "Epoch [1960]/[5000], train_loss: 0.047600, train_acc: 94.63%, val_loss: 2.775900, val_acc: 54.56%\n",
      "Epoch [1961]/[5000], train_loss: 0.045000, train_acc: 94.78%, val_loss: 2.748100, val_acc: 53.91%\n",
      "Epoch [1962]/[5000], train_loss: 0.058200, train_acc: 94.09%, val_loss: 2.880300, val_acc: 54.17%\n",
      "Epoch [1963]/[5000], train_loss: 0.068200, train_acc: 93.51%, val_loss: 2.559300, val_acc: 52.73%\n",
      "Epoch [1964]/[5000], train_loss: 0.067300, train_acc: 93.99%, val_loss: 2.413900, val_acc: 54.43%\n",
      "Epoch [1965]/[5000], train_loss: 0.080300, train_acc: 93.31%, val_loss: 2.176800, val_acc: 55.60%\n",
      "Epoch [1966]/[5000], train_loss: 0.071700, train_acc: 93.65%, val_loss: 2.287400, val_acc: 53.26%\n",
      "Epoch [1967]/[5000], train_loss: 0.075700, train_acc: 93.51%, val_loss: 2.413400, val_acc: 53.26%\n",
      "Epoch [1968]/[5000], train_loss: 0.064900, train_acc: 93.90%, val_loss: 2.338700, val_acc: 56.25%\n",
      "Epoch [1969]/[5000], train_loss: 0.064000, train_acc: 93.95%, val_loss: 2.438800, val_acc: 55.47%\n",
      "Epoch [1970]/[5000], train_loss: 0.065800, train_acc: 93.85%, val_loss: 2.649200, val_acc: 57.29%\n",
      "Epoch [1971]/[5000], train_loss: 0.054100, train_acc: 94.34%, val_loss: 2.922000, val_acc: 54.69%\n",
      "Epoch [1972]/[5000], train_loss: 0.084000, train_acc: 93.02%, val_loss: 2.432500, val_acc: 54.43%\n",
      "Epoch [1973]/[5000], train_loss: 0.060600, train_acc: 94.04%, val_loss: 2.697200, val_acc: 53.52%\n",
      "Epoch [1974]/[5000], train_loss: 0.060800, train_acc: 93.99%, val_loss: 2.476500, val_acc: 55.08%\n",
      "Epoch [1975]/[5000], train_loss: 0.072200, train_acc: 93.31%, val_loss: 2.585200, val_acc: 53.91%\n",
      "Epoch [1976]/[5000], train_loss: 0.051800, train_acc: 93.95%, val_loss: 3.135600, val_acc: 51.95%\n",
      "Epoch [1977]/[5000], train_loss: 0.071500, train_acc: 93.70%, val_loss: 2.989400, val_acc: 54.95%\n",
      "Epoch [1978]/[5000], train_loss: 0.064200, train_acc: 93.12%, val_loss: 2.682800, val_acc: 51.56%\n",
      "Epoch [1979]/[5000], train_loss: 0.075500, train_acc: 93.51%, val_loss: 2.900900, val_acc: 51.43%\n",
      "Epoch [1980]/[5000], train_loss: 0.068500, train_acc: 93.60%, val_loss: 2.453500, val_acc: 52.08%\n",
      "Epoch [1981]/[5000], train_loss: 0.049000, train_acc: 94.19%, val_loss: 2.506200, val_acc: 55.08%\n",
      "Epoch [1982]/[5000], train_loss: 0.073000, train_acc: 93.55%, val_loss: 2.672500, val_acc: 55.08%\n",
      "Epoch [1983]/[5000], train_loss: 0.086300, train_acc: 93.31%, val_loss: 2.618700, val_acc: 52.47%\n",
      "Epoch [1984]/[5000], train_loss: 0.072000, train_acc: 93.51%, val_loss: 2.642400, val_acc: 53.65%\n",
      "Epoch [1985]/[5000], train_loss: 0.078400, train_acc: 93.31%, val_loss: 2.414300, val_acc: 52.47%\n",
      "Epoch [1986]/[5000], train_loss: 0.081800, train_acc: 93.31%, val_loss: 2.197500, val_acc: 54.69%\n",
      "Epoch [1987]/[5000], train_loss: 0.100300, train_acc: 92.48%, val_loss: 2.636100, val_acc: 53.26%\n",
      "Epoch [1988]/[5000], train_loss: 0.067500, train_acc: 93.80%, val_loss: 2.793400, val_acc: 55.60%\n",
      "Epoch [1989]/[5000], train_loss: 0.064300, train_acc: 93.55%, val_loss: 2.465000, val_acc: 55.99%\n",
      "Epoch [1990]/[5000], train_loss: 0.092600, train_acc: 93.36%, val_loss: 2.585700, val_acc: 55.99%\n",
      "Epoch [1991]/[5000], train_loss: 0.071900, train_acc: 93.51%, val_loss: 2.558900, val_acc: 54.17%\n",
      "Epoch [1992]/[5000], train_loss: 0.122400, train_acc: 91.99%, val_loss: 2.331000, val_acc: 54.82%\n",
      "Epoch [1993]/[5000], train_loss: 0.091600, train_acc: 93.12%, val_loss: 2.382700, val_acc: 52.34%\n",
      "Epoch [1994]/[5000], train_loss: 0.119300, train_acc: 92.19%, val_loss: 2.438400, val_acc: 54.30%\n",
      "Epoch [1995]/[5000], train_loss: 0.078700, train_acc: 93.51%, val_loss: 2.432500, val_acc: 55.73%\n",
      "Epoch [1996]/[5000], train_loss: 0.067800, train_acc: 93.36%, val_loss: 2.293700, val_acc: 54.82%\n",
      "Epoch [1997]/[5000], train_loss: 0.061200, train_acc: 94.09%, val_loss: 2.171800, val_acc: 54.56%\n",
      "Epoch [1998]/[5000], train_loss: 0.062900, train_acc: 93.55%, val_loss: 2.446700, val_acc: 54.17%\n",
      "Epoch [1999]/[5000], train_loss: 0.087700, train_acc: 93.16%, val_loss: 2.337100, val_acc: 53.26%\n",
      "Epoch [2000]/[5000], train_loss: 0.076000, train_acc: 93.46%, val_loss: 2.292600, val_acc: 54.56%\n",
      "Epoch [2001]/[5000], train_loss: 0.064700, train_acc: 93.80%, val_loss: 2.470600, val_acc: 53.39%\n",
      "Epoch [2002]/[5000], train_loss: 0.057800, train_acc: 93.99%, val_loss: 2.500900, val_acc: 54.30%\n",
      "Epoch [2003]/[5000], train_loss: 0.048500, train_acc: 94.68%, val_loss: 2.877900, val_acc: 55.21%\n",
      "Epoch [2004]/[5000], train_loss: 0.041800, train_acc: 94.53%, val_loss: 2.327200, val_acc: 52.47%\n",
      "Epoch [2005]/[5000], train_loss: 0.045400, train_acc: 94.43%, val_loss: 2.675000, val_acc: 50.13%\n",
      "Epoch [2006]/[5000], train_loss: 0.054800, train_acc: 94.14%, val_loss: 2.440600, val_acc: 54.17%\n",
      "Epoch [2007]/[5000], train_loss: 0.070400, train_acc: 93.65%, val_loss: 2.571300, val_acc: 56.38%\n",
      "Epoch [2008]/[5000], train_loss: 0.051700, train_acc: 94.09%, val_loss: 2.463600, val_acc: 53.78%\n",
      "Epoch [2009]/[5000], train_loss: 0.063300, train_acc: 93.95%, val_loss: 2.559400, val_acc: 57.29%\n",
      "Epoch [2010]/[5000], train_loss: 0.055500, train_acc: 94.04%, val_loss: 2.307600, val_acc: 52.47%\n",
      "Epoch [2011]/[5000], train_loss: 0.054500, train_acc: 94.48%, val_loss: 2.148000, val_acc: 55.34%\n",
      "Epoch [2012]/[5000], train_loss: 0.044800, train_acc: 94.53%, val_loss: 2.961900, val_acc: 52.60%\n",
      "Epoch [2013]/[5000], train_loss: 0.075100, train_acc: 93.65%, val_loss: 2.665700, val_acc: 54.17%\n",
      "Epoch [2014]/[5000], train_loss: 0.048400, train_acc: 94.24%, val_loss: 2.286600, val_acc: 55.21%\n",
      "Epoch [2015]/[5000], train_loss: 0.047300, train_acc: 94.48%, val_loss: 2.314600, val_acc: 52.99%\n",
      "Epoch [2016]/[5000], train_loss: 0.064900, train_acc: 93.85%, val_loss: 2.568700, val_acc: 56.51%\n",
      "Epoch [2017]/[5000], train_loss: 0.072000, train_acc: 93.70%, val_loss: 2.480000, val_acc: 52.21%\n",
      "Epoch [2018]/[5000], train_loss: 0.090800, train_acc: 92.68%, val_loss: 2.998000, val_acc: 53.39%\n",
      "Epoch [2019]/[5000], train_loss: 0.101100, train_acc: 93.26%, val_loss: 2.681500, val_acc: 51.30%\n",
      "Epoch [2020]/[5000], train_loss: 0.090500, train_acc: 92.82%, val_loss: 2.228100, val_acc: 51.43%\n",
      "Epoch [2021]/[5000], train_loss: 0.092500, train_acc: 93.21%, val_loss: 2.463900, val_acc: 51.82%\n",
      "Epoch [2022]/[5000], train_loss: 0.066700, train_acc: 93.65%, val_loss: 2.303200, val_acc: 53.65%\n",
      "Epoch [2023]/[5000], train_loss: 0.065400, train_acc: 93.90%, val_loss: 2.660300, val_acc: 54.04%\n",
      "Epoch [2024]/[5000], train_loss: 0.057800, train_acc: 94.38%, val_loss: 2.472500, val_acc: 53.65%\n",
      "Epoch [2025]/[5000], train_loss: 0.075000, train_acc: 93.46%, val_loss: 2.421400, val_acc: 53.65%\n",
      "Epoch [2026]/[5000], train_loss: 0.061800, train_acc: 93.80%, val_loss: 2.606200, val_acc: 50.65%\n",
      "Epoch [2027]/[5000], train_loss: 0.056100, train_acc: 93.99%, val_loss: 2.695200, val_acc: 55.47%\n",
      "Epoch [2028]/[5000], train_loss: 0.061300, train_acc: 94.19%, val_loss: 2.625100, val_acc: 57.03%\n",
      "Epoch [2029]/[5000], train_loss: 0.046100, train_acc: 94.48%, val_loss: 2.388100, val_acc: 52.73%\n",
      "Epoch [2030]/[5000], train_loss: 0.065200, train_acc: 93.90%, val_loss: 2.607200, val_acc: 54.69%\n",
      "Epoch [2031]/[5000], train_loss: 0.086100, train_acc: 93.02%, val_loss: 2.429500, val_acc: 54.82%\n",
      "Epoch [2032]/[5000], train_loss: 0.071700, train_acc: 93.90%, val_loss: 2.525400, val_acc: 55.86%\n",
      "Epoch [2033]/[5000], train_loss: 0.061400, train_acc: 93.99%, val_loss: 2.725100, val_acc: 53.52%\n",
      "Epoch [2034]/[5000], train_loss: 0.060000, train_acc: 94.34%, val_loss: 2.640900, val_acc: 54.95%\n",
      "Epoch [2035]/[5000], train_loss: 0.049500, train_acc: 94.58%, val_loss: 3.305100, val_acc: 53.26%\n",
      "Epoch [2036]/[5000], train_loss: 0.075100, train_acc: 93.80%, val_loss: 2.548300, val_acc: 55.60%\n",
      "Epoch [2037]/[5000], train_loss: 0.085800, train_acc: 92.87%, val_loss: 2.642100, val_acc: 51.43%\n",
      "Epoch [2038]/[5000], train_loss: 0.081300, train_acc: 93.31%, val_loss: 2.282000, val_acc: 52.86%\n",
      "Epoch [2039]/[5000], train_loss: 0.077900, train_acc: 93.65%, val_loss: 2.856200, val_acc: 55.08%\n",
      "Epoch [2040]/[5000], train_loss: 0.041000, train_acc: 94.78%, val_loss: 2.666000, val_acc: 54.95%\n",
      "Epoch [2041]/[5000], train_loss: 0.067800, train_acc: 93.70%, val_loss: 2.715900, val_acc: 53.65%\n",
      "Epoch [2042]/[5000], train_loss: 0.067900, train_acc: 94.09%, val_loss: 2.709100, val_acc: 52.60%\n",
      "Epoch [2043]/[5000], train_loss: 0.056100, train_acc: 94.53%, val_loss: 2.563900, val_acc: 52.86%\n",
      "Epoch [2044]/[5000], train_loss: 0.053500, train_acc: 93.99%, val_loss: 2.751500, val_acc: 52.86%\n",
      "Epoch [2045]/[5000], train_loss: 0.055900, train_acc: 93.99%, val_loss: 2.476300, val_acc: 54.82%\n",
      "Epoch [2046]/[5000], train_loss: 0.038700, train_acc: 94.73%, val_loss: 2.548700, val_acc: 55.34%\n",
      "Epoch [2047]/[5000], train_loss: 0.043200, train_acc: 94.34%, val_loss: 2.610000, val_acc: 52.60%\n",
      "Epoch [2048]/[5000], train_loss: 0.072300, train_acc: 94.04%, val_loss: 2.574400, val_acc: 54.43%\n",
      "Epoch [2049]/[5000], train_loss: 0.053900, train_acc: 94.09%, val_loss: 2.728200, val_acc: 54.69%\n",
      "Epoch [2050]/[5000], train_loss: 0.038500, train_acc: 95.12%, val_loss: 2.738600, val_acc: 49.35%\n",
      "Epoch [2051]/[5000], train_loss: 0.047200, train_acc: 94.38%, val_loss: 2.573400, val_acc: 53.91%\n",
      "Epoch [2052]/[5000], train_loss: 0.044200, train_acc: 94.63%, val_loss: 2.805500, val_acc: 54.17%\n",
      "Epoch [2053]/[5000], train_loss: 0.049600, train_acc: 94.34%, val_loss: 2.587600, val_acc: 51.69%\n",
      "Epoch [2054]/[5000], train_loss: 0.047800, train_acc: 94.48%, val_loss: 2.858000, val_acc: 51.82%\n",
      "Epoch [2055]/[5000], train_loss: 0.049100, train_acc: 94.48%, val_loss: 2.387900, val_acc: 54.56%\n",
      "Epoch [2056]/[5000], train_loss: 0.070400, train_acc: 93.75%, val_loss: 2.792000, val_acc: 53.39%\n",
      "Epoch [2057]/[5000], train_loss: 0.057400, train_acc: 93.90%, val_loss: 2.948200, val_acc: 52.34%\n",
      "Epoch [2058]/[5000], train_loss: 0.062600, train_acc: 93.41%, val_loss: 2.630800, val_acc: 53.26%\n",
      "Epoch [2059]/[5000], train_loss: 0.054600, train_acc: 94.34%, val_loss: 2.558300, val_acc: 55.34%\n",
      "Epoch [2060]/[5000], train_loss: 0.049400, train_acc: 94.58%, val_loss: 2.490800, val_acc: 55.34%\n",
      "Epoch [2061]/[5000], train_loss: 0.070900, train_acc: 93.51%, val_loss: 2.593600, val_acc: 54.04%\n",
      "Epoch [2062]/[5000], train_loss: 0.073200, train_acc: 93.21%, val_loss: 2.591900, val_acc: 54.69%\n",
      "Epoch [2063]/[5000], train_loss: 0.078700, train_acc: 93.90%, val_loss: 2.811000, val_acc: 56.38%\n",
      "Epoch [2064]/[5000], train_loss: 0.106300, train_acc: 92.43%, val_loss: 2.660300, val_acc: 53.65%\n",
      "Epoch [2065]/[5000], train_loss: 0.090000, train_acc: 93.02%, val_loss: 2.574900, val_acc: 49.74%\n",
      "Epoch [2066]/[5000], train_loss: 0.074500, train_acc: 93.85%, val_loss: 2.322700, val_acc: 53.78%\n",
      "Epoch [2067]/[5000], train_loss: 0.068800, train_acc: 93.51%, val_loss: 2.682400, val_acc: 51.17%\n",
      "Epoch [2068]/[5000], train_loss: 0.079600, train_acc: 93.16%, val_loss: 2.571700, val_acc: 56.51%\n",
      "Epoch [2069]/[5000], train_loss: 0.066100, train_acc: 93.90%, val_loss: 2.429900, val_acc: 54.82%\n",
      "Epoch [2070]/[5000], train_loss: 0.079900, train_acc: 93.36%, val_loss: 2.587200, val_acc: 52.34%\n",
      "Epoch [2071]/[5000], train_loss: 0.068100, train_acc: 94.04%, val_loss: 2.440000, val_acc: 51.30%\n",
      "Epoch [2072]/[5000], train_loss: 0.094200, train_acc: 93.12%, val_loss: 2.680000, val_acc: 52.73%\n",
      "Epoch [2073]/[5000], train_loss: 0.067300, train_acc: 93.75%, val_loss: 2.361600, val_acc: 53.91%\n",
      "Epoch [2074]/[5000], train_loss: 0.075800, train_acc: 93.95%, val_loss: 2.661700, val_acc: 52.60%\n",
      "Epoch [2075]/[5000], train_loss: 0.080700, train_acc: 93.51%, val_loss: 2.415900, val_acc: 51.30%\n",
      "Epoch [2076]/[5000], train_loss: 0.063700, train_acc: 93.65%, val_loss: 2.253200, val_acc: 55.08%\n",
      "Epoch [2077]/[5000], train_loss: 0.074200, train_acc: 93.41%, val_loss: 2.643200, val_acc: 54.56%\n",
      "Epoch [2078]/[5000], train_loss: 0.064900, train_acc: 93.70%, val_loss: 2.754700, val_acc: 52.21%\n",
      "Epoch [2079]/[5000], train_loss: 0.054100, train_acc: 94.09%, val_loss: 2.943200, val_acc: 52.21%\n",
      "Epoch [2080]/[5000], train_loss: 0.042600, train_acc: 94.82%, val_loss: 2.525300, val_acc: 53.26%\n",
      "Epoch [2081]/[5000], train_loss: 0.057500, train_acc: 94.24%, val_loss: 2.392600, val_acc: 54.30%\n",
      "Epoch [2082]/[5000], train_loss: 0.061600, train_acc: 93.55%, val_loss: 2.616500, val_acc: 52.21%\n",
      "Epoch [2083]/[5000], train_loss: 0.111800, train_acc: 92.82%, val_loss: 3.094900, val_acc: 53.12%\n",
      "Epoch [2084]/[5000], train_loss: 0.126200, train_acc: 91.70%, val_loss: 2.807700, val_acc: 50.91%\n",
      "Epoch [2085]/[5000], train_loss: 0.077700, train_acc: 93.60%, val_loss: 2.461600, val_acc: 51.82%\n",
      "Epoch [2086]/[5000], train_loss: 0.082500, train_acc: 93.12%, val_loss: 2.124600, val_acc: 54.43%\n",
      "Epoch [2087]/[5000], train_loss: 0.065000, train_acc: 93.99%, val_loss: 2.747300, val_acc: 51.95%\n",
      "Epoch [2088]/[5000], train_loss: 0.074700, train_acc: 93.65%, val_loss: 2.434600, val_acc: 54.95%\n",
      "Epoch [2089]/[5000], train_loss: 0.050100, train_acc: 94.34%, val_loss: 2.322900, val_acc: 55.21%\n",
      "Epoch [2090]/[5000], train_loss: 0.054400, train_acc: 94.24%, val_loss: 2.616100, val_acc: 53.78%\n",
      "Epoch [2091]/[5000], train_loss: 0.029200, train_acc: 95.17%, val_loss: 2.533700, val_acc: 55.34%\n",
      "Epoch [2092]/[5000], train_loss: 0.060900, train_acc: 94.04%, val_loss: 2.851100, val_acc: 54.43%\n",
      "Epoch [2093]/[5000], train_loss: 0.064000, train_acc: 93.70%, val_loss: 2.507700, val_acc: 53.91%\n",
      "Epoch [2094]/[5000], train_loss: 0.070900, train_acc: 93.95%, val_loss: 2.613800, val_acc: 55.47%\n",
      "Epoch [2095]/[5000], train_loss: 0.072500, train_acc: 93.36%, val_loss: 2.848800, val_acc: 55.73%\n",
      "Epoch [2096]/[5000], train_loss: 0.064100, train_acc: 93.85%, val_loss: 2.539800, val_acc: 54.69%\n",
      "Epoch [2097]/[5000], train_loss: 0.059200, train_acc: 93.85%, val_loss: 2.723600, val_acc: 53.39%\n",
      "Epoch [2098]/[5000], train_loss: 0.055800, train_acc: 93.90%, val_loss: 2.564800, val_acc: 52.08%\n",
      "Epoch [2099]/[5000], train_loss: 0.055300, train_acc: 94.38%, val_loss: 2.417000, val_acc: 53.91%\n",
      "Epoch [2100]/[5000], train_loss: 0.039900, train_acc: 94.73%, val_loss: 2.386100, val_acc: 52.73%\n",
      "Epoch [2101]/[5000], train_loss: 0.075100, train_acc: 93.65%, val_loss: 2.225400, val_acc: 54.56%\n",
      "Epoch [2102]/[5000], train_loss: 0.051800, train_acc: 94.78%, val_loss: 2.446100, val_acc: 54.82%\n",
      "Epoch [2103]/[5000], train_loss: 0.057900, train_acc: 93.99%, val_loss: 2.306400, val_acc: 53.26%\n",
      "Epoch [2104]/[5000], train_loss: 0.057600, train_acc: 94.48%, val_loss: 2.534900, val_acc: 51.69%\n",
      "Epoch [2105]/[5000], train_loss: 0.075600, train_acc: 93.90%, val_loss: 2.525500, val_acc: 55.21%\n",
      "Epoch [2106]/[5000], train_loss: 0.063600, train_acc: 93.95%, val_loss: 2.446800, val_acc: 53.52%\n",
      "Epoch [2107]/[5000], train_loss: 0.055100, train_acc: 93.99%, val_loss: 2.457600, val_acc: 51.82%\n",
      "Epoch [2108]/[5000], train_loss: 0.058500, train_acc: 94.34%, val_loss: 2.845000, val_acc: 52.34%\n",
      "Epoch [2109]/[5000], train_loss: 0.058500, train_acc: 93.99%, val_loss: 2.334900, val_acc: 53.12%\n",
      "Epoch [2110]/[5000], train_loss: 0.048700, train_acc: 94.63%, val_loss: 2.513300, val_acc: 54.56%\n",
      "Epoch [2111]/[5000], train_loss: 0.040100, train_acc: 94.53%, val_loss: 2.444600, val_acc: 53.78%\n",
      "Epoch [2112]/[5000], train_loss: 0.036000, train_acc: 94.87%, val_loss: 2.772400, val_acc: 55.73%\n",
      "Epoch [2113]/[5000], train_loss: 0.036600, train_acc: 94.73%, val_loss: 2.708800, val_acc: 53.39%\n",
      "Epoch [2114]/[5000], train_loss: 0.042300, train_acc: 94.58%, val_loss: 2.918000, val_acc: 51.30%\n",
      "Epoch [2115]/[5000], train_loss: 0.044700, train_acc: 94.82%, val_loss: 2.605400, val_acc: 55.73%\n",
      "Epoch [2116]/[5000], train_loss: 0.036800, train_acc: 94.53%, val_loss: 2.641500, val_acc: 52.47%\n",
      "Epoch [2117]/[5000], train_loss: 0.048200, train_acc: 94.53%, val_loss: 2.947700, val_acc: 53.52%\n",
      "Epoch [2118]/[5000], train_loss: 0.035300, train_acc: 95.17%, val_loss: 2.831000, val_acc: 52.34%\n",
      "Epoch [2119]/[5000], train_loss: 0.061800, train_acc: 93.90%, val_loss: 2.410500, val_acc: 53.91%\n",
      "Epoch [2120]/[5000], train_loss: 0.043400, train_acc: 94.63%, val_loss: 3.047100, val_acc: 53.52%\n",
      "Epoch [2121]/[5000], train_loss: 0.069000, train_acc: 93.95%, val_loss: 2.581500, val_acc: 52.21%\n",
      "Epoch [2122]/[5000], train_loss: 0.068200, train_acc: 93.65%, val_loss: 2.706300, val_acc: 54.30%\n",
      "Epoch [2123]/[5000], train_loss: 0.071100, train_acc: 93.90%, val_loss: 2.687200, val_acc: 54.17%\n",
      "Epoch [2124]/[5000], train_loss: 0.074300, train_acc: 93.65%, val_loss: 2.419300, val_acc: 54.69%\n",
      "Epoch [2125]/[5000], train_loss: 0.047300, train_acc: 94.53%, val_loss: 2.486400, val_acc: 55.34%\n",
      "Epoch [2126]/[5000], train_loss: 0.064000, train_acc: 93.65%, val_loss: 2.949600, val_acc: 52.08%\n",
      "Epoch [2127]/[5000], train_loss: 0.054000, train_acc: 94.24%, val_loss: 2.521500, val_acc: 54.95%\n",
      "Epoch [2128]/[5000], train_loss: 0.055600, train_acc: 94.14%, val_loss: 2.929000, val_acc: 53.78%\n",
      "Epoch [2129]/[5000], train_loss: 0.072600, train_acc: 93.60%, val_loss: 2.729500, val_acc: 55.34%\n",
      "Epoch [2130]/[5000], train_loss: 0.068100, train_acc: 94.29%, val_loss: 2.774100, val_acc: 55.47%\n",
      "Epoch [2131]/[5000], train_loss: 0.068300, train_acc: 93.51%, val_loss: 2.465700, val_acc: 51.43%\n",
      "Epoch [2132]/[5000], train_loss: 0.062600, train_acc: 93.80%, val_loss: 2.256400, val_acc: 52.60%\n",
      "Epoch [2133]/[5000], train_loss: 0.069200, train_acc: 93.65%, val_loss: 2.618800, val_acc: 51.30%\n",
      "Epoch [2134]/[5000], train_loss: 0.061100, train_acc: 93.70%, val_loss: 2.506200, val_acc: 52.21%\n",
      "Epoch [2135]/[5000], train_loss: 0.083400, train_acc: 92.97%, val_loss: 2.711400, val_acc: 52.34%\n",
      "Epoch [2136]/[5000], train_loss: 0.096800, train_acc: 92.58%, val_loss: 2.890800, val_acc: 51.56%\n",
      "Epoch [2137]/[5000], train_loss: 0.102100, train_acc: 92.33%, val_loss: 2.550200, val_acc: 53.39%\n",
      "Epoch [2138]/[5000], train_loss: 0.084600, train_acc: 93.12%, val_loss: 2.589300, val_acc: 53.39%\n",
      "Epoch [2139]/[5000], train_loss: 0.083000, train_acc: 93.02%, val_loss: 2.561700, val_acc: 52.21%\n",
      "Epoch [2140]/[5000], train_loss: 0.107800, train_acc: 92.53%, val_loss: 2.662300, val_acc: 53.78%\n",
      "Epoch [2141]/[5000], train_loss: 0.087500, train_acc: 93.26%, val_loss: 2.480700, val_acc: 51.17%\n",
      "Epoch [2142]/[5000], train_loss: 0.094500, train_acc: 92.97%, val_loss: 2.696000, val_acc: 51.17%\n",
      "Epoch [2143]/[5000], train_loss: 0.106500, train_acc: 92.82%, val_loss: 2.286600, val_acc: 52.99%\n",
      "Epoch [2144]/[5000], train_loss: 0.102900, train_acc: 92.48%, val_loss: 2.440800, val_acc: 52.47%\n",
      "Epoch [2145]/[5000], train_loss: 0.091800, train_acc: 92.68%, val_loss: 2.062800, val_acc: 57.03%\n",
      "Epoch [2146]/[5000], train_loss: 0.056400, train_acc: 94.19%, val_loss: 2.439500, val_acc: 54.04%\n",
      "Epoch [2147]/[5000], train_loss: 0.049800, train_acc: 94.48%, val_loss: 2.472000, val_acc: 52.60%\n",
      "Epoch [2148]/[5000], train_loss: 0.048600, train_acc: 94.34%, val_loss: 2.472100, val_acc: 54.82%\n",
      "Epoch [2149]/[5000], train_loss: 0.065300, train_acc: 93.85%, val_loss: 2.905100, val_acc: 54.17%\n",
      "Epoch [2150]/[5000], train_loss: 0.085300, train_acc: 92.72%, val_loss: 2.490600, val_acc: 52.08%\n",
      "Epoch [2151]/[5000], train_loss: 0.065200, train_acc: 93.75%, val_loss: 2.663000, val_acc: 51.69%\n",
      "Epoch [2152]/[5000], train_loss: 0.082400, train_acc: 93.21%, val_loss: 2.452300, val_acc: 54.95%\n",
      "Epoch [2153]/[5000], train_loss: 0.067600, train_acc: 93.95%, val_loss: 2.613600, val_acc: 54.95%\n",
      "Epoch [2154]/[5000], train_loss: 0.055900, train_acc: 94.38%, val_loss: 2.592500, val_acc: 54.43%\n",
      "Epoch [2155]/[5000], train_loss: 0.051200, train_acc: 94.38%, val_loss: 2.299400, val_acc: 54.56%\n",
      "Epoch [2156]/[5000], train_loss: 0.059200, train_acc: 94.14%, val_loss: 2.846900, val_acc: 53.78%\n",
      "Epoch [2157]/[5000], train_loss: 0.054500, train_acc: 94.19%, val_loss: 2.761100, val_acc: 52.73%\n",
      "Epoch [2158]/[5000], train_loss: 0.061000, train_acc: 94.04%, val_loss: 2.542300, val_acc: 53.78%\n",
      "Epoch [2159]/[5000], train_loss: 0.066300, train_acc: 93.95%, val_loss: 2.504500, val_acc: 52.60%\n",
      "Epoch [2160]/[5000], train_loss: 0.055300, train_acc: 94.29%, val_loss: 2.365600, val_acc: 52.47%\n",
      "Epoch [2161]/[5000], train_loss: 0.062300, train_acc: 94.14%, val_loss: 2.368400, val_acc: 55.73%\n",
      "Epoch [2162]/[5000], train_loss: 0.088500, train_acc: 94.04%, val_loss: 2.343700, val_acc: 51.95%\n",
      "Epoch [2163]/[5000], train_loss: 0.082200, train_acc: 93.07%, val_loss: 2.582100, val_acc: 55.08%\n",
      "Epoch [2164]/[5000], train_loss: 0.095900, train_acc: 93.21%, val_loss: 2.470400, val_acc: 56.51%\n",
      "Epoch [2165]/[5000], train_loss: 0.108900, train_acc: 92.09%, val_loss: 2.362600, val_acc: 52.60%\n",
      "Epoch [2166]/[5000], train_loss: 0.094200, train_acc: 92.72%, val_loss: 2.275600, val_acc: 53.65%\n",
      "Epoch [2167]/[5000], train_loss: 0.092400, train_acc: 92.58%, val_loss: 2.684300, val_acc: 50.26%\n",
      "Epoch [2168]/[5000], train_loss: 0.073100, train_acc: 93.65%, val_loss: 2.582500, val_acc: 51.69%\n",
      "Epoch [2169]/[5000], train_loss: 0.053600, train_acc: 94.09%, val_loss: 2.468000, val_acc: 54.04%\n",
      "Epoch [2170]/[5000], train_loss: 0.056800, train_acc: 94.14%, val_loss: 2.420800, val_acc: 53.65%\n",
      "Epoch [2171]/[5000], train_loss: 0.056100, train_acc: 94.19%, val_loss: 2.377600, val_acc: 52.99%\n",
      "Epoch [2172]/[5000], train_loss: 0.056000, train_acc: 94.38%, val_loss: 2.541000, val_acc: 55.21%\n",
      "Epoch [2173]/[5000], train_loss: 0.067500, train_acc: 93.75%, val_loss: 2.260400, val_acc: 55.99%\n",
      "Epoch [2174]/[5000], train_loss: 0.043100, train_acc: 94.73%, val_loss: 2.513400, val_acc: 56.90%\n",
      "Epoch [2175]/[5000], train_loss: 0.047600, train_acc: 94.24%, val_loss: 2.503900, val_acc: 55.73%\n",
      "Epoch [2176]/[5000], train_loss: 0.046200, train_acc: 94.14%, val_loss: 2.701500, val_acc: 53.12%\n",
      "Epoch [2177]/[5000], train_loss: 0.045300, train_acc: 94.48%, val_loss: 2.624700, val_acc: 55.08%\n",
      "Epoch [2178]/[5000], train_loss: 0.036200, train_acc: 94.73%, val_loss: 2.592500, val_acc: 56.90%\n",
      "Epoch [2179]/[5000], train_loss: 0.035600, train_acc: 95.07%, val_loss: 2.756700, val_acc: 54.04%\n",
      "Epoch [2180]/[5000], train_loss: 0.034100, train_acc: 95.07%, val_loss: 2.915600, val_acc: 54.43%\n",
      "Epoch [2181]/[5000], train_loss: 0.055300, train_acc: 94.29%, val_loss: 2.700300, val_acc: 55.08%\n",
      "Epoch [2182]/[5000], train_loss: 0.056000, train_acc: 94.38%, val_loss: 2.823800, val_acc: 51.43%\n",
      "Epoch [2183]/[5000], train_loss: 0.041200, train_acc: 94.78%, val_loss: 2.781900, val_acc: 55.60%\n",
      "Epoch [2184]/[5000], train_loss: 0.035400, train_acc: 94.73%, val_loss: 2.773200, val_acc: 52.99%\n",
      "Epoch [2185]/[5000], train_loss: 0.054300, train_acc: 94.38%, val_loss: 2.754500, val_acc: 53.52%\n",
      "Epoch [2186]/[5000], train_loss: 0.043600, train_acc: 94.43%, val_loss: 2.355200, val_acc: 53.52%\n",
      "Epoch [2187]/[5000], train_loss: 0.054300, train_acc: 94.14%, val_loss: 2.540000, val_acc: 55.21%\n",
      "Epoch [2188]/[5000], train_loss: 0.044800, train_acc: 94.58%, val_loss: 2.440000, val_acc: 52.86%\n",
      "Epoch [2189]/[5000], train_loss: 0.061200, train_acc: 93.85%, val_loss: 2.696900, val_acc: 53.12%\n",
      "Epoch [2190]/[5000], train_loss: 0.061000, train_acc: 94.04%, val_loss: 2.724100, val_acc: 53.52%\n",
      "Epoch [2191]/[5000], train_loss: 0.072700, train_acc: 93.51%, val_loss: 2.984100, val_acc: 53.91%\n",
      "Epoch [2192]/[5000], train_loss: 0.088300, train_acc: 93.26%, val_loss: 2.719500, val_acc: 53.78%\n",
      "Epoch [2193]/[5000], train_loss: 0.092300, train_acc: 93.12%, val_loss: 2.853900, val_acc: 51.04%\n",
      "Epoch [2194]/[5000], train_loss: 0.075000, train_acc: 93.90%, val_loss: 2.611900, val_acc: 54.69%\n",
      "Epoch [2195]/[5000], train_loss: 0.059100, train_acc: 94.04%, val_loss: 2.908200, val_acc: 51.43%\n",
      "Epoch [2196]/[5000], train_loss: 0.080700, train_acc: 93.41%, val_loss: 2.949800, val_acc: 52.86%\n",
      "Epoch [2197]/[5000], train_loss: 0.040800, train_acc: 94.48%, val_loss: 2.276900, val_acc: 54.95%\n",
      "Epoch [2198]/[5000], train_loss: 0.058900, train_acc: 94.14%, val_loss: 2.517600, val_acc: 54.43%\n",
      "Epoch [2199]/[5000], train_loss: 0.049700, train_acc: 94.29%, val_loss: 2.570900, val_acc: 50.78%\n",
      "Epoch [2200]/[5000], train_loss: 0.060800, train_acc: 93.65%, val_loss: 2.471400, val_acc: 52.73%\n",
      "Epoch [2201]/[5000], train_loss: 0.045400, train_acc: 94.38%, val_loss: 2.839200, val_acc: 52.99%\n",
      "Epoch [2202]/[5000], train_loss: 0.043900, train_acc: 94.53%, val_loss: 2.412200, val_acc: 55.86%\n",
      "Epoch [2203]/[5000], train_loss: 0.040500, train_acc: 94.43%, val_loss: 2.636200, val_acc: 54.82%\n",
      "Epoch [2204]/[5000], train_loss: 0.053800, train_acc: 94.19%, val_loss: 2.541800, val_acc: 54.04%\n",
      "Epoch [2205]/[5000], train_loss: 0.054700, train_acc: 94.14%, val_loss: 2.664000, val_acc: 52.47%\n",
      "Epoch [2206]/[5000], train_loss: 0.037900, train_acc: 94.53%, val_loss: 2.557600, val_acc: 53.26%\n",
      "Epoch [2207]/[5000], train_loss: 0.092200, train_acc: 93.26%, val_loss: 2.706000, val_acc: 53.26%\n",
      "Epoch [2208]/[5000], train_loss: 0.070500, train_acc: 93.95%, val_loss: 2.842900, val_acc: 50.13%\n",
      "Epoch [2209]/[5000], train_loss: 0.080900, train_acc: 93.26%, val_loss: 2.481200, val_acc: 51.43%\n",
      "Epoch [2210]/[5000], train_loss: 0.070500, train_acc: 93.07%, val_loss: 2.928100, val_acc: 48.57%\n",
      "Epoch [2211]/[5000], train_loss: 0.067700, train_acc: 93.36%, val_loss: 2.883700, val_acc: 52.08%\n",
      "Epoch [2212]/[5000], train_loss: 0.044800, train_acc: 94.34%, val_loss: 2.459000, val_acc: 56.77%\n",
      "Epoch [2213]/[5000], train_loss: 0.044800, train_acc: 94.29%, val_loss: 2.811400, val_acc: 54.30%\n",
      "Epoch [2214]/[5000], train_loss: 0.038000, train_acc: 94.73%, val_loss: 2.713800, val_acc: 52.73%\n",
      "Epoch [2215]/[5000], train_loss: 0.053100, train_acc: 94.14%, val_loss: 2.556200, val_acc: 54.17%\n",
      "Epoch [2216]/[5000], train_loss: 0.042600, train_acc: 94.73%, val_loss: 3.183900, val_acc: 55.86%\n",
      "Epoch [2217]/[5000], train_loss: 0.063000, train_acc: 93.90%, val_loss: 2.877300, val_acc: 53.12%\n",
      "Epoch [2218]/[5000], train_loss: 0.067800, train_acc: 94.14%, val_loss: 2.483900, val_acc: 55.08%\n",
      "Epoch [2219]/[5000], train_loss: 0.069200, train_acc: 94.24%, val_loss: 2.892200, val_acc: 51.30%\n",
      "Epoch [2220]/[5000], train_loss: 0.082700, train_acc: 93.31%, val_loss: 2.655200, val_acc: 54.04%\n",
      "Epoch [2221]/[5000], train_loss: 0.073800, train_acc: 93.80%, val_loss: 2.607100, val_acc: 53.12%\n",
      "Epoch [2222]/[5000], train_loss: 0.050900, train_acc: 94.43%, val_loss: 2.430100, val_acc: 55.99%\n",
      "Epoch [2223]/[5000], train_loss: 0.058200, train_acc: 93.85%, val_loss: 2.468300, val_acc: 50.78%\n",
      "Epoch [2224]/[5000], train_loss: 0.079000, train_acc: 93.85%, val_loss: 2.727600, val_acc: 55.34%\n",
      "Epoch [2225]/[5000], train_loss: 0.079200, train_acc: 93.41%, val_loss: 2.301800, val_acc: 53.52%\n",
      "Epoch [2226]/[5000], train_loss: 0.091200, train_acc: 93.21%, val_loss: 2.684600, val_acc: 54.04%\n",
      "Epoch [2227]/[5000], train_loss: 0.055000, train_acc: 94.04%, val_loss: 2.196000, val_acc: 54.82%\n",
      "Epoch [2228]/[5000], train_loss: 0.060000, train_acc: 93.99%, val_loss: 2.522200, val_acc: 53.12%\n",
      "Epoch [2229]/[5000], train_loss: 0.067600, train_acc: 93.85%, val_loss: 2.526500, val_acc: 51.82%\n",
      "Epoch [2230]/[5000], train_loss: 0.055900, train_acc: 94.38%, val_loss: 2.549700, val_acc: 53.65%\n",
      "Epoch [2231]/[5000], train_loss: 0.042600, train_acc: 94.73%, val_loss: 2.244900, val_acc: 55.21%\n",
      "Epoch [2232]/[5000], train_loss: 0.059800, train_acc: 93.99%, val_loss: 2.743500, val_acc: 54.82%\n",
      "Epoch [2233]/[5000], train_loss: 0.055500, train_acc: 94.09%, val_loss: 2.357400, val_acc: 55.60%\n",
      "Epoch [2234]/[5000], train_loss: 0.041100, train_acc: 94.53%, val_loss: 2.637100, val_acc: 57.29%\n",
      "Epoch [2235]/[5000], train_loss: 0.054400, train_acc: 94.14%, val_loss: 2.539800, val_acc: 52.99%\n",
      "Epoch [2236]/[5000], train_loss: 0.050300, train_acc: 94.63%, val_loss: 2.376800, val_acc: 51.43%\n",
      "Epoch [2237]/[5000], train_loss: 0.039000, train_acc: 94.92%, val_loss: 2.888000, val_acc: 52.47%\n",
      "Epoch [2238]/[5000], train_loss: 0.058200, train_acc: 94.19%, val_loss: 2.385600, val_acc: 54.17%\n",
      "Epoch [2239]/[5000], train_loss: 0.092800, train_acc: 92.68%, val_loss: 2.550100, val_acc: 49.61%\n",
      "Epoch [2240]/[5000], train_loss: 0.085200, train_acc: 93.51%, val_loss: 2.717900, val_acc: 53.39%\n",
      "Epoch [2241]/[5000], train_loss: 0.109600, train_acc: 92.48%, val_loss: 3.135700, val_acc: 53.39%\n",
      "Epoch [2242]/[5000], train_loss: 0.076900, train_acc: 93.36%, val_loss: 2.627400, val_acc: 54.82%\n",
      "Epoch [2243]/[5000], train_loss: 0.065400, train_acc: 94.24%, val_loss: 2.513600, val_acc: 53.91%\n",
      "Epoch [2244]/[5000], train_loss: 0.049000, train_acc: 94.38%, val_loss: 2.462600, val_acc: 53.52%\n",
      "Epoch [2245]/[5000], train_loss: 0.046200, train_acc: 94.58%, val_loss: 2.680600, val_acc: 54.95%\n",
      "Epoch [2246]/[5000], train_loss: 0.044900, train_acc: 94.38%, val_loss: 2.514600, val_acc: 51.30%\n",
      "Epoch [2247]/[5000], train_loss: 0.062000, train_acc: 93.55%, val_loss: 2.340600, val_acc: 52.08%\n",
      "Epoch [2248]/[5000], train_loss: 0.058400, train_acc: 94.38%, val_loss: 2.870900, val_acc: 52.73%\n",
      "Epoch [2249]/[5000], train_loss: 0.067600, train_acc: 93.90%, val_loss: 2.569600, val_acc: 49.61%\n",
      "Epoch [2250]/[5000], train_loss: 0.072400, train_acc: 93.85%, val_loss: 2.532700, val_acc: 52.34%\n",
      "Epoch [2251]/[5000], train_loss: 0.103500, train_acc: 92.53%, val_loss: 3.014300, val_acc: 50.52%\n",
      "Epoch [2252]/[5000], train_loss: 0.086700, train_acc: 93.21%, val_loss: 2.469900, val_acc: 52.99%\n",
      "Epoch [2253]/[5000], train_loss: 0.090200, train_acc: 92.77%, val_loss: 2.533300, val_acc: 55.86%\n",
      "Epoch [2254]/[5000], train_loss: 0.084000, train_acc: 93.21%, val_loss: 2.501800, val_acc: 53.52%\n",
      "Epoch [2255]/[5000], train_loss: 0.094200, train_acc: 92.92%, val_loss: 2.466900, val_acc: 52.73%\n",
      "Epoch [2256]/[5000], train_loss: 0.072300, train_acc: 93.51%, val_loss: 2.652500, val_acc: 53.65%\n",
      "Epoch [2257]/[5000], train_loss: 0.062500, train_acc: 93.46%, val_loss: 2.473300, val_acc: 53.78%\n",
      "Epoch [2258]/[5000], train_loss: 0.051400, train_acc: 94.48%, val_loss: 2.455100, val_acc: 53.65%\n",
      "Epoch [2259]/[5000], train_loss: 0.050200, train_acc: 94.63%, val_loss: 2.562500, val_acc: 56.38%\n",
      "Epoch [2260]/[5000], train_loss: 0.056500, train_acc: 93.99%, val_loss: 2.313600, val_acc: 54.82%\n",
      "Epoch [2261]/[5000], train_loss: 0.052000, train_acc: 94.29%, val_loss: 2.426500, val_acc: 51.95%\n",
      "Epoch [2262]/[5000], train_loss: 0.052100, train_acc: 94.38%, val_loss: 2.520100, val_acc: 52.47%\n",
      "Epoch [2263]/[5000], train_loss: 0.031400, train_acc: 95.07%, val_loss: 2.881600, val_acc: 54.43%\n",
      "Epoch [2264]/[5000], train_loss: 0.039600, train_acc: 94.82%, val_loss: 2.311900, val_acc: 55.21%\n",
      "Epoch [2265]/[5000], train_loss: 0.043400, train_acc: 94.53%, val_loss: 2.675400, val_acc: 55.21%\n",
      "Epoch [2266]/[5000], train_loss: 0.053200, train_acc: 94.14%, val_loss: 2.973100, val_acc: 56.12%\n",
      "Epoch [2267]/[5000], train_loss: 0.051400, train_acc: 94.24%, val_loss: 2.801700, val_acc: 52.47%\n",
      "Epoch [2268]/[5000], train_loss: 0.059900, train_acc: 94.09%, val_loss: 2.760500, val_acc: 49.74%\n",
      "Epoch [2269]/[5000], train_loss: 0.078400, train_acc: 93.26%, val_loss: 2.778700, val_acc: 55.21%\n",
      "Epoch [2270]/[5000], train_loss: 0.063200, train_acc: 94.29%, val_loss: 2.766800, val_acc: 52.21%\n",
      "Epoch [2271]/[5000], train_loss: 0.035800, train_acc: 94.53%, val_loss: 2.871600, val_acc: 50.00%\n",
      "Epoch [2272]/[5000], train_loss: 0.037000, train_acc: 94.92%, val_loss: 2.774300, val_acc: 54.43%\n",
      "Epoch [2273]/[5000], train_loss: 0.052500, train_acc: 94.09%, val_loss: 2.557700, val_acc: 53.39%\n",
      "Epoch [2274]/[5000], train_loss: 0.033200, train_acc: 95.12%, val_loss: 2.739600, val_acc: 52.73%\n",
      "Epoch [2275]/[5000], train_loss: 0.042900, train_acc: 94.92%, val_loss: 2.492000, val_acc: 55.21%\n",
      "Epoch [2276]/[5000], train_loss: 0.042400, train_acc: 94.92%, val_loss: 2.725200, val_acc: 55.34%\n",
      "Epoch [2277]/[5000], train_loss: 0.031800, train_acc: 94.97%, val_loss: 2.566200, val_acc: 52.47%\n",
      "Epoch [2278]/[5000], train_loss: 0.044800, train_acc: 94.73%, val_loss: 2.310800, val_acc: 55.99%\n",
      "Epoch [2279]/[5000], train_loss: 0.051900, train_acc: 94.34%, val_loss: 2.369200, val_acc: 54.56%\n",
      "Epoch [2280]/[5000], train_loss: 0.062000, train_acc: 94.04%, val_loss: 2.803900, val_acc: 51.69%\n",
      "Epoch [2281]/[5000], train_loss: 0.056200, train_acc: 94.14%, val_loss: 2.903200, val_acc: 52.86%\n",
      "Epoch [2282]/[5000], train_loss: 0.072800, train_acc: 93.90%, val_loss: 2.644800, val_acc: 52.86%\n",
      "Epoch [2283]/[5000], train_loss: 0.053400, train_acc: 94.34%, val_loss: 2.368500, val_acc: 54.82%\n",
      "Epoch [2284]/[5000], train_loss: 0.061200, train_acc: 94.14%, val_loss: 2.959200, val_acc: 52.99%\n",
      "Epoch [2285]/[5000], train_loss: 0.060700, train_acc: 94.24%, val_loss: 2.690900, val_acc: 55.60%\n",
      "Epoch [2286]/[5000], train_loss: 0.058400, train_acc: 94.38%, val_loss: 2.464700, val_acc: 53.12%\n",
      "Epoch [2287]/[5000], train_loss: 0.050400, train_acc: 94.48%, val_loss: 2.704500, val_acc: 54.30%\n",
      "Epoch [2288]/[5000], train_loss: 0.052700, train_acc: 94.29%, val_loss: 2.815900, val_acc: 53.26%\n",
      "Epoch [2289]/[5000], train_loss: 0.039200, train_acc: 94.78%, val_loss: 2.533000, val_acc: 55.47%\n",
      "Epoch [2290]/[5000], train_loss: 0.049500, train_acc: 94.53%, val_loss: 2.498500, val_acc: 55.73%\n",
      "Epoch [2291]/[5000], train_loss: 0.058900, train_acc: 94.14%, val_loss: 2.716700, val_acc: 51.04%\n",
      "Epoch [2292]/[5000], train_loss: 0.053600, train_acc: 94.43%, val_loss: 2.560000, val_acc: 53.78%\n",
      "Epoch [2293]/[5000], train_loss: 0.062600, train_acc: 93.75%, val_loss: 2.467400, val_acc: 51.30%\n",
      "Epoch [2294]/[5000], train_loss: 0.071400, train_acc: 93.46%, val_loss: 2.587500, val_acc: 53.91%\n",
      "Epoch [2295]/[5000], train_loss: 0.069100, train_acc: 94.04%, val_loss: 2.344500, val_acc: 52.60%\n",
      "Epoch [2296]/[5000], train_loss: 0.049700, train_acc: 94.34%, val_loss: 2.550800, val_acc: 50.91%\n",
      "Epoch [2297]/[5000], train_loss: 0.052200, train_acc: 94.34%, val_loss: 2.547000, val_acc: 53.78%\n",
      "Epoch [2298]/[5000], train_loss: 0.049400, train_acc: 94.53%, val_loss: 2.669000, val_acc: 55.08%\n",
      "Epoch [2299]/[5000], train_loss: 0.051800, train_acc: 94.34%, val_loss: 2.946300, val_acc: 49.87%\n",
      "Epoch [2300]/[5000], train_loss: 0.063100, train_acc: 94.19%, val_loss: 2.246100, val_acc: 52.99%\n",
      "Epoch [2301]/[5000], train_loss: 0.036300, train_acc: 94.92%, val_loss: 2.509400, val_acc: 52.60%\n",
      "Epoch [2302]/[5000], train_loss: 0.039800, train_acc: 94.53%, val_loss: 2.412900, val_acc: 54.69%\n",
      "Epoch [2303]/[5000], train_loss: 0.055800, train_acc: 94.34%, val_loss: 2.576400, val_acc: 53.91%\n",
      "Epoch [2304]/[5000], train_loss: 0.066700, train_acc: 93.99%, val_loss: 3.000000, val_acc: 53.12%\n",
      "Epoch [2305]/[5000], train_loss: 0.080300, train_acc: 93.26%, val_loss: 2.850600, val_acc: 52.21%\n",
      "Epoch [2306]/[5000], train_loss: 0.052600, train_acc: 94.48%, val_loss: 2.417600, val_acc: 54.82%\n",
      "Epoch [2307]/[5000], train_loss: 0.060600, train_acc: 93.90%, val_loss: 2.989100, val_acc: 52.99%\n",
      "Epoch [2308]/[5000], train_loss: 0.067900, train_acc: 93.80%, val_loss: 2.752400, val_acc: 49.87%\n",
      "Epoch [2309]/[5000], train_loss: 0.072100, train_acc: 93.90%, val_loss: 2.281200, val_acc: 54.95%\n",
      "Epoch [2310]/[5000], train_loss: 0.048000, train_acc: 94.43%, val_loss: 2.339800, val_acc: 51.56%\n",
      "Epoch [2311]/[5000], train_loss: 0.045900, train_acc: 94.19%, val_loss: 2.909900, val_acc: 56.90%\n",
      "Epoch [2312]/[5000], train_loss: 0.071800, train_acc: 94.19%, val_loss: 2.591200, val_acc: 54.17%\n",
      "Epoch [2313]/[5000], train_loss: 0.050800, train_acc: 94.68%, val_loss: 2.562400, val_acc: 54.30%\n",
      "Epoch [2314]/[5000], train_loss: 0.068900, train_acc: 93.55%, val_loss: 2.237400, val_acc: 55.08%\n",
      "Epoch [2315]/[5000], train_loss: 0.094700, train_acc: 92.77%, val_loss: 2.333800, val_acc: 52.08%\n",
      "Epoch [2316]/[5000], train_loss: 0.083800, train_acc: 93.12%, val_loss: 2.971700, val_acc: 57.42%\n",
      "Epoch [2317]/[5000], train_loss: 0.082100, train_acc: 92.97%, val_loss: 2.775200, val_acc: 50.26%\n",
      "Epoch [2318]/[5000], train_loss: 0.079800, train_acc: 93.12%, val_loss: 2.526800, val_acc: 50.78%\n",
      "Epoch [2319]/[5000], train_loss: 0.051500, train_acc: 94.19%, val_loss: 2.474700, val_acc: 52.73%\n",
      "Epoch [2320]/[5000], train_loss: 0.052200, train_acc: 94.24%, val_loss: 2.548100, val_acc: 52.60%\n",
      "Epoch [2321]/[5000], train_loss: 0.043700, train_acc: 94.68%, val_loss: 2.545900, val_acc: 55.21%\n",
      "Epoch [2322]/[5000], train_loss: 0.055800, train_acc: 94.04%, val_loss: 2.939100, val_acc: 56.64%\n",
      "Epoch [2323]/[5000], train_loss: 0.056100, train_acc: 94.43%, val_loss: 2.611000, val_acc: 55.34%\n",
      "Epoch [2324]/[5000], train_loss: 0.058200, train_acc: 93.99%, val_loss: 2.607500, val_acc: 54.69%\n",
      "Epoch [2325]/[5000], train_loss: 0.057300, train_acc: 94.04%, val_loss: 2.304200, val_acc: 54.56%\n",
      "Epoch [2326]/[5000], train_loss: 0.060700, train_acc: 94.29%, val_loss: 2.538600, val_acc: 57.55%\n",
      "Epoch [2327]/[5000], train_loss: 0.045600, train_acc: 94.78%, val_loss: 2.290100, val_acc: 54.43%\n",
      "Epoch [2328]/[5000], train_loss: 0.047500, train_acc: 94.48%, val_loss: 2.121300, val_acc: 55.47%\n",
      "Epoch [2329]/[5000], train_loss: 0.057800, train_acc: 94.14%, val_loss: 2.353900, val_acc: 54.82%\n",
      "Epoch [2330]/[5000], train_loss: 0.049300, train_acc: 94.09%, val_loss: 2.687200, val_acc: 56.51%\n",
      "Epoch [2331]/[5000], train_loss: 0.039200, train_acc: 94.73%, val_loss: 2.266400, val_acc: 54.95%\n",
      "Epoch [2332]/[5000], train_loss: 0.051800, train_acc: 94.63%, val_loss: 2.850700, val_acc: 52.34%\n",
      "Epoch [2333]/[5000], train_loss: 0.057800, train_acc: 94.14%, val_loss: 2.414800, val_acc: 55.08%\n",
      "Epoch [2334]/[5000], train_loss: 0.057600, train_acc: 94.34%, val_loss: 2.531700, val_acc: 51.43%\n",
      "Epoch [2335]/[5000], train_loss: 0.041600, train_acc: 94.43%, val_loss: 2.751100, val_acc: 52.08%\n",
      "Epoch [2336]/[5000], train_loss: 0.049600, train_acc: 94.48%, val_loss: 2.411700, val_acc: 54.30%\n",
      "Epoch [2337]/[5000], train_loss: 0.044000, train_acc: 94.58%, val_loss: 2.528200, val_acc: 56.64%\n",
      "Epoch [2338]/[5000], train_loss: 0.054400, train_acc: 94.19%, val_loss: 2.419900, val_acc: 52.47%\n",
      "Epoch [2339]/[5000], train_loss: 0.052200, train_acc: 94.19%, val_loss: 2.827300, val_acc: 54.17%\n",
      "Epoch [2340]/[5000], train_loss: 0.038800, train_acc: 94.58%, val_loss: 2.468400, val_acc: 51.30%\n",
      "Epoch [2341]/[5000], train_loss: 0.043300, train_acc: 94.29%, val_loss: 3.219700, val_acc: 50.91%\n",
      "Epoch [2342]/[5000], train_loss: 0.030000, train_acc: 94.97%, val_loss: 2.417900, val_acc: 53.91%\n",
      "Epoch [2343]/[5000], train_loss: 0.038000, train_acc: 94.92%, val_loss: 2.700800, val_acc: 51.69%\n",
      "Epoch [2344]/[5000], train_loss: 0.057600, train_acc: 94.19%, val_loss: 2.566800, val_acc: 55.34%\n",
      "Epoch [2345]/[5000], train_loss: 0.040200, train_acc: 94.73%, val_loss: 2.371900, val_acc: 53.26%\n",
      "Epoch [2346]/[5000], train_loss: 0.056500, train_acc: 94.24%, val_loss: 2.751900, val_acc: 53.52%\n",
      "Epoch [2347]/[5000], train_loss: 0.064900, train_acc: 93.65%, val_loss: 2.768600, val_acc: 56.25%\n",
      "Epoch [2348]/[5000], train_loss: 0.094000, train_acc: 92.87%, val_loss: 2.816700, val_acc: 50.91%\n",
      "Epoch [2349]/[5000], train_loss: 0.131400, train_acc: 92.33%, val_loss: 2.487500, val_acc: 52.34%\n",
      "Epoch [2350]/[5000], train_loss: 0.094400, train_acc: 93.12%, val_loss: 2.650900, val_acc: 53.78%\n",
      "Epoch [2351]/[5000], train_loss: 0.072800, train_acc: 93.51%, val_loss: 2.561900, val_acc: 53.65%\n",
      "Epoch [2352]/[5000], train_loss: 0.085600, train_acc: 93.07%, val_loss: 2.707300, val_acc: 52.73%\n",
      "Epoch [2353]/[5000], train_loss: 0.078900, train_acc: 93.41%, val_loss: 2.284000, val_acc: 51.56%\n",
      "Epoch [2354]/[5000], train_loss: 0.081100, train_acc: 93.36%, val_loss: 2.684000, val_acc: 50.91%\n",
      "Epoch [2355]/[5000], train_loss: 0.139100, train_acc: 91.65%, val_loss: 2.443200, val_acc: 53.52%\n",
      "Epoch [2356]/[5000], train_loss: 0.101600, train_acc: 92.43%, val_loss: 2.734100, val_acc: 54.69%\n",
      "Epoch [2357]/[5000], train_loss: 0.090000, train_acc: 93.12%, val_loss: 2.510800, val_acc: 53.26%\n",
      "Epoch [2358]/[5000], train_loss: 0.064300, train_acc: 93.80%, val_loss: 3.233500, val_acc: 50.26%\n",
      "Epoch [2359]/[5000], train_loss: 0.057300, train_acc: 94.24%, val_loss: 2.778500, val_acc: 52.99%\n",
      "Epoch [2360]/[5000], train_loss: 0.061000, train_acc: 93.80%, val_loss: 3.015100, val_acc: 52.34%\n",
      "Epoch [2361]/[5000], train_loss: 0.054500, train_acc: 94.19%, val_loss: 2.408600, val_acc: 56.64%\n",
      "Epoch [2362]/[5000], train_loss: 0.044100, train_acc: 94.82%, val_loss: 2.341700, val_acc: 55.73%\n",
      "Epoch [2363]/[5000], train_loss: 0.050900, train_acc: 94.24%, val_loss: 2.421200, val_acc: 54.69%\n",
      "Epoch [2364]/[5000], train_loss: 0.055900, train_acc: 94.53%, val_loss: 2.799000, val_acc: 54.95%\n",
      "Epoch [2365]/[5000], train_loss: 0.041000, train_acc: 94.58%, val_loss: 2.579100, val_acc: 51.17%\n",
      "Epoch [2366]/[5000], train_loss: 0.043700, train_acc: 94.82%, val_loss: 2.484500, val_acc: 52.86%\n",
      "Epoch [2367]/[5000], train_loss: 0.029100, train_acc: 95.07%, val_loss: 2.294300, val_acc: 55.08%\n",
      "Epoch [2368]/[5000], train_loss: 0.046400, train_acc: 94.34%, val_loss: 2.234000, val_acc: 56.90%\n",
      "Epoch [2369]/[5000], train_loss: 0.052400, train_acc: 94.58%, val_loss: 2.547800, val_acc: 54.82%\n",
      "Epoch [2370]/[5000], train_loss: 0.056700, train_acc: 94.14%, val_loss: 3.000000, val_acc: 53.52%\n",
      "Epoch [2371]/[5000], train_loss: 0.052800, train_acc: 94.29%, val_loss: 2.513500, val_acc: 54.95%\n",
      "Epoch [2372]/[5000], train_loss: 0.038100, train_acc: 94.78%, val_loss: 2.521900, val_acc: 57.29%\n",
      "Epoch [2373]/[5000], train_loss: 0.038000, train_acc: 94.82%, val_loss: 2.623000, val_acc: 56.77%\n",
      "Epoch [2374]/[5000], train_loss: 0.043600, train_acc: 94.68%, val_loss: 2.951400, val_acc: 53.52%\n",
      "Epoch [2375]/[5000], train_loss: 0.034200, train_acc: 95.17%, val_loss: 2.762500, val_acc: 55.60%\n",
      "Epoch [2376]/[5000], train_loss: 0.055300, train_acc: 94.19%, val_loss: 2.692700, val_acc: 55.86%\n",
      "Epoch [2377]/[5000], train_loss: 0.044800, train_acc: 94.78%, val_loss: 2.844500, val_acc: 50.91%\n",
      "Epoch [2378]/[5000], train_loss: 0.071000, train_acc: 93.65%, val_loss: 2.793500, val_acc: 51.56%\n",
      "Epoch [2379]/[5000], train_loss: 0.058800, train_acc: 94.14%, val_loss: 2.910100, val_acc: 55.47%\n",
      "Epoch [2380]/[5000], train_loss: 0.053900, train_acc: 94.09%, val_loss: 2.639500, val_acc: 52.34%\n",
      "Epoch [2381]/[5000], train_loss: 0.040600, train_acc: 94.78%, val_loss: 2.240000, val_acc: 54.04%\n",
      "Epoch [2382]/[5000], train_loss: 0.037800, train_acc: 94.87%, val_loss: 2.848400, val_acc: 51.69%\n",
      "Epoch [2383]/[5000], train_loss: 0.043800, train_acc: 94.63%, val_loss: 2.538300, val_acc: 52.99%\n",
      "Epoch [2384]/[5000], train_loss: 0.055700, train_acc: 93.90%, val_loss: 3.007200, val_acc: 51.04%\n",
      "Epoch [2385]/[5000], train_loss: 0.058000, train_acc: 94.19%, val_loss: 2.867700, val_acc: 48.44%\n",
      "Epoch [2386]/[5000], train_loss: 0.056000, train_acc: 94.43%, val_loss: 2.826500, val_acc: 53.52%\n",
      "Epoch [2387]/[5000], train_loss: 0.063600, train_acc: 93.85%, val_loss: 2.454400, val_acc: 55.08%\n",
      "Epoch [2388]/[5000], train_loss: 0.050700, train_acc: 94.43%, val_loss: 2.822700, val_acc: 54.30%\n",
      "Epoch [2389]/[5000], train_loss: 0.044800, train_acc: 94.34%, val_loss: 2.502000, val_acc: 53.26%\n",
      "Epoch [2390]/[5000], train_loss: 0.052400, train_acc: 94.34%, val_loss: 2.693400, val_acc: 52.86%\n",
      "Epoch [2391]/[5000], train_loss: 0.042900, train_acc: 94.73%, val_loss: 2.739600, val_acc: 53.26%\n",
      "Epoch [2392]/[5000], train_loss: 0.031600, train_acc: 95.21%, val_loss: 2.553600, val_acc: 54.30%\n",
      "Epoch [2393]/[5000], train_loss: 0.027100, train_acc: 95.17%, val_loss: 2.726800, val_acc: 55.60%\n",
      "Epoch [2394]/[5000], train_loss: 0.046800, train_acc: 94.38%, val_loss: 2.772200, val_acc: 53.78%\n",
      "Epoch [2395]/[5000], train_loss: 0.039200, train_acc: 94.87%, val_loss: 2.967600, val_acc: 53.26%\n",
      "Epoch [2396]/[5000], train_loss: 0.032500, train_acc: 95.07%, val_loss: 2.958600, val_acc: 55.47%\n",
      "Epoch [2397]/[5000], train_loss: 0.036600, train_acc: 94.97%, val_loss: 2.612500, val_acc: 54.04%\n",
      "Epoch [2398]/[5000], train_loss: 0.059600, train_acc: 94.24%, val_loss: 2.848200, val_acc: 55.47%\n",
      "Epoch [2399]/[5000], train_loss: 0.062200, train_acc: 94.04%, val_loss: 2.543800, val_acc: 54.04%\n",
      "Epoch [2400]/[5000], train_loss: 0.114000, train_acc: 92.24%, val_loss: 2.885500, val_acc: 51.43%\n",
      "Epoch [2401]/[5000], train_loss: 0.102700, train_acc: 92.72%, val_loss: 2.748500, val_acc: 52.34%\n",
      "Epoch [2402]/[5000], train_loss: 0.108400, train_acc: 92.53%, val_loss: 2.386600, val_acc: 54.56%\n",
      "Epoch [2403]/[5000], train_loss: 0.079000, train_acc: 93.21%, val_loss: 2.762800, val_acc: 52.34%\n",
      "Epoch [2404]/[5000], train_loss: 0.095300, train_acc: 92.87%, val_loss: 2.512000, val_acc: 52.86%\n",
      "Epoch [2405]/[5000], train_loss: 0.065200, train_acc: 94.04%, val_loss: 2.587200, val_acc: 52.08%\n",
      "Epoch [2406]/[5000], train_loss: 0.061200, train_acc: 94.19%, val_loss: 2.359600, val_acc: 55.60%\n",
      "Epoch [2407]/[5000], train_loss: 0.062200, train_acc: 93.90%, val_loss: 2.662900, val_acc: 54.43%\n",
      "Epoch [2408]/[5000], train_loss: 0.071100, train_acc: 93.90%, val_loss: 2.535500, val_acc: 52.60%\n",
      "Epoch [2409]/[5000], train_loss: 0.069900, train_acc: 93.99%, val_loss: 2.666700, val_acc: 52.60%\n",
      "Epoch [2410]/[5000], train_loss: 0.050800, train_acc: 94.48%, val_loss: 2.390900, val_acc: 54.43%\n",
      "Epoch [2411]/[5000], train_loss: 0.036300, train_acc: 94.68%, val_loss: 2.792000, val_acc: 56.12%\n",
      "Epoch [2412]/[5000], train_loss: 0.030200, train_acc: 95.12%, val_loss: 2.251700, val_acc: 55.99%\n",
      "Epoch [2413]/[5000], train_loss: 0.044100, train_acc: 94.87%, val_loss: 2.558900, val_acc: 55.73%\n",
      "Epoch [2414]/[5000], train_loss: 0.031600, train_acc: 95.02%, val_loss: 2.314300, val_acc: 55.47%\n",
      "Epoch [2415]/[5000], train_loss: 0.031800, train_acc: 94.97%, val_loss: 2.745100, val_acc: 53.52%\n",
      "Epoch [2416]/[5000], train_loss: 0.046500, train_acc: 94.48%, val_loss: 2.419400, val_acc: 54.30%\n",
      "Epoch [2417]/[5000], train_loss: 0.043000, train_acc: 94.34%, val_loss: 2.786400, val_acc: 55.08%\n",
      "Epoch [2418]/[5000], train_loss: 0.037100, train_acc: 94.58%, val_loss: 2.930800, val_acc: 55.21%\n",
      "Epoch [2419]/[5000], train_loss: 0.055100, train_acc: 94.04%, val_loss: 2.675600, val_acc: 57.29%\n",
      "Epoch [2420]/[5000], train_loss: 0.033200, train_acc: 95.02%, val_loss: 3.098900, val_acc: 55.60%\n",
      "Epoch [2421]/[5000], train_loss: 0.042300, train_acc: 94.58%, val_loss: 2.630000, val_acc: 55.86%\n",
      "Epoch [2422]/[5000], train_loss: 0.035200, train_acc: 95.12%, val_loss: 2.971900, val_acc: 56.77%\n",
      "Epoch [2423]/[5000], train_loss: 0.039700, train_acc: 94.87%, val_loss: 2.538200, val_acc: 56.51%\n",
      "Epoch [2424]/[5000], train_loss: 0.045500, train_acc: 94.29%, val_loss: 2.985600, val_acc: 53.26%\n",
      "Epoch [2425]/[5000], train_loss: 0.067400, train_acc: 94.09%, val_loss: 2.737300, val_acc: 51.95%\n",
      "Epoch [2426]/[5000], train_loss: 0.084300, train_acc: 93.41%, val_loss: 3.066000, val_acc: 53.65%\n",
      "Epoch [2427]/[5000], train_loss: 0.062900, train_acc: 93.41%, val_loss: 2.340300, val_acc: 54.69%\n",
      "Epoch [2428]/[5000], train_loss: 0.056000, train_acc: 93.95%, val_loss: 2.434400, val_acc: 53.39%\n",
      "Epoch [2429]/[5000], train_loss: 0.055900, train_acc: 94.48%, val_loss: 2.810100, val_acc: 51.17%\n",
      "Epoch [2430]/[5000], train_loss: 0.068700, train_acc: 94.29%, val_loss: 2.646300, val_acc: 51.69%\n",
      "Epoch [2431]/[5000], train_loss: 0.075200, train_acc: 93.07%, val_loss: 2.780100, val_acc: 53.52%\n",
      "Epoch [2432]/[5000], train_loss: 0.079200, train_acc: 93.90%, val_loss: 2.945200, val_acc: 53.65%\n",
      "Epoch [2433]/[5000], train_loss: 0.053500, train_acc: 94.14%, val_loss: 3.164200, val_acc: 53.52%\n",
      "Epoch [2434]/[5000], train_loss: 0.083900, train_acc: 92.97%, val_loss: 2.861300, val_acc: 52.73%\n",
      "Epoch [2435]/[5000], train_loss: 0.074600, train_acc: 93.60%, val_loss: 2.893600, val_acc: 52.34%\n",
      "Epoch [2436]/[5000], train_loss: 0.074400, train_acc: 93.46%, val_loss: 3.276300, val_acc: 55.21%\n",
      "Epoch [2437]/[5000], train_loss: 0.067800, train_acc: 93.80%, val_loss: 2.810800, val_acc: 50.52%\n",
      "Epoch [2438]/[5000], train_loss: 0.076800, train_acc: 93.75%, val_loss: 2.524700, val_acc: 52.47%\n",
      "Epoch [2439]/[5000], train_loss: 0.063700, train_acc: 94.53%, val_loss: 2.699500, val_acc: 53.52%\n",
      "Epoch [2440]/[5000], train_loss: 0.074600, train_acc: 93.21%, val_loss: 3.020600, val_acc: 52.08%\n",
      "Epoch [2441]/[5000], train_loss: 0.079300, train_acc: 93.51%, val_loss: 2.393700, val_acc: 55.34%\n",
      "Epoch [2442]/[5000], train_loss: 0.071600, train_acc: 93.85%, val_loss: 2.756100, val_acc: 55.08%\n",
      "Epoch [2443]/[5000], train_loss: 0.071100, train_acc: 93.60%, val_loss: 2.617300, val_acc: 53.52%\n",
      "Epoch [2444]/[5000], train_loss: 0.068500, train_acc: 93.85%, val_loss: 2.618400, val_acc: 53.12%\n",
      "Epoch [2445]/[5000], train_loss: 0.058900, train_acc: 94.14%, val_loss: 2.988900, val_acc: 50.26%\n",
      "Epoch [2446]/[5000], train_loss: 0.052500, train_acc: 94.53%, val_loss: 2.765300, val_acc: 55.34%\n",
      "Epoch [2447]/[5000], train_loss: 0.033800, train_acc: 94.92%, val_loss: 3.007500, val_acc: 53.78%\n",
      "Epoch [2448]/[5000], train_loss: 0.043600, train_acc: 94.58%, val_loss: 2.581500, val_acc: 55.47%\n",
      "Epoch [2449]/[5000], train_loss: 0.037300, train_acc: 94.63%, val_loss: 2.842300, val_acc: 55.73%\n",
      "Epoch [2450]/[5000], train_loss: 0.043800, train_acc: 94.53%, val_loss: 3.098200, val_acc: 51.30%\n",
      "Epoch [2451]/[5000], train_loss: 0.050500, train_acc: 94.43%, val_loss: 2.932600, val_acc: 55.99%\n",
      "Epoch [2452]/[5000], train_loss: 0.042300, train_acc: 94.53%, val_loss: 2.810600, val_acc: 54.04%\n",
      "Epoch [2453]/[5000], train_loss: 0.038400, train_acc: 94.68%, val_loss: 2.779100, val_acc: 54.43%\n",
      "Epoch [2454]/[5000], train_loss: 0.036900, train_acc: 94.78%, val_loss: 2.650800, val_acc: 54.17%\n",
      "Epoch [2455]/[5000], train_loss: 0.051900, train_acc: 94.19%, val_loss: 2.570600, val_acc: 54.43%\n",
      "Epoch [2456]/[5000], train_loss: 0.040300, train_acc: 94.68%, val_loss: 3.095900, val_acc: 55.86%\n",
      "Epoch [2457]/[5000], train_loss: 0.034600, train_acc: 94.92%, val_loss: 3.007200, val_acc: 53.78%\n",
      "Epoch [2458]/[5000], train_loss: 0.042600, train_acc: 94.58%, val_loss: 2.755300, val_acc: 53.91%\n",
      "Epoch [2459]/[5000], train_loss: 0.039000, train_acc: 94.73%, val_loss: 2.683800, val_acc: 53.65%\n",
      "Epoch [2460]/[5000], train_loss: 0.035300, train_acc: 94.87%, val_loss: 2.895800, val_acc: 54.04%\n",
      "Epoch [2461]/[5000], train_loss: 0.044200, train_acc: 94.19%, val_loss: 3.029600, val_acc: 50.78%\n",
      "Epoch [2462]/[5000], train_loss: 0.050400, train_acc: 94.14%, val_loss: 2.673900, val_acc: 55.60%\n",
      "Epoch [2463]/[5000], train_loss: 0.051800, train_acc: 94.43%, val_loss: 2.923000, val_acc: 51.82%\n",
      "Epoch [2464]/[5000], train_loss: 0.055700, train_acc: 93.80%, val_loss: 2.947700, val_acc: 54.95%\n",
      "Epoch [2465]/[5000], train_loss: 0.056300, train_acc: 94.09%, val_loss: 3.297300, val_acc: 54.43%\n",
      "Epoch [2466]/[5000], train_loss: 0.078500, train_acc: 93.12%, val_loss: 3.012900, val_acc: 53.12%\n",
      "Epoch [2467]/[5000], train_loss: 0.061000, train_acc: 93.75%, val_loss: 3.114400, val_acc: 55.73%\n",
      "Epoch [2468]/[5000], train_loss: 0.082500, train_acc: 93.31%, val_loss: 3.231800, val_acc: 50.13%\n",
      "Epoch [2469]/[5000], train_loss: 0.048700, train_acc: 94.53%, val_loss: 2.707400, val_acc: 52.73%\n",
      "Epoch [2470]/[5000], train_loss: 0.046600, train_acc: 94.19%, val_loss: 2.658200, val_acc: 54.56%\n",
      "Epoch [2471]/[5000], train_loss: 0.030000, train_acc: 95.12%, val_loss: 2.787800, val_acc: 54.04%\n",
      "Epoch [2472]/[5000], train_loss: 0.041600, train_acc: 94.68%, val_loss: 2.522700, val_acc: 54.69%\n",
      "Epoch [2473]/[5000], train_loss: 0.073900, train_acc: 93.21%, val_loss: 2.748700, val_acc: 50.52%\n",
      "Epoch [2474]/[5000], train_loss: 0.070000, train_acc: 93.70%, val_loss: 2.549800, val_acc: 55.08%\n",
      "Epoch [2475]/[5000], train_loss: 0.058500, train_acc: 94.19%, val_loss: 2.516300, val_acc: 53.65%\n",
      "Epoch [2476]/[5000], train_loss: 0.064800, train_acc: 93.90%, val_loss: 2.959500, val_acc: 51.95%\n",
      "Epoch [2477]/[5000], train_loss: 0.059100, train_acc: 93.95%, val_loss: 2.716600, val_acc: 53.91%\n",
      "Epoch [2478]/[5000], train_loss: 0.043400, train_acc: 94.19%, val_loss: 2.508300, val_acc: 56.64%\n",
      "Epoch [2479]/[5000], train_loss: 0.067500, train_acc: 93.80%, val_loss: 2.499100, val_acc: 52.86%\n",
      "Epoch [2480]/[5000], train_loss: 0.086800, train_acc: 92.82%, val_loss: 2.612500, val_acc: 53.26%\n",
      "Epoch [2481]/[5000], train_loss: 0.071800, train_acc: 93.80%, val_loss: 2.776400, val_acc: 53.91%\n",
      "Epoch [2482]/[5000], train_loss: 0.118700, train_acc: 91.89%, val_loss: 3.055500, val_acc: 53.12%\n",
      "Epoch [2483]/[5000], train_loss: 0.099900, train_acc: 93.21%, val_loss: 2.449800, val_acc: 52.73%\n",
      "Epoch [2484]/[5000], train_loss: 0.100500, train_acc: 93.46%, val_loss: 2.682500, val_acc: 53.39%\n",
      "Epoch [2485]/[5000], train_loss: 0.082900, train_acc: 93.70%, val_loss: 2.314600, val_acc: 50.52%\n",
      "Epoch [2486]/[5000], train_loss: 0.074300, train_acc: 93.60%, val_loss: 2.774300, val_acc: 53.52%\n",
      "Epoch [2487]/[5000], train_loss: 0.086400, train_acc: 92.97%, val_loss: 2.439900, val_acc: 52.60%\n",
      "Epoch [2488]/[5000], train_loss: 0.055300, train_acc: 94.29%, val_loss: 2.239600, val_acc: 53.39%\n",
      "Epoch [2489]/[5000], train_loss: 0.093200, train_acc: 93.12%, val_loss: 2.628900, val_acc: 49.22%\n",
      "Epoch [2490]/[5000], train_loss: 0.101900, train_acc: 92.63%, val_loss: 2.887300, val_acc: 55.73%\n",
      "Epoch [2491]/[5000], train_loss: 0.060300, train_acc: 93.90%, val_loss: 2.414100, val_acc: 52.47%\n",
      "Epoch [2492]/[5000], train_loss: 0.040200, train_acc: 94.48%, val_loss: 2.470600, val_acc: 56.38%\n",
      "Epoch [2493]/[5000], train_loss: 0.031600, train_acc: 95.17%, val_loss: 2.274900, val_acc: 52.47%\n",
      "Epoch [2494]/[5000], train_loss: 0.046900, train_acc: 94.48%, val_loss: 2.586400, val_acc: 54.69%\n",
      "Epoch [2495]/[5000], train_loss: 0.045800, train_acc: 94.78%, val_loss: 2.631400, val_acc: 55.08%\n",
      "Epoch [2496]/[5000], train_loss: 0.044000, train_acc: 94.43%, val_loss: 2.514500, val_acc: 54.17%\n",
      "Epoch [2497]/[5000], train_loss: 0.034800, train_acc: 94.92%, val_loss: 2.976100, val_acc: 52.60%\n",
      "Epoch [2498]/[5000], train_loss: 0.037900, train_acc: 94.82%, val_loss: 2.410600, val_acc: 54.82%\n",
      "Epoch [2499]/[5000], train_loss: 0.042200, train_acc: 94.53%, val_loss: 2.563000, val_acc: 55.34%\n",
      "Epoch [2500]/[5000], train_loss: 0.039000, train_acc: 94.73%, val_loss: 2.626400, val_acc: 54.56%\n",
      "Epoch [2501]/[5000], train_loss: 0.041500, train_acc: 94.82%, val_loss: 2.543100, val_acc: 55.99%\n",
      "Epoch [2502]/[5000], train_loss: 0.046700, train_acc: 94.63%, val_loss: 2.952000, val_acc: 52.34%\n",
      "Epoch [2503]/[5000], train_loss: 0.045000, train_acc: 94.48%, val_loss: 2.613000, val_acc: 54.69%\n",
      "Epoch [2504]/[5000], train_loss: 0.053600, train_acc: 94.14%, val_loss: 2.607400, val_acc: 54.04%\n",
      "Epoch [2505]/[5000], train_loss: 0.044500, train_acc: 94.63%, val_loss: 2.522200, val_acc: 53.91%\n",
      "Epoch [2506]/[5000], train_loss: 0.038700, train_acc: 94.73%, val_loss: 2.656700, val_acc: 54.95%\n",
      "Epoch [2507]/[5000], train_loss: 0.061800, train_acc: 94.34%, val_loss: 2.821900, val_acc: 54.69%\n",
      "Epoch [2508]/[5000], train_loss: 0.043800, train_acc: 94.29%, val_loss: 2.544700, val_acc: 53.91%\n",
      "Epoch [2509]/[5000], train_loss: 0.051400, train_acc: 94.43%, val_loss: 3.229500, val_acc: 51.43%\n",
      "Epoch [2510]/[5000], train_loss: 0.062800, train_acc: 93.99%, val_loss: 2.515600, val_acc: 55.08%\n",
      "Epoch [2511]/[5000], train_loss: 0.066300, train_acc: 93.95%, val_loss: 2.555800, val_acc: 53.52%\n",
      "Epoch [2512]/[5000], train_loss: 0.047900, train_acc: 94.34%, val_loss: 2.645100, val_acc: 54.69%\n",
      "Epoch [2513]/[5000], train_loss: 0.058200, train_acc: 93.90%, val_loss: 2.838600, val_acc: 55.34%\n",
      "Epoch [2514]/[5000], train_loss: 0.063900, train_acc: 93.55%, val_loss: 2.585000, val_acc: 54.82%\n",
      "Epoch [2515]/[5000], train_loss: 0.051800, train_acc: 94.19%, val_loss: 2.811200, val_acc: 54.17%\n",
      "Epoch [2516]/[5000], train_loss: 0.040700, train_acc: 94.73%, val_loss: 2.723600, val_acc: 54.82%\n",
      "Epoch [2517]/[5000], train_loss: 0.036900, train_acc: 94.87%, val_loss: 2.907100, val_acc: 52.34%\n",
      "Epoch [2518]/[5000], train_loss: 0.045800, train_acc: 94.73%, val_loss: 2.466700, val_acc: 54.56%\n",
      "Epoch [2519]/[5000], train_loss: 0.042300, train_acc: 94.58%, val_loss: 2.271700, val_acc: 54.17%\n",
      "Epoch [2520]/[5000], train_loss: 0.045300, train_acc: 94.53%, val_loss: 2.587800, val_acc: 49.09%\n",
      "Epoch [2521]/[5000], train_loss: 0.052300, train_acc: 94.68%, val_loss: 2.786800, val_acc: 54.30%\n",
      "Epoch [2522]/[5000], train_loss: 0.057800, train_acc: 93.80%, val_loss: 3.061200, val_acc: 49.35%\n",
      "Epoch [2523]/[5000], train_loss: 0.076400, train_acc: 93.07%, val_loss: 2.440300, val_acc: 56.64%\n",
      "Epoch [2524]/[5000], train_loss: 0.061300, train_acc: 93.99%, val_loss: 2.699600, val_acc: 54.82%\n",
      "Epoch [2525]/[5000], train_loss: 0.055600, train_acc: 94.24%, val_loss: 2.600900, val_acc: 54.82%\n",
      "Epoch [2526]/[5000], train_loss: 0.056200, train_acc: 94.48%, val_loss: 2.754800, val_acc: 54.69%\n",
      "Epoch [2527]/[5000], train_loss: 0.068300, train_acc: 94.09%, val_loss: 2.510000, val_acc: 52.21%\n",
      "Epoch [2528]/[5000], train_loss: 0.048100, train_acc: 94.58%, val_loss: 2.564800, val_acc: 54.56%\n",
      "Epoch [2529]/[5000], train_loss: 0.055400, train_acc: 94.29%, val_loss: 3.057800, val_acc: 53.91%\n",
      "Epoch [2530]/[5000], train_loss: 0.066400, train_acc: 94.78%, val_loss: 2.904000, val_acc: 57.16%\n",
      "Epoch [2531]/[5000], train_loss: 0.048300, train_acc: 94.43%, val_loss: 2.324800, val_acc: 54.82%\n",
      "Epoch [2532]/[5000], train_loss: 0.055900, train_acc: 94.58%, val_loss: 2.872800, val_acc: 50.52%\n",
      "Epoch [2533]/[5000], train_loss: 0.048500, train_acc: 94.38%, val_loss: 3.261800, val_acc: 53.12%\n",
      "Epoch [2534]/[5000], train_loss: 0.051000, train_acc: 94.29%, val_loss: 2.850900, val_acc: 52.60%\n",
      "Epoch [2535]/[5000], train_loss: 0.068500, train_acc: 94.09%, val_loss: 2.859700, val_acc: 53.12%\n",
      "Epoch [2536]/[5000], train_loss: 0.066600, train_acc: 93.99%, val_loss: 2.756800, val_acc: 54.04%\n",
      "Epoch [2537]/[5000], train_loss: 0.076500, train_acc: 93.26%, val_loss: 2.723800, val_acc: 54.43%\n",
      "Epoch [2538]/[5000], train_loss: 0.074600, train_acc: 93.65%, val_loss: 2.428200, val_acc: 54.56%\n",
      "Epoch [2539]/[5000], train_loss: 0.059000, train_acc: 94.04%, val_loss: 2.942800, val_acc: 53.78%\n",
      "Epoch [2540]/[5000], train_loss: 0.076700, train_acc: 93.26%, val_loss: 2.721100, val_acc: 52.60%\n",
      "Epoch [2541]/[5000], train_loss: 0.076100, train_acc: 93.51%, val_loss: 2.900600, val_acc: 52.47%\n",
      "Epoch [2542]/[5000], train_loss: 0.057700, train_acc: 94.58%, val_loss: 2.744200, val_acc: 50.65%\n",
      "Epoch [2543]/[5000], train_loss: 0.048000, train_acc: 94.68%, val_loss: 2.778300, val_acc: 56.25%\n",
      "Epoch [2544]/[5000], train_loss: 0.047900, train_acc: 94.43%, val_loss: 2.909100, val_acc: 51.43%\n",
      "Epoch [2545]/[5000], train_loss: 0.048000, train_acc: 94.53%, val_loss: 2.481800, val_acc: 54.56%\n",
      "Epoch [2546]/[5000], train_loss: 0.055200, train_acc: 93.99%, val_loss: 2.364500, val_acc: 56.38%\n",
      "Epoch [2547]/[5000], train_loss: 0.048300, train_acc: 94.34%, val_loss: 2.831300, val_acc: 55.21%\n",
      "Epoch [2548]/[5000], train_loss: 0.039800, train_acc: 95.12%, val_loss: 2.688500, val_acc: 57.03%\n",
      "Epoch [2549]/[5000], train_loss: 0.043900, train_acc: 94.68%, val_loss: 2.680900, val_acc: 54.04%\n",
      "Epoch [2550]/[5000], train_loss: 0.039700, train_acc: 94.87%, val_loss: 2.979900, val_acc: 52.73%\n",
      "Epoch [2551]/[5000], train_loss: 0.058600, train_acc: 93.75%, val_loss: 2.751900, val_acc: 54.95%\n",
      "Epoch [2552]/[5000], train_loss: 0.058800, train_acc: 94.29%, val_loss: 2.949400, val_acc: 52.34%\n",
      "Epoch [2553]/[5000], train_loss: 0.073100, train_acc: 93.51%, val_loss: 2.499800, val_acc: 54.82%\n",
      "Epoch [2554]/[5000], train_loss: 0.052600, train_acc: 94.68%, val_loss: 2.643300, val_acc: 53.12%\n",
      "Epoch [2555]/[5000], train_loss: 0.064600, train_acc: 93.70%, val_loss: 2.517400, val_acc: 53.52%\n",
      "Epoch [2556]/[5000], train_loss: 0.061500, train_acc: 93.60%, val_loss: 2.553000, val_acc: 54.69%\n",
      "Epoch [2557]/[5000], train_loss: 0.043400, train_acc: 94.58%, val_loss: 2.532600, val_acc: 48.70%\n",
      "Epoch [2558]/[5000], train_loss: 0.046700, train_acc: 94.34%, val_loss: 2.481400, val_acc: 55.21%\n",
      "Epoch [2559]/[5000], train_loss: 0.052300, train_acc: 94.38%, val_loss: 2.480600, val_acc: 56.25%\n",
      "Epoch [2560]/[5000], train_loss: 0.049300, train_acc: 94.38%, val_loss: 2.431400, val_acc: 52.60%\n",
      "Epoch [2561]/[5000], train_loss: 0.051400, train_acc: 94.29%, val_loss: 2.559200, val_acc: 54.56%\n",
      "Epoch [2562]/[5000], train_loss: 0.064900, train_acc: 93.99%, val_loss: 2.705400, val_acc: 54.82%\n",
      "Epoch [2563]/[5000], train_loss: 0.055800, train_acc: 94.29%, val_loss: 2.956200, val_acc: 54.82%\n",
      "Epoch [2564]/[5000], train_loss: 0.053100, train_acc: 93.99%, val_loss: 2.831600, val_acc: 54.95%\n",
      "Epoch [2565]/[5000], train_loss: 0.051200, train_acc: 94.09%, val_loss: 2.603400, val_acc: 54.43%\n",
      "Epoch [2566]/[5000], train_loss: 0.033900, train_acc: 95.02%, val_loss: 2.717200, val_acc: 54.17%\n",
      "Epoch [2567]/[5000], train_loss: 0.039500, train_acc: 94.78%, val_loss: 2.546700, val_acc: 55.21%\n",
      "Epoch [2568]/[5000], train_loss: 0.031600, train_acc: 95.21%, val_loss: 2.660700, val_acc: 54.69%\n",
      "Epoch [2569]/[5000], train_loss: 0.048200, train_acc: 94.48%, val_loss: 2.891400, val_acc: 54.56%\n",
      "Epoch [2570]/[5000], train_loss: 0.040100, train_acc: 94.87%, val_loss: 2.908300, val_acc: 52.34%\n",
      "Epoch [2571]/[5000], train_loss: 0.052500, train_acc: 93.90%, val_loss: 2.772200, val_acc: 56.64%\n",
      "Epoch [2572]/[5000], train_loss: 0.048700, train_acc: 94.38%, val_loss: 2.498600, val_acc: 53.12%\n",
      "Epoch [2573]/[5000], train_loss: 0.046900, train_acc: 94.53%, val_loss: 2.960100, val_acc: 55.34%\n",
      "Epoch [2574]/[5000], train_loss: 0.036700, train_acc: 94.87%, val_loss: 2.828800, val_acc: 54.69%\n",
      "Epoch [2575]/[5000], train_loss: 0.043900, train_acc: 94.73%, val_loss: 2.724700, val_acc: 53.12%\n",
      "Epoch [2576]/[5000], train_loss: 0.045000, train_acc: 94.73%, val_loss: 2.370000, val_acc: 54.17%\n",
      "Epoch [2577]/[5000], train_loss: 0.034000, train_acc: 95.07%, val_loss: 3.003100, val_acc: 54.43%\n",
      "Epoch [2578]/[5000], train_loss: 0.047800, train_acc: 94.53%, val_loss: 2.847200, val_acc: 52.99%\n",
      "Epoch [2579]/[5000], train_loss: 0.041900, train_acc: 94.78%, val_loss: 2.771500, val_acc: 54.04%\n",
      "Epoch [2580]/[5000], train_loss: 0.047500, train_acc: 94.48%, val_loss: 2.915000, val_acc: 51.17%\n",
      "Epoch [2581]/[5000], train_loss: 0.077500, train_acc: 93.21%, val_loss: 2.790100, val_acc: 51.04%\n",
      "Epoch [2582]/[5000], train_loss: 0.057500, train_acc: 94.14%, val_loss: 2.541400, val_acc: 55.99%\n",
      "Epoch [2583]/[5000], train_loss: 0.059100, train_acc: 94.29%, val_loss: 2.800300, val_acc: 54.82%\n",
      "Epoch [2584]/[5000], train_loss: 0.070500, train_acc: 94.04%, val_loss: 3.206600, val_acc: 52.47%\n",
      "Epoch [2585]/[5000], train_loss: 0.056100, train_acc: 94.38%, val_loss: 2.983300, val_acc: 55.34%\n",
      "Epoch [2586]/[5000], train_loss: 0.050800, train_acc: 94.53%, val_loss: 2.696800, val_acc: 53.52%\n",
      "Epoch [2587]/[5000], train_loss: 0.051100, train_acc: 93.85%, val_loss: 2.668800, val_acc: 56.25%\n",
      "Epoch [2588]/[5000], train_loss: 0.066900, train_acc: 93.95%, val_loss: 2.858100, val_acc: 53.26%\n",
      "Epoch [2589]/[5000], train_loss: 0.064200, train_acc: 93.85%, val_loss: 2.477100, val_acc: 52.86%\n",
      "Epoch [2590]/[5000], train_loss: 0.046000, train_acc: 94.19%, val_loss: 2.411400, val_acc: 55.60%\n",
      "Epoch [2591]/[5000], train_loss: 0.055500, train_acc: 93.60%, val_loss: 2.695200, val_acc: 53.26%\n",
      "Epoch [2592]/[5000], train_loss: 0.051400, train_acc: 94.34%, val_loss: 2.452700, val_acc: 55.08%\n",
      "Epoch [2593]/[5000], train_loss: 0.056500, train_acc: 94.34%, val_loss: 2.656300, val_acc: 55.34%\n",
      "Epoch [2594]/[5000], train_loss: 0.052600, train_acc: 93.99%, val_loss: 2.901300, val_acc: 53.26%\n",
      "Epoch [2595]/[5000], train_loss: 0.053100, train_acc: 94.58%, val_loss: 2.831600, val_acc: 54.04%\n",
      "Epoch [2596]/[5000], train_loss: 0.049100, train_acc: 94.29%, val_loss: 2.621800, val_acc: 55.86%\n",
      "Epoch [2597]/[5000], train_loss: 0.055900, train_acc: 94.34%, val_loss: 2.841000, val_acc: 52.99%\n",
      "Epoch [2598]/[5000], train_loss: 0.058700, train_acc: 94.04%, val_loss: 2.824300, val_acc: 54.43%\n",
      "Epoch [2599]/[5000], train_loss: 0.057400, train_acc: 94.09%, val_loss: 2.607900, val_acc: 55.73%\n",
      "Epoch [2600]/[5000], train_loss: 0.066900, train_acc: 93.99%, val_loss: 3.187000, val_acc: 52.60%\n",
      "Epoch [2601]/[5000], train_loss: 0.068700, train_acc: 93.75%, val_loss: 2.504700, val_acc: 53.12%\n",
      "Epoch [2602]/[5000], train_loss: 0.049400, train_acc: 94.09%, val_loss: 2.521700, val_acc: 52.86%\n",
      "Epoch [2603]/[5000], train_loss: 0.040400, train_acc: 94.82%, val_loss: 2.754700, val_acc: 54.30%\n",
      "Epoch [2604]/[5000], train_loss: 0.056400, train_acc: 94.29%, val_loss: 3.029400, val_acc: 52.99%\n",
      "Epoch [2605]/[5000], train_loss: 0.050100, train_acc: 94.92%, val_loss: 3.384600, val_acc: 53.12%\n",
      "Epoch [2606]/[5000], train_loss: 0.060300, train_acc: 94.58%, val_loss: 2.910000, val_acc: 54.56%\n",
      "Epoch [2607]/[5000], train_loss: 0.062200, train_acc: 94.24%, val_loss: 2.980600, val_acc: 51.95%\n",
      "Epoch [2608]/[5000], train_loss: 0.051000, train_acc: 94.24%, val_loss: 2.762600, val_acc: 56.25%\n",
      "Epoch [2609]/[5000], train_loss: 0.050100, train_acc: 94.53%, val_loss: 2.643200, val_acc: 51.82%\n",
      "Epoch [2610]/[5000], train_loss: 0.055800, train_acc: 94.29%, val_loss: 2.688500, val_acc: 53.26%\n",
      "Epoch [2611]/[5000], train_loss: 0.051700, train_acc: 94.34%, val_loss: 2.881800, val_acc: 49.48%\n",
      "Epoch [2612]/[5000], train_loss: 0.059400, train_acc: 93.90%, val_loss: 2.730800, val_acc: 52.60%\n",
      "Epoch [2613]/[5000], train_loss: 0.059800, train_acc: 93.95%, val_loss: 2.761200, val_acc: 56.38%\n",
      "Epoch [2614]/[5000], train_loss: 0.070100, train_acc: 94.09%, val_loss: 2.884700, val_acc: 53.78%\n",
      "Epoch [2615]/[5000], train_loss: 0.054200, train_acc: 94.09%, val_loss: 2.570900, val_acc: 50.13%\n",
      "Epoch [2616]/[5000], train_loss: 0.047400, train_acc: 95.02%, val_loss: 2.706500, val_acc: 53.26%\n",
      "Epoch [2617]/[5000], train_loss: 0.081500, train_acc: 93.51%, val_loss: 2.433100, val_acc: 52.73%\n",
      "Epoch [2618]/[5000], train_loss: 0.081700, train_acc: 93.36%, val_loss: 2.388100, val_acc: 55.73%\n",
      "Epoch [2619]/[5000], train_loss: 0.057400, train_acc: 93.90%, val_loss: 2.689200, val_acc: 53.12%\n",
      "Epoch [2620]/[5000], train_loss: 0.064300, train_acc: 93.95%, val_loss: 2.914600, val_acc: 54.56%\n",
      "Epoch [2621]/[5000], train_loss: 0.060200, train_acc: 94.19%, val_loss: 2.757600, val_acc: 52.73%\n",
      "Epoch [2622]/[5000], train_loss: 0.053400, train_acc: 93.99%, val_loss: 2.694900, val_acc: 51.95%\n",
      "Epoch [2623]/[5000], train_loss: 0.037000, train_acc: 94.78%, val_loss: 2.691500, val_acc: 54.04%\n",
      "Epoch [2624]/[5000], train_loss: 0.035000, train_acc: 94.87%, val_loss: 2.488400, val_acc: 54.56%\n",
      "Epoch [2625]/[5000], train_loss: 0.048100, train_acc: 94.58%, val_loss: 2.977500, val_acc: 53.39%\n",
      "Epoch [2626]/[5000], train_loss: 0.049200, train_acc: 94.24%, val_loss: 2.622200, val_acc: 53.52%\n",
      "Epoch [2627]/[5000], train_loss: 0.059200, train_acc: 94.19%, val_loss: 2.997100, val_acc: 52.60%\n",
      "Epoch [2628]/[5000], train_loss: 0.109800, train_acc: 92.14%, val_loss: 2.904300, val_acc: 49.09%\n",
      "Epoch [2629]/[5000], train_loss: 0.093600, train_acc: 92.97%, val_loss: 2.777800, val_acc: 53.39%\n",
      "Epoch [2630]/[5000], train_loss: 0.072900, train_acc: 93.21%, val_loss: 2.564400, val_acc: 53.26%\n",
      "Epoch [2631]/[5000], train_loss: 0.054100, train_acc: 94.53%, val_loss: 2.832400, val_acc: 53.78%\n",
      "Epoch [2632]/[5000], train_loss: 0.058300, train_acc: 94.09%, val_loss: 3.047000, val_acc: 54.82%\n",
      "Epoch [2633]/[5000], train_loss: 0.060100, train_acc: 94.38%, val_loss: 2.317600, val_acc: 54.43%\n",
      "Epoch [2634]/[5000], train_loss: 0.054600, train_acc: 94.19%, val_loss: 2.463700, val_acc: 54.30%\n",
      "Epoch [2635]/[5000], train_loss: 0.054100, train_acc: 94.34%, val_loss: 2.362800, val_acc: 53.39%\n",
      "Epoch [2636]/[5000], train_loss: 0.072400, train_acc: 93.46%, val_loss: 2.585800, val_acc: 55.47%\n",
      "Epoch [2637]/[5000], train_loss: 0.056200, train_acc: 94.34%, val_loss: 2.706900, val_acc: 55.73%\n",
      "Epoch [2638]/[5000], train_loss: 0.057000, train_acc: 94.09%, val_loss: 2.822300, val_acc: 52.73%\n",
      "Epoch [2639]/[5000], train_loss: 0.061000, train_acc: 93.90%, val_loss: 2.867100, val_acc: 54.43%\n",
      "Epoch [2640]/[5000], train_loss: 0.047900, train_acc: 94.58%, val_loss: 2.678200, val_acc: 53.26%\n",
      "Epoch [2641]/[5000], train_loss: 0.049400, train_acc: 94.19%, val_loss: 2.602100, val_acc: 55.47%\n",
      "Epoch [2642]/[5000], train_loss: 0.038600, train_acc: 94.87%, val_loss: 2.476300, val_acc: 52.47%\n",
      "Epoch [2643]/[5000], train_loss: 0.041700, train_acc: 94.58%, val_loss: 2.514700, val_acc: 54.30%\n",
      "Epoch [2644]/[5000], train_loss: 0.048400, train_acc: 94.63%, val_loss: 2.855900, val_acc: 55.86%\n",
      "Epoch [2645]/[5000], train_loss: 0.045400, train_acc: 94.68%, val_loss: 2.405300, val_acc: 54.43%\n",
      "Epoch [2646]/[5000], train_loss: 0.048800, train_acc: 94.68%, val_loss: 2.943600, val_acc: 53.91%\n",
      "Epoch [2647]/[5000], train_loss: 0.033100, train_acc: 95.02%, val_loss: 2.942400, val_acc: 52.21%\n",
      "Epoch [2648]/[5000], train_loss: 0.031200, train_acc: 95.26%, val_loss: 2.935900, val_acc: 54.04%\n",
      "Epoch [2649]/[5000], train_loss: 0.024900, train_acc: 95.46%, val_loss: 2.857400, val_acc: 53.91%\n",
      "Epoch [2650]/[5000], train_loss: 0.034500, train_acc: 94.87%, val_loss: 2.839300, val_acc: 56.12%\n",
      "Epoch [2651]/[5000], train_loss: 0.037300, train_acc: 94.97%, val_loss: 2.825500, val_acc: 57.29%\n",
      "Epoch [2652]/[5000], train_loss: 0.043800, train_acc: 94.58%, val_loss: 3.001500, val_acc: 55.73%\n",
      "Epoch [2653]/[5000], train_loss: 0.063700, train_acc: 93.95%, val_loss: 2.645700, val_acc: 52.99%\n",
      "Epoch [2654]/[5000], train_loss: 0.065200, train_acc: 93.65%, val_loss: 2.449600, val_acc: 51.95%\n",
      "Epoch [2655]/[5000], train_loss: 0.059500, train_acc: 93.70%, val_loss: 2.506300, val_acc: 53.39%\n",
      "Epoch [2656]/[5000], train_loss: 0.046300, train_acc: 94.58%, val_loss: 2.754300, val_acc: 51.69%\n",
      "Epoch [2657]/[5000], train_loss: 0.052400, train_acc: 94.78%, val_loss: 2.613300, val_acc: 51.56%\n",
      "Epoch [2658]/[5000], train_loss: 0.054700, train_acc: 94.19%, val_loss: 2.813000, val_acc: 54.43%\n",
      "Epoch [2659]/[5000], train_loss: 0.034200, train_acc: 95.07%, val_loss: 2.927900, val_acc: 54.04%\n",
      "Epoch [2660]/[5000], train_loss: 0.057800, train_acc: 94.24%, val_loss: 2.794700, val_acc: 51.69%\n",
      "Epoch [2661]/[5000], train_loss: 0.068600, train_acc: 94.19%, val_loss: 2.892400, val_acc: 55.21%\n",
      "Epoch [2662]/[5000], train_loss: 0.077400, train_acc: 93.51%, val_loss: 2.554000, val_acc: 49.35%\n",
      "Epoch [2663]/[5000], train_loss: 0.058400, train_acc: 93.90%, val_loss: 3.095000, val_acc: 54.04%\n",
      "Epoch [2664]/[5000], train_loss: 0.055100, train_acc: 94.29%, val_loss: 2.378100, val_acc: 54.95%\n",
      "Epoch [2665]/[5000], train_loss: 0.059200, train_acc: 94.19%, val_loss: 2.844700, val_acc: 55.47%\n",
      "Epoch [2666]/[5000], train_loss: 0.064700, train_acc: 93.65%, val_loss: 2.504200, val_acc: 50.13%\n",
      "Epoch [2667]/[5000], train_loss: 0.042800, train_acc: 94.53%, val_loss: 2.581600, val_acc: 55.21%\n",
      "Epoch [2668]/[5000], train_loss: 0.038300, train_acc: 94.73%, val_loss: 3.519400, val_acc: 52.34%\n",
      "Epoch [2669]/[5000], train_loss: 0.040600, train_acc: 94.63%, val_loss: 3.215900, val_acc: 54.30%\n",
      "Epoch [2670]/[5000], train_loss: 0.040700, train_acc: 94.73%, val_loss: 2.900900, val_acc: 52.86%\n",
      "Epoch [2671]/[5000], train_loss: 0.039200, train_acc: 94.68%, val_loss: 3.069700, val_acc: 53.65%\n",
      "Epoch [2672]/[5000], train_loss: 0.034700, train_acc: 95.02%, val_loss: 2.855400, val_acc: 54.17%\n",
      "Epoch [2673]/[5000], train_loss: 0.038600, train_acc: 94.43%, val_loss: 2.476600, val_acc: 55.08%\n",
      "Epoch [2674]/[5000], train_loss: 0.033900, train_acc: 94.92%, val_loss: 3.038800, val_acc: 52.99%\n",
      "Epoch [2675]/[5000], train_loss: 0.031000, train_acc: 95.07%, val_loss: 2.470500, val_acc: 54.04%\n",
      "Epoch [2676]/[5000], train_loss: 0.043100, train_acc: 94.68%, val_loss: 2.804000, val_acc: 53.12%\n",
      "Epoch [2677]/[5000], train_loss: 0.026300, train_acc: 95.31%, val_loss: 2.764000, val_acc: 52.47%\n",
      "Epoch [2678]/[5000], train_loss: 0.024900, train_acc: 95.31%, val_loss: 2.866100, val_acc: 54.82%\n",
      "Epoch [2679]/[5000], train_loss: 0.024800, train_acc: 95.36%, val_loss: 2.922900, val_acc: 53.65%\n",
      "Epoch [2680]/[5000], train_loss: 0.038900, train_acc: 94.92%, val_loss: 2.482900, val_acc: 54.82%\n",
      "Epoch [2681]/[5000], train_loss: 0.031300, train_acc: 94.97%, val_loss: 2.851700, val_acc: 51.82%\n",
      "Epoch [2682]/[5000], train_loss: 0.039700, train_acc: 95.02%, val_loss: 2.657100, val_acc: 55.99%\n",
      "Epoch [2683]/[5000], train_loss: 0.033000, train_acc: 94.92%, val_loss: 2.798200, val_acc: 52.99%\n",
      "Epoch [2684]/[5000], train_loss: 0.051400, train_acc: 94.14%, val_loss: 2.893100, val_acc: 53.39%\n",
      "Epoch [2685]/[5000], train_loss: 0.036500, train_acc: 94.97%, val_loss: 2.961700, val_acc: 54.17%\n",
      "Epoch [2686]/[5000], train_loss: 0.051100, train_acc: 94.82%, val_loss: 2.770200, val_acc: 56.38%\n",
      "Epoch [2687]/[5000], train_loss: 0.061800, train_acc: 94.09%, val_loss: 3.369900, val_acc: 53.52%\n",
      "Epoch [2688]/[5000], train_loss: 0.035400, train_acc: 94.73%, val_loss: 2.513800, val_acc: 53.12%\n",
      "Epoch [2689]/[5000], train_loss: 0.037500, train_acc: 94.82%, val_loss: 2.911900, val_acc: 55.34%\n",
      "Epoch [2690]/[5000], train_loss: 0.050700, train_acc: 94.48%, val_loss: 2.983200, val_acc: 50.65%\n",
      "Epoch [2691]/[5000], train_loss: 0.052700, train_acc: 94.24%, val_loss: 2.566800, val_acc: 52.21%\n",
      "Epoch [2692]/[5000], train_loss: 0.060200, train_acc: 93.75%, val_loss: 3.149500, val_acc: 52.47%\n",
      "Epoch [2693]/[5000], train_loss: 0.091800, train_acc: 92.92%, val_loss: 2.760000, val_acc: 50.52%\n",
      "Epoch [2694]/[5000], train_loss: 0.079200, train_acc: 93.12%, val_loss: 2.778900, val_acc: 52.34%\n",
      "Epoch [2695]/[5000], train_loss: 0.071400, train_acc: 93.41%, val_loss: 2.876000, val_acc: 54.82%\n",
      "Epoch [2696]/[5000], train_loss: 0.038600, train_acc: 94.82%, val_loss: 2.782700, val_acc: 53.78%\n",
      "Epoch [2697]/[5000], train_loss: 0.042500, train_acc: 94.48%, val_loss: 3.359400, val_acc: 53.78%\n",
      "Epoch [2698]/[5000], train_loss: 0.050700, train_acc: 94.58%, val_loss: 2.869300, val_acc: 53.78%\n",
      "Epoch [2699]/[5000], train_loss: 0.045600, train_acc: 94.38%, val_loss: 2.866700, val_acc: 55.60%\n",
      "Epoch [2700]/[5000], train_loss: 0.056600, train_acc: 94.29%, val_loss: 2.950200, val_acc: 51.82%\n",
      "Epoch [2701]/[5000], train_loss: 0.051100, train_acc: 94.24%, val_loss: 2.796200, val_acc: 52.99%\n",
      "Epoch [2702]/[5000], train_loss: 0.034400, train_acc: 94.82%, val_loss: 3.141600, val_acc: 53.78%\n",
      "Epoch [2703]/[5000], train_loss: 0.042800, train_acc: 94.43%, val_loss: 2.915100, val_acc: 54.04%\n",
      "Epoch [2704]/[5000], train_loss: 0.040600, train_acc: 94.48%, val_loss: 2.514100, val_acc: 56.64%\n",
      "Epoch [2705]/[5000], train_loss: 0.044800, train_acc: 94.53%, val_loss: 2.682600, val_acc: 52.73%\n",
      "Epoch [2706]/[5000], train_loss: 0.039800, train_acc: 94.73%, val_loss: 2.719600, val_acc: 53.78%\n",
      "Epoch [2707]/[5000], train_loss: 0.055200, train_acc: 94.14%, val_loss: 2.644500, val_acc: 52.86%\n",
      "Epoch [2708]/[5000], train_loss: 0.029300, train_acc: 95.21%, val_loss: 2.480800, val_acc: 52.08%\n",
      "Epoch [2709]/[5000], train_loss: 0.035400, train_acc: 94.87%, val_loss: 2.620200, val_acc: 52.86%\n",
      "Epoch [2710]/[5000], train_loss: 0.045000, train_acc: 94.63%, val_loss: 2.653700, val_acc: 54.43%\n",
      "Epoch [2711]/[5000], train_loss: 0.051700, train_acc: 94.87%, val_loss: 2.569900, val_acc: 55.73%\n",
      "Epoch [2712]/[5000], train_loss: 0.062600, train_acc: 93.90%, val_loss: 2.443200, val_acc: 55.60%\n",
      "Epoch [2713]/[5000], train_loss: 0.071600, train_acc: 93.65%, val_loss: 3.011300, val_acc: 49.74%\n",
      "Epoch [2714]/[5000], train_loss: 0.043000, train_acc: 94.53%, val_loss: 2.410100, val_acc: 54.04%\n",
      "Epoch [2715]/[5000], train_loss: 0.042200, train_acc: 94.87%, val_loss: 2.966100, val_acc: 54.82%\n",
      "Epoch [2716]/[5000], train_loss: 0.052300, train_acc: 94.04%, val_loss: 2.619200, val_acc: 52.73%\n",
      "Epoch [2717]/[5000], train_loss: 0.067400, train_acc: 93.51%, val_loss: 2.570600, val_acc: 55.34%\n",
      "Epoch [2718]/[5000], train_loss: 0.057800, train_acc: 94.09%, val_loss: 3.064000, val_acc: 54.43%\n",
      "Epoch [2719]/[5000], train_loss: 0.054500, train_acc: 94.29%, val_loss: 2.776200, val_acc: 54.43%\n",
      "Epoch [2720]/[5000], train_loss: 0.056400, train_acc: 94.24%, val_loss: 2.681500, val_acc: 54.69%\n",
      "Epoch [2721]/[5000], train_loss: 0.052800, train_acc: 94.29%, val_loss: 2.613900, val_acc: 52.73%\n",
      "Epoch [2722]/[5000], train_loss: 0.033900, train_acc: 95.12%, val_loss: 3.160400, val_acc: 53.65%\n",
      "Epoch [2723]/[5000], train_loss: 0.050700, train_acc: 94.63%, val_loss: 2.721400, val_acc: 53.52%\n",
      "Epoch [2724]/[5000], train_loss: 0.052800, train_acc: 94.19%, val_loss: 2.592600, val_acc: 54.69%\n",
      "Epoch [2725]/[5000], train_loss: 0.053500, train_acc: 94.19%, val_loss: 2.744400, val_acc: 53.39%\n",
      "Epoch [2726]/[5000], train_loss: 0.069300, train_acc: 93.55%, val_loss: 2.934600, val_acc: 52.86%\n",
      "Epoch [2727]/[5000], train_loss: 0.084000, train_acc: 93.51%, val_loss: 2.805100, val_acc: 54.43%\n",
      "Epoch [2728]/[5000], train_loss: 0.059200, train_acc: 93.65%, val_loss: 2.894400, val_acc: 53.39%\n",
      "Epoch [2729]/[5000], train_loss: 0.079100, train_acc: 93.70%, val_loss: 2.879900, val_acc: 53.39%\n",
      "Epoch [2730]/[5000], train_loss: 0.068800, train_acc: 93.75%, val_loss: 2.719200, val_acc: 50.52%\n",
      "Epoch [2731]/[5000], train_loss: 0.068100, train_acc: 94.04%, val_loss: 2.655800, val_acc: 53.65%\n",
      "Epoch [2732]/[5000], train_loss: 0.072300, train_acc: 93.80%, val_loss: 2.444400, val_acc: 52.73%\n",
      "Epoch [2733]/[5000], train_loss: 0.062300, train_acc: 93.99%, val_loss: 2.772000, val_acc: 53.65%\n",
      "Epoch [2734]/[5000], train_loss: 0.055000, train_acc: 93.95%, val_loss: 2.382700, val_acc: 53.65%\n",
      "Epoch [2735]/[5000], train_loss: 0.046400, train_acc: 94.43%, val_loss: 2.795200, val_acc: 53.65%\n",
      "Epoch [2736]/[5000], train_loss: 0.047600, train_acc: 94.48%, val_loss: 2.741700, val_acc: 53.78%\n",
      "Epoch [2737]/[5000], train_loss: 0.040400, train_acc: 94.97%, val_loss: 2.708400, val_acc: 53.12%\n",
      "Epoch [2738]/[5000], train_loss: 0.053900, train_acc: 94.43%, val_loss: 2.525400, val_acc: 52.60%\n",
      "Epoch [2739]/[5000], train_loss: 0.044200, train_acc: 94.78%, val_loss: 2.453000, val_acc: 54.56%\n",
      "Epoch [2740]/[5000], train_loss: 0.051900, train_acc: 94.78%, val_loss: 2.744500, val_acc: 53.39%\n",
      "Epoch [2741]/[5000], train_loss: 0.062100, train_acc: 94.19%, val_loss: 2.787200, val_acc: 54.56%\n",
      "Epoch [2742]/[5000], train_loss: 0.058700, train_acc: 93.80%, val_loss: 2.403800, val_acc: 51.56%\n",
      "Epoch [2743]/[5000], train_loss: 0.056700, train_acc: 94.09%, val_loss: 2.545600, val_acc: 54.17%\n",
      "Epoch [2744]/[5000], train_loss: 0.042900, train_acc: 94.58%, val_loss: 2.495600, val_acc: 53.91%\n",
      "Epoch [2745]/[5000], train_loss: 0.038100, train_acc: 94.73%, val_loss: 2.748400, val_acc: 54.30%\n",
      "Epoch [2746]/[5000], train_loss: 0.034500, train_acc: 94.73%, val_loss: 2.711600, val_acc: 56.38%\n",
      "Epoch [2747]/[5000], train_loss: 0.029900, train_acc: 95.07%, val_loss: 2.534400, val_acc: 54.82%\n",
      "Epoch [2748]/[5000], train_loss: 0.036100, train_acc: 95.07%, val_loss: 3.029300, val_acc: 54.82%\n",
      "Epoch [2749]/[5000], train_loss: 0.041000, train_acc: 94.73%, val_loss: 2.610700, val_acc: 53.65%\n",
      "Epoch [2750]/[5000], train_loss: 0.053900, train_acc: 94.48%, val_loss: 2.947400, val_acc: 51.56%\n",
      "Epoch [2751]/[5000], train_loss: 0.055200, train_acc: 94.04%, val_loss: 2.870900, val_acc: 53.65%\n",
      "Epoch [2752]/[5000], train_loss: 0.055600, train_acc: 94.38%, val_loss: 2.418100, val_acc: 54.95%\n",
      "Epoch [2753]/[5000], train_loss: 0.049800, train_acc: 94.48%, val_loss: 2.723300, val_acc: 51.95%\n",
      "Epoch [2754]/[5000], train_loss: 0.078800, train_acc: 93.65%, val_loss: 2.592900, val_acc: 53.26%\n",
      "Epoch [2755]/[5000], train_loss: 0.062500, train_acc: 94.34%, val_loss: 2.732100, val_acc: 51.95%\n",
      "Epoch [2756]/[5000], train_loss: 0.063400, train_acc: 93.99%, val_loss: 2.626200, val_acc: 52.08%\n",
      "Epoch [2757]/[5000], train_loss: 0.058300, train_acc: 93.80%, val_loss: 2.645400, val_acc: 54.30%\n",
      "Epoch [2758]/[5000], train_loss: 0.053000, train_acc: 94.09%, val_loss: 2.399200, val_acc: 55.21%\n",
      "Epoch [2759]/[5000], train_loss: 0.051100, train_acc: 94.58%, val_loss: 2.781000, val_acc: 53.65%\n",
      "Epoch [2760]/[5000], train_loss: 0.062900, train_acc: 93.85%, val_loss: 2.670300, val_acc: 52.73%\n",
      "Epoch [2761]/[5000], train_loss: 0.068800, train_acc: 93.90%, val_loss: 2.677900, val_acc: 53.39%\n",
      "Epoch [2762]/[5000], train_loss: 0.067400, train_acc: 93.46%, val_loss: 2.464200, val_acc: 53.78%\n",
      "Epoch [2763]/[5000], train_loss: 0.050200, train_acc: 94.43%, val_loss: 2.629500, val_acc: 54.69%\n",
      "Epoch [2764]/[5000], train_loss: 0.054100, train_acc: 94.19%, val_loss: 2.529000, val_acc: 54.95%\n",
      "Epoch [2765]/[5000], train_loss: 0.032900, train_acc: 94.82%, val_loss: 2.563000, val_acc: 54.17%\n",
      "Epoch [2766]/[5000], train_loss: 0.036400, train_acc: 94.73%, val_loss: 2.550100, val_acc: 54.30%\n",
      "Epoch [2767]/[5000], train_loss: 0.037200, train_acc: 94.68%, val_loss: 2.679200, val_acc: 54.82%\n",
      "Epoch [2768]/[5000], train_loss: 0.035400, train_acc: 94.92%, val_loss: 2.767400, val_acc: 54.04%\n",
      "Epoch [2769]/[5000], train_loss: 0.055200, train_acc: 94.19%, val_loss: 2.963200, val_acc: 51.43%\n",
      "Epoch [2770]/[5000], train_loss: 0.056300, train_acc: 94.29%, val_loss: 2.494200, val_acc: 53.26%\n",
      "Epoch [2771]/[5000], train_loss: 0.054100, train_acc: 94.09%, val_loss: 2.504800, val_acc: 54.56%\n",
      "Epoch [2772]/[5000], train_loss: 0.030200, train_acc: 95.02%, val_loss: 2.692700, val_acc: 54.30%\n",
      "Epoch [2773]/[5000], train_loss: 0.031100, train_acc: 95.12%, val_loss: 2.320700, val_acc: 55.86%\n",
      "Epoch [2774]/[5000], train_loss: 0.036500, train_acc: 94.68%, val_loss: 2.592700, val_acc: 55.73%\n",
      "Epoch [2775]/[5000], train_loss: 0.027400, train_acc: 95.26%, val_loss: 2.872000, val_acc: 54.43%\n",
      "Epoch [2776]/[5000], train_loss: 0.040500, train_acc: 94.34%, val_loss: 2.904800, val_acc: 53.65%\n",
      "Epoch [2777]/[5000], train_loss: 0.084800, train_acc: 93.31%, val_loss: 3.017200, val_acc: 50.78%\n",
      "Epoch [2778]/[5000], train_loss: 0.064800, train_acc: 93.90%, val_loss: 2.655500, val_acc: 52.60%\n",
      "Epoch [2779]/[5000], train_loss: 0.036100, train_acc: 94.97%, val_loss: 2.553300, val_acc: 53.26%\n",
      "Epoch [2780]/[5000], train_loss: 0.044800, train_acc: 94.58%, val_loss: 2.634100, val_acc: 52.60%\n",
      "Epoch [2781]/[5000], train_loss: 0.038300, train_acc: 94.87%, val_loss: 2.985400, val_acc: 52.86%\n",
      "Epoch [2782]/[5000], train_loss: 0.033000, train_acc: 94.97%, val_loss: 2.871500, val_acc: 54.82%\n",
      "Epoch [2783]/[5000], train_loss: 0.038200, train_acc: 94.73%, val_loss: 3.150400, val_acc: 55.99%\n",
      "Epoch [2784]/[5000], train_loss: 0.050100, train_acc: 94.48%, val_loss: 2.880400, val_acc: 52.99%\n",
      "Epoch [2785]/[5000], train_loss: 0.062600, train_acc: 94.04%, val_loss: 2.553300, val_acc: 54.43%\n",
      "Epoch [2786]/[5000], train_loss: 0.061100, train_acc: 94.24%, val_loss: 2.525400, val_acc: 53.52%\n",
      "Epoch [2787]/[5000], train_loss: 0.049000, train_acc: 94.48%, val_loss: 2.794400, val_acc: 55.60%\n",
      "Epoch [2788]/[5000], train_loss: 0.036600, train_acc: 94.63%, val_loss: 2.646700, val_acc: 53.39%\n",
      "Epoch [2789]/[5000], train_loss: 0.047700, train_acc: 94.19%, val_loss: 2.691800, val_acc: 52.99%\n",
      "Epoch [2790]/[5000], train_loss: 0.038200, train_acc: 94.87%, val_loss: 2.561500, val_acc: 52.47%\n",
      "Epoch [2791]/[5000], train_loss: 0.045600, train_acc: 94.68%, val_loss: 2.691900, val_acc: 55.73%\n",
      "Epoch [2792]/[5000], train_loss: 0.050600, train_acc: 94.24%, val_loss: 2.619100, val_acc: 52.21%\n",
      "Epoch [2793]/[5000], train_loss: 0.037500, train_acc: 94.68%, val_loss: 3.011500, val_acc: 55.60%\n",
      "Epoch [2794]/[5000], train_loss: 0.045200, train_acc: 94.87%, val_loss: 2.550100, val_acc: 57.03%\n",
      "Epoch [2795]/[5000], train_loss: 0.037700, train_acc: 94.82%, val_loss: 2.715100, val_acc: 53.91%\n",
      "Epoch [2796]/[5000], train_loss: 0.044700, train_acc: 94.48%, val_loss: 2.699400, val_acc: 54.82%\n",
      "Epoch [2797]/[5000], train_loss: 0.063600, train_acc: 93.75%, val_loss: 3.097700, val_acc: 51.95%\n",
      "Epoch [2798]/[5000], train_loss: 0.058300, train_acc: 94.34%, val_loss: 2.830100, val_acc: 52.99%\n",
      "Epoch [2799]/[5000], train_loss: 0.048500, train_acc: 94.09%, val_loss: 3.225000, val_acc: 55.08%\n",
      "Epoch [2800]/[5000], train_loss: 0.067300, train_acc: 93.95%, val_loss: 3.045800, val_acc: 54.30%\n",
      "Epoch [2801]/[5000], train_loss: 0.055100, train_acc: 94.43%, val_loss: 3.365600, val_acc: 52.34%\n",
      "Epoch [2802]/[5000], train_loss: 0.051900, train_acc: 94.04%, val_loss: 2.663800, val_acc: 55.73%\n",
      "Epoch [2803]/[5000], train_loss: 0.049300, train_acc: 94.58%, val_loss: 2.915400, val_acc: 53.78%\n",
      "Epoch [2804]/[5000], train_loss: 0.035600, train_acc: 94.78%, val_loss: 3.006700, val_acc: 56.12%\n",
      "Epoch [2805]/[5000], train_loss: 0.037000, train_acc: 94.43%, val_loss: 3.397400, val_acc: 54.43%\n",
      "Epoch [2806]/[5000], train_loss: 0.037900, train_acc: 94.58%, val_loss: 2.312800, val_acc: 54.95%\n",
      "Epoch [2807]/[5000], train_loss: 0.034400, train_acc: 94.73%, val_loss: 2.733900, val_acc: 55.60%\n",
      "Epoch [2808]/[5000], train_loss: 0.037800, train_acc: 94.68%, val_loss: 2.977600, val_acc: 56.51%\n",
      "Epoch [2809]/[5000], train_loss: 0.026900, train_acc: 95.21%, val_loss: 2.870900, val_acc: 54.56%\n",
      "Epoch [2810]/[5000], train_loss: 0.030000, train_acc: 95.36%, val_loss: 2.883200, val_acc: 54.17%\n",
      "Epoch [2811]/[5000], train_loss: 0.036000, train_acc: 94.68%, val_loss: 3.461600, val_acc: 54.43%\n",
      "Epoch [2812]/[5000], train_loss: 0.034500, train_acc: 95.12%, val_loss: 3.107400, val_acc: 53.26%\n",
      "Epoch [2813]/[5000], train_loss: 0.042800, train_acc: 94.29%, val_loss: 2.996200, val_acc: 53.39%\n",
      "Epoch [2814]/[5000], train_loss: 0.037600, train_acc: 94.82%, val_loss: 3.243500, val_acc: 56.51%\n",
      "Epoch [2815]/[5000], train_loss: 0.027600, train_acc: 95.26%, val_loss: 2.768600, val_acc: 54.82%\n",
      "Epoch [2816]/[5000], train_loss: 0.032700, train_acc: 95.02%, val_loss: 2.796500, val_acc: 55.34%\n",
      "Epoch [2817]/[5000], train_loss: 0.041200, train_acc: 94.87%, val_loss: 2.914100, val_acc: 54.69%\n",
      "Epoch [2818]/[5000], train_loss: 0.033700, train_acc: 94.68%, val_loss: 2.526400, val_acc: 54.43%\n",
      "Epoch [2819]/[5000], train_loss: 0.034900, train_acc: 94.92%, val_loss: 2.909200, val_acc: 54.82%\n",
      "Epoch [2820]/[5000], train_loss: 0.029600, train_acc: 95.12%, val_loss: 2.971600, val_acc: 53.91%\n",
      "Epoch [2821]/[5000], train_loss: 0.036600, train_acc: 94.87%, val_loss: 2.798100, val_acc: 54.17%\n",
      "Epoch [2822]/[5000], train_loss: 0.032900, train_acc: 94.92%, val_loss: 2.709100, val_acc: 53.39%\n",
      "Epoch [2823]/[5000], train_loss: 0.015400, train_acc: 95.65%, val_loss: 2.921400, val_acc: 52.86%\n",
      "Epoch [2824]/[5000], train_loss: 0.026600, train_acc: 95.31%, val_loss: 3.107300, val_acc: 54.56%\n",
      "Epoch [2825]/[5000], train_loss: 0.025900, train_acc: 95.26%, val_loss: 3.095800, val_acc: 53.78%\n",
      "Epoch [2826]/[5000], train_loss: 0.021900, train_acc: 95.17%, val_loss: 2.925200, val_acc: 55.86%\n",
      "Epoch [2827]/[5000], train_loss: 0.031100, train_acc: 95.21%, val_loss: 3.104200, val_acc: 55.60%\n",
      "Epoch [2828]/[5000], train_loss: 0.034100, train_acc: 95.41%, val_loss: 3.213800, val_acc: 54.82%\n",
      "Epoch [2829]/[5000], train_loss: 0.024000, train_acc: 95.56%, val_loss: 3.208700, val_acc: 54.04%\n",
      "Epoch [2830]/[5000], train_loss: 0.043000, train_acc: 94.78%, val_loss: 3.058600, val_acc: 53.52%\n",
      "Epoch [2831]/[5000], train_loss: 0.063100, train_acc: 93.85%, val_loss: 3.077900, val_acc: 56.77%\n",
      "Epoch [2832]/[5000], train_loss: 0.061200, train_acc: 93.99%, val_loss: 3.028900, val_acc: 54.17%\n",
      "Epoch [2833]/[5000], train_loss: 0.092200, train_acc: 92.82%, val_loss: 2.765300, val_acc: 51.17%\n",
      "Epoch [2834]/[5000], train_loss: 0.079400, train_acc: 93.31%, val_loss: 3.057200, val_acc: 54.43%\n",
      "Epoch [2835]/[5000], train_loss: 0.065300, train_acc: 93.70%, val_loss: 3.332300, val_acc: 53.52%\n",
      "Epoch [2836]/[5000], train_loss: 0.058500, train_acc: 94.14%, val_loss: 2.987600, val_acc: 54.04%\n",
      "Epoch [2837]/[5000], train_loss: 0.064700, train_acc: 93.90%, val_loss: 2.624300, val_acc: 52.34%\n",
      "Epoch [2838]/[5000], train_loss: 0.060100, train_acc: 94.04%, val_loss: 2.791500, val_acc: 53.65%\n",
      "Epoch [2839]/[5000], train_loss: 0.044100, train_acc: 94.68%, val_loss: 2.745700, val_acc: 55.34%\n",
      "Epoch [2840]/[5000], train_loss: 0.028200, train_acc: 95.12%, val_loss: 2.890500, val_acc: 54.82%\n",
      "Epoch [2841]/[5000], train_loss: 0.069600, train_acc: 94.09%, val_loss: 2.999600, val_acc: 54.43%\n",
      "Epoch [2842]/[5000], train_loss: 0.086300, train_acc: 93.36%, val_loss: 2.600600, val_acc: 52.21%\n",
      "Epoch [2843]/[5000], train_loss: 0.080700, train_acc: 93.31%, val_loss: 2.749400, val_acc: 53.39%\n",
      "Epoch [2844]/[5000], train_loss: 0.051600, train_acc: 94.24%, val_loss: 2.429500, val_acc: 54.17%\n",
      "Epoch [2845]/[5000], train_loss: 0.052800, train_acc: 94.63%, val_loss: 2.427400, val_acc: 52.08%\n",
      "Epoch [2846]/[5000], train_loss: 0.050500, train_acc: 94.48%, val_loss: 2.639400, val_acc: 55.21%\n",
      "Epoch [2847]/[5000], train_loss: 0.048600, train_acc: 94.38%, val_loss: 2.532600, val_acc: 53.65%\n",
      "Epoch [2848]/[5000], train_loss: 0.045600, train_acc: 94.34%, val_loss: 2.511700, val_acc: 54.82%\n",
      "Epoch [2849]/[5000], train_loss: 0.047500, train_acc: 94.43%, val_loss: 2.986500, val_acc: 54.69%\n",
      "Epoch [2850]/[5000], train_loss: 0.038400, train_acc: 94.53%, val_loss: 2.708900, val_acc: 53.78%\n",
      "Epoch [2851]/[5000], train_loss: 0.032600, train_acc: 94.82%, val_loss: 2.774100, val_acc: 55.99%\n",
      "Epoch [2852]/[5000], train_loss: 0.049700, train_acc: 94.38%, val_loss: 2.913200, val_acc: 55.86%\n",
      "Epoch [2853]/[5000], train_loss: 0.056300, train_acc: 94.09%, val_loss: 2.714500, val_acc: 52.99%\n",
      "Epoch [2854]/[5000], train_loss: 0.047400, train_acc: 94.24%, val_loss: 2.827200, val_acc: 55.47%\n",
      "Epoch [2855]/[5000], train_loss: 0.030400, train_acc: 95.12%, val_loss: 2.753400, val_acc: 56.51%\n",
      "Epoch [2856]/[5000], train_loss: 0.044900, train_acc: 94.68%, val_loss: 2.685400, val_acc: 53.26%\n",
      "Epoch [2857]/[5000], train_loss: 0.045600, train_acc: 94.63%, val_loss: 3.092600, val_acc: 53.26%\n",
      "Epoch [2858]/[5000], train_loss: 0.036000, train_acc: 94.82%, val_loss: 2.932200, val_acc: 54.43%\n",
      "Epoch [2859]/[5000], train_loss: 0.026800, train_acc: 95.12%, val_loss: 2.838400, val_acc: 54.69%\n",
      "Epoch [2860]/[5000], train_loss: 0.042500, train_acc: 94.29%, val_loss: 2.627200, val_acc: 55.47%\n",
      "Epoch [2861]/[5000], train_loss: 0.039600, train_acc: 94.78%, val_loss: 3.296000, val_acc: 54.82%\n",
      "Epoch [2862]/[5000], train_loss: 0.045500, train_acc: 94.24%, val_loss: 2.536900, val_acc: 54.56%\n",
      "Epoch [2863]/[5000], train_loss: 0.050700, train_acc: 94.38%, val_loss: 2.587200, val_acc: 54.17%\n",
      "Epoch [2864]/[5000], train_loss: 0.051500, train_acc: 94.68%, val_loss: 2.705100, val_acc: 56.64%\n",
      "Epoch [2865]/[5000], train_loss: 0.034100, train_acc: 95.02%, val_loss: 2.945200, val_acc: 53.91%\n",
      "Epoch [2866]/[5000], train_loss: 0.035900, train_acc: 94.63%, val_loss: 2.620200, val_acc: 54.04%\n",
      "Epoch [2867]/[5000], train_loss: 0.036000, train_acc: 94.97%, val_loss: 2.526100, val_acc: 55.21%\n",
      "Epoch [2868]/[5000], train_loss: 0.033500, train_acc: 94.73%, val_loss: 2.845600, val_acc: 55.21%\n",
      "Epoch [2869]/[5000], train_loss: 0.049600, train_acc: 94.43%, val_loss: 2.895900, val_acc: 50.39%\n",
      "Epoch [2870]/[5000], train_loss: 0.045100, train_acc: 94.58%, val_loss: 2.794500, val_acc: 50.52%\n",
      "Epoch [2871]/[5000], train_loss: 0.042900, train_acc: 94.48%, val_loss: 2.470200, val_acc: 55.86%\n",
      "Epoch [2872]/[5000], train_loss: 0.044900, train_acc: 94.58%, val_loss: 2.900100, val_acc: 54.69%\n",
      "Epoch [2873]/[5000], train_loss: 0.034400, train_acc: 94.73%, val_loss: 2.668500, val_acc: 54.69%\n",
      "Epoch [2874]/[5000], train_loss: 0.034300, train_acc: 95.02%, val_loss: 3.059900, val_acc: 53.52%\n",
      "Epoch [2875]/[5000], train_loss: 0.041000, train_acc: 94.58%, val_loss: 2.912900, val_acc: 55.99%\n",
      "Epoch [2876]/[5000], train_loss: 0.050000, train_acc: 94.58%, val_loss: 3.188600, val_acc: 53.65%\n",
      "Epoch [2877]/[5000], train_loss: 0.041700, train_acc: 94.53%, val_loss: 2.883200, val_acc: 54.04%\n",
      "Epoch [2878]/[5000], train_loss: 0.035900, train_acc: 94.68%, val_loss: 2.643400, val_acc: 53.39%\n",
      "Epoch [2879]/[5000], train_loss: 0.044700, train_acc: 94.73%, val_loss: 2.763000, val_acc: 52.99%\n",
      "Epoch [2880]/[5000], train_loss: 0.040000, train_acc: 94.58%, val_loss: 2.716600, val_acc: 53.52%\n",
      "Epoch [2881]/[5000], train_loss: 0.036800, train_acc: 94.73%, val_loss: 3.057100, val_acc: 54.17%\n",
      "Epoch [2882]/[5000], train_loss: 0.046700, train_acc: 94.38%, val_loss: 2.758400, val_acc: 55.21%\n",
      "Epoch [2883]/[5000], train_loss: 0.031000, train_acc: 94.73%, val_loss: 3.471800, val_acc: 54.69%\n",
      "Epoch [2884]/[5000], train_loss: 0.041600, train_acc: 94.68%, val_loss: 2.699600, val_acc: 53.39%\n",
      "Epoch [2885]/[5000], train_loss: 0.038800, train_acc: 94.68%, val_loss: 2.513300, val_acc: 57.03%\n",
      "Epoch [2886]/[5000], train_loss: 0.034600, train_acc: 94.78%, val_loss: 3.038000, val_acc: 55.86%\n",
      "Epoch [2887]/[5000], train_loss: 0.051100, train_acc: 94.29%, val_loss: 2.576000, val_acc: 56.12%\n",
      "Epoch [2888]/[5000], train_loss: 0.041100, train_acc: 94.63%, val_loss: 3.172700, val_acc: 54.69%\n",
      "Epoch [2889]/[5000], train_loss: 0.052500, train_acc: 94.09%, val_loss: 2.814400, val_acc: 52.73%\n",
      "Epoch [2890]/[5000], train_loss: 0.039900, train_acc: 94.53%, val_loss: 2.639300, val_acc: 53.78%\n",
      "Epoch [2891]/[5000], train_loss: 0.046300, train_acc: 94.34%, val_loss: 2.769000, val_acc: 52.60%\n",
      "Epoch [2892]/[5000], train_loss: 0.043200, train_acc: 94.73%, val_loss: 3.082900, val_acc: 53.91%\n",
      "Epoch [2893]/[5000], train_loss: 0.047400, train_acc: 94.43%, val_loss: 3.290500, val_acc: 51.43%\n",
      "Epoch [2894]/[5000], train_loss: 0.038500, train_acc: 94.63%, val_loss: 2.970000, val_acc: 54.17%\n",
      "Epoch [2895]/[5000], train_loss: 0.052600, train_acc: 94.82%, val_loss: 2.714400, val_acc: 55.21%\n",
      "Epoch [2896]/[5000], train_loss: 0.069900, train_acc: 93.31%, val_loss: 2.780900, val_acc: 53.12%\n",
      "Epoch [2897]/[5000], train_loss: 0.068800, train_acc: 93.85%, val_loss: 2.770800, val_acc: 50.52%\n",
      "Epoch [2898]/[5000], train_loss: 0.078000, train_acc: 93.12%, val_loss: 2.692200, val_acc: 54.82%\n",
      "Epoch [2899]/[5000], train_loss: 0.083000, train_acc: 93.85%, val_loss: 2.633200, val_acc: 54.30%\n",
      "Epoch [2900]/[5000], train_loss: 0.086400, train_acc: 93.60%, val_loss: 2.826400, val_acc: 52.21%\n",
      "Epoch [2901]/[5000], train_loss: 0.054600, train_acc: 94.14%, val_loss: 2.846800, val_acc: 53.65%\n",
      "Epoch [2902]/[5000], train_loss: 0.051700, train_acc: 94.68%, val_loss: 3.167300, val_acc: 54.82%\n",
      "Epoch [2903]/[5000], train_loss: 0.043500, train_acc: 94.48%, val_loss: 2.615400, val_acc: 54.30%\n",
      "Epoch [2904]/[5000], train_loss: 0.051400, train_acc: 94.24%, val_loss: 2.662800, val_acc: 54.17%\n",
      "Epoch [2905]/[5000], train_loss: 0.032900, train_acc: 95.02%, val_loss: 2.814500, val_acc: 54.17%\n",
      "Epoch [2906]/[5000], train_loss: 0.042800, train_acc: 94.63%, val_loss: 2.768400, val_acc: 54.04%\n",
      "Epoch [2907]/[5000], train_loss: 0.033900, train_acc: 95.36%, val_loss: 2.987700, val_acc: 56.38%\n",
      "Epoch [2908]/[5000], train_loss: 0.043300, train_acc: 95.17%, val_loss: 2.738300, val_acc: 52.99%\n",
      "Epoch [2909]/[5000], train_loss: 0.039200, train_acc: 94.48%, val_loss: 3.007100, val_acc: 54.95%\n",
      "Epoch [2910]/[5000], train_loss: 0.049300, train_acc: 94.43%, val_loss: 3.078600, val_acc: 56.12%\n",
      "Epoch [2911]/[5000], train_loss: 0.047200, train_acc: 94.58%, val_loss: 2.796600, val_acc: 55.34%\n",
      "Epoch [2912]/[5000], train_loss: 0.044900, train_acc: 94.34%, val_loss: 2.514200, val_acc: 54.82%\n",
      "Epoch [2913]/[5000], train_loss: 0.035000, train_acc: 94.97%, val_loss: 2.720400, val_acc: 53.52%\n",
      "Epoch [2914]/[5000], train_loss: 0.028900, train_acc: 95.07%, val_loss: 3.248700, val_acc: 54.04%\n",
      "Epoch [2915]/[5000], train_loss: 0.047700, train_acc: 94.68%, val_loss: 2.734100, val_acc: 55.47%\n",
      "Epoch [2916]/[5000], train_loss: 0.058400, train_acc: 94.48%, val_loss: 2.907100, val_acc: 53.39%\n",
      "Epoch [2917]/[5000], train_loss: 0.071700, train_acc: 93.85%, val_loss: 3.602800, val_acc: 56.25%\n",
      "Epoch [2918]/[5000], train_loss: 0.051000, train_acc: 94.38%, val_loss: 2.782400, val_acc: 51.69%\n",
      "Epoch [2919]/[5000], train_loss: 0.079600, train_acc: 93.80%, val_loss: 2.942600, val_acc: 52.86%\n",
      "Epoch [2920]/[5000], train_loss: 0.062500, train_acc: 93.75%, val_loss: 2.666100, val_acc: 53.78%\n",
      "Epoch [2921]/[5000], train_loss: 0.068300, train_acc: 93.95%, val_loss: 2.456100, val_acc: 55.60%\n",
      "Epoch [2922]/[5000], train_loss: 0.066100, train_acc: 93.21%, val_loss: 2.244000, val_acc: 54.69%\n",
      "Epoch [2923]/[5000], train_loss: 0.068500, train_acc: 93.60%, val_loss: 2.620000, val_acc: 56.12%\n",
      "Epoch [2924]/[5000], train_loss: 0.063200, train_acc: 94.58%, val_loss: 2.949800, val_acc: 52.73%\n",
      "Epoch [2925]/[5000], train_loss: 0.055400, train_acc: 93.90%, val_loss: 2.529400, val_acc: 51.04%\n",
      "Epoch [2926]/[5000], train_loss: 0.064700, train_acc: 93.99%, val_loss: 3.268600, val_acc: 55.73%\n",
      "Epoch [2927]/[5000], train_loss: 0.053300, train_acc: 94.58%, val_loss: 2.679000, val_acc: 53.78%\n",
      "Epoch [2928]/[5000], train_loss: 0.047200, train_acc: 94.68%, val_loss: 2.660900, val_acc: 55.08%\n",
      "Epoch [2929]/[5000], train_loss: 0.060500, train_acc: 93.90%, val_loss: 2.674500, val_acc: 52.34%\n",
      "Epoch [2930]/[5000], train_loss: 0.079800, train_acc: 93.41%, val_loss: 2.754000, val_acc: 51.95%\n",
      "Epoch [2931]/[5000], train_loss: 0.059200, train_acc: 94.29%, val_loss: 2.795400, val_acc: 56.25%\n",
      "Epoch [2932]/[5000], train_loss: 0.056900, train_acc: 93.95%, val_loss: 2.552800, val_acc: 52.08%\n",
      "Epoch [2933]/[5000], train_loss: 0.050500, train_acc: 94.38%, val_loss: 2.748000, val_acc: 55.47%\n",
      "Epoch [2934]/[5000], train_loss: 0.069200, train_acc: 93.90%, val_loss: 2.783300, val_acc: 53.26%\n",
      "Epoch [2935]/[5000], train_loss: 0.060500, train_acc: 94.29%, val_loss: 2.795600, val_acc: 53.26%\n",
      "Epoch [2936]/[5000], train_loss: 0.068700, train_acc: 94.29%, val_loss: 2.646300, val_acc: 55.47%\n",
      "Epoch [2937]/[5000], train_loss: 0.062500, train_acc: 94.04%, val_loss: 2.624600, val_acc: 52.34%\n",
      "Epoch [2938]/[5000], train_loss: 0.048500, train_acc: 94.24%, val_loss: 2.833900, val_acc: 54.95%\n",
      "Epoch [2939]/[5000], train_loss: 0.054600, train_acc: 94.38%, val_loss: 3.176000, val_acc: 51.95%\n",
      "Epoch [2940]/[5000], train_loss: 0.044900, train_acc: 94.68%, val_loss: 2.376000, val_acc: 56.38%\n",
      "Epoch [2941]/[5000], train_loss: 0.043100, train_acc: 94.53%, val_loss: 2.742900, val_acc: 51.30%\n",
      "Epoch [2942]/[5000], train_loss: 0.034000, train_acc: 95.02%, val_loss: 2.810300, val_acc: 56.77%\n",
      "Epoch [2943]/[5000], train_loss: 0.041700, train_acc: 94.78%, val_loss: 2.677900, val_acc: 55.86%\n",
      "Epoch [2944]/[5000], train_loss: 0.067900, train_acc: 94.34%, val_loss: 2.909300, val_acc: 54.56%\n",
      "Epoch [2945]/[5000], train_loss: 0.045400, train_acc: 94.63%, val_loss: 2.832200, val_acc: 55.08%\n",
      "Epoch [2946]/[5000], train_loss: 0.037400, train_acc: 94.87%, val_loss: 2.640700, val_acc: 52.60%\n",
      "Epoch [2947]/[5000], train_loss: 0.040500, train_acc: 94.73%, val_loss: 2.798200, val_acc: 53.91%\n",
      "Epoch [2948]/[5000], train_loss: 0.043800, train_acc: 94.58%, val_loss: 2.663200, val_acc: 53.65%\n",
      "Epoch [2949]/[5000], train_loss: 0.043200, train_acc: 94.38%, val_loss: 2.659400, val_acc: 52.47%\n",
      "Epoch [2950]/[5000], train_loss: 0.041400, train_acc: 94.58%, val_loss: 2.597800, val_acc: 52.34%\n",
      "Epoch [2951]/[5000], train_loss: 0.044600, train_acc: 94.78%, val_loss: 2.750400, val_acc: 56.51%\n",
      "Epoch [2952]/[5000], train_loss: 0.041900, train_acc: 94.34%, val_loss: 3.206800, val_acc: 54.95%\n",
      "Epoch [2953]/[5000], train_loss: 0.036000, train_acc: 94.92%, val_loss: 2.929700, val_acc: 53.39%\n",
      "Epoch [2954]/[5000], train_loss: 0.036100, train_acc: 94.43%, val_loss: 3.040500, val_acc: 53.91%\n",
      "Epoch [2955]/[5000], train_loss: 0.021500, train_acc: 95.51%, val_loss: 2.880800, val_acc: 53.12%\n",
      "Epoch [2956]/[5000], train_loss: 0.021400, train_acc: 95.41%, val_loss: 2.845500, val_acc: 53.52%\n",
      "Epoch [2957]/[5000], train_loss: 0.023900, train_acc: 95.26%, val_loss: 3.401700, val_acc: 55.60%\n",
      "Epoch [2958]/[5000], train_loss: 0.031400, train_acc: 95.36%, val_loss: 3.000100, val_acc: 52.73%\n",
      "Epoch [2959]/[5000], train_loss: 0.060300, train_acc: 94.09%, val_loss: 2.767800, val_acc: 54.69%\n",
      "Epoch [2960]/[5000], train_loss: 0.048000, train_acc: 94.68%, val_loss: 2.963600, val_acc: 54.04%\n",
      "Epoch [2961]/[5000], train_loss: 0.039000, train_acc: 94.87%, val_loss: 2.644200, val_acc: 51.82%\n",
      "Epoch [2962]/[5000], train_loss: 0.030000, train_acc: 95.12%, val_loss: 2.904200, val_acc: 53.65%\n",
      "Epoch [2963]/[5000], train_loss: 0.030800, train_acc: 95.26%, val_loss: 3.179700, val_acc: 54.69%\n",
      "Epoch [2964]/[5000], train_loss: 0.044500, train_acc: 94.43%, val_loss: 2.910100, val_acc: 54.69%\n",
      "Epoch [2965]/[5000], train_loss: 0.034500, train_acc: 94.92%, val_loss: 2.856700, val_acc: 54.30%\n",
      "Epoch [2966]/[5000], train_loss: 0.034400, train_acc: 94.87%, val_loss: 2.738100, val_acc: 52.60%\n",
      "Epoch [2967]/[5000], train_loss: 0.052300, train_acc: 94.48%, val_loss: 2.890400, val_acc: 54.30%\n",
      "Epoch [2968]/[5000], train_loss: 0.045100, train_acc: 94.63%, val_loss: 3.086500, val_acc: 54.43%\n",
      "Epoch [2969]/[5000], train_loss: 0.037300, train_acc: 94.82%, val_loss: 3.306700, val_acc: 51.43%\n",
      "Epoch [2970]/[5000], train_loss: 0.053600, train_acc: 94.43%, val_loss: 3.028700, val_acc: 55.08%\n",
      "Epoch [2971]/[5000], train_loss: 0.052700, train_acc: 94.24%, val_loss: 2.822500, val_acc: 52.47%\n",
      "Epoch [2972]/[5000], train_loss: 0.076500, train_acc: 93.51%, val_loss: 3.334400, val_acc: 51.30%\n",
      "Epoch [2973]/[5000], train_loss: 0.053300, train_acc: 94.73%, val_loss: 3.438600, val_acc: 54.56%\n",
      "Epoch [2974]/[5000], train_loss: 0.060500, train_acc: 94.14%, val_loss: 2.860700, val_acc: 53.65%\n",
      "Epoch [2975]/[5000], train_loss: 0.037600, train_acc: 94.78%, val_loss: 2.865700, val_acc: 54.30%\n",
      "Epoch [2976]/[5000], train_loss: 0.059800, train_acc: 94.19%, val_loss: 2.745700, val_acc: 55.21%\n",
      "Epoch [2977]/[5000], train_loss: 0.068000, train_acc: 93.60%, val_loss: 2.922600, val_acc: 52.47%\n",
      "Epoch [2978]/[5000], train_loss: 0.053200, train_acc: 94.43%, val_loss: 2.910000, val_acc: 50.26%\n",
      "Epoch [2979]/[5000], train_loss: 0.060600, train_acc: 93.90%, val_loss: 2.827900, val_acc: 53.26%\n",
      "Epoch [2980]/[5000], train_loss: 0.045700, train_acc: 94.78%, val_loss: 2.909900, val_acc: 54.04%\n",
      "Epoch [2981]/[5000], train_loss: 0.041600, train_acc: 94.68%, val_loss: 2.553100, val_acc: 55.21%\n",
      "Epoch [2982]/[5000], train_loss: 0.055300, train_acc: 94.29%, val_loss: 2.660900, val_acc: 54.69%\n",
      "Epoch [2983]/[5000], train_loss: 0.062100, train_acc: 94.14%, val_loss: 2.660900, val_acc: 52.47%\n",
      "Epoch [2984]/[5000], train_loss: 0.048300, train_acc: 94.29%, val_loss: 2.866800, val_acc: 51.95%\n",
      "Epoch [2985]/[5000], train_loss: 0.044000, train_acc: 94.48%, val_loss: 2.801900, val_acc: 55.21%\n",
      "Epoch [2986]/[5000], train_loss: 0.077900, train_acc: 93.16%, val_loss: 2.839000, val_acc: 47.79%\n",
      "Epoch [2987]/[5000], train_loss: 0.065900, train_acc: 93.80%, val_loss: 2.780800, val_acc: 53.65%\n",
      "Epoch [2988]/[5000], train_loss: 0.053000, train_acc: 94.19%, val_loss: 2.838200, val_acc: 51.69%\n",
      "Epoch [2989]/[5000], train_loss: 0.060100, train_acc: 94.24%, val_loss: 3.142100, val_acc: 55.34%\n",
      "Epoch [2990]/[5000], train_loss: 0.068800, train_acc: 93.75%, val_loss: 2.904000, val_acc: 53.12%\n",
      "Epoch [2991]/[5000], train_loss: 0.075700, train_acc: 93.80%, val_loss: 2.868100, val_acc: 50.65%\n",
      "Epoch [2992]/[5000], train_loss: 0.055400, train_acc: 94.53%, val_loss: 2.600000, val_acc: 53.12%\n",
      "Epoch [2993]/[5000], train_loss: 0.068800, train_acc: 93.80%, val_loss: 2.905800, val_acc: 53.78%\n",
      "Epoch [2994]/[5000], train_loss: 0.044900, train_acc: 94.82%, val_loss: 2.792100, val_acc: 53.12%\n",
      "Epoch [2995]/[5000], train_loss: 0.046200, train_acc: 94.53%, val_loss: 3.187800, val_acc: 55.21%\n",
      "Epoch [2996]/[5000], train_loss: 0.064500, train_acc: 94.09%, val_loss: 2.854300, val_acc: 54.17%\n",
      "Epoch [2997]/[5000], train_loss: 0.041200, train_acc: 94.73%, val_loss: 2.831900, val_acc: 56.25%\n",
      "Epoch [2998]/[5000], train_loss: 0.046700, train_acc: 94.58%, val_loss: 2.505000, val_acc: 54.30%\n",
      "Epoch [2999]/[5000], train_loss: 0.043900, train_acc: 94.73%, val_loss: 2.492500, val_acc: 54.43%\n",
      "Epoch [3000]/[5000], train_loss: 0.059300, train_acc: 93.80%, val_loss: 2.850900, val_acc: 56.12%\n",
      "Epoch [3001]/[5000], train_loss: 0.047800, train_acc: 94.43%, val_loss: 3.120700, val_acc: 54.82%\n",
      "Epoch [3002]/[5000], train_loss: 0.049000, train_acc: 94.53%, val_loss: 2.595100, val_acc: 54.82%\n",
      "Epoch [3003]/[5000], train_loss: 0.029900, train_acc: 95.21%, val_loss: 2.400000, val_acc: 54.30%\n",
      "Epoch [3004]/[5000], train_loss: 0.032600, train_acc: 95.12%, val_loss: 2.811900, val_acc: 54.43%\n",
      "Epoch [3005]/[5000], train_loss: 0.032800, train_acc: 95.07%, val_loss: 2.559600, val_acc: 52.99%\n",
      "Epoch [3006]/[5000], train_loss: 0.044000, train_acc: 94.38%, val_loss: 2.812500, val_acc: 54.56%\n",
      "Epoch [3007]/[5000], train_loss: 0.035900, train_acc: 94.78%, val_loss: 2.748800, val_acc: 54.17%\n",
      "Epoch [3008]/[5000], train_loss: 0.056200, train_acc: 93.65%, val_loss: 2.830300, val_acc: 51.82%\n",
      "Epoch [3009]/[5000], train_loss: 0.034900, train_acc: 95.02%, val_loss: 3.070400, val_acc: 54.43%\n",
      "Epoch [3010]/[5000], train_loss: 0.035800, train_acc: 94.97%, val_loss: 2.690900, val_acc: 53.12%\n",
      "Epoch [3011]/[5000], train_loss: 0.036200, train_acc: 94.87%, val_loss: 2.780400, val_acc: 55.21%\n",
      "Epoch [3012]/[5000], train_loss: 0.040500, train_acc: 94.38%, val_loss: 2.563000, val_acc: 54.04%\n",
      "Epoch [3013]/[5000], train_loss: 0.043200, train_acc: 94.58%, val_loss: 2.765200, val_acc: 54.95%\n",
      "Epoch [3014]/[5000], train_loss: 0.021600, train_acc: 95.21%, val_loss: 3.472800, val_acc: 53.12%\n",
      "Epoch [3015]/[5000], train_loss: 0.024800, train_acc: 95.21%, val_loss: 2.917100, val_acc: 55.21%\n",
      "Epoch [3016]/[5000], train_loss: 0.035400, train_acc: 94.92%, val_loss: 3.126000, val_acc: 55.47%\n",
      "Epoch [3017]/[5000], train_loss: 0.042600, train_acc: 94.78%, val_loss: 2.861300, val_acc: 55.99%\n",
      "Epoch [3018]/[5000], train_loss: 0.065300, train_acc: 94.19%, val_loss: 2.847700, val_acc: 51.04%\n",
      "Epoch [3019]/[5000], train_loss: 0.051400, train_acc: 94.19%, val_loss: 3.111600, val_acc: 55.86%\n",
      "Epoch [3020]/[5000], train_loss: 0.037600, train_acc: 94.87%, val_loss: 2.946700, val_acc: 52.86%\n",
      "Epoch [3021]/[5000], train_loss: 0.038300, train_acc: 94.63%, val_loss: 2.938500, val_acc: 53.91%\n",
      "Epoch [3022]/[5000], train_loss: 0.043300, train_acc: 94.73%, val_loss: 2.583200, val_acc: 52.21%\n",
      "Epoch [3023]/[5000], train_loss: 0.034700, train_acc: 94.78%, val_loss: 2.986300, val_acc: 52.86%\n",
      "Epoch [3024]/[5000], train_loss: 0.051400, train_acc: 94.43%, val_loss: 2.728200, val_acc: 55.08%\n",
      "Epoch [3025]/[5000], train_loss: 0.068300, train_acc: 93.70%, val_loss: 3.015400, val_acc: 52.21%\n",
      "Epoch [3026]/[5000], train_loss: 0.049100, train_acc: 94.48%, val_loss: 2.859400, val_acc: 55.34%\n",
      "Epoch [3027]/[5000], train_loss: 0.050900, train_acc: 94.58%, val_loss: 3.143000, val_acc: 52.60%\n",
      "Epoch [3028]/[5000], train_loss: 0.063100, train_acc: 93.95%, val_loss: 2.662200, val_acc: 51.69%\n",
      "Epoch [3029]/[5000], train_loss: 0.064000, train_acc: 94.09%, val_loss: 2.828600, val_acc: 53.12%\n",
      "Epoch [3030]/[5000], train_loss: 0.062500, train_acc: 93.90%, val_loss: 2.772600, val_acc: 52.60%\n",
      "Epoch [3031]/[5000], train_loss: 0.060600, train_acc: 93.95%, val_loss: 2.888400, val_acc: 53.52%\n",
      "Epoch [3032]/[5000], train_loss: 0.046200, train_acc: 94.34%, val_loss: 2.790000, val_acc: 54.30%\n",
      "Epoch [3033]/[5000], train_loss: 0.054800, train_acc: 94.19%, val_loss: 2.958600, val_acc: 52.47%\n",
      "Epoch [3034]/[5000], train_loss: 0.052900, train_acc: 94.19%, val_loss: 2.999300, val_acc: 55.60%\n",
      "Epoch [3035]/[5000], train_loss: 0.066000, train_acc: 93.99%, val_loss: 2.619900, val_acc: 55.21%\n",
      "Epoch [3036]/[5000], train_loss: 0.050000, train_acc: 94.24%, val_loss: 2.719400, val_acc: 54.69%\n",
      "Epoch [3037]/[5000], train_loss: 0.048000, train_acc: 94.58%, val_loss: 3.052800, val_acc: 56.25%\n",
      "Epoch [3038]/[5000], train_loss: 0.062500, train_acc: 93.95%, val_loss: 2.784600, val_acc: 51.17%\n",
      "Epoch [3039]/[5000], train_loss: 0.039800, train_acc: 94.73%, val_loss: 2.640600, val_acc: 55.99%\n",
      "Epoch [3040]/[5000], train_loss: 0.033700, train_acc: 95.02%, val_loss: 2.762800, val_acc: 51.95%\n",
      "Epoch [3041]/[5000], train_loss: 0.045100, train_acc: 94.78%, val_loss: 2.728500, val_acc: 53.39%\n",
      "Epoch [3042]/[5000], train_loss: 0.031900, train_acc: 95.21%, val_loss: 2.631600, val_acc: 56.90%\n",
      "Epoch [3043]/[5000], train_loss: 0.036600, train_acc: 94.63%, val_loss: 3.160400, val_acc: 55.47%\n",
      "Epoch [3044]/[5000], train_loss: 0.035000, train_acc: 95.17%, val_loss: 2.784400, val_acc: 52.47%\n",
      "Epoch [3045]/[5000], train_loss: 0.042000, train_acc: 94.63%, val_loss: 2.619900, val_acc: 56.38%\n",
      "Epoch [3046]/[5000], train_loss: 0.029500, train_acc: 95.02%, val_loss: 2.757200, val_acc: 52.34%\n",
      "Epoch [3047]/[5000], train_loss: 0.048000, train_acc: 94.73%, val_loss: 3.153800, val_acc: 56.25%\n",
      "Epoch [3048]/[5000], train_loss: 0.038500, train_acc: 94.58%, val_loss: 3.030700, val_acc: 54.43%\n",
      "Epoch [3049]/[5000], train_loss: 0.034100, train_acc: 95.26%, val_loss: 2.714100, val_acc: 54.30%\n",
      "Epoch [3050]/[5000], train_loss: 0.039700, train_acc: 94.97%, val_loss: 2.822800, val_acc: 53.91%\n",
      "Epoch [3051]/[5000], train_loss: 0.036900, train_acc: 95.12%, val_loss: 2.774800, val_acc: 55.08%\n",
      "Epoch [3052]/[5000], train_loss: 0.052200, train_acc: 94.38%, val_loss: 2.665200, val_acc: 54.82%\n",
      "Epoch [3053]/[5000], train_loss: 0.055600, train_acc: 93.65%, val_loss: 2.460400, val_acc: 52.99%\n",
      "Epoch [3054]/[5000], train_loss: 0.044600, train_acc: 94.43%, val_loss: 3.031600, val_acc: 54.04%\n",
      "Epoch [3055]/[5000], train_loss: 0.038600, train_acc: 94.92%, val_loss: 2.665600, val_acc: 51.82%\n",
      "Epoch [3056]/[5000], train_loss: 0.045200, train_acc: 94.38%, val_loss: 2.429300, val_acc: 54.43%\n",
      "Epoch [3057]/[5000], train_loss: 0.017100, train_acc: 95.41%, val_loss: 2.951000, val_acc: 54.82%\n",
      "Epoch [3058]/[5000], train_loss: 0.025000, train_acc: 95.07%, val_loss: 3.168800, val_acc: 53.65%\n",
      "Epoch [3059]/[5000], train_loss: 0.032800, train_acc: 94.87%, val_loss: 2.912000, val_acc: 54.69%\n",
      "Epoch [3060]/[5000], train_loss: 0.042300, train_acc: 95.02%, val_loss: 2.490800, val_acc: 54.17%\n",
      "Epoch [3061]/[5000], train_loss: 0.031000, train_acc: 95.17%, val_loss: 2.734000, val_acc: 54.04%\n",
      "Epoch [3062]/[5000], train_loss: 0.027000, train_acc: 95.07%, val_loss: 3.173000, val_acc: 54.43%\n",
      "Epoch [3063]/[5000], train_loss: 0.028100, train_acc: 94.97%, val_loss: 2.920100, val_acc: 57.03%\n",
      "Epoch [3064]/[5000], train_loss: 0.027500, train_acc: 95.17%, val_loss: 3.357600, val_acc: 54.43%\n",
      "Epoch [3065]/[5000], train_loss: 0.049300, train_acc: 94.53%, val_loss: 3.038600, val_acc: 54.04%\n",
      "Epoch [3066]/[5000], train_loss: 0.039100, train_acc: 94.58%, val_loss: 2.785900, val_acc: 54.17%\n",
      "Epoch [3067]/[5000], train_loss: 0.060200, train_acc: 94.19%, val_loss: 2.615200, val_acc: 53.26%\n",
      "Epoch [3068]/[5000], train_loss: 0.035900, train_acc: 94.97%, val_loss: 2.799100, val_acc: 54.56%\n",
      "Epoch [3069]/[5000], train_loss: 0.058400, train_acc: 93.90%, val_loss: 3.134500, val_acc: 52.73%\n",
      "Epoch [3070]/[5000], train_loss: 0.048900, train_acc: 94.53%, val_loss: 2.724800, val_acc: 53.52%\n",
      "Epoch [3071]/[5000], train_loss: 0.055200, train_acc: 94.09%, val_loss: 2.845000, val_acc: 53.65%\n",
      "Epoch [3072]/[5000], train_loss: 0.065400, train_acc: 93.95%, val_loss: 2.678500, val_acc: 53.52%\n",
      "Epoch [3073]/[5000], train_loss: 0.053900, train_acc: 94.58%, val_loss: 2.760800, val_acc: 51.69%\n",
      "Epoch [3074]/[5000], train_loss: 0.068400, train_acc: 93.55%, val_loss: 2.742900, val_acc: 49.74%\n",
      "Epoch [3075]/[5000], train_loss: 0.055300, train_acc: 94.38%, val_loss: 3.053400, val_acc: 55.08%\n",
      "Epoch [3076]/[5000], train_loss: 0.054000, train_acc: 94.24%, val_loss: 2.693000, val_acc: 54.04%\n",
      "Epoch [3077]/[5000], train_loss: 0.047100, train_acc: 94.68%, val_loss: 2.820500, val_acc: 55.08%\n",
      "Epoch [3078]/[5000], train_loss: 0.038200, train_acc: 94.73%, val_loss: 3.519800, val_acc: 52.08%\n",
      "Epoch [3079]/[5000], train_loss: 0.056900, train_acc: 94.09%, val_loss: 2.549700, val_acc: 53.65%\n",
      "Epoch [3080]/[5000], train_loss: 0.041500, train_acc: 94.53%, val_loss: 2.493300, val_acc: 55.47%\n",
      "Epoch [3081]/[5000], train_loss: 0.059800, train_acc: 94.04%, val_loss: 2.787800, val_acc: 51.82%\n",
      "Epoch [3082]/[5000], train_loss: 0.044900, train_acc: 94.58%, val_loss: 2.822700, val_acc: 52.60%\n",
      "Epoch [3083]/[5000], train_loss: 0.035500, train_acc: 94.87%, val_loss: 2.845000, val_acc: 54.04%\n",
      "Epoch [3084]/[5000], train_loss: 0.040200, train_acc: 94.63%, val_loss: 3.246400, val_acc: 54.30%\n",
      "Epoch [3085]/[5000], train_loss: 0.038100, train_acc: 94.53%, val_loss: 2.899700, val_acc: 53.26%\n",
      "Epoch [3086]/[5000], train_loss: 0.038000, train_acc: 94.78%, val_loss: 3.165600, val_acc: 55.21%\n",
      "Epoch [3087]/[5000], train_loss: 0.064000, train_acc: 93.99%, val_loss: 2.499200, val_acc: 55.86%\n",
      "Epoch [3088]/[5000], train_loss: 0.046200, train_acc: 94.48%, val_loss: 2.905300, val_acc: 54.69%\n",
      "Epoch [3089]/[5000], train_loss: 0.054400, train_acc: 94.48%, val_loss: 3.417600, val_acc: 55.34%\n",
      "Epoch [3090]/[5000], train_loss: 0.053100, train_acc: 94.43%, val_loss: 2.903400, val_acc: 52.08%\n",
      "Epoch [3091]/[5000], train_loss: 0.062000, train_acc: 93.85%, val_loss: 2.881000, val_acc: 54.30%\n",
      "Epoch [3092]/[5000], train_loss: 0.079200, train_acc: 93.75%, val_loss: 3.102800, val_acc: 50.91%\n",
      "Epoch [3093]/[5000], train_loss: 0.049200, train_acc: 94.38%, val_loss: 3.077900, val_acc: 52.21%\n",
      "Epoch [3094]/[5000], train_loss: 0.044100, train_acc: 94.92%, val_loss: 2.715300, val_acc: 54.95%\n",
      "Epoch [3095]/[5000], train_loss: 0.035600, train_acc: 94.97%, val_loss: 2.890100, val_acc: 53.39%\n",
      "Epoch [3096]/[5000], train_loss: 0.034400, train_acc: 94.97%, val_loss: 2.894600, val_acc: 52.47%\n",
      "Epoch [3097]/[5000], train_loss: 0.051400, train_acc: 94.14%, val_loss: 2.636300, val_acc: 55.60%\n",
      "Epoch [3098]/[5000], train_loss: 0.072000, train_acc: 94.14%, val_loss: 2.925100, val_acc: 53.26%\n",
      "Epoch [3099]/[5000], train_loss: 0.075400, train_acc: 93.46%, val_loss: 2.981100, val_acc: 54.30%\n",
      "Epoch [3100]/[5000], train_loss: 0.049400, train_acc: 94.19%, val_loss: 3.582200, val_acc: 53.26%\n",
      "Epoch [3101]/[5000], train_loss: 0.061900, train_acc: 93.99%, val_loss: 2.816900, val_acc: 53.78%\n",
      "Epoch [3102]/[5000], train_loss: 0.040900, train_acc: 94.58%, val_loss: 2.776900, val_acc: 54.95%\n",
      "Epoch [3103]/[5000], train_loss: 0.041200, train_acc: 94.87%, val_loss: 2.607200, val_acc: 54.82%\n",
      "Epoch [3104]/[5000], train_loss: 0.044500, train_acc: 94.78%, val_loss: 2.869100, val_acc: 53.39%\n",
      "Epoch [3105]/[5000], train_loss: 0.059300, train_acc: 94.04%, val_loss: 2.659600, val_acc: 53.91%\n",
      "Epoch [3106]/[5000], train_loss: 0.056200, train_acc: 94.38%, val_loss: 2.572000, val_acc: 54.04%\n",
      "Epoch [3107]/[5000], train_loss: 0.049700, train_acc: 94.14%, val_loss: 2.847600, val_acc: 54.69%\n",
      "Epoch [3108]/[5000], train_loss: 0.044200, train_acc: 94.29%, val_loss: 2.941100, val_acc: 55.21%\n",
      "Epoch [3109]/[5000], train_loss: 0.032500, train_acc: 95.02%, val_loss: 2.977600, val_acc: 53.26%\n",
      "Epoch [3110]/[5000], train_loss: 0.031700, train_acc: 94.97%, val_loss: 2.867400, val_acc: 54.04%\n",
      "Epoch [3111]/[5000], train_loss: 0.037400, train_acc: 94.87%, val_loss: 2.588900, val_acc: 54.56%\n",
      "Epoch [3112]/[5000], train_loss: 0.031500, train_acc: 95.31%, val_loss: 2.753200, val_acc: 55.21%\n",
      "Epoch [3113]/[5000], train_loss: 0.038900, train_acc: 94.78%, val_loss: 3.144600, val_acc: 55.21%\n",
      "Epoch [3114]/[5000], train_loss: 0.020900, train_acc: 95.41%, val_loss: 2.763300, val_acc: 55.73%\n",
      "Epoch [3115]/[5000], train_loss: 0.032300, train_acc: 94.97%, val_loss: 3.069600, val_acc: 55.99%\n",
      "Epoch [3116]/[5000], train_loss: 0.032700, train_acc: 95.02%, val_loss: 3.203600, val_acc: 54.95%\n",
      "Epoch [3117]/[5000], train_loss: 0.020300, train_acc: 95.61%, val_loss: 3.261100, val_acc: 54.17%\n",
      "Epoch [3118]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 2.807400, val_acc: 55.73%\n",
      "Epoch [3119]/[5000], train_loss: 0.035000, train_acc: 95.21%, val_loss: 2.647800, val_acc: 54.17%\n",
      "Epoch [3120]/[5000], train_loss: 0.023400, train_acc: 95.26%, val_loss: 3.037600, val_acc: 54.30%\n",
      "Epoch [3121]/[5000], train_loss: 0.037500, train_acc: 94.87%, val_loss: 2.962700, val_acc: 54.30%\n",
      "Epoch [3122]/[5000], train_loss: 0.033400, train_acc: 94.97%, val_loss: 2.931800, val_acc: 53.52%\n",
      "Epoch [3123]/[5000], train_loss: 0.046200, train_acc: 94.43%, val_loss: 4.098900, val_acc: 54.43%\n",
      "Epoch [3124]/[5000], train_loss: 0.065700, train_acc: 93.85%, val_loss: 2.678500, val_acc: 57.16%\n",
      "Epoch [3125]/[5000], train_loss: 0.052500, train_acc: 94.38%, val_loss: 2.697400, val_acc: 53.52%\n",
      "Epoch [3126]/[5000], train_loss: 0.043700, train_acc: 94.63%, val_loss: 2.911400, val_acc: 56.25%\n",
      "Epoch [3127]/[5000], train_loss: 0.030100, train_acc: 95.12%, val_loss: 3.021200, val_acc: 52.86%\n",
      "Epoch [3128]/[5000], train_loss: 0.036200, train_acc: 94.78%, val_loss: 3.678200, val_acc: 51.82%\n",
      "Epoch [3129]/[5000], train_loss: 0.040600, train_acc: 94.63%, val_loss: 3.301100, val_acc: 55.08%\n",
      "Epoch [3130]/[5000], train_loss: 0.040700, train_acc: 94.63%, val_loss: 3.166700, val_acc: 53.65%\n",
      "Epoch [3131]/[5000], train_loss: 0.070600, train_acc: 94.29%, val_loss: 2.951000, val_acc: 51.82%\n",
      "Epoch [3132]/[5000], train_loss: 0.073700, train_acc: 93.55%, val_loss: 2.793300, val_acc: 50.78%\n",
      "Epoch [3133]/[5000], train_loss: 0.062300, train_acc: 94.19%, val_loss: 2.831000, val_acc: 52.21%\n",
      "Epoch [3134]/[5000], train_loss: 0.048200, train_acc: 94.38%, val_loss: 3.115600, val_acc: 55.08%\n",
      "Epoch [3135]/[5000], train_loss: 0.029800, train_acc: 94.87%, val_loss: 2.866500, val_acc: 56.64%\n",
      "Epoch [3136]/[5000], train_loss: 0.030100, train_acc: 95.07%, val_loss: 2.859900, val_acc: 55.08%\n",
      "Epoch [3137]/[5000], train_loss: 0.028000, train_acc: 95.46%, val_loss: 3.014500, val_acc: 53.91%\n",
      "Epoch [3138]/[5000], train_loss: 0.033000, train_acc: 95.07%, val_loss: 2.672500, val_acc: 55.86%\n",
      "Epoch [3139]/[5000], train_loss: 0.028500, train_acc: 95.07%, val_loss: 2.672800, val_acc: 58.20%\n",
      "Epoch [3140]/[5000], train_loss: 0.036300, train_acc: 94.82%, val_loss: 2.749900, val_acc: 55.73%\n",
      "Epoch [3141]/[5000], train_loss: 0.025700, train_acc: 95.21%, val_loss: 3.242600, val_acc: 54.82%\n",
      "Epoch [3142]/[5000], train_loss: 0.040200, train_acc: 94.78%, val_loss: 2.922600, val_acc: 56.12%\n",
      "Epoch [3143]/[5000], train_loss: 0.039000, train_acc: 95.07%, val_loss: 2.837900, val_acc: 53.12%\n",
      "Epoch [3144]/[5000], train_loss: 0.058700, train_acc: 93.80%, val_loss: 2.745700, val_acc: 51.56%\n",
      "Epoch [3145]/[5000], train_loss: 0.041200, train_acc: 94.63%, val_loss: 3.373000, val_acc: 53.91%\n",
      "Epoch [3146]/[5000], train_loss: 0.032700, train_acc: 95.21%, val_loss: 3.276500, val_acc: 56.64%\n",
      "Epoch [3147]/[5000], train_loss: 0.046200, train_acc: 94.38%, val_loss: 2.704600, val_acc: 54.17%\n",
      "Epoch [3148]/[5000], train_loss: 0.031400, train_acc: 94.92%, val_loss: 2.945500, val_acc: 54.56%\n",
      "Epoch [3149]/[5000], train_loss: 0.047200, train_acc: 94.82%, val_loss: 2.882400, val_acc: 56.38%\n",
      "Epoch [3150]/[5000], train_loss: 0.049500, train_acc: 94.29%, val_loss: 3.132300, val_acc: 54.56%\n",
      "Epoch [3151]/[5000], train_loss: 0.043500, train_acc: 94.68%, val_loss: 2.727200, val_acc: 54.30%\n",
      "Epoch [3152]/[5000], train_loss: 0.063400, train_acc: 93.65%, val_loss: 3.096300, val_acc: 52.73%\n",
      "Epoch [3153]/[5000], train_loss: 0.062900, train_acc: 93.75%, val_loss: 3.131900, val_acc: 52.73%\n",
      "Epoch [3154]/[5000], train_loss: 0.064700, train_acc: 93.75%, val_loss: 3.015200, val_acc: 51.43%\n",
      "Epoch [3155]/[5000], train_loss: 0.050400, train_acc: 94.24%, val_loss: 3.116300, val_acc: 51.17%\n",
      "Epoch [3156]/[5000], train_loss: 0.044000, train_acc: 94.48%, val_loss: 3.073400, val_acc: 55.34%\n",
      "Epoch [3157]/[5000], train_loss: 0.034600, train_acc: 94.97%, val_loss: 2.807200, val_acc: 54.04%\n",
      "Epoch [3158]/[5000], train_loss: 0.050700, train_acc: 94.48%, val_loss: 3.314100, val_acc: 52.99%\n",
      "Epoch [3159]/[5000], train_loss: 0.066100, train_acc: 93.99%, val_loss: 3.186900, val_acc: 55.60%\n",
      "Epoch [3160]/[5000], train_loss: 0.057400, train_acc: 94.34%, val_loss: 2.612700, val_acc: 54.95%\n",
      "Epoch [3161]/[5000], train_loss: 0.059700, train_acc: 94.38%, val_loss: 2.907700, val_acc: 56.38%\n",
      "Epoch [3162]/[5000], train_loss: 0.044900, train_acc: 94.29%, val_loss: 3.113300, val_acc: 52.99%\n",
      "Epoch [3163]/[5000], train_loss: 0.055800, train_acc: 94.14%, val_loss: 3.208900, val_acc: 53.91%\n",
      "Epoch [3164]/[5000], train_loss: 0.045000, train_acc: 94.34%, val_loss: 2.827500, val_acc: 54.56%\n",
      "Epoch [3165]/[5000], train_loss: 0.047200, train_acc: 94.48%, val_loss: 3.119000, val_acc: 53.65%\n",
      "Epoch [3166]/[5000], train_loss: 0.071300, train_acc: 94.19%, val_loss: 2.717300, val_acc: 53.12%\n",
      "Epoch [3167]/[5000], train_loss: 0.065700, train_acc: 93.99%, val_loss: 2.748300, val_acc: 53.26%\n",
      "Epoch [3168]/[5000], train_loss: 0.048600, train_acc: 94.29%, val_loss: 2.785300, val_acc: 52.21%\n",
      "Epoch [3169]/[5000], train_loss: 0.045100, train_acc: 94.82%, val_loss: 2.542400, val_acc: 54.95%\n",
      "Epoch [3170]/[5000], train_loss: 0.040000, train_acc: 94.97%, val_loss: 3.177000, val_acc: 54.95%\n",
      "Epoch [3171]/[5000], train_loss: 0.033900, train_acc: 94.92%, val_loss: 2.696800, val_acc: 51.95%\n",
      "Epoch [3172]/[5000], train_loss: 0.040800, train_acc: 94.48%, val_loss: 2.894600, val_acc: 55.08%\n",
      "Epoch [3173]/[5000], train_loss: 0.041600, train_acc: 94.73%, val_loss: 2.912200, val_acc: 55.86%\n",
      "Epoch [3174]/[5000], train_loss: 0.040800, train_acc: 94.87%, val_loss: 2.833200, val_acc: 53.91%\n",
      "Epoch [3175]/[5000], train_loss: 0.024400, train_acc: 95.12%, val_loss: 2.835000, val_acc: 56.12%\n",
      "Epoch [3176]/[5000], train_loss: 0.041900, train_acc: 94.73%, val_loss: 2.775700, val_acc: 55.60%\n",
      "Epoch [3177]/[5000], train_loss: 0.029300, train_acc: 95.07%, val_loss: 3.193300, val_acc: 56.51%\n",
      "Epoch [3178]/[5000], train_loss: 0.038700, train_acc: 94.73%, val_loss: 3.014100, val_acc: 52.86%\n",
      "Epoch [3179]/[5000], train_loss: 0.039200, train_acc: 94.82%, val_loss: 2.734400, val_acc: 53.39%\n",
      "Epoch [3180]/[5000], train_loss: 0.033300, train_acc: 94.82%, val_loss: 2.674000, val_acc: 53.65%\n",
      "Epoch [3181]/[5000], train_loss: 0.028000, train_acc: 95.02%, val_loss: 3.193800, val_acc: 50.26%\n",
      "Epoch [3182]/[5000], train_loss: 0.051400, train_acc: 94.29%, val_loss: 2.884900, val_acc: 56.77%\n",
      "Epoch [3183]/[5000], train_loss: 0.040700, train_acc: 94.87%, val_loss: 2.701800, val_acc: 54.04%\n",
      "Epoch [3184]/[5000], train_loss: 0.041300, train_acc: 94.53%, val_loss: 3.264600, val_acc: 53.26%\n",
      "Epoch [3185]/[5000], train_loss: 0.044100, train_acc: 94.63%, val_loss: 2.854800, val_acc: 52.21%\n",
      "Epoch [3186]/[5000], train_loss: 0.080100, train_acc: 94.73%, val_loss: 2.913100, val_acc: 51.69%\n",
      "Epoch [3187]/[5000], train_loss: 0.094400, train_acc: 93.26%, val_loss: 2.683200, val_acc: 53.12%\n",
      "Epoch [3188]/[5000], train_loss: 0.063800, train_acc: 93.51%, val_loss: 2.720900, val_acc: 55.86%\n",
      "Epoch [3189]/[5000], train_loss: 0.039700, train_acc: 94.68%, val_loss: 2.770800, val_acc: 54.43%\n",
      "Epoch [3190]/[5000], train_loss: 0.034800, train_acc: 94.82%, val_loss: 2.674100, val_acc: 54.30%\n",
      "Epoch [3191]/[5000], train_loss: 0.029300, train_acc: 95.31%, val_loss: 2.993600, val_acc: 54.69%\n",
      "Epoch [3192]/[5000], train_loss: 0.024800, train_acc: 95.12%, val_loss: 2.624500, val_acc: 53.39%\n",
      "Epoch [3193]/[5000], train_loss: 0.034200, train_acc: 94.97%, val_loss: 2.726100, val_acc: 53.91%\n",
      "Epoch [3194]/[5000], train_loss: 0.035000, train_acc: 94.97%, val_loss: 2.704200, val_acc: 54.17%\n",
      "Epoch [3195]/[5000], train_loss: 0.041500, train_acc: 94.68%, val_loss: 3.309300, val_acc: 51.30%\n",
      "Epoch [3196]/[5000], train_loss: 0.051300, train_acc: 94.43%, val_loss: 2.705000, val_acc: 54.43%\n",
      "Epoch [3197]/[5000], train_loss: 0.035100, train_acc: 94.97%, val_loss: 3.309900, val_acc: 52.08%\n",
      "Epoch [3198]/[5000], train_loss: 0.030300, train_acc: 94.82%, val_loss: 2.793600, val_acc: 54.95%\n",
      "Epoch [3199]/[5000], train_loss: 0.046600, train_acc: 94.73%, val_loss: 2.569900, val_acc: 53.12%\n",
      "Epoch [3200]/[5000], train_loss: 0.026800, train_acc: 95.02%, val_loss: 2.745500, val_acc: 53.26%\n",
      "Epoch [3201]/[5000], train_loss: 0.018700, train_acc: 95.61%, val_loss: 3.014600, val_acc: 53.26%\n",
      "Epoch [3202]/[5000], train_loss: 0.019000, train_acc: 95.56%, val_loss: 2.816600, val_acc: 54.56%\n",
      "Epoch [3203]/[5000], train_loss: 0.036100, train_acc: 94.82%, val_loss: 2.903500, val_acc: 56.25%\n",
      "Epoch [3204]/[5000], train_loss: 0.051900, train_acc: 94.43%, val_loss: 2.835700, val_acc: 49.48%\n",
      "Epoch [3205]/[5000], train_loss: 0.070300, train_acc: 93.36%, val_loss: 3.111700, val_acc: 53.12%\n",
      "Epoch [3206]/[5000], train_loss: 0.043700, train_acc: 94.63%, val_loss: 2.635600, val_acc: 53.91%\n",
      "Epoch [3207]/[5000], train_loss: 0.041300, train_acc: 94.78%, val_loss: 2.770500, val_acc: 55.99%\n",
      "Epoch [3208]/[5000], train_loss: 0.043600, train_acc: 94.68%, val_loss: 2.833900, val_acc: 52.86%\n",
      "Epoch [3209]/[5000], train_loss: 0.057300, train_acc: 94.04%, val_loss: 2.773400, val_acc: 55.47%\n",
      "Epoch [3210]/[5000], train_loss: 0.050500, train_acc: 94.14%, val_loss: 2.901800, val_acc: 54.43%\n",
      "Epoch [3211]/[5000], train_loss: 0.045900, train_acc: 94.78%, val_loss: 2.923200, val_acc: 55.60%\n",
      "Epoch [3212]/[5000], train_loss: 0.051100, train_acc: 94.58%, val_loss: 2.879400, val_acc: 54.82%\n",
      "Epoch [3213]/[5000], train_loss: 0.046200, train_acc: 94.53%, val_loss: 2.952800, val_acc: 51.43%\n",
      "Epoch [3214]/[5000], train_loss: 0.034600, train_acc: 94.82%, val_loss: 3.292600, val_acc: 54.82%\n",
      "Epoch [3215]/[5000], train_loss: 0.024100, train_acc: 95.26%, val_loss: 2.533700, val_acc: 55.47%\n",
      "Epoch [3216]/[5000], train_loss: 0.022000, train_acc: 95.26%, val_loss: 2.867500, val_acc: 54.56%\n",
      "Epoch [3217]/[5000], train_loss: 0.027100, train_acc: 95.02%, val_loss: 2.625600, val_acc: 53.39%\n",
      "Epoch [3218]/[5000], train_loss: 0.020300, train_acc: 95.41%, val_loss: 2.897200, val_acc: 51.56%\n",
      "Epoch [3219]/[5000], train_loss: 0.027900, train_acc: 95.12%, val_loss: 3.012600, val_acc: 54.30%\n",
      "Epoch [3220]/[5000], train_loss: 0.022300, train_acc: 95.26%, val_loss: 2.685200, val_acc: 56.38%\n",
      "Epoch [3221]/[5000], train_loss: 0.028900, train_acc: 95.46%, val_loss: 2.748700, val_acc: 52.73%\n",
      "Epoch [3222]/[5000], train_loss: 0.030300, train_acc: 94.97%, val_loss: 2.803200, val_acc: 53.39%\n",
      "Epoch [3223]/[5000], train_loss: 0.030700, train_acc: 94.97%, val_loss: 2.847700, val_acc: 56.38%\n",
      "Epoch [3224]/[5000], train_loss: 0.025200, train_acc: 95.21%, val_loss: 2.991900, val_acc: 54.17%\n",
      "Epoch [3225]/[5000], train_loss: 0.031100, train_acc: 95.07%, val_loss: 3.201000, val_acc: 52.60%\n",
      "Epoch [3226]/[5000], train_loss: 0.035500, train_acc: 94.97%, val_loss: 2.810100, val_acc: 54.69%\n",
      "Epoch [3227]/[5000], train_loss: 0.041900, train_acc: 94.73%, val_loss: 2.799100, val_acc: 54.17%\n",
      "Epoch [3228]/[5000], train_loss: 0.029100, train_acc: 95.07%, val_loss: 3.081800, val_acc: 55.21%\n",
      "Epoch [3229]/[5000], train_loss: 0.024800, train_acc: 95.21%, val_loss: 3.142300, val_acc: 51.82%\n",
      "Epoch [3230]/[5000], train_loss: 0.045000, train_acc: 94.87%, val_loss: 2.884300, val_acc: 56.12%\n",
      "Epoch [3231]/[5000], train_loss: 0.064200, train_acc: 93.90%, val_loss: 3.101300, val_acc: 55.21%\n",
      "Epoch [3232]/[5000], train_loss: 0.064000, train_acc: 93.65%, val_loss: 3.414900, val_acc: 50.39%\n",
      "Epoch [3233]/[5000], train_loss: 0.066800, train_acc: 93.70%, val_loss: 3.042600, val_acc: 52.99%\n",
      "Epoch [3234]/[5000], train_loss: 0.054600, train_acc: 94.34%, val_loss: 2.712500, val_acc: 56.77%\n",
      "Epoch [3235]/[5000], train_loss: 0.049700, train_acc: 94.58%, val_loss: 2.793300, val_acc: 53.39%\n",
      "Epoch [3236]/[5000], train_loss: 0.042300, train_acc: 94.63%, val_loss: 3.052900, val_acc: 50.39%\n",
      "Epoch [3237]/[5000], train_loss: 0.045200, train_acc: 94.24%, val_loss: 2.890600, val_acc: 52.86%\n",
      "Epoch [3238]/[5000], train_loss: 0.046400, train_acc: 94.58%, val_loss: 2.852300, val_acc: 53.12%\n",
      "Epoch [3239]/[5000], train_loss: 0.056700, train_acc: 94.53%, val_loss: 2.639300, val_acc: 49.61%\n",
      "Epoch [3240]/[5000], train_loss: 0.042500, train_acc: 94.68%, val_loss: 2.845800, val_acc: 55.34%\n",
      "Epoch [3241]/[5000], train_loss: 0.038100, train_acc: 94.97%, val_loss: 2.837900, val_acc: 53.12%\n",
      "Epoch [3242]/[5000], train_loss: 0.045600, train_acc: 94.82%, val_loss: 3.145300, val_acc: 56.90%\n",
      "Epoch [3243]/[5000], train_loss: 0.040000, train_acc: 94.82%, val_loss: 2.879000, val_acc: 54.56%\n",
      "Epoch [3244]/[5000], train_loss: 0.024000, train_acc: 95.36%, val_loss: 2.810400, val_acc: 54.95%\n",
      "Epoch [3245]/[5000], train_loss: 0.065400, train_acc: 93.51%, val_loss: 3.427100, val_acc: 54.56%\n",
      "Epoch [3246]/[5000], train_loss: 0.046200, train_acc: 94.43%, val_loss: 3.423600, val_acc: 56.38%\n",
      "Epoch [3247]/[5000], train_loss: 0.045900, train_acc: 94.73%, val_loss: 3.434000, val_acc: 55.08%\n",
      "Epoch [3248]/[5000], train_loss: 0.027600, train_acc: 95.31%, val_loss: 2.728200, val_acc: 54.17%\n",
      "Epoch [3249]/[5000], train_loss: 0.022000, train_acc: 95.36%, val_loss: 2.941400, val_acc: 53.65%\n",
      "Epoch [3250]/[5000], train_loss: 0.038200, train_acc: 94.58%, val_loss: 3.313900, val_acc: 55.99%\n",
      "Epoch [3251]/[5000], train_loss: 0.029800, train_acc: 95.12%, val_loss: 2.962100, val_acc: 57.03%\n",
      "Epoch [3252]/[5000], train_loss: 0.028600, train_acc: 95.17%, val_loss: 2.938100, val_acc: 53.52%\n",
      "Epoch [3253]/[5000], train_loss: 0.038800, train_acc: 94.82%, val_loss: 4.195100, val_acc: 55.73%\n",
      "Epoch [3254]/[5000], train_loss: 0.045700, train_acc: 94.58%, val_loss: 2.685800, val_acc: 54.56%\n",
      "Epoch [3255]/[5000], train_loss: 0.038600, train_acc: 94.78%, val_loss: 3.268900, val_acc: 55.34%\n",
      "Epoch [3256]/[5000], train_loss: 0.050400, train_acc: 94.34%, val_loss: 3.062600, val_acc: 50.39%\n",
      "Epoch [3257]/[5000], train_loss: 0.056600, train_acc: 94.53%, val_loss: 2.646400, val_acc: 53.78%\n",
      "Epoch [3258]/[5000], train_loss: 0.063000, train_acc: 94.09%, val_loss: 3.034900, val_acc: 51.56%\n",
      "Epoch [3259]/[5000], train_loss: 0.060800, train_acc: 94.09%, val_loss: 2.896100, val_acc: 58.72%\n",
      "Epoch [3260]/[5000], train_loss: 0.051900, train_acc: 94.19%, val_loss: 2.821100, val_acc: 55.21%\n",
      "Epoch [3261]/[5000], train_loss: 0.043600, train_acc: 94.48%, val_loss: 2.683500, val_acc: 52.86%\n",
      "Epoch [3262]/[5000], train_loss: 0.054100, train_acc: 94.43%, val_loss: 2.723800, val_acc: 55.08%\n",
      "Epoch [3263]/[5000], train_loss: 0.060400, train_acc: 94.14%, val_loss: 2.811600, val_acc: 52.73%\n",
      "Epoch [3264]/[5000], train_loss: 0.064000, train_acc: 93.85%, val_loss: 2.648200, val_acc: 53.52%\n",
      "Epoch [3265]/[5000], train_loss: 0.056800, train_acc: 93.70%, val_loss: 2.902000, val_acc: 54.17%\n",
      "Epoch [3266]/[5000], train_loss: 0.052400, train_acc: 94.19%, val_loss: 2.750600, val_acc: 53.26%\n",
      "Epoch [3267]/[5000], train_loss: 0.045000, train_acc: 94.68%, val_loss: 2.620700, val_acc: 54.56%\n",
      "Epoch [3268]/[5000], train_loss: 0.025400, train_acc: 95.36%, val_loss: 2.686400, val_acc: 55.99%\n",
      "Epoch [3269]/[5000], train_loss: 0.042900, train_acc: 94.73%, val_loss: 2.780500, val_acc: 55.60%\n",
      "Epoch [3270]/[5000], train_loss: 0.027000, train_acc: 95.12%, val_loss: 2.821800, val_acc: 54.30%\n",
      "Epoch [3271]/[5000], train_loss: 0.040100, train_acc: 94.78%, val_loss: 2.738400, val_acc: 55.21%\n",
      "Epoch [3272]/[5000], train_loss: 0.024400, train_acc: 95.31%, val_loss: 2.580900, val_acc: 53.65%\n",
      "Epoch [3273]/[5000], train_loss: 0.051500, train_acc: 94.04%, val_loss: 2.880300, val_acc: 52.99%\n",
      "Epoch [3274]/[5000], train_loss: 0.045500, train_acc: 94.34%, val_loss: 2.894800, val_acc: 57.16%\n",
      "Epoch [3275]/[5000], train_loss: 0.043200, train_acc: 94.73%, val_loss: 2.578200, val_acc: 53.78%\n",
      "Epoch [3276]/[5000], train_loss: 0.064600, train_acc: 93.60%, val_loss: 3.336900, val_acc: 51.69%\n",
      "Epoch [3277]/[5000], train_loss: 0.104100, train_acc: 92.82%, val_loss: 2.806300, val_acc: 54.43%\n",
      "Epoch [3278]/[5000], train_loss: 0.066300, train_acc: 93.90%, val_loss: 3.036300, val_acc: 52.47%\n",
      "Epoch [3279]/[5000], train_loss: 0.051300, train_acc: 94.29%, val_loss: 2.278100, val_acc: 56.25%\n",
      "Epoch [3280]/[5000], train_loss: 0.050300, train_acc: 94.53%, val_loss: 2.352000, val_acc: 53.52%\n",
      "Epoch [3281]/[5000], train_loss: 0.042100, train_acc: 94.87%, val_loss: 2.506300, val_acc: 53.78%\n",
      "Epoch [3282]/[5000], train_loss: 0.044300, train_acc: 94.58%, val_loss: 2.520000, val_acc: 54.56%\n",
      "Epoch [3283]/[5000], train_loss: 0.025300, train_acc: 95.31%, val_loss: 3.067600, val_acc: 53.78%\n",
      "Epoch [3284]/[5000], train_loss: 0.036400, train_acc: 94.48%, val_loss: 2.712800, val_acc: 54.04%\n",
      "Epoch [3285]/[5000], train_loss: 0.032300, train_acc: 95.17%, val_loss: 3.154900, val_acc: 53.12%\n",
      "Epoch [3286]/[5000], train_loss: 0.036200, train_acc: 94.82%, val_loss: 2.900000, val_acc: 52.86%\n",
      "Epoch [3287]/[5000], train_loss: 0.053900, train_acc: 94.53%, val_loss: 2.871000, val_acc: 51.95%\n",
      "Epoch [3288]/[5000], train_loss: 0.050300, train_acc: 94.63%, val_loss: 3.224500, val_acc: 52.34%\n",
      "Epoch [3289]/[5000], train_loss: 0.041200, train_acc: 94.48%, val_loss: 2.821600, val_acc: 53.39%\n",
      "Epoch [3290]/[5000], train_loss: 0.045200, train_acc: 94.82%, val_loss: 3.041100, val_acc: 55.60%\n",
      "Epoch [3291]/[5000], train_loss: 0.059500, train_acc: 93.95%, val_loss: 3.057000, val_acc: 54.43%\n",
      "Epoch [3292]/[5000], train_loss: 0.037800, train_acc: 94.87%, val_loss: 2.645800, val_acc: 55.47%\n",
      "Epoch [3293]/[5000], train_loss: 0.045100, train_acc: 94.87%, val_loss: 3.207600, val_acc: 54.69%\n",
      "Epoch [3294]/[5000], train_loss: 0.042500, train_acc: 94.58%, val_loss: 2.741700, val_acc: 51.04%\n",
      "Epoch [3295]/[5000], train_loss: 0.037800, train_acc: 94.97%, val_loss: 2.837500, val_acc: 53.39%\n",
      "Epoch [3296]/[5000], train_loss: 0.024800, train_acc: 95.41%, val_loss: 2.719700, val_acc: 54.69%\n",
      "Epoch [3297]/[5000], train_loss: 0.032200, train_acc: 95.07%, val_loss: 2.609300, val_acc: 57.29%\n",
      "Epoch [3298]/[5000], train_loss: 0.044600, train_acc: 94.73%, val_loss: 3.026200, val_acc: 54.17%\n",
      "Epoch [3299]/[5000], train_loss: 0.027800, train_acc: 94.97%, val_loss: 2.781300, val_acc: 56.90%\n",
      "Epoch [3300]/[5000], train_loss: 0.028000, train_acc: 95.07%, val_loss: 2.832300, val_acc: 56.64%\n",
      "Epoch [3301]/[5000], train_loss: 0.024500, train_acc: 95.17%, val_loss: 2.943100, val_acc: 52.99%\n",
      "Epoch [3302]/[5000], train_loss: 0.030000, train_acc: 94.73%, val_loss: 2.591800, val_acc: 54.95%\n",
      "Epoch [3303]/[5000], train_loss: 0.049900, train_acc: 94.58%, val_loss: 2.779500, val_acc: 53.65%\n",
      "Epoch [3304]/[5000], train_loss: 0.034400, train_acc: 95.02%, val_loss: 2.800500, val_acc: 54.04%\n",
      "Epoch [3305]/[5000], train_loss: 0.024600, train_acc: 95.36%, val_loss: 2.673700, val_acc: 54.30%\n",
      "Epoch [3306]/[5000], train_loss: 0.027000, train_acc: 95.07%, val_loss: 3.325000, val_acc: 54.17%\n",
      "Epoch [3307]/[5000], train_loss: 0.037100, train_acc: 94.78%, val_loss: 2.728900, val_acc: 54.69%\n",
      "Epoch [3308]/[5000], train_loss: 0.039700, train_acc: 94.53%, val_loss: 2.788100, val_acc: 54.17%\n",
      "Epoch [3309]/[5000], train_loss: 0.036200, train_acc: 94.82%, val_loss: 2.517400, val_acc: 56.51%\n",
      "Epoch [3310]/[5000], train_loss: 0.027100, train_acc: 95.46%, val_loss: 2.781300, val_acc: 57.16%\n",
      "Epoch [3311]/[5000], train_loss: 0.028900, train_acc: 95.17%, val_loss: 2.660400, val_acc: 56.51%\n",
      "Epoch [3312]/[5000], train_loss: 0.028000, train_acc: 94.87%, val_loss: 2.843200, val_acc: 55.86%\n",
      "Epoch [3313]/[5000], train_loss: 0.036800, train_acc: 94.78%, val_loss: 3.008200, val_acc: 54.17%\n",
      "Epoch [3314]/[5000], train_loss: 0.061500, train_acc: 94.68%, val_loss: 3.122000, val_acc: 55.60%\n",
      "Epoch [3315]/[5000], train_loss: 0.082400, train_acc: 93.31%, val_loss: 3.391100, val_acc: 54.43%\n",
      "Epoch [3316]/[5000], train_loss: 0.048700, train_acc: 94.24%, val_loss: 2.706700, val_acc: 56.12%\n",
      "Epoch [3317]/[5000], train_loss: 0.064600, train_acc: 93.99%, val_loss: 2.733800, val_acc: 52.86%\n",
      "Epoch [3318]/[5000], train_loss: 0.089700, train_acc: 93.26%, val_loss: 2.896600, val_acc: 52.08%\n",
      "Epoch [3319]/[5000], train_loss: 0.083700, train_acc: 93.36%, val_loss: 3.071900, val_acc: 52.99%\n",
      "Epoch [3320]/[5000], train_loss: 0.073100, train_acc: 93.60%, val_loss: 2.868900, val_acc: 53.12%\n",
      "Epoch [3321]/[5000], train_loss: 0.048800, train_acc: 94.38%, val_loss: 2.726600, val_acc: 51.82%\n",
      "Epoch [3322]/[5000], train_loss: 0.071100, train_acc: 93.65%, val_loss: 2.980100, val_acc: 54.95%\n",
      "Epoch [3323]/[5000], train_loss: 0.057600, train_acc: 93.99%, val_loss: 2.839300, val_acc: 56.64%\n",
      "Epoch [3324]/[5000], train_loss: 0.048200, train_acc: 94.24%, val_loss: 2.960700, val_acc: 53.78%\n",
      "Epoch [3325]/[5000], train_loss: 0.040900, train_acc: 94.63%, val_loss: 2.841100, val_acc: 53.78%\n",
      "Epoch [3326]/[5000], train_loss: 0.044800, train_acc: 94.68%, val_loss: 2.920400, val_acc: 54.82%\n",
      "Epoch [3327]/[5000], train_loss: 0.038000, train_acc: 94.87%, val_loss: 2.813800, val_acc: 54.82%\n",
      "Epoch [3328]/[5000], train_loss: 0.032100, train_acc: 94.97%, val_loss: 2.762800, val_acc: 55.60%\n",
      "Epoch [3329]/[5000], train_loss: 0.027300, train_acc: 95.07%, val_loss: 3.059200, val_acc: 56.77%\n",
      "Epoch [3330]/[5000], train_loss: 0.040100, train_acc: 94.68%, val_loss: 2.579000, val_acc: 51.56%\n",
      "Epoch [3331]/[5000], train_loss: 0.042900, train_acc: 95.07%, val_loss: 2.691300, val_acc: 55.99%\n",
      "Epoch [3332]/[5000], train_loss: 0.038500, train_acc: 94.87%, val_loss: 2.852000, val_acc: 54.95%\n",
      "Epoch [3333]/[5000], train_loss: 0.029700, train_acc: 95.02%, val_loss: 3.101400, val_acc: 53.39%\n",
      "Epoch [3334]/[5000], train_loss: 0.043800, train_acc: 94.43%, val_loss: 2.579500, val_acc: 56.25%\n",
      "Epoch [3335]/[5000], train_loss: 0.037500, train_acc: 95.07%, val_loss: 3.141700, val_acc: 54.56%\n",
      "Epoch [3336]/[5000], train_loss: 0.040200, train_acc: 94.82%, val_loss: 3.215700, val_acc: 55.34%\n",
      "Epoch [3337]/[5000], train_loss: 0.037200, train_acc: 94.82%, val_loss: 2.777800, val_acc: 55.34%\n",
      "Epoch [3338]/[5000], train_loss: 0.036200, train_acc: 94.87%, val_loss: 2.796700, val_acc: 56.12%\n",
      "Epoch [3339]/[5000], train_loss: 0.029000, train_acc: 95.12%, val_loss: 2.812200, val_acc: 54.95%\n",
      "Epoch [3340]/[5000], train_loss: 0.030200, train_acc: 94.97%, val_loss: 3.263900, val_acc: 54.82%\n",
      "Epoch [3341]/[5000], train_loss: 0.027100, train_acc: 95.12%, val_loss: 2.737400, val_acc: 54.56%\n",
      "Epoch [3342]/[5000], train_loss: 0.021500, train_acc: 95.21%, val_loss: 3.398100, val_acc: 54.69%\n",
      "Epoch [3343]/[5000], train_loss: 0.029000, train_acc: 95.26%, val_loss: 2.784500, val_acc: 54.95%\n",
      "Epoch [3344]/[5000], train_loss: 0.024800, train_acc: 95.36%, val_loss: 3.023900, val_acc: 54.69%\n",
      "Epoch [3345]/[5000], train_loss: 0.019000, train_acc: 95.51%, val_loss: 2.865700, val_acc: 54.30%\n",
      "Epoch [3346]/[5000], train_loss: 0.020800, train_acc: 95.51%, val_loss: 2.703100, val_acc: 55.08%\n",
      "Epoch [3347]/[5000], train_loss: 0.020400, train_acc: 95.36%, val_loss: 2.951900, val_acc: 54.17%\n",
      "Epoch [3348]/[5000], train_loss: 0.023000, train_acc: 95.21%, val_loss: 2.760500, val_acc: 54.04%\n",
      "Epoch [3349]/[5000], train_loss: 0.026600, train_acc: 95.26%, val_loss: 2.838300, val_acc: 55.73%\n",
      "Epoch [3350]/[5000], train_loss: 0.017800, train_acc: 95.46%, val_loss: 3.271500, val_acc: 54.04%\n",
      "Epoch [3351]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 3.189900, val_acc: 54.30%\n",
      "Epoch [3352]/[5000], train_loss: 0.037000, train_acc: 94.73%, val_loss: 2.757900, val_acc: 54.95%\n",
      "Epoch [3353]/[5000], train_loss: 0.041100, train_acc: 94.82%, val_loss: 3.019300, val_acc: 56.77%\n",
      "Epoch [3354]/[5000], train_loss: 0.034200, train_acc: 94.92%, val_loss: 3.022400, val_acc: 57.16%\n",
      "Epoch [3355]/[5000], train_loss: 0.025200, train_acc: 95.12%, val_loss: 3.087300, val_acc: 53.91%\n",
      "Epoch [3356]/[5000], train_loss: 0.030100, train_acc: 95.12%, val_loss: 2.947500, val_acc: 53.91%\n",
      "Epoch [3357]/[5000], train_loss: 0.038100, train_acc: 94.92%, val_loss: 2.705600, val_acc: 52.73%\n",
      "Epoch [3358]/[5000], train_loss: 0.031000, train_acc: 94.92%, val_loss: 3.085900, val_acc: 51.82%\n",
      "Epoch [3359]/[5000], train_loss: 0.029400, train_acc: 95.07%, val_loss: 3.302700, val_acc: 52.47%\n",
      "Epoch [3360]/[5000], train_loss: 0.035700, train_acc: 94.87%, val_loss: 3.218500, val_acc: 51.56%\n",
      "Epoch [3361]/[5000], train_loss: 0.023000, train_acc: 95.07%, val_loss: 3.244800, val_acc: 48.44%\n",
      "Epoch [3362]/[5000], train_loss: 0.038200, train_acc: 94.63%, val_loss: 3.484200, val_acc: 52.60%\n",
      "Epoch [3363]/[5000], train_loss: 0.044200, train_acc: 94.63%, val_loss: 3.397900, val_acc: 54.43%\n",
      "Epoch [3364]/[5000], train_loss: 0.049700, train_acc: 94.43%, val_loss: 3.156600, val_acc: 55.47%\n",
      "Epoch [3365]/[5000], train_loss: 0.036800, train_acc: 94.68%, val_loss: 3.179000, val_acc: 56.12%\n",
      "Epoch [3366]/[5000], train_loss: 0.035000, train_acc: 95.02%, val_loss: 2.991300, val_acc: 54.95%\n",
      "Epoch [3367]/[5000], train_loss: 0.051500, train_acc: 94.34%, val_loss: 3.209500, val_acc: 53.26%\n",
      "Epoch [3368]/[5000], train_loss: 0.041900, train_acc: 94.78%, val_loss: 2.916500, val_acc: 53.78%\n",
      "Epoch [3369]/[5000], train_loss: 0.057600, train_acc: 93.85%, val_loss: 2.896100, val_acc: 52.86%\n",
      "Epoch [3370]/[5000], train_loss: 0.065700, train_acc: 94.14%, val_loss: 3.012200, val_acc: 53.26%\n",
      "Epoch [3371]/[5000], train_loss: 0.063700, train_acc: 94.29%, val_loss: 2.617800, val_acc: 55.86%\n",
      "Epoch [3372]/[5000], train_loss: 0.038200, train_acc: 94.43%, val_loss: 2.871500, val_acc: 56.90%\n",
      "Epoch [3373]/[5000], train_loss: 0.050300, train_acc: 94.63%, val_loss: 2.862600, val_acc: 54.56%\n",
      "Epoch [3374]/[5000], train_loss: 0.075400, train_acc: 93.51%, val_loss: 2.920600, val_acc: 53.52%\n",
      "Epoch [3375]/[5000], train_loss: 0.048500, train_acc: 94.34%, val_loss: 3.195500, val_acc: 51.30%\n",
      "Epoch [3376]/[5000], train_loss: 0.056800, train_acc: 94.19%, val_loss: 3.271900, val_acc: 52.73%\n",
      "Epoch [3377]/[5000], train_loss: 0.051900, train_acc: 94.82%, val_loss: 2.715500, val_acc: 54.04%\n",
      "Epoch [3378]/[5000], train_loss: 0.042600, train_acc: 94.58%, val_loss: 2.657200, val_acc: 55.73%\n",
      "Epoch [3379]/[5000], train_loss: 0.045000, train_acc: 94.73%, val_loss: 2.737400, val_acc: 53.91%\n",
      "Epoch [3380]/[5000], train_loss: 0.078700, train_acc: 93.60%, val_loss: 3.076400, val_acc: 53.26%\n",
      "Epoch [3381]/[5000], train_loss: 0.063100, train_acc: 93.80%, val_loss: 2.589700, val_acc: 52.99%\n",
      "Epoch [3382]/[5000], train_loss: 0.066200, train_acc: 93.75%, val_loss: 3.124500, val_acc: 53.12%\n",
      "Epoch [3383]/[5000], train_loss: 0.047900, train_acc: 94.38%, val_loss: 2.463800, val_acc: 55.08%\n",
      "Epoch [3384]/[5000], train_loss: 0.039700, train_acc: 94.63%, val_loss: 2.942200, val_acc: 51.82%\n",
      "Epoch [3385]/[5000], train_loss: 0.042200, train_acc: 94.87%, val_loss: 2.837600, val_acc: 53.65%\n",
      "Epoch [3386]/[5000], train_loss: 0.050700, train_acc: 93.99%, val_loss: 2.919300, val_acc: 54.43%\n",
      "Epoch [3387]/[5000], train_loss: 0.039000, train_acc: 94.73%, val_loss: 3.337600, val_acc: 55.86%\n",
      "Epoch [3388]/[5000], train_loss: 0.035100, train_acc: 94.87%, val_loss: 2.968600, val_acc: 55.47%\n",
      "Epoch [3389]/[5000], train_loss: 0.030700, train_acc: 95.07%, val_loss: 2.747800, val_acc: 55.86%\n",
      "Epoch [3390]/[5000], train_loss: 0.025900, train_acc: 95.17%, val_loss: 2.993100, val_acc: 53.39%\n",
      "Epoch [3391]/[5000], train_loss: 0.035400, train_acc: 94.78%, val_loss: 2.784000, val_acc: 55.86%\n",
      "Epoch [3392]/[5000], train_loss: 0.052900, train_acc: 94.58%, val_loss: 2.697600, val_acc: 53.52%\n",
      "Epoch [3393]/[5000], train_loss: 0.063900, train_acc: 94.04%, val_loss: 2.877600, val_acc: 54.17%\n",
      "Epoch [3394]/[5000], train_loss: 0.061700, train_acc: 94.19%, val_loss: 2.612500, val_acc: 53.52%\n",
      "Epoch [3395]/[5000], train_loss: 0.047200, train_acc: 94.09%, val_loss: 2.480700, val_acc: 54.69%\n",
      "Epoch [3396]/[5000], train_loss: 0.044100, train_acc: 94.78%, val_loss: 2.750600, val_acc: 53.65%\n",
      "Epoch [3397]/[5000], train_loss: 0.029700, train_acc: 94.97%, val_loss: 2.686500, val_acc: 55.99%\n",
      "Epoch [3398]/[5000], train_loss: 0.032800, train_acc: 95.41%, val_loss: 2.808900, val_acc: 54.04%\n",
      "Epoch [3399]/[5000], train_loss: 0.028300, train_acc: 95.07%, val_loss: 2.976600, val_acc: 54.95%\n",
      "Epoch [3400]/[5000], train_loss: 0.023100, train_acc: 95.36%, val_loss: 3.065600, val_acc: 53.52%\n",
      "Epoch [3401]/[5000], train_loss: 0.031300, train_acc: 94.97%, val_loss: 2.935300, val_acc: 57.16%\n",
      "Epoch [3402]/[5000], train_loss: 0.029700, train_acc: 95.21%, val_loss: 3.153900, val_acc: 56.38%\n",
      "Epoch [3403]/[5000], train_loss: 0.025600, train_acc: 95.36%, val_loss: 2.803600, val_acc: 53.12%\n",
      "Epoch [3404]/[5000], train_loss: 0.031400, train_acc: 95.02%, val_loss: 3.138400, val_acc: 55.73%\n",
      "Epoch [3405]/[5000], train_loss: 0.025400, train_acc: 95.36%, val_loss: 2.920700, val_acc: 55.08%\n",
      "Epoch [3406]/[5000], train_loss: 0.034200, train_acc: 94.87%, val_loss: 3.100800, val_acc: 54.95%\n",
      "Epoch [3407]/[5000], train_loss: 0.022000, train_acc: 95.31%, val_loss: 3.478500, val_acc: 53.12%\n",
      "Epoch [3408]/[5000], train_loss: 0.025500, train_acc: 95.36%, val_loss: 3.168600, val_acc: 55.86%\n",
      "Epoch [3409]/[5000], train_loss: 0.025000, train_acc: 95.21%, val_loss: 3.201900, val_acc: 55.60%\n",
      "Epoch [3410]/[5000], train_loss: 0.021900, train_acc: 95.41%, val_loss: 3.281600, val_acc: 56.25%\n",
      "Epoch [3411]/[5000], train_loss: 0.024200, train_acc: 95.31%, val_loss: 2.932600, val_acc: 54.82%\n",
      "Epoch [3412]/[5000], train_loss: 0.025000, train_acc: 95.21%, val_loss: 3.129500, val_acc: 53.39%\n",
      "Epoch [3413]/[5000], train_loss: 0.017400, train_acc: 95.61%, val_loss: 3.606600, val_acc: 54.95%\n",
      "Epoch [3414]/[5000], train_loss: 0.023500, train_acc: 95.41%, val_loss: 2.811700, val_acc: 54.95%\n",
      "Epoch [3415]/[5000], train_loss: 0.017400, train_acc: 95.65%, val_loss: 3.363200, val_acc: 55.47%\n",
      "Epoch [3416]/[5000], train_loss: 0.017100, train_acc: 95.56%, val_loss: 3.169100, val_acc: 55.47%\n",
      "Epoch [3417]/[5000], train_loss: 0.021500, train_acc: 95.51%, val_loss: 2.897400, val_acc: 56.25%\n",
      "Epoch [3418]/[5000], train_loss: 0.033200, train_acc: 94.82%, val_loss: 3.225100, val_acc: 55.08%\n",
      "Epoch [3419]/[5000], train_loss: 0.079700, train_acc: 93.95%, val_loss: 3.164600, val_acc: 53.26%\n",
      "Epoch [3420]/[5000], train_loss: 0.057900, train_acc: 93.85%, val_loss: 3.005800, val_acc: 56.64%\n",
      "Epoch [3421]/[5000], train_loss: 0.053200, train_acc: 94.48%, val_loss: 2.929400, val_acc: 51.30%\n",
      "Epoch [3422]/[5000], train_loss: 0.044400, train_acc: 94.43%, val_loss: 2.917800, val_acc: 53.91%\n",
      "Epoch [3423]/[5000], train_loss: 0.040700, train_acc: 94.73%, val_loss: 2.876100, val_acc: 55.99%\n",
      "Epoch [3424]/[5000], train_loss: 0.030200, train_acc: 95.31%, val_loss: 2.997900, val_acc: 54.69%\n",
      "Epoch [3425]/[5000], train_loss: 0.040800, train_acc: 94.78%, val_loss: 2.731200, val_acc: 55.08%\n",
      "Epoch [3426]/[5000], train_loss: 0.023700, train_acc: 95.31%, val_loss: 2.935200, val_acc: 55.21%\n",
      "Epoch [3427]/[5000], train_loss: 0.034400, train_acc: 94.73%, val_loss: 3.089900, val_acc: 53.91%\n",
      "Epoch [3428]/[5000], train_loss: 0.036300, train_acc: 94.73%, val_loss: 2.905300, val_acc: 54.30%\n",
      "Epoch [3429]/[5000], train_loss: 0.034800, train_acc: 95.02%, val_loss: 3.100800, val_acc: 54.56%\n",
      "Epoch [3430]/[5000], train_loss: 0.056700, train_acc: 94.38%, val_loss: 2.902300, val_acc: 56.38%\n",
      "Epoch [3431]/[5000], train_loss: 0.028800, train_acc: 95.02%, val_loss: 3.011600, val_acc: 54.04%\n",
      "Epoch [3432]/[5000], train_loss: 0.032900, train_acc: 94.78%, val_loss: 2.786000, val_acc: 57.81%\n",
      "Epoch [3433]/[5000], train_loss: 0.029700, train_acc: 94.97%, val_loss: 2.770800, val_acc: 54.82%\n",
      "Epoch [3434]/[5000], train_loss: 0.041200, train_acc: 94.82%, val_loss: 3.246500, val_acc: 54.04%\n",
      "Epoch [3435]/[5000], train_loss: 0.058800, train_acc: 94.04%, val_loss: 3.052700, val_acc: 51.69%\n",
      "Epoch [3436]/[5000], train_loss: 0.049600, train_acc: 94.78%, val_loss: 2.904500, val_acc: 55.73%\n",
      "Epoch [3437]/[5000], train_loss: 0.059900, train_acc: 94.19%, val_loss: 2.871800, val_acc: 52.86%\n",
      "Epoch [3438]/[5000], train_loss: 0.063900, train_acc: 93.85%, val_loss: 2.799400, val_acc: 55.47%\n",
      "Epoch [3439]/[5000], train_loss: 0.049900, train_acc: 94.38%, val_loss: 3.152000, val_acc: 54.17%\n",
      "Epoch [3440]/[5000], train_loss: 0.051100, train_acc: 94.14%, val_loss: 2.849200, val_acc: 55.34%\n",
      "Epoch [3441]/[5000], train_loss: 0.043700, train_acc: 94.53%, val_loss: 3.361700, val_acc: 53.78%\n",
      "Epoch [3442]/[5000], train_loss: 0.022100, train_acc: 95.31%, val_loss: 3.005100, val_acc: 55.21%\n",
      "Epoch [3443]/[5000], train_loss: 0.031800, train_acc: 95.17%, val_loss: 3.163400, val_acc: 55.73%\n",
      "Epoch [3444]/[5000], train_loss: 0.051900, train_acc: 94.34%, val_loss: 2.829700, val_acc: 53.91%\n",
      "Epoch [3445]/[5000], train_loss: 0.041600, train_acc: 94.68%, val_loss: 2.891800, val_acc: 55.60%\n",
      "Epoch [3446]/[5000], train_loss: 0.049000, train_acc: 94.58%, val_loss: 2.885600, val_acc: 53.39%\n",
      "Epoch [3447]/[5000], train_loss: 0.061800, train_acc: 94.09%, val_loss: 2.720200, val_acc: 55.73%\n",
      "Epoch [3448]/[5000], train_loss: 0.031300, train_acc: 95.31%, val_loss: 3.168200, val_acc: 55.73%\n",
      "Epoch [3449]/[5000], train_loss: 0.046400, train_acc: 94.68%, val_loss: 2.902000, val_acc: 55.08%\n",
      "Epoch [3450]/[5000], train_loss: 0.036200, train_acc: 94.92%, val_loss: 3.274300, val_acc: 52.60%\n",
      "Epoch [3451]/[5000], train_loss: 0.043700, train_acc: 94.92%, val_loss: 2.862600, val_acc: 56.38%\n",
      "Epoch [3452]/[5000], train_loss: 0.038100, train_acc: 94.43%, val_loss: 2.692800, val_acc: 55.08%\n",
      "Epoch [3453]/[5000], train_loss: 0.043000, train_acc: 94.73%, val_loss: 2.905800, val_acc: 56.64%\n",
      "Epoch [3454]/[5000], train_loss: 0.031600, train_acc: 94.82%, val_loss: 2.812600, val_acc: 55.73%\n",
      "Epoch [3455]/[5000], train_loss: 0.033500, train_acc: 94.87%, val_loss: 2.974500, val_acc: 55.34%\n",
      "Epoch [3456]/[5000], train_loss: 0.028700, train_acc: 94.97%, val_loss: 2.985100, val_acc: 52.47%\n",
      "Epoch [3457]/[5000], train_loss: 0.034800, train_acc: 95.12%, val_loss: 3.270100, val_acc: 55.34%\n",
      "Epoch [3458]/[5000], train_loss: 0.039100, train_acc: 94.82%, val_loss: 2.995000, val_acc: 52.86%\n",
      "Epoch [3459]/[5000], train_loss: 0.035600, train_acc: 95.12%, val_loss: 2.450100, val_acc: 53.26%\n",
      "Epoch [3460]/[5000], train_loss: 0.038600, train_acc: 94.78%, val_loss: 2.657700, val_acc: 55.99%\n",
      "Epoch [3461]/[5000], train_loss: 0.053400, train_acc: 94.38%, val_loss: 2.954700, val_acc: 54.04%\n",
      "Epoch [3462]/[5000], train_loss: 0.050200, train_acc: 94.29%, val_loss: 2.924200, val_acc: 53.39%\n",
      "Epoch [3463]/[5000], train_loss: 0.063300, train_acc: 93.95%, val_loss: 2.634800, val_acc: 55.08%\n",
      "Epoch [3464]/[5000], train_loss: 0.045300, train_acc: 94.92%, val_loss: 3.151100, val_acc: 54.82%\n",
      "Epoch [3465]/[5000], train_loss: 0.030700, train_acc: 94.87%, val_loss: 2.769800, val_acc: 51.30%\n",
      "Epoch [3466]/[5000], train_loss: 0.056800, train_acc: 94.53%, val_loss: 3.037100, val_acc: 52.99%\n",
      "Epoch [3467]/[5000], train_loss: 0.056900, train_acc: 94.34%, val_loss: 2.943600, val_acc: 54.56%\n",
      "Epoch [3468]/[5000], train_loss: 0.052600, train_acc: 94.29%, val_loss: 2.945600, val_acc: 54.95%\n",
      "Epoch [3469]/[5000], train_loss: 0.079500, train_acc: 93.60%, val_loss: 2.794900, val_acc: 55.34%\n",
      "Epoch [3470]/[5000], train_loss: 0.086300, train_acc: 93.51%, val_loss: 2.688700, val_acc: 52.34%\n",
      "Epoch [3471]/[5000], train_loss: 0.087000, train_acc: 93.12%, val_loss: 2.666800, val_acc: 52.21%\n",
      "Epoch [3472]/[5000], train_loss: 0.069100, train_acc: 93.75%, val_loss: 3.364200, val_acc: 55.99%\n",
      "Epoch [3473]/[5000], train_loss: 0.061800, train_acc: 93.60%, val_loss: 2.768500, val_acc: 54.69%\n",
      "Epoch [3474]/[5000], train_loss: 0.050000, train_acc: 94.53%, val_loss: 2.729500, val_acc: 53.39%\n",
      "Epoch [3475]/[5000], train_loss: 0.035100, train_acc: 95.07%, val_loss: 2.745100, val_acc: 53.52%\n",
      "Epoch [3476]/[5000], train_loss: 0.032800, train_acc: 94.92%, val_loss: 2.530500, val_acc: 53.78%\n",
      "Epoch [3477]/[5000], train_loss: 0.044300, train_acc: 94.38%, val_loss: 2.778000, val_acc: 52.86%\n",
      "Epoch [3478]/[5000], train_loss: 0.054400, train_acc: 94.63%, val_loss: 2.687400, val_acc: 54.69%\n",
      "Epoch [3479]/[5000], train_loss: 0.033800, train_acc: 95.12%, val_loss: 2.548500, val_acc: 55.86%\n",
      "Epoch [3480]/[5000], train_loss: 0.028700, train_acc: 94.87%, val_loss: 3.099100, val_acc: 55.21%\n",
      "Epoch [3481]/[5000], train_loss: 0.030000, train_acc: 95.41%, val_loss: 3.031800, val_acc: 51.56%\n",
      "Epoch [3482]/[5000], train_loss: 0.041300, train_acc: 94.68%, val_loss: 2.642400, val_acc: 54.95%\n",
      "Epoch [3483]/[5000], train_loss: 0.041300, train_acc: 94.43%, val_loss: 2.765800, val_acc: 53.52%\n",
      "Epoch [3484]/[5000], train_loss: 0.029700, train_acc: 95.02%, val_loss: 2.994200, val_acc: 54.56%\n",
      "Epoch [3485]/[5000], train_loss: 0.033400, train_acc: 94.97%, val_loss: 2.810000, val_acc: 55.47%\n",
      "Epoch [3486]/[5000], train_loss: 0.030400, train_acc: 95.02%, val_loss: 2.787900, val_acc: 57.03%\n",
      "Epoch [3487]/[5000], train_loss: 0.029500, train_acc: 95.46%, val_loss: 2.626400, val_acc: 57.29%\n",
      "Epoch [3488]/[5000], train_loss: 0.025100, train_acc: 95.31%, val_loss: 2.691700, val_acc: 54.56%\n",
      "Epoch [3489]/[5000], train_loss: 0.041300, train_acc: 94.92%, val_loss: 2.945800, val_acc: 55.34%\n",
      "Epoch [3490]/[5000], train_loss: 0.035900, train_acc: 94.58%, val_loss: 2.658300, val_acc: 55.47%\n",
      "Epoch [3491]/[5000], train_loss: 0.027700, train_acc: 94.92%, val_loss: 2.930200, val_acc: 54.17%\n",
      "Epoch [3492]/[5000], train_loss: 0.031400, train_acc: 94.87%, val_loss: 2.751100, val_acc: 54.17%\n",
      "Epoch [3493]/[5000], train_loss: 0.026300, train_acc: 95.41%, val_loss: 2.956500, val_acc: 54.95%\n",
      "Epoch [3494]/[5000], train_loss: 0.029600, train_acc: 95.36%, val_loss: 2.927700, val_acc: 56.90%\n",
      "Epoch [3495]/[5000], train_loss: 0.039000, train_acc: 94.92%, val_loss: 2.674100, val_acc: 55.86%\n",
      "Epoch [3496]/[5000], train_loss: 0.029100, train_acc: 94.87%, val_loss: 2.631700, val_acc: 54.17%\n",
      "Epoch [3497]/[5000], train_loss: 0.030000, train_acc: 94.97%, val_loss: 3.127300, val_acc: 53.12%\n",
      "Epoch [3498]/[5000], train_loss: 0.028300, train_acc: 95.36%, val_loss: 2.760900, val_acc: 54.17%\n",
      "Epoch [3499]/[5000], train_loss: 0.025700, train_acc: 95.12%, val_loss: 2.771000, val_acc: 53.52%\n",
      "Epoch [3500]/[5000], train_loss: 0.037400, train_acc: 95.02%, val_loss: 2.680300, val_acc: 57.16%\n",
      "Epoch [3501]/[5000], train_loss: 0.031600, train_acc: 94.97%, val_loss: 2.613100, val_acc: 55.08%\n",
      "Epoch [3502]/[5000], train_loss: 0.029100, train_acc: 95.12%, val_loss: 2.987800, val_acc: 54.95%\n",
      "Epoch [3503]/[5000], train_loss: 0.022500, train_acc: 95.36%, val_loss: 2.716700, val_acc: 54.56%\n",
      "Epoch [3504]/[5000], train_loss: 0.040700, train_acc: 94.73%, val_loss: 3.239900, val_acc: 55.08%\n",
      "Epoch [3505]/[5000], train_loss: 0.038000, train_acc: 95.07%, val_loss: 3.015400, val_acc: 55.34%\n",
      "Epoch [3506]/[5000], train_loss: 0.061300, train_acc: 94.04%, val_loss: 3.072600, val_acc: 53.39%\n",
      "Epoch [3507]/[5000], train_loss: 0.043500, train_acc: 94.53%, val_loss: 2.836700, val_acc: 56.77%\n",
      "Epoch [3508]/[5000], train_loss: 0.044400, train_acc: 94.73%, val_loss: 2.982700, val_acc: 50.00%\n",
      "Epoch [3509]/[5000], train_loss: 0.040200, train_acc: 94.63%, val_loss: 2.839200, val_acc: 53.78%\n",
      "Epoch [3510]/[5000], train_loss: 0.051200, train_acc: 94.24%, val_loss: 2.965100, val_acc: 57.03%\n",
      "Epoch [3511]/[5000], train_loss: 0.045000, train_acc: 94.63%, val_loss: 2.823800, val_acc: 54.04%\n",
      "Epoch [3512]/[5000], train_loss: 0.059300, train_acc: 94.34%, val_loss: 2.810300, val_acc: 55.60%\n",
      "Epoch [3513]/[5000], train_loss: 0.063900, train_acc: 94.04%, val_loss: 2.842800, val_acc: 53.52%\n",
      "Epoch [3514]/[5000], train_loss: 0.097200, train_acc: 93.07%, val_loss: 2.706200, val_acc: 54.95%\n",
      "Epoch [3515]/[5000], train_loss: 0.063000, train_acc: 94.04%, val_loss: 3.078500, val_acc: 55.73%\n",
      "Epoch [3516]/[5000], train_loss: 0.044600, train_acc: 94.34%, val_loss: 3.058900, val_acc: 53.65%\n",
      "Epoch [3517]/[5000], train_loss: 0.048600, train_acc: 94.53%, val_loss: 3.118300, val_acc: 54.69%\n",
      "Epoch [3518]/[5000], train_loss: 0.044200, train_acc: 94.48%, val_loss: 3.095000, val_acc: 53.26%\n",
      "Epoch [3519]/[5000], train_loss: 0.051000, train_acc: 94.14%, val_loss: 2.843400, val_acc: 54.04%\n",
      "Epoch [3520]/[5000], train_loss: 0.034700, train_acc: 94.73%, val_loss: 2.969200, val_acc: 52.34%\n",
      "Epoch [3521]/[5000], train_loss: 0.043200, train_acc: 94.58%, val_loss: 2.519800, val_acc: 56.38%\n",
      "Epoch [3522]/[5000], train_loss: 0.040900, train_acc: 94.82%, val_loss: 2.795300, val_acc: 55.47%\n",
      "Epoch [3523]/[5000], train_loss: 0.048900, train_acc: 94.53%, val_loss: 2.609300, val_acc: 52.34%\n",
      "Epoch [3524]/[5000], train_loss: 0.038300, train_acc: 94.78%, val_loss: 3.306700, val_acc: 52.21%\n",
      "Epoch [3525]/[5000], train_loss: 0.028200, train_acc: 95.07%, val_loss: 3.133200, val_acc: 54.04%\n",
      "Epoch [3526]/[5000], train_loss: 0.035900, train_acc: 95.02%, val_loss: 3.265700, val_acc: 50.91%\n",
      "Epoch [3527]/[5000], train_loss: 0.062400, train_acc: 93.95%, val_loss: 3.083500, val_acc: 54.30%\n",
      "Epoch [3528]/[5000], train_loss: 0.037300, train_acc: 94.78%, val_loss: 2.786800, val_acc: 54.56%\n",
      "Epoch [3529]/[5000], train_loss: 0.037200, train_acc: 94.82%, val_loss: 3.066000, val_acc: 55.60%\n",
      "Epoch [3530]/[5000], train_loss: 0.040900, train_acc: 94.58%, val_loss: 2.614500, val_acc: 54.30%\n",
      "Epoch [3531]/[5000], train_loss: 0.048200, train_acc: 94.58%, val_loss: 3.013900, val_acc: 54.17%\n",
      "Epoch [3532]/[5000], train_loss: 0.059100, train_acc: 94.58%, val_loss: 3.090400, val_acc: 55.73%\n",
      "Epoch [3533]/[5000], train_loss: 0.039600, train_acc: 94.87%, val_loss: 3.191700, val_acc: 55.34%\n",
      "Epoch [3534]/[5000], train_loss: 0.052000, train_acc: 94.53%, val_loss: 2.658300, val_acc: 54.69%\n",
      "Epoch [3535]/[5000], train_loss: 0.057900, train_acc: 94.34%, val_loss: 2.628400, val_acc: 56.90%\n",
      "Epoch [3536]/[5000], train_loss: 0.053700, train_acc: 94.14%, val_loss: 2.710900, val_acc: 54.04%\n",
      "Epoch [3537]/[5000], train_loss: 0.062100, train_acc: 94.04%, val_loss: 2.763000, val_acc: 52.99%\n",
      "Epoch [3538]/[5000], train_loss: 0.059500, train_acc: 93.99%, val_loss: 2.796200, val_acc: 48.70%\n",
      "Epoch [3539]/[5000], train_loss: 0.053500, train_acc: 94.19%, val_loss: 2.754000, val_acc: 54.17%\n",
      "Epoch [3540]/[5000], train_loss: 0.044900, train_acc: 94.38%, val_loss: 2.556100, val_acc: 54.56%\n",
      "Epoch [3541]/[5000], train_loss: 0.056600, train_acc: 94.38%, val_loss: 2.820400, val_acc: 56.51%\n",
      "Epoch [3542]/[5000], train_loss: 0.065800, train_acc: 94.09%, val_loss: 2.759200, val_acc: 56.51%\n",
      "Epoch [3543]/[5000], train_loss: 0.043700, train_acc: 94.78%, val_loss: 2.878800, val_acc: 50.91%\n",
      "Epoch [3544]/[5000], train_loss: 0.044500, train_acc: 94.38%, val_loss: 2.805200, val_acc: 56.51%\n",
      "Epoch [3545]/[5000], train_loss: 0.042700, train_acc: 94.82%, val_loss: 2.737300, val_acc: 53.91%\n",
      "Epoch [3546]/[5000], train_loss: 0.047400, train_acc: 94.24%, val_loss: 2.531000, val_acc: 54.69%\n",
      "Epoch [3547]/[5000], train_loss: 0.067900, train_acc: 94.38%, val_loss: 2.773400, val_acc: 55.60%\n",
      "Epoch [3548]/[5000], train_loss: 0.049100, train_acc: 94.53%, val_loss: 3.046900, val_acc: 50.65%\n",
      "Epoch [3549]/[5000], train_loss: 0.071900, train_acc: 93.60%, val_loss: 2.430700, val_acc: 54.04%\n",
      "Epoch [3550]/[5000], train_loss: 0.069500, train_acc: 93.85%, val_loss: 2.818800, val_acc: 52.99%\n",
      "Epoch [3551]/[5000], train_loss: 0.052700, train_acc: 94.09%, val_loss: 2.787700, val_acc: 52.86%\n",
      "Epoch [3552]/[5000], train_loss: 0.056900, train_acc: 94.38%, val_loss: 2.938000, val_acc: 53.65%\n",
      "Epoch [3553]/[5000], train_loss: 0.041500, train_acc: 94.82%, val_loss: 2.693000, val_acc: 55.73%\n",
      "Epoch [3554]/[5000], train_loss: 0.053900, train_acc: 94.29%, val_loss: 2.697100, val_acc: 52.60%\n",
      "Epoch [3555]/[5000], train_loss: 0.049900, train_acc: 94.63%, val_loss: 2.740900, val_acc: 56.12%\n",
      "Epoch [3556]/[5000], train_loss: 0.034000, train_acc: 94.87%, val_loss: 2.473200, val_acc: 54.04%\n",
      "Epoch [3557]/[5000], train_loss: 0.023400, train_acc: 95.56%, val_loss: 2.498200, val_acc: 52.73%\n",
      "Epoch [3558]/[5000], train_loss: 0.031700, train_acc: 95.07%, val_loss: 2.708600, val_acc: 55.34%\n",
      "Epoch [3559]/[5000], train_loss: 0.029700, train_acc: 94.97%, val_loss: 2.749300, val_acc: 53.39%\n",
      "Epoch [3560]/[5000], train_loss: 0.033900, train_acc: 94.82%, val_loss: 2.786200, val_acc: 53.91%\n",
      "Epoch [3561]/[5000], train_loss: 0.020900, train_acc: 95.51%, val_loss: 2.594600, val_acc: 55.86%\n",
      "Epoch [3562]/[5000], train_loss: 0.030400, train_acc: 95.21%, val_loss: 3.083300, val_acc: 55.47%\n",
      "Epoch [3563]/[5000], train_loss: 0.027800, train_acc: 95.31%, val_loss: 2.549800, val_acc: 53.65%\n",
      "Epoch [3564]/[5000], train_loss: 0.038600, train_acc: 95.12%, val_loss: 2.541300, val_acc: 54.95%\n",
      "Epoch [3565]/[5000], train_loss: 0.023800, train_acc: 95.51%, val_loss: 2.642400, val_acc: 52.99%\n",
      "Epoch [3566]/[5000], train_loss: 0.024700, train_acc: 95.21%, val_loss: 2.749400, val_acc: 54.95%\n",
      "Epoch [3567]/[5000], train_loss: 0.027900, train_acc: 95.36%, val_loss: 2.634400, val_acc: 56.12%\n",
      "Epoch [3568]/[5000], train_loss: 0.034100, train_acc: 94.97%, val_loss: 3.083800, val_acc: 54.30%\n",
      "Epoch [3569]/[5000], train_loss: 0.038200, train_acc: 94.92%, val_loss: 2.654400, val_acc: 54.56%\n",
      "Epoch [3570]/[5000], train_loss: 0.030900, train_acc: 95.26%, val_loss: 2.848400, val_acc: 52.86%\n",
      "Epoch [3571]/[5000], train_loss: 0.032600, train_acc: 95.02%, val_loss: 2.765600, val_acc: 55.34%\n",
      "Epoch [3572]/[5000], train_loss: 0.022800, train_acc: 95.41%, val_loss: 2.758100, val_acc: 54.04%\n",
      "Epoch [3573]/[5000], train_loss: 0.022700, train_acc: 95.61%, val_loss: 3.066400, val_acc: 55.86%\n",
      "Epoch [3574]/[5000], train_loss: 0.029400, train_acc: 95.17%, val_loss: 3.530700, val_acc: 55.73%\n",
      "Epoch [3575]/[5000], train_loss: 0.027900, train_acc: 95.07%, val_loss: 3.022900, val_acc: 54.95%\n",
      "Epoch [3576]/[5000], train_loss: 0.029200, train_acc: 94.92%, val_loss: 3.088000, val_acc: 53.39%\n",
      "Epoch [3577]/[5000], train_loss: 0.042000, train_acc: 95.02%, val_loss: 3.295000, val_acc: 55.34%\n",
      "Epoch [3578]/[5000], train_loss: 0.032100, train_acc: 95.07%, val_loss: 2.694800, val_acc: 55.34%\n",
      "Epoch [3579]/[5000], train_loss: 0.036400, train_acc: 94.82%, val_loss: 2.754800, val_acc: 50.39%\n",
      "Epoch [3580]/[5000], train_loss: 0.022500, train_acc: 95.51%, val_loss: 3.032800, val_acc: 53.39%\n",
      "Epoch [3581]/[5000], train_loss: 0.025900, train_acc: 95.41%, val_loss: 2.909300, val_acc: 56.38%\n",
      "Epoch [3582]/[5000], train_loss: 0.027700, train_acc: 95.12%, val_loss: 2.733800, val_acc: 55.99%\n",
      "Epoch [3583]/[5000], train_loss: 0.018900, train_acc: 95.41%, val_loss: 3.162100, val_acc: 54.82%\n",
      "Epoch [3584]/[5000], train_loss: 0.027100, train_acc: 95.12%, val_loss: 2.682800, val_acc: 56.51%\n",
      "Epoch [3585]/[5000], train_loss: 0.026700, train_acc: 95.36%, val_loss: 2.987300, val_acc: 54.69%\n",
      "Epoch [3586]/[5000], train_loss: 0.020400, train_acc: 95.36%, val_loss: 3.208800, val_acc: 57.94%\n",
      "Epoch [3587]/[5000], train_loss: 0.024700, train_acc: 95.21%, val_loss: 3.005300, val_acc: 54.17%\n",
      "Epoch [3588]/[5000], train_loss: 0.029500, train_acc: 94.97%, val_loss: 3.262000, val_acc: 55.47%\n",
      "Epoch [3589]/[5000], train_loss: 0.047000, train_acc: 94.24%, val_loss: 2.916100, val_acc: 53.91%\n",
      "Epoch [3590]/[5000], train_loss: 0.033200, train_acc: 94.92%, val_loss: 2.818500, val_acc: 56.77%\n",
      "Epoch [3591]/[5000], train_loss: 0.027300, train_acc: 95.07%, val_loss: 3.227000, val_acc: 56.25%\n",
      "Epoch [3592]/[5000], train_loss: 0.022200, train_acc: 95.21%, val_loss: 3.406300, val_acc: 54.17%\n",
      "Epoch [3593]/[5000], train_loss: 0.020200, train_acc: 95.46%, val_loss: 3.192400, val_acc: 55.34%\n",
      "Epoch [3594]/[5000], train_loss: 0.060500, train_acc: 94.24%, val_loss: 3.548400, val_acc: 55.21%\n",
      "Epoch [3595]/[5000], train_loss: 0.039100, train_acc: 94.43%, val_loss: 3.322800, val_acc: 54.56%\n",
      "Epoch [3596]/[5000], train_loss: 0.025900, train_acc: 95.02%, val_loss: 2.792700, val_acc: 52.08%\n",
      "Epoch [3597]/[5000], train_loss: 0.053800, train_acc: 94.48%, val_loss: 2.768700, val_acc: 54.43%\n",
      "Epoch [3598]/[5000], train_loss: 0.072400, train_acc: 93.70%, val_loss: 3.152900, val_acc: 55.34%\n",
      "Epoch [3599]/[5000], train_loss: 0.058900, train_acc: 94.24%, val_loss: 2.730700, val_acc: 51.30%\n",
      "Epoch [3600]/[5000], train_loss: 0.051600, train_acc: 94.29%, val_loss: 3.086400, val_acc: 51.56%\n",
      "Epoch [3601]/[5000], train_loss: 0.069900, train_acc: 93.65%, val_loss: 2.883800, val_acc: 54.04%\n",
      "Epoch [3602]/[5000], train_loss: 0.038500, train_acc: 94.78%, val_loss: 2.843400, val_acc: 52.86%\n",
      "Epoch [3603]/[5000], train_loss: 0.027300, train_acc: 95.07%, val_loss: 3.090300, val_acc: 53.78%\n",
      "Epoch [3604]/[5000], train_loss: 0.035000, train_acc: 94.68%, val_loss: 2.827600, val_acc: 53.91%\n",
      "Epoch [3605]/[5000], train_loss: 0.029600, train_acc: 95.21%, val_loss: 3.038500, val_acc: 55.08%\n",
      "Epoch [3606]/[5000], train_loss: 0.023600, train_acc: 95.31%, val_loss: 3.234600, val_acc: 54.82%\n",
      "Epoch [3607]/[5000], train_loss: 0.039500, train_acc: 95.07%, val_loss: 2.852500, val_acc: 55.34%\n",
      "Epoch [3608]/[5000], train_loss: 0.031700, train_acc: 95.41%, val_loss: 2.982000, val_acc: 55.21%\n",
      "Epoch [3609]/[5000], train_loss: 0.026800, train_acc: 94.97%, val_loss: 3.508500, val_acc: 51.69%\n",
      "Epoch [3610]/[5000], train_loss: 0.028700, train_acc: 95.17%, val_loss: 2.673600, val_acc: 55.99%\n",
      "Epoch [3611]/[5000], train_loss: 0.029700, train_acc: 95.17%, val_loss: 3.006600, val_acc: 55.73%\n",
      "Epoch [3612]/[5000], train_loss: 0.032200, train_acc: 95.07%, val_loss: 3.117800, val_acc: 51.43%\n",
      "Epoch [3613]/[5000], train_loss: 0.020300, train_acc: 95.31%, val_loss: 2.699100, val_acc: 53.39%\n",
      "Epoch [3614]/[5000], train_loss: 0.019100, train_acc: 95.46%, val_loss: 3.254300, val_acc: 55.99%\n",
      "Epoch [3615]/[5000], train_loss: 0.024500, train_acc: 95.26%, val_loss: 2.899100, val_acc: 56.64%\n",
      "Epoch [3616]/[5000], train_loss: 0.030500, train_acc: 94.97%, val_loss: 2.907000, val_acc: 52.99%\n",
      "Epoch [3617]/[5000], train_loss: 0.030700, train_acc: 94.97%, val_loss: 2.926400, val_acc: 52.86%\n",
      "Epoch [3618]/[5000], train_loss: 0.017500, train_acc: 95.41%, val_loss: 2.986600, val_acc: 55.47%\n",
      "Epoch [3619]/[5000], train_loss: 0.029000, train_acc: 95.12%, val_loss: 3.015900, val_acc: 50.26%\n",
      "Epoch [3620]/[5000], train_loss: 0.031500, train_acc: 95.07%, val_loss: 2.883200, val_acc: 55.34%\n",
      "Epoch [3621]/[5000], train_loss: 0.029200, train_acc: 95.07%, val_loss: 3.067800, val_acc: 56.51%\n",
      "Epoch [3622]/[5000], train_loss: 0.027900, train_acc: 95.21%, val_loss: 3.369700, val_acc: 55.99%\n",
      "Epoch [3623]/[5000], train_loss: 0.031400, train_acc: 94.87%, val_loss: 3.002000, val_acc: 54.17%\n",
      "Epoch [3624]/[5000], train_loss: 0.044100, train_acc: 94.58%, val_loss: 3.603200, val_acc: 52.86%\n",
      "Epoch [3625]/[5000], train_loss: 0.058600, train_acc: 94.24%, val_loss: 3.384000, val_acc: 54.69%\n",
      "Epoch [3626]/[5000], train_loss: 0.063700, train_acc: 93.95%, val_loss: 3.358600, val_acc: 52.08%\n",
      "Epoch [3627]/[5000], train_loss: 0.069500, train_acc: 93.46%, val_loss: 3.540300, val_acc: 54.56%\n",
      "Epoch [3628]/[5000], train_loss: 0.066500, train_acc: 93.90%, val_loss: 2.751900, val_acc: 52.21%\n",
      "Epoch [3629]/[5000], train_loss: 0.056500, train_acc: 94.14%, val_loss: 3.266700, val_acc: 55.34%\n",
      "Epoch [3630]/[5000], train_loss: 0.044200, train_acc: 94.68%, val_loss: 2.796800, val_acc: 54.69%\n",
      "Epoch [3631]/[5000], train_loss: 0.057300, train_acc: 94.14%, val_loss: 2.632100, val_acc: 53.65%\n",
      "Epoch [3632]/[5000], train_loss: 0.045200, train_acc: 94.58%, val_loss: 2.892700, val_acc: 55.08%\n",
      "Epoch [3633]/[5000], train_loss: 0.033400, train_acc: 94.82%, val_loss: 3.198800, val_acc: 53.52%\n",
      "Epoch [3634]/[5000], train_loss: 0.033200, train_acc: 95.02%, val_loss: 2.915200, val_acc: 54.69%\n",
      "Epoch [3635]/[5000], train_loss: 0.040100, train_acc: 94.73%, val_loss: 2.993500, val_acc: 54.43%\n",
      "Epoch [3636]/[5000], train_loss: 0.027100, train_acc: 94.92%, val_loss: 2.896300, val_acc: 54.43%\n",
      "Epoch [3637]/[5000], train_loss: 0.031700, train_acc: 94.97%, val_loss: 3.018600, val_acc: 57.81%\n",
      "Epoch [3638]/[5000], train_loss: 0.027700, train_acc: 95.17%, val_loss: 3.115100, val_acc: 55.60%\n",
      "Epoch [3639]/[5000], train_loss: 0.042100, train_acc: 94.68%, val_loss: 2.641400, val_acc: 55.60%\n",
      "Epoch [3640]/[5000], train_loss: 0.050700, train_acc: 94.38%, val_loss: 2.970000, val_acc: 53.78%\n",
      "Epoch [3641]/[5000], train_loss: 0.079000, train_acc: 93.02%, val_loss: 2.694100, val_acc: 53.26%\n",
      "Epoch [3642]/[5000], train_loss: 0.059800, train_acc: 94.09%, val_loss: 3.135900, val_acc: 55.34%\n",
      "Epoch [3643]/[5000], train_loss: 0.036100, train_acc: 94.68%, val_loss: 3.162500, val_acc: 52.73%\n",
      "Epoch [3644]/[5000], train_loss: 0.026300, train_acc: 95.41%, val_loss: 2.884900, val_acc: 53.91%\n",
      "Epoch [3645]/[5000], train_loss: 0.026900, train_acc: 95.41%, val_loss: 3.114400, val_acc: 55.08%\n",
      "Epoch [3646]/[5000], train_loss: 0.027300, train_acc: 95.02%, val_loss: 3.176600, val_acc: 54.43%\n",
      "Epoch [3647]/[5000], train_loss: 0.032000, train_acc: 95.12%, val_loss: 2.551700, val_acc: 54.17%\n",
      "Epoch [3648]/[5000], train_loss: 0.027000, train_acc: 95.07%, val_loss: 3.491300, val_acc: 53.52%\n",
      "Epoch [3649]/[5000], train_loss: 0.038300, train_acc: 94.63%, val_loss: 2.960600, val_acc: 54.69%\n",
      "Epoch [3650]/[5000], train_loss: 0.043100, train_acc: 94.58%, val_loss: 2.789500, val_acc: 52.34%\n",
      "Epoch [3651]/[5000], train_loss: 0.042600, train_acc: 94.78%, val_loss: 2.772700, val_acc: 56.77%\n",
      "Epoch [3652]/[5000], train_loss: 0.029900, train_acc: 95.31%, val_loss: 3.027500, val_acc: 53.26%\n",
      "Epoch [3653]/[5000], train_loss: 0.044200, train_acc: 94.92%, val_loss: 3.012900, val_acc: 53.52%\n",
      "Epoch [3654]/[5000], train_loss: 0.041300, train_acc: 94.78%, val_loss: 2.811500, val_acc: 54.43%\n",
      "Epoch [3655]/[5000], train_loss: 0.031600, train_acc: 95.21%, val_loss: 3.124500, val_acc: 55.60%\n",
      "Epoch [3656]/[5000], train_loss: 0.043800, train_acc: 94.48%, val_loss: 2.891800, val_acc: 50.39%\n",
      "Epoch [3657]/[5000], train_loss: 0.047500, train_acc: 94.04%, val_loss: 3.141500, val_acc: 56.51%\n",
      "Epoch [3658]/[5000], train_loss: 0.035500, train_acc: 95.21%, val_loss: 2.876200, val_acc: 53.39%\n",
      "Epoch [3659]/[5000], train_loss: 0.046600, train_acc: 94.87%, val_loss: 3.053600, val_acc: 53.39%\n",
      "Epoch [3660]/[5000], train_loss: 0.046700, train_acc: 94.82%, val_loss: 2.946200, val_acc: 57.68%\n",
      "Epoch [3661]/[5000], train_loss: 0.043800, train_acc: 94.63%, val_loss: 2.990100, val_acc: 53.78%\n",
      "Epoch [3662]/[5000], train_loss: 0.049000, train_acc: 94.34%, val_loss: 3.086900, val_acc: 55.08%\n",
      "Epoch [3663]/[5000], train_loss: 0.038400, train_acc: 94.58%, val_loss: 2.793000, val_acc: 55.21%\n",
      "Epoch [3664]/[5000], train_loss: 0.035600, train_acc: 94.63%, val_loss: 2.858700, val_acc: 55.86%\n",
      "Epoch [3665]/[5000], train_loss: 0.068100, train_acc: 94.19%, val_loss: 3.038600, val_acc: 54.17%\n",
      "Epoch [3666]/[5000], train_loss: 0.068700, train_acc: 93.80%, val_loss: 3.008700, val_acc: 53.65%\n",
      "Epoch [3667]/[5000], train_loss: 0.070100, train_acc: 93.70%, val_loss: 2.972000, val_acc: 52.47%\n",
      "Epoch [3668]/[5000], train_loss: 0.035700, train_acc: 94.82%, val_loss: 3.138200, val_acc: 54.30%\n",
      "Epoch [3669]/[5000], train_loss: 0.039500, train_acc: 95.02%, val_loss: 2.949300, val_acc: 54.43%\n",
      "Epoch [3670]/[5000], train_loss: 0.040600, train_acc: 94.68%, val_loss: 2.816900, val_acc: 53.65%\n",
      "Epoch [3671]/[5000], train_loss: 0.027200, train_acc: 95.02%, val_loss: 2.862600, val_acc: 53.65%\n",
      "Epoch [3672]/[5000], train_loss: 0.032000, train_acc: 94.82%, val_loss: 3.215600, val_acc: 54.69%\n",
      "Epoch [3673]/[5000], train_loss: 0.049600, train_acc: 94.09%, val_loss: 3.196100, val_acc: 54.04%\n",
      "Epoch [3674]/[5000], train_loss: 0.027700, train_acc: 95.02%, val_loss: 2.805800, val_acc: 53.91%\n",
      "Epoch [3675]/[5000], train_loss: 0.037400, train_acc: 94.68%, val_loss: 2.881800, val_acc: 53.52%\n",
      "Epoch [3676]/[5000], train_loss: 0.040600, train_acc: 94.73%, val_loss: 2.731100, val_acc: 56.25%\n",
      "Epoch [3677]/[5000], train_loss: 0.040300, train_acc: 94.82%, val_loss: 2.466400, val_acc: 56.90%\n",
      "Epoch [3678]/[5000], train_loss: 0.034900, train_acc: 94.82%, val_loss: 3.027600, val_acc: 56.38%\n",
      "Epoch [3679]/[5000], train_loss: 0.037600, train_acc: 94.73%, val_loss: 2.933400, val_acc: 53.65%\n",
      "Epoch [3680]/[5000], train_loss: 0.033200, train_acc: 94.97%, val_loss: 2.985200, val_acc: 55.34%\n",
      "Epoch [3681]/[5000], train_loss: 0.069200, train_acc: 94.29%, val_loss: 3.036900, val_acc: 53.91%\n",
      "Epoch [3682]/[5000], train_loss: 0.035300, train_acc: 94.97%, val_loss: 2.901400, val_acc: 51.69%\n",
      "Epoch [3683]/[5000], train_loss: 0.049900, train_acc: 94.58%, val_loss: 2.718500, val_acc: 56.38%\n",
      "Epoch [3684]/[5000], train_loss: 0.031300, train_acc: 94.97%, val_loss: 3.095000, val_acc: 53.12%\n",
      "Epoch [3685]/[5000], train_loss: 0.044700, train_acc: 94.63%, val_loss: 3.116800, val_acc: 54.30%\n",
      "Epoch [3686]/[5000], train_loss: 0.037500, train_acc: 95.07%, val_loss: 2.987000, val_acc: 56.12%\n",
      "Epoch [3687]/[5000], train_loss: 0.027600, train_acc: 95.36%, val_loss: 2.823500, val_acc: 56.38%\n",
      "Epoch [3688]/[5000], train_loss: 0.027200, train_acc: 95.07%, val_loss: 3.112200, val_acc: 54.95%\n",
      "Epoch [3689]/[5000], train_loss: 0.032700, train_acc: 94.92%, val_loss: 2.796200, val_acc: 57.29%\n",
      "Epoch [3690]/[5000], train_loss: 0.038800, train_acc: 94.92%, val_loss: 3.276700, val_acc: 55.08%\n",
      "Epoch [3691]/[5000], train_loss: 0.030700, train_acc: 95.07%, val_loss: 3.015600, val_acc: 57.29%\n",
      "Epoch [3692]/[5000], train_loss: 0.032800, train_acc: 95.07%, val_loss: 3.016700, val_acc: 53.52%\n",
      "Epoch [3693]/[5000], train_loss: 0.027500, train_acc: 95.12%, val_loss: 3.123300, val_acc: 56.51%\n",
      "Epoch [3694]/[5000], train_loss: 0.023200, train_acc: 95.26%, val_loss: 2.788900, val_acc: 58.33%\n",
      "Epoch [3695]/[5000], train_loss: 0.020600, train_acc: 95.31%, val_loss: 2.496200, val_acc: 56.38%\n",
      "Epoch [3696]/[5000], train_loss: 0.015600, train_acc: 95.75%, val_loss: 2.667700, val_acc: 55.73%\n",
      "Epoch [3697]/[5000], train_loss: 0.024100, train_acc: 95.31%, val_loss: 2.815600, val_acc: 56.25%\n",
      "Epoch [3698]/[5000], train_loss: 0.025100, train_acc: 95.07%, val_loss: 4.210900, val_acc: 54.30%\n",
      "Epoch [3699]/[5000], train_loss: 0.028100, train_acc: 95.21%, val_loss: 3.074900, val_acc: 52.21%\n",
      "Epoch [3700]/[5000], train_loss: 0.019000, train_acc: 95.31%, val_loss: 3.261000, val_acc: 55.86%\n",
      "Epoch [3701]/[5000], train_loss: 0.044800, train_acc: 94.68%, val_loss: 3.269100, val_acc: 55.21%\n",
      "Epoch [3702]/[5000], train_loss: 0.051800, train_acc: 95.07%, val_loss: 3.254200, val_acc: 54.04%\n",
      "Epoch [3703]/[5000], train_loss: 0.047500, train_acc: 94.43%, val_loss: 3.219600, val_acc: 52.86%\n",
      "Epoch [3704]/[5000], train_loss: 0.040300, train_acc: 94.82%, val_loss: 2.964400, val_acc: 54.04%\n",
      "Epoch [3705]/[5000], train_loss: 0.028200, train_acc: 95.12%, val_loss: 2.994700, val_acc: 54.17%\n",
      "Epoch [3706]/[5000], train_loss: 0.037700, train_acc: 94.73%, val_loss: 3.683800, val_acc: 53.26%\n",
      "Epoch [3707]/[5000], train_loss: 0.039200, train_acc: 94.43%, val_loss: 3.036100, val_acc: 51.82%\n",
      "Epoch [3708]/[5000], train_loss: 0.038400, train_acc: 94.63%, val_loss: 2.887300, val_acc: 52.47%\n",
      "Epoch [3709]/[5000], train_loss: 0.046900, train_acc: 94.63%, val_loss: 3.191200, val_acc: 56.51%\n",
      "Epoch [3710]/[5000], train_loss: 0.040400, train_acc: 94.58%, val_loss: 3.083900, val_acc: 54.17%\n",
      "Epoch [3711]/[5000], train_loss: 0.026100, train_acc: 95.07%, val_loss: 3.113000, val_acc: 55.08%\n",
      "Epoch [3712]/[5000], train_loss: 0.024800, train_acc: 95.31%, val_loss: 2.916200, val_acc: 53.39%\n",
      "Epoch [3713]/[5000], train_loss: 0.025700, train_acc: 95.26%, val_loss: 3.111900, val_acc: 53.26%\n",
      "Epoch [3714]/[5000], train_loss: 0.024000, train_acc: 95.31%, val_loss: 2.975900, val_acc: 56.25%\n",
      "Epoch [3715]/[5000], train_loss: 0.025900, train_acc: 95.21%, val_loss: 3.032900, val_acc: 54.04%\n",
      "Epoch [3716]/[5000], train_loss: 0.032500, train_acc: 94.92%, val_loss: 3.128100, val_acc: 54.95%\n",
      "Epoch [3717]/[5000], train_loss: 0.060300, train_acc: 94.29%, val_loss: 3.025400, val_acc: 52.99%\n",
      "Epoch [3718]/[5000], train_loss: 0.056100, train_acc: 94.38%, val_loss: 3.351900, val_acc: 52.47%\n",
      "Epoch [3719]/[5000], train_loss: 0.074700, train_acc: 93.51%, val_loss: 2.767800, val_acc: 54.69%\n",
      "Epoch [3720]/[5000], train_loss: 0.048200, train_acc: 94.38%, val_loss: 3.317300, val_acc: 53.12%\n",
      "Epoch [3721]/[5000], train_loss: 0.033200, train_acc: 94.82%, val_loss: 3.053100, val_acc: 55.08%\n",
      "Epoch [3722]/[5000], train_loss: 0.035600, train_acc: 95.07%, val_loss: 3.062000, val_acc: 52.73%\n",
      "Epoch [3723]/[5000], train_loss: 0.041800, train_acc: 94.53%, val_loss: 3.205500, val_acc: 53.65%\n",
      "Epoch [3724]/[5000], train_loss: 0.029800, train_acc: 95.17%, val_loss: 2.927100, val_acc: 55.08%\n",
      "Epoch [3725]/[5000], train_loss: 0.045400, train_acc: 94.63%, val_loss: 2.997600, val_acc: 54.95%\n",
      "Epoch [3726]/[5000], train_loss: 0.045200, train_acc: 94.29%, val_loss: 3.211700, val_acc: 53.65%\n",
      "Epoch [3727]/[5000], train_loss: 0.035700, train_acc: 95.02%, val_loss: 3.245800, val_acc: 53.65%\n",
      "Epoch [3728]/[5000], train_loss: 0.020200, train_acc: 95.41%, val_loss: 2.858800, val_acc: 55.73%\n",
      "Epoch [3729]/[5000], train_loss: 0.052800, train_acc: 94.53%, val_loss: 3.117500, val_acc: 54.04%\n",
      "Epoch [3730]/[5000], train_loss: 0.026400, train_acc: 95.12%, val_loss: 2.749100, val_acc: 55.73%\n",
      "Epoch [3731]/[5000], train_loss: 0.036300, train_acc: 95.12%, val_loss: 2.917200, val_acc: 53.12%\n",
      "Epoch [3732]/[5000], train_loss: 0.035900, train_acc: 94.58%, val_loss: 3.403900, val_acc: 53.12%\n",
      "Epoch [3733]/[5000], train_loss: 0.041900, train_acc: 94.53%, val_loss: 2.999200, val_acc: 54.56%\n",
      "Epoch [3734]/[5000], train_loss: 0.029300, train_acc: 94.82%, val_loss: 2.858800, val_acc: 54.82%\n",
      "Epoch [3735]/[5000], train_loss: 0.050600, train_acc: 94.68%, val_loss: 3.281700, val_acc: 54.82%\n",
      "Epoch [3736]/[5000], train_loss: 0.050500, train_acc: 94.24%, val_loss: 2.722200, val_acc: 54.56%\n",
      "Epoch [3737]/[5000], train_loss: 0.064400, train_acc: 94.04%, val_loss: 2.555600, val_acc: 53.26%\n",
      "Epoch [3738]/[5000], train_loss: 0.049500, train_acc: 94.63%, val_loss: 2.527600, val_acc: 54.17%\n",
      "Epoch [3739]/[5000], train_loss: 0.038400, train_acc: 94.53%, val_loss: 2.805500, val_acc: 54.30%\n",
      "Epoch [3740]/[5000], train_loss: 0.025200, train_acc: 95.36%, val_loss: 3.232400, val_acc: 55.73%\n",
      "Epoch [3741]/[5000], train_loss: 0.036600, train_acc: 94.73%, val_loss: 2.667800, val_acc: 54.69%\n",
      "Epoch [3742]/[5000], train_loss: 0.033600, train_acc: 94.87%, val_loss: 2.726700, val_acc: 54.69%\n",
      "Epoch [3743]/[5000], train_loss: 0.024600, train_acc: 95.26%, val_loss: 2.830600, val_acc: 54.69%\n",
      "Epoch [3744]/[5000], train_loss: 0.039500, train_acc: 95.02%, val_loss: 2.818000, val_acc: 52.08%\n",
      "Epoch [3745]/[5000], train_loss: 0.122600, train_acc: 92.38%, val_loss: 3.314400, val_acc: 53.12%\n",
      "Epoch [3746]/[5000], train_loss: 0.112700, train_acc: 92.38%, val_loss: 2.822200, val_acc: 54.69%\n",
      "Epoch [3747]/[5000], train_loss: 0.086200, train_acc: 93.55%, val_loss: 2.920400, val_acc: 53.78%\n",
      "Epoch [3748]/[5000], train_loss: 0.069100, train_acc: 93.60%, val_loss: 2.789700, val_acc: 53.26%\n",
      "Epoch [3749]/[5000], train_loss: 0.046500, train_acc: 94.34%, val_loss: 2.819800, val_acc: 54.30%\n",
      "Epoch [3750]/[5000], train_loss: 0.038000, train_acc: 94.97%, val_loss: 2.804000, val_acc: 56.51%\n",
      "Epoch [3751]/[5000], train_loss: 0.034000, train_acc: 95.12%, val_loss: 3.337400, val_acc: 52.86%\n",
      "Epoch [3752]/[5000], train_loss: 0.045000, train_acc: 94.38%, val_loss: 2.903100, val_acc: 52.34%\n",
      "Epoch [3753]/[5000], train_loss: 0.033700, train_acc: 95.12%, val_loss: 2.736600, val_acc: 53.39%\n",
      "Epoch [3754]/[5000], train_loss: 0.037800, train_acc: 94.63%, val_loss: 3.012000, val_acc: 55.21%\n",
      "Epoch [3755]/[5000], train_loss: 0.026500, train_acc: 95.07%, val_loss: 3.193500, val_acc: 54.56%\n",
      "Epoch [3756]/[5000], train_loss: 0.020700, train_acc: 95.51%, val_loss: 2.792400, val_acc: 53.91%\n",
      "Epoch [3757]/[5000], train_loss: 0.029700, train_acc: 95.17%, val_loss: 2.975200, val_acc: 53.52%\n",
      "Epoch [3758]/[5000], train_loss: 0.031300, train_acc: 95.12%, val_loss: 2.667300, val_acc: 54.17%\n",
      "Epoch [3759]/[5000], train_loss: 0.025600, train_acc: 95.07%, val_loss: 2.896100, val_acc: 55.99%\n",
      "Epoch [3760]/[5000], train_loss: 0.048000, train_acc: 94.58%, val_loss: 2.750400, val_acc: 56.12%\n",
      "Epoch [3761]/[5000], train_loss: 0.029300, train_acc: 95.17%, val_loss: 2.820500, val_acc: 55.73%\n",
      "Epoch [3762]/[5000], train_loss: 0.042600, train_acc: 95.02%, val_loss: 3.288000, val_acc: 54.82%\n",
      "Epoch [3763]/[5000], train_loss: 0.035700, train_acc: 95.02%, val_loss: 3.082800, val_acc: 57.29%\n",
      "Epoch [3764]/[5000], train_loss: 0.036700, train_acc: 94.97%, val_loss: 2.994600, val_acc: 54.17%\n",
      "Epoch [3765]/[5000], train_loss: 0.016500, train_acc: 95.56%, val_loss: 3.426800, val_acc: 56.64%\n",
      "Epoch [3766]/[5000], train_loss: 0.024800, train_acc: 95.26%, val_loss: 3.130500, val_acc: 55.99%\n",
      "Epoch [3767]/[5000], train_loss: 0.029600, train_acc: 95.07%, val_loss: 2.721000, val_acc: 55.73%\n",
      "Epoch [3768]/[5000], train_loss: 0.027100, train_acc: 95.07%, val_loss: 2.831700, val_acc: 55.73%\n",
      "Epoch [3769]/[5000], train_loss: 0.028000, train_acc: 95.07%, val_loss: 3.108300, val_acc: 54.95%\n",
      "Epoch [3770]/[5000], train_loss: 0.024800, train_acc: 95.41%, val_loss: 2.837100, val_acc: 54.69%\n",
      "Epoch [3771]/[5000], train_loss: 0.030000, train_acc: 94.97%, val_loss: 3.077900, val_acc: 51.43%\n",
      "Epoch [3772]/[5000], train_loss: 0.032500, train_acc: 95.07%, val_loss: 2.963000, val_acc: 53.78%\n",
      "Epoch [3773]/[5000], train_loss: 0.036300, train_acc: 95.07%, val_loss: 2.972900, val_acc: 53.78%\n",
      "Epoch [3774]/[5000], train_loss: 0.036900, train_acc: 94.73%, val_loss: 2.821400, val_acc: 57.29%\n",
      "Epoch [3775]/[5000], train_loss: 0.043500, train_acc: 94.53%, val_loss: 2.821400, val_acc: 55.34%\n",
      "Epoch [3776]/[5000], train_loss: 0.052900, train_acc: 94.14%, val_loss: 2.929900, val_acc: 53.78%\n",
      "Epoch [3777]/[5000], train_loss: 0.031600, train_acc: 95.31%, val_loss: 2.936000, val_acc: 54.95%\n",
      "Epoch [3778]/[5000], train_loss: 0.018800, train_acc: 95.41%, val_loss: 2.933500, val_acc: 55.60%\n",
      "Epoch [3779]/[5000], train_loss: 0.028800, train_acc: 95.12%, val_loss: 3.034600, val_acc: 54.04%\n",
      "Epoch [3780]/[5000], train_loss: 0.051500, train_acc: 94.78%, val_loss: 3.122700, val_acc: 53.39%\n",
      "Epoch [3781]/[5000], train_loss: 0.045300, train_acc: 94.58%, val_loss: 2.908200, val_acc: 55.08%\n",
      "Epoch [3782]/[5000], train_loss: 0.042500, train_acc: 94.68%, val_loss: 2.626100, val_acc: 53.91%\n",
      "Epoch [3783]/[5000], train_loss: 0.025500, train_acc: 95.17%, val_loss: 2.849500, val_acc: 55.99%\n",
      "Epoch [3784]/[5000], train_loss: 0.023600, train_acc: 95.26%, val_loss: 3.068500, val_acc: 54.43%\n",
      "Epoch [3785]/[5000], train_loss: 0.018600, train_acc: 95.56%, val_loss: 2.864300, val_acc: 56.38%\n",
      "Epoch [3786]/[5000], train_loss: 0.025400, train_acc: 95.02%, val_loss: 2.884000, val_acc: 53.78%\n",
      "Epoch [3787]/[5000], train_loss: 0.032500, train_acc: 95.17%, val_loss: 2.965100, val_acc: 56.64%\n",
      "Epoch [3788]/[5000], train_loss: 0.022100, train_acc: 95.26%, val_loss: 2.928600, val_acc: 54.30%\n",
      "Epoch [3789]/[5000], train_loss: 0.043300, train_acc: 94.82%, val_loss: 3.155400, val_acc: 55.08%\n",
      "Epoch [3790]/[5000], train_loss: 0.044600, train_acc: 94.63%, val_loss: 3.027400, val_acc: 55.60%\n",
      "Epoch [3791]/[5000], train_loss: 0.045000, train_acc: 94.68%, val_loss: 2.704900, val_acc: 55.34%\n",
      "Epoch [3792]/[5000], train_loss: 0.027800, train_acc: 94.92%, val_loss: 3.032300, val_acc: 53.78%\n",
      "Epoch [3793]/[5000], train_loss: 0.029200, train_acc: 95.17%, val_loss: 2.996000, val_acc: 55.60%\n",
      "Epoch [3794]/[5000], train_loss: 0.035300, train_acc: 94.92%, val_loss: 3.268200, val_acc: 54.69%\n",
      "Epoch [3795]/[5000], train_loss: 0.022600, train_acc: 95.21%, val_loss: 3.006700, val_acc: 54.95%\n",
      "Epoch [3796]/[5000], train_loss: 0.020400, train_acc: 95.36%, val_loss: 2.873900, val_acc: 55.60%\n",
      "Epoch [3797]/[5000], train_loss: 0.033600, train_acc: 95.02%, val_loss: 3.013600, val_acc: 56.12%\n",
      "Epoch [3798]/[5000], train_loss: 0.032500, train_acc: 95.17%, val_loss: 2.946900, val_acc: 53.91%\n",
      "Epoch [3799]/[5000], train_loss: 0.023300, train_acc: 95.21%, val_loss: 3.691700, val_acc: 56.90%\n",
      "Epoch [3800]/[5000], train_loss: 0.029100, train_acc: 95.02%, val_loss: 3.265000, val_acc: 54.95%\n",
      "Epoch [3801]/[5000], train_loss: 0.045100, train_acc: 94.78%, val_loss: 3.193100, val_acc: 54.43%\n",
      "Epoch [3802]/[5000], train_loss: 0.038900, train_acc: 94.68%, val_loss: 2.985300, val_acc: 54.95%\n",
      "Epoch [3803]/[5000], train_loss: 0.026500, train_acc: 94.97%, val_loss: 3.105700, val_acc: 54.95%\n",
      "Epoch [3804]/[5000], train_loss: 0.025900, train_acc: 95.07%, val_loss: 3.525900, val_acc: 55.08%\n",
      "Epoch [3805]/[5000], train_loss: 0.029400, train_acc: 94.92%, val_loss: 2.895300, val_acc: 54.30%\n",
      "Epoch [3806]/[5000], train_loss: 0.017400, train_acc: 95.51%, val_loss: 2.741900, val_acc: 56.12%\n",
      "Epoch [3807]/[5000], train_loss: 0.016800, train_acc: 95.61%, val_loss: 3.577800, val_acc: 53.91%\n",
      "Epoch [3808]/[5000], train_loss: 0.025300, train_acc: 95.26%, val_loss: 2.617600, val_acc: 56.90%\n",
      "Epoch [3809]/[5000], train_loss: 0.031100, train_acc: 95.17%, val_loss: 3.393600, val_acc: 54.95%\n",
      "Epoch [3810]/[5000], train_loss: 0.028000, train_acc: 95.21%, val_loss: 3.260100, val_acc: 51.69%\n",
      "Epoch [3811]/[5000], train_loss: 0.029800, train_acc: 95.21%, val_loss: 2.998200, val_acc: 54.56%\n",
      "Epoch [3812]/[5000], train_loss: 0.022700, train_acc: 95.31%, val_loss: 2.930300, val_acc: 56.64%\n",
      "Epoch [3813]/[5000], train_loss: 0.030700, train_acc: 94.92%, val_loss: 3.014600, val_acc: 57.03%\n",
      "Epoch [3814]/[5000], train_loss: 0.038800, train_acc: 94.43%, val_loss: 3.068100, val_acc: 52.99%\n",
      "Epoch [3815]/[5000], train_loss: 0.043200, train_acc: 94.68%, val_loss: 3.010300, val_acc: 51.95%\n",
      "Epoch [3816]/[5000], train_loss: 0.034400, train_acc: 94.97%, val_loss: 3.097500, val_acc: 51.43%\n",
      "Epoch [3817]/[5000], train_loss: 0.023600, train_acc: 95.31%, val_loss: 2.827800, val_acc: 55.08%\n",
      "Epoch [3818]/[5000], train_loss: 0.036800, train_acc: 94.92%, val_loss: 2.865500, val_acc: 55.21%\n",
      "Epoch [3819]/[5000], train_loss: 0.027900, train_acc: 95.31%, val_loss: 2.996300, val_acc: 53.12%\n",
      "Epoch [3820]/[5000], train_loss: 0.049600, train_acc: 94.53%, val_loss: 3.137400, val_acc: 55.86%\n",
      "Epoch [3821]/[5000], train_loss: 0.037400, train_acc: 94.82%, val_loss: 3.434300, val_acc: 53.52%\n",
      "Epoch [3822]/[5000], train_loss: 0.057000, train_acc: 94.24%, val_loss: 3.374000, val_acc: 54.95%\n",
      "Epoch [3823]/[5000], train_loss: 0.064200, train_acc: 93.65%, val_loss: 3.174500, val_acc: 54.43%\n",
      "Epoch [3824]/[5000], train_loss: 0.042300, train_acc: 94.58%, val_loss: 2.834000, val_acc: 56.12%\n",
      "Epoch [3825]/[5000], train_loss: 0.035800, train_acc: 94.97%, val_loss: 2.992900, val_acc: 56.77%\n",
      "Epoch [3826]/[5000], train_loss: 0.028700, train_acc: 95.21%, val_loss: 2.849000, val_acc: 55.21%\n",
      "Epoch [3827]/[5000], train_loss: 0.036100, train_acc: 95.12%, val_loss: 3.246200, val_acc: 55.60%\n",
      "Epoch [3828]/[5000], train_loss: 0.039500, train_acc: 94.78%, val_loss: 2.680200, val_acc: 54.17%\n",
      "Epoch [3829]/[5000], train_loss: 0.032600, train_acc: 95.02%, val_loss: 2.728900, val_acc: 55.73%\n",
      "Epoch [3830]/[5000], train_loss: 0.031600, train_acc: 95.17%, val_loss: 3.309100, val_acc: 54.30%\n",
      "Epoch [3831]/[5000], train_loss: 0.027500, train_acc: 95.46%, val_loss: 3.418400, val_acc: 56.64%\n",
      "Epoch [3832]/[5000], train_loss: 0.026300, train_acc: 95.31%, val_loss: 2.984900, val_acc: 56.51%\n",
      "Epoch [3833]/[5000], train_loss: 0.020300, train_acc: 95.46%, val_loss: 3.166800, val_acc: 52.47%\n",
      "Epoch [3834]/[5000], train_loss: 0.020900, train_acc: 95.41%, val_loss: 2.941800, val_acc: 57.16%\n",
      "Epoch [3835]/[5000], train_loss: 0.026400, train_acc: 95.26%, val_loss: 2.853300, val_acc: 55.21%\n",
      "Epoch [3836]/[5000], train_loss: 0.025700, train_acc: 95.21%, val_loss: 3.102800, val_acc: 55.99%\n",
      "Epoch [3837]/[5000], train_loss: 0.040000, train_acc: 94.53%, val_loss: 3.231700, val_acc: 56.12%\n",
      "Epoch [3838]/[5000], train_loss: 0.027100, train_acc: 95.31%, val_loss: 3.075300, val_acc: 57.55%\n",
      "Epoch [3839]/[5000], train_loss: 0.036600, train_acc: 95.02%, val_loss: 2.679700, val_acc: 54.43%\n",
      "Epoch [3840]/[5000], train_loss: 0.040300, train_acc: 94.82%, val_loss: 2.860600, val_acc: 54.95%\n",
      "Epoch [3841]/[5000], train_loss: 0.033000, train_acc: 95.07%, val_loss: 2.784300, val_acc: 55.47%\n",
      "Epoch [3842]/[5000], train_loss: 0.032500, train_acc: 94.92%, val_loss: 3.188900, val_acc: 53.39%\n",
      "Epoch [3843]/[5000], train_loss: 0.040000, train_acc: 94.43%, val_loss: 3.088800, val_acc: 54.43%\n",
      "Epoch [3844]/[5000], train_loss: 0.032000, train_acc: 94.92%, val_loss: 3.158800, val_acc: 54.43%\n",
      "Epoch [3845]/[5000], train_loss: 0.046400, train_acc: 94.73%, val_loss: 3.037900, val_acc: 51.56%\n",
      "Epoch [3846]/[5000], train_loss: 0.034900, train_acc: 95.17%, val_loss: 3.055500, val_acc: 54.69%\n",
      "Epoch [3847]/[5000], train_loss: 0.039800, train_acc: 94.92%, val_loss: 2.862400, val_acc: 54.43%\n",
      "Epoch [3848]/[5000], train_loss: 0.050300, train_acc: 94.53%, val_loss: 3.352600, val_acc: 54.17%\n",
      "Epoch [3849]/[5000], train_loss: 0.043700, train_acc: 94.38%, val_loss: 2.935900, val_acc: 54.30%\n",
      "Epoch [3850]/[5000], train_loss: 0.035400, train_acc: 94.87%, val_loss: 3.022900, val_acc: 55.47%\n",
      "Epoch [3851]/[5000], train_loss: 0.048300, train_acc: 94.58%, val_loss: 3.184900, val_acc: 52.21%\n",
      "Epoch [3852]/[5000], train_loss: 0.037200, train_acc: 94.87%, val_loss: 3.357800, val_acc: 53.65%\n",
      "Epoch [3853]/[5000], train_loss: 0.049800, train_acc: 94.09%, val_loss: 3.114500, val_acc: 56.90%\n",
      "Epoch [3854]/[5000], train_loss: 0.037000, train_acc: 94.78%, val_loss: 3.273700, val_acc: 56.38%\n",
      "Epoch [3855]/[5000], train_loss: 0.038900, train_acc: 95.02%, val_loss: 2.870500, val_acc: 51.82%\n",
      "Epoch [3856]/[5000], train_loss: 0.055900, train_acc: 93.85%, val_loss: 2.605500, val_acc: 54.95%\n",
      "Epoch [3857]/[5000], train_loss: 0.044800, train_acc: 94.38%, val_loss: 3.073800, val_acc: 54.82%\n",
      "Epoch [3858]/[5000], train_loss: 0.028700, train_acc: 94.92%, val_loss: 3.346500, val_acc: 53.12%\n",
      "Epoch [3859]/[5000], train_loss: 0.044300, train_acc: 94.82%, val_loss: 3.101600, val_acc: 54.95%\n",
      "Epoch [3860]/[5000], train_loss: 0.033200, train_acc: 95.02%, val_loss: 2.439600, val_acc: 57.29%\n",
      "Epoch [3861]/[5000], train_loss: 0.031000, train_acc: 95.21%, val_loss: 2.939200, val_acc: 52.73%\n",
      "Epoch [3862]/[5000], train_loss: 0.036900, train_acc: 94.78%, val_loss: 3.166100, val_acc: 55.47%\n",
      "Epoch [3863]/[5000], train_loss: 0.036900, train_acc: 94.92%, val_loss: 3.282700, val_acc: 52.99%\n",
      "Epoch [3864]/[5000], train_loss: 0.033500, train_acc: 95.07%, val_loss: 2.647800, val_acc: 54.43%\n",
      "Epoch [3865]/[5000], train_loss: 0.024900, train_acc: 95.26%, val_loss: 3.074800, val_acc: 55.21%\n",
      "Epoch [3866]/[5000], train_loss: 0.035100, train_acc: 94.92%, val_loss: 3.076100, val_acc: 55.21%\n",
      "Epoch [3867]/[5000], train_loss: 0.024800, train_acc: 95.41%, val_loss: 2.941000, val_acc: 56.12%\n",
      "Epoch [3868]/[5000], train_loss: 0.026500, train_acc: 95.12%, val_loss: 2.796800, val_acc: 54.43%\n",
      "Epoch [3869]/[5000], train_loss: 0.022200, train_acc: 95.61%, val_loss: 2.759100, val_acc: 54.04%\n",
      "Epoch [3870]/[5000], train_loss: 0.025700, train_acc: 95.02%, val_loss: 3.137800, val_acc: 57.68%\n",
      "Epoch [3871]/[5000], train_loss: 0.028000, train_acc: 95.07%, val_loss: 2.773900, val_acc: 57.16%\n",
      "Epoch [3872]/[5000], train_loss: 0.021400, train_acc: 95.31%, val_loss: 3.202200, val_acc: 56.25%\n",
      "Epoch [3873]/[5000], train_loss: 0.033600, train_acc: 94.92%, val_loss: 3.291100, val_acc: 54.04%\n",
      "Epoch [3874]/[5000], train_loss: 0.035700, train_acc: 94.97%, val_loss: 2.743300, val_acc: 52.99%\n",
      "Epoch [3875]/[5000], train_loss: 0.044300, train_acc: 94.73%, val_loss: 4.023100, val_acc: 56.12%\n",
      "Epoch [3876]/[5000], train_loss: 0.021200, train_acc: 95.26%, val_loss: 2.914200, val_acc: 57.94%\n",
      "Epoch [3877]/[5000], train_loss: 0.046100, train_acc: 94.68%, val_loss: 3.055700, val_acc: 54.56%\n",
      "Epoch [3878]/[5000], train_loss: 0.039300, train_acc: 94.82%, val_loss: 3.100500, val_acc: 54.43%\n",
      "Epoch [3879]/[5000], train_loss: 0.032700, train_acc: 94.78%, val_loss: 2.917900, val_acc: 55.08%\n",
      "Epoch [3880]/[5000], train_loss: 0.029500, train_acc: 95.12%, val_loss: 3.123900, val_acc: 54.30%\n",
      "Epoch [3881]/[5000], train_loss: 0.020000, train_acc: 95.46%, val_loss: 2.831300, val_acc: 52.99%\n",
      "Epoch [3882]/[5000], train_loss: 0.021200, train_acc: 95.46%, val_loss: 3.270400, val_acc: 55.47%\n",
      "Epoch [3883]/[5000], train_loss: 0.018900, train_acc: 95.41%, val_loss: 2.686900, val_acc: 55.86%\n",
      "Epoch [3884]/[5000], train_loss: 0.027900, train_acc: 95.17%, val_loss: 3.272300, val_acc: 53.91%\n",
      "Epoch [3885]/[5000], train_loss: 0.023100, train_acc: 95.31%, val_loss: 3.653100, val_acc: 53.52%\n",
      "Epoch [3886]/[5000], train_loss: 0.029900, train_acc: 94.92%, val_loss: 2.831800, val_acc: 53.39%\n",
      "Epoch [3887]/[5000], train_loss: 0.051800, train_acc: 94.34%, val_loss: 3.038800, val_acc: 57.29%\n",
      "Epoch [3888]/[5000], train_loss: 0.034700, train_acc: 95.07%, val_loss: 3.103000, val_acc: 53.26%\n",
      "Epoch [3889]/[5000], train_loss: 0.030500, train_acc: 95.07%, val_loss: 2.908300, val_acc: 55.47%\n",
      "Epoch [3890]/[5000], train_loss: 0.016200, train_acc: 95.56%, val_loss: 3.172200, val_acc: 57.94%\n",
      "Epoch [3891]/[5000], train_loss: 0.028700, train_acc: 95.31%, val_loss: 3.180500, val_acc: 55.99%\n",
      "Epoch [3892]/[5000], train_loss: 0.033400, train_acc: 95.12%, val_loss: 3.164100, val_acc: 54.69%\n",
      "Epoch [3893]/[5000], train_loss: 0.029100, train_acc: 95.31%, val_loss: 3.261900, val_acc: 52.73%\n",
      "Epoch [3894]/[5000], train_loss: 0.041700, train_acc: 94.63%, val_loss: 3.086800, val_acc: 55.08%\n",
      "Epoch [3895]/[5000], train_loss: 0.040000, train_acc: 94.63%, val_loss: 2.669100, val_acc: 55.34%\n",
      "Epoch [3896]/[5000], train_loss: 0.042600, train_acc: 94.68%, val_loss: 3.054500, val_acc: 54.69%\n",
      "Epoch [3897]/[5000], train_loss: 0.053300, train_acc: 94.43%, val_loss: 3.031100, val_acc: 54.69%\n",
      "Epoch [3898]/[5000], train_loss: 0.046100, train_acc: 94.78%, val_loss: 3.191700, val_acc: 53.91%\n",
      "Epoch [3899]/[5000], train_loss: 0.057100, train_acc: 93.75%, val_loss: 3.309300, val_acc: 51.30%\n",
      "Epoch [3900]/[5000], train_loss: 0.059300, train_acc: 94.29%, val_loss: 3.168300, val_acc: 53.78%\n",
      "Epoch [3901]/[5000], train_loss: 0.073500, train_acc: 93.55%, val_loss: 3.294200, val_acc: 50.91%\n",
      "Epoch [3902]/[5000], train_loss: 0.070600, train_acc: 93.85%, val_loss: 2.701600, val_acc: 57.42%\n",
      "Epoch [3903]/[5000], train_loss: 0.079900, train_acc: 93.36%, val_loss: 3.073700, val_acc: 52.73%\n",
      "Epoch [3904]/[5000], train_loss: 0.085600, train_acc: 93.65%, val_loss: 2.674100, val_acc: 56.25%\n",
      "Epoch [3905]/[5000], train_loss: 0.059200, train_acc: 93.75%, val_loss: 3.188000, val_acc: 55.73%\n",
      "Epoch [3906]/[5000], train_loss: 0.051500, train_acc: 94.24%, val_loss: 2.939800, val_acc: 54.95%\n",
      "Epoch [3907]/[5000], train_loss: 0.044800, train_acc: 94.63%, val_loss: 2.912600, val_acc: 52.86%\n",
      "Epoch [3908]/[5000], train_loss: 0.044200, train_acc: 95.12%, val_loss: 2.740000, val_acc: 55.47%\n",
      "Epoch [3909]/[5000], train_loss: 0.043800, train_acc: 94.68%, val_loss: 2.488400, val_acc: 52.99%\n",
      "Epoch [3910]/[5000], train_loss: 0.047100, train_acc: 94.53%, val_loss: 3.015300, val_acc: 55.47%\n",
      "Epoch [3911]/[5000], train_loss: 0.055300, train_acc: 94.29%, val_loss: 2.503400, val_acc: 55.47%\n",
      "Epoch [3912]/[5000], train_loss: 0.040000, train_acc: 94.97%, val_loss: 2.922100, val_acc: 54.56%\n",
      "Epoch [3913]/[5000], train_loss: 0.043300, train_acc: 94.58%, val_loss: 2.720500, val_acc: 57.29%\n",
      "Epoch [3914]/[5000], train_loss: 0.035400, train_acc: 95.07%, val_loss: 2.928600, val_acc: 56.90%\n",
      "Epoch [3915]/[5000], train_loss: 0.030500, train_acc: 94.92%, val_loss: 3.007300, val_acc: 54.43%\n",
      "Epoch [3916]/[5000], train_loss: 0.027200, train_acc: 95.12%, val_loss: 2.891300, val_acc: 55.34%\n",
      "Epoch [3917]/[5000], train_loss: 0.025500, train_acc: 95.26%, val_loss: 2.853400, val_acc: 57.42%\n",
      "Epoch [3918]/[5000], train_loss: 0.027800, train_acc: 95.12%, val_loss: 2.606600, val_acc: 55.47%\n",
      "Epoch [3919]/[5000], train_loss: 0.027300, train_acc: 95.07%, val_loss: 2.947100, val_acc: 55.08%\n",
      "Epoch [3920]/[5000], train_loss: 0.025900, train_acc: 95.41%, val_loss: 2.725400, val_acc: 56.64%\n",
      "Epoch [3921]/[5000], train_loss: 0.015600, train_acc: 95.51%, val_loss: 3.220100, val_acc: 55.86%\n",
      "Epoch [3922]/[5000], train_loss: 0.020400, train_acc: 95.36%, val_loss: 3.131900, val_acc: 55.99%\n",
      "Epoch [3923]/[5000], train_loss: 0.011900, train_acc: 95.70%, val_loss: 2.995800, val_acc: 55.08%\n",
      "Epoch [3924]/[5000], train_loss: 0.015400, train_acc: 95.70%, val_loss: 2.768300, val_acc: 56.38%\n",
      "Epoch [3925]/[5000], train_loss: 0.018000, train_acc: 95.56%, val_loss: 3.039500, val_acc: 55.34%\n",
      "Epoch [3926]/[5000], train_loss: 0.022200, train_acc: 95.41%, val_loss: 3.083500, val_acc: 56.25%\n",
      "Epoch [3927]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 2.760600, val_acc: 57.42%\n",
      "Epoch [3928]/[5000], train_loss: 0.022100, train_acc: 95.51%, val_loss: 3.527000, val_acc: 54.95%\n",
      "Epoch [3929]/[5000], train_loss: 0.019600, train_acc: 95.46%, val_loss: 2.689900, val_acc: 53.91%\n",
      "Epoch [3930]/[5000], train_loss: 0.017000, train_acc: 95.61%, val_loss: 3.157600, val_acc: 54.43%\n",
      "Epoch [3931]/[5000], train_loss: 0.021400, train_acc: 95.41%, val_loss: 3.075200, val_acc: 57.55%\n",
      "Epoch [3932]/[5000], train_loss: 0.019500, train_acc: 95.41%, val_loss: 2.915000, val_acc: 56.38%\n",
      "Epoch [3933]/[5000], train_loss: 0.022900, train_acc: 95.21%, val_loss: 2.936500, val_acc: 56.12%\n",
      "Epoch [3934]/[5000], train_loss: 0.029900, train_acc: 95.07%, val_loss: 3.042400, val_acc: 54.69%\n",
      "Epoch [3935]/[5000], train_loss: 0.059300, train_acc: 94.58%, val_loss: 3.168000, val_acc: 54.95%\n",
      "Epoch [3936]/[5000], train_loss: 0.040900, train_acc: 94.34%, val_loss: 3.041400, val_acc: 55.86%\n",
      "Epoch [3937]/[5000], train_loss: 0.037700, train_acc: 94.82%, val_loss: 3.136300, val_acc: 54.17%\n",
      "Epoch [3938]/[5000], train_loss: 0.065100, train_acc: 93.90%, val_loss: 3.438300, val_acc: 51.04%\n",
      "Epoch [3939]/[5000], train_loss: 0.057600, train_acc: 94.38%, val_loss: 3.040700, val_acc: 51.30%\n",
      "Epoch [3940]/[5000], train_loss: 0.039200, train_acc: 94.63%, val_loss: 3.090800, val_acc: 53.52%\n",
      "Epoch [3941]/[5000], train_loss: 0.052600, train_acc: 94.29%, val_loss: 3.217200, val_acc: 53.65%\n",
      "Epoch [3942]/[5000], train_loss: 0.036000, train_acc: 95.02%, val_loss: 3.088500, val_acc: 54.17%\n",
      "Epoch [3943]/[5000], train_loss: 0.045400, train_acc: 94.38%, val_loss: 2.852900, val_acc: 55.08%\n",
      "Epoch [3944]/[5000], train_loss: 0.039500, train_acc: 94.87%, val_loss: 2.940200, val_acc: 54.17%\n",
      "Epoch [3945]/[5000], train_loss: 0.021500, train_acc: 95.65%, val_loss: 2.658000, val_acc: 58.07%\n",
      "Epoch [3946]/[5000], train_loss: 0.032500, train_acc: 94.87%, val_loss: 3.130600, val_acc: 56.25%\n",
      "Epoch [3947]/[5000], train_loss: 0.029700, train_acc: 95.02%, val_loss: 2.551700, val_acc: 53.91%\n",
      "Epoch [3948]/[5000], train_loss: 0.022600, train_acc: 95.41%, val_loss: 3.012500, val_acc: 53.26%\n",
      "Epoch [3949]/[5000], train_loss: 0.025000, train_acc: 95.46%, val_loss: 3.161500, val_acc: 54.43%\n",
      "Epoch [3950]/[5000], train_loss: 0.025300, train_acc: 95.26%, val_loss: 2.643500, val_acc: 53.39%\n",
      "Epoch [3951]/[5000], train_loss: 0.031900, train_acc: 94.92%, val_loss: 2.905500, val_acc: 53.26%\n",
      "Epoch [3952]/[5000], train_loss: 0.037800, train_acc: 94.78%, val_loss: 2.914400, val_acc: 56.25%\n",
      "Epoch [3953]/[5000], train_loss: 0.029900, train_acc: 95.07%, val_loss: 2.681500, val_acc: 55.60%\n",
      "Epoch [3954]/[5000], train_loss: 0.030800, train_acc: 94.92%, val_loss: 3.046900, val_acc: 54.95%\n",
      "Epoch [3955]/[5000], train_loss: 0.033700, train_acc: 95.17%, val_loss: 2.895900, val_acc: 57.29%\n",
      "Epoch [3956]/[5000], train_loss: 0.044200, train_acc: 94.68%, val_loss: 3.097800, val_acc: 52.73%\n",
      "Epoch [3957]/[5000], train_loss: 0.052400, train_acc: 94.24%, val_loss: 3.154400, val_acc: 52.73%\n",
      "Epoch [3958]/[5000], train_loss: 0.056500, train_acc: 94.53%, val_loss: 3.622600, val_acc: 56.38%\n",
      "Epoch [3959]/[5000], train_loss: 0.042500, train_acc: 94.43%, val_loss: 2.861100, val_acc: 55.86%\n",
      "Epoch [3960]/[5000], train_loss: 0.061800, train_acc: 94.19%, val_loss: 2.915800, val_acc: 54.82%\n",
      "Epoch [3961]/[5000], train_loss: 0.042600, train_acc: 94.97%, val_loss: 2.967200, val_acc: 56.38%\n",
      "Epoch [3962]/[5000], train_loss: 0.034700, train_acc: 94.73%, val_loss: 2.584900, val_acc: 56.64%\n",
      "Epoch [3963]/[5000], train_loss: 0.031600, train_acc: 94.92%, val_loss: 3.346500, val_acc: 52.99%\n",
      "Epoch [3964]/[5000], train_loss: 0.041400, train_acc: 94.78%, val_loss: 2.974100, val_acc: 58.07%\n",
      "Epoch [3965]/[5000], train_loss: 0.031800, train_acc: 94.87%, val_loss: 3.035500, val_acc: 55.73%\n",
      "Epoch [3966]/[5000], train_loss: 0.044700, train_acc: 94.78%, val_loss: 2.861700, val_acc: 51.30%\n",
      "Epoch [3967]/[5000], train_loss: 0.068100, train_acc: 94.24%, val_loss: 2.926900, val_acc: 50.91%\n",
      "Epoch [3968]/[5000], train_loss: 0.058300, train_acc: 94.24%, val_loss: 3.246700, val_acc: 53.12%\n",
      "Epoch [3969]/[5000], train_loss: 0.070200, train_acc: 94.04%, val_loss: 2.735200, val_acc: 53.12%\n",
      "Epoch [3970]/[5000], train_loss: 0.079700, train_acc: 93.75%, val_loss: 2.862000, val_acc: 57.81%\n",
      "Epoch [3971]/[5000], train_loss: 0.042400, train_acc: 94.48%, val_loss: 2.701200, val_acc: 54.17%\n",
      "Epoch [3972]/[5000], train_loss: 0.060500, train_acc: 93.95%, val_loss: 3.403900, val_acc: 55.34%\n",
      "Epoch [3973]/[5000], train_loss: 0.041600, train_acc: 94.63%, val_loss: 2.828100, val_acc: 55.99%\n",
      "Epoch [3974]/[5000], train_loss: 0.040200, train_acc: 94.58%, val_loss: 2.952800, val_acc: 52.73%\n",
      "Epoch [3975]/[5000], train_loss: 0.026500, train_acc: 95.21%, val_loss: 3.043500, val_acc: 55.99%\n",
      "Epoch [3976]/[5000], train_loss: 0.031500, train_acc: 94.92%, val_loss: 2.857700, val_acc: 56.90%\n",
      "Epoch [3977]/[5000], train_loss: 0.019300, train_acc: 95.51%, val_loss: 2.962100, val_acc: 57.55%\n",
      "Epoch [3978]/[5000], train_loss: 0.019400, train_acc: 95.65%, val_loss: 2.700000, val_acc: 56.38%\n",
      "Epoch [3979]/[5000], train_loss: 0.021900, train_acc: 95.41%, val_loss: 2.906200, val_acc: 55.21%\n",
      "Epoch [3980]/[5000], train_loss: 0.032300, train_acc: 95.21%, val_loss: 3.254000, val_acc: 54.30%\n",
      "Epoch [3981]/[5000], train_loss: 0.032500, train_acc: 95.02%, val_loss: 3.073800, val_acc: 52.47%\n",
      "Epoch [3982]/[5000], train_loss: 0.024900, train_acc: 95.26%, val_loss: 2.951200, val_acc: 56.77%\n",
      "Epoch [3983]/[5000], train_loss: 0.020000, train_acc: 95.46%, val_loss: 2.850200, val_acc: 57.55%\n",
      "Epoch [3984]/[5000], train_loss: 0.015700, train_acc: 95.46%, val_loss: 3.110500, val_acc: 54.56%\n",
      "Epoch [3985]/[5000], train_loss: 0.018600, train_acc: 95.46%, val_loss: 3.288800, val_acc: 53.78%\n",
      "Epoch [3986]/[5000], train_loss: 0.025900, train_acc: 95.26%, val_loss: 2.891800, val_acc: 55.73%\n",
      "Epoch [3987]/[5000], train_loss: 0.018000, train_acc: 95.46%, val_loss: 3.169800, val_acc: 57.16%\n",
      "Epoch [3988]/[5000], train_loss: 0.020500, train_acc: 95.07%, val_loss: 2.548100, val_acc: 57.81%\n",
      "Epoch [3989]/[5000], train_loss: 0.015200, train_acc: 95.61%, val_loss: 2.921200, val_acc: 56.51%\n",
      "Epoch [3990]/[5000], train_loss: 0.025300, train_acc: 94.92%, val_loss: 2.695200, val_acc: 55.60%\n",
      "Epoch [3991]/[5000], train_loss: 0.026000, train_acc: 95.12%, val_loss: 3.003400, val_acc: 56.51%\n",
      "Epoch [3992]/[5000], train_loss: 0.027200, train_acc: 94.87%, val_loss: 2.839400, val_acc: 55.21%\n",
      "Epoch [3993]/[5000], train_loss: 0.041700, train_acc: 94.78%, val_loss: 2.852000, val_acc: 53.39%\n",
      "Epoch [3994]/[5000], train_loss: 0.043300, train_acc: 94.68%, val_loss: 2.705100, val_acc: 56.51%\n",
      "Epoch [3995]/[5000], train_loss: 0.030400, train_acc: 94.97%, val_loss: 3.055200, val_acc: 55.73%\n",
      "Epoch [3996]/[5000], train_loss: 0.020900, train_acc: 95.41%, val_loss: 3.065300, val_acc: 55.34%\n",
      "Epoch [3997]/[5000], train_loss: 0.020700, train_acc: 95.31%, val_loss: 2.784500, val_acc: 52.73%\n",
      "Epoch [3998]/[5000], train_loss: 0.028100, train_acc: 94.97%, val_loss: 3.090500, val_acc: 56.25%\n",
      "Epoch [3999]/[5000], train_loss: 0.021600, train_acc: 95.26%, val_loss: 2.915100, val_acc: 54.69%\n",
      "Epoch [4000]/[5000], train_loss: 0.029200, train_acc: 95.02%, val_loss: 3.336900, val_acc: 55.47%\n",
      "Epoch [4001]/[5000], train_loss: 0.021000, train_acc: 95.46%, val_loss: 2.927900, val_acc: 55.86%\n",
      "Epoch [4002]/[5000], train_loss: 0.021700, train_acc: 95.36%, val_loss: 3.603600, val_acc: 53.26%\n",
      "Epoch [4003]/[5000], train_loss: 0.032200, train_acc: 94.97%, val_loss: 3.052100, val_acc: 54.56%\n",
      "Epoch [4004]/[5000], train_loss: 0.054000, train_acc: 94.58%, val_loss: 3.051400, val_acc: 55.34%\n",
      "Epoch [4005]/[5000], train_loss: 0.054700, train_acc: 94.34%, val_loss: 2.951700, val_acc: 55.60%\n",
      "Epoch [4006]/[5000], train_loss: 0.040600, train_acc: 94.73%, val_loss: 3.290200, val_acc: 54.17%\n",
      "Epoch [4007]/[5000], train_loss: 0.050000, train_acc: 94.38%, val_loss: 3.111500, val_acc: 55.73%\n",
      "Epoch [4008]/[5000], train_loss: 0.035500, train_acc: 94.92%, val_loss: 2.974300, val_acc: 55.73%\n",
      "Epoch [4009]/[5000], train_loss: 0.030300, train_acc: 95.17%, val_loss: 2.883800, val_acc: 55.86%\n",
      "Epoch [4010]/[5000], train_loss: 0.020800, train_acc: 95.41%, val_loss: 3.087800, val_acc: 55.08%\n",
      "Epoch [4011]/[5000], train_loss: 0.034200, train_acc: 94.78%, val_loss: 3.202300, val_acc: 55.73%\n",
      "Epoch [4012]/[5000], train_loss: 0.042700, train_acc: 94.38%, val_loss: 2.940000, val_acc: 52.86%\n",
      "Epoch [4013]/[5000], train_loss: 0.043700, train_acc: 94.78%, val_loss: 2.989000, val_acc: 56.25%\n",
      "Epoch [4014]/[5000], train_loss: 0.035600, train_acc: 94.97%, val_loss: 2.831300, val_acc: 54.56%\n",
      "Epoch [4015]/[5000], train_loss: 0.023500, train_acc: 95.36%, val_loss: 2.705600, val_acc: 55.34%\n",
      "Epoch [4016]/[5000], train_loss: 0.028000, train_acc: 95.17%, val_loss: 3.258400, val_acc: 54.56%\n",
      "Epoch [4017]/[5000], train_loss: 0.030900, train_acc: 95.02%, val_loss: 2.792000, val_acc: 55.34%\n",
      "Epoch [4018]/[5000], train_loss: 0.032600, train_acc: 95.46%, val_loss: 3.427300, val_acc: 54.56%\n",
      "Epoch [4019]/[5000], train_loss: 0.032600, train_acc: 94.68%, val_loss: 3.022100, val_acc: 53.12%\n",
      "Epoch [4020]/[5000], train_loss: 0.044300, train_acc: 94.63%, val_loss: 3.167300, val_acc: 51.95%\n",
      "Epoch [4021]/[5000], train_loss: 0.047800, train_acc: 94.48%, val_loss: 3.115900, val_acc: 54.43%\n",
      "Epoch [4022]/[5000], train_loss: 0.052700, train_acc: 94.53%, val_loss: 2.775300, val_acc: 54.43%\n",
      "Epoch [4023]/[5000], train_loss: 0.053600, train_acc: 94.09%, val_loss: 2.791000, val_acc: 55.21%\n",
      "Epoch [4024]/[5000], train_loss: 0.054000, train_acc: 94.29%, val_loss: 2.752200, val_acc: 54.56%\n",
      "Epoch [4025]/[5000], train_loss: 0.045400, train_acc: 94.58%, val_loss: 2.769100, val_acc: 55.47%\n",
      "Epoch [4026]/[5000], train_loss: 0.044100, train_acc: 94.53%, val_loss: 3.204900, val_acc: 54.17%\n",
      "Epoch [4027]/[5000], train_loss: 0.041700, train_acc: 94.73%, val_loss: 3.020200, val_acc: 53.91%\n",
      "Epoch [4028]/[5000], train_loss: 0.041400, train_acc: 95.17%, val_loss: 2.690200, val_acc: 54.17%\n",
      "Epoch [4029]/[5000], train_loss: 0.046900, train_acc: 94.58%, val_loss: 2.656200, val_acc: 56.38%\n",
      "Epoch [4030]/[5000], train_loss: 0.033400, train_acc: 94.97%, val_loss: 2.758100, val_acc: 49.87%\n",
      "Epoch [4031]/[5000], train_loss: 0.034900, train_acc: 94.68%, val_loss: 3.001000, val_acc: 54.04%\n",
      "Epoch [4032]/[5000], train_loss: 0.023700, train_acc: 95.17%, val_loss: 2.565500, val_acc: 54.69%\n",
      "Epoch [4033]/[5000], train_loss: 0.019600, train_acc: 95.65%, val_loss: 2.800900, val_acc: 54.95%\n",
      "Epoch [4034]/[5000], train_loss: 0.042700, train_acc: 94.78%, val_loss: 3.274400, val_acc: 55.34%\n",
      "Epoch [4035]/[5000], train_loss: 0.037700, train_acc: 94.78%, val_loss: 3.184900, val_acc: 52.99%\n",
      "Epoch [4036]/[5000], train_loss: 0.031500, train_acc: 95.17%, val_loss: 3.013300, val_acc: 51.69%\n",
      "Epoch [4037]/[5000], train_loss: 0.043800, train_acc: 94.78%, val_loss: 2.876600, val_acc: 55.99%\n",
      "Epoch [4038]/[5000], train_loss: 0.039900, train_acc: 94.48%, val_loss: 2.668900, val_acc: 55.73%\n",
      "Epoch [4039]/[5000], train_loss: 0.023700, train_acc: 95.31%, val_loss: 2.919600, val_acc: 55.86%\n",
      "Epoch [4040]/[5000], train_loss: 0.030900, train_acc: 94.92%, val_loss: 2.974100, val_acc: 55.73%\n",
      "Epoch [4041]/[5000], train_loss: 0.023900, train_acc: 95.26%, val_loss: 2.820300, val_acc: 54.69%\n",
      "Epoch [4042]/[5000], train_loss: 0.032900, train_acc: 95.02%, val_loss: 3.044900, val_acc: 56.77%\n",
      "Epoch [4043]/[5000], train_loss: 0.023200, train_acc: 95.36%, val_loss: 2.830400, val_acc: 56.12%\n",
      "Epoch [4044]/[5000], train_loss: 0.022700, train_acc: 95.41%, val_loss: 3.104900, val_acc: 54.43%\n",
      "Epoch [4045]/[5000], train_loss: 0.027400, train_acc: 94.97%, val_loss: 3.820100, val_acc: 56.64%\n",
      "Epoch [4046]/[5000], train_loss: 0.026800, train_acc: 95.17%, val_loss: 2.961200, val_acc: 54.17%\n",
      "Epoch [4047]/[5000], train_loss: 0.023500, train_acc: 95.41%, val_loss: 3.474100, val_acc: 54.04%\n",
      "Epoch [4048]/[5000], train_loss: 0.032700, train_acc: 95.26%, val_loss: 3.028800, val_acc: 52.34%\n",
      "Epoch [4049]/[5000], train_loss: 0.028300, train_acc: 95.26%, val_loss: 3.126600, val_acc: 53.65%\n",
      "Epoch [4050]/[5000], train_loss: 0.019200, train_acc: 95.36%, val_loss: 3.309400, val_acc: 53.78%\n",
      "Epoch [4051]/[5000], train_loss: 0.029300, train_acc: 95.07%, val_loss: 3.203800, val_acc: 55.86%\n",
      "Epoch [4052]/[5000], train_loss: 0.031000, train_acc: 94.97%, val_loss: 3.152300, val_acc: 54.17%\n",
      "Epoch [4053]/[5000], train_loss: 0.018500, train_acc: 95.56%, val_loss: 2.868400, val_acc: 55.08%\n",
      "Epoch [4054]/[5000], train_loss: 0.024900, train_acc: 95.41%, val_loss: 2.869100, val_acc: 55.21%\n",
      "Epoch [4055]/[5000], train_loss: 0.023400, train_acc: 95.12%, val_loss: 2.980700, val_acc: 57.29%\n",
      "Epoch [4056]/[5000], train_loss: 0.028700, train_acc: 95.21%, val_loss: 3.268000, val_acc: 54.43%\n",
      "Epoch [4057]/[5000], train_loss: 0.031600, train_acc: 95.12%, val_loss: 2.677400, val_acc: 54.30%\n",
      "Epoch [4058]/[5000], train_loss: 0.023900, train_acc: 95.26%, val_loss: 2.766300, val_acc: 56.12%\n",
      "Epoch [4059]/[5000], train_loss: 0.025600, train_acc: 95.36%, val_loss: 3.087600, val_acc: 54.82%\n",
      "Epoch [4060]/[5000], train_loss: 0.025800, train_acc: 95.26%, val_loss: 2.805000, val_acc: 54.43%\n",
      "Epoch [4061]/[5000], train_loss: 0.036100, train_acc: 94.87%, val_loss: 2.978000, val_acc: 54.95%\n",
      "Epoch [4062]/[5000], train_loss: 0.026300, train_acc: 95.12%, val_loss: 3.101300, val_acc: 56.51%\n",
      "Epoch [4063]/[5000], train_loss: 0.024600, train_acc: 95.12%, val_loss: 3.162100, val_acc: 55.34%\n",
      "Epoch [4064]/[5000], train_loss: 0.033500, train_acc: 94.97%, val_loss: 3.279700, val_acc: 56.38%\n",
      "Epoch [4065]/[5000], train_loss: 0.072300, train_acc: 93.99%, val_loss: 2.900300, val_acc: 50.52%\n",
      "Epoch [4066]/[5000], train_loss: 0.049300, train_acc: 94.48%, val_loss: 2.861000, val_acc: 53.91%\n",
      "Epoch [4067]/[5000], train_loss: 0.040300, train_acc: 94.78%, val_loss: 3.072900, val_acc: 54.69%\n",
      "Epoch [4068]/[5000], train_loss: 0.036300, train_acc: 94.92%, val_loss: 3.202300, val_acc: 55.73%\n",
      "Epoch [4069]/[5000], train_loss: 0.065400, train_acc: 94.14%, val_loss: 3.170100, val_acc: 48.57%\n",
      "Epoch [4070]/[5000], train_loss: 0.101300, train_acc: 93.36%, val_loss: 3.245300, val_acc: 56.25%\n",
      "Epoch [4071]/[5000], train_loss: 0.051400, train_acc: 94.24%, val_loss: 2.767100, val_acc: 51.17%\n",
      "Epoch [4072]/[5000], train_loss: 0.056900, train_acc: 94.29%, val_loss: 2.905100, val_acc: 53.78%\n",
      "Epoch [4073]/[5000], train_loss: 0.028900, train_acc: 95.07%, val_loss: 3.190300, val_acc: 53.12%\n",
      "Epoch [4074]/[5000], train_loss: 0.033300, train_acc: 94.87%, val_loss: 3.029300, val_acc: 55.21%\n",
      "Epoch [4075]/[5000], train_loss: 0.036700, train_acc: 94.82%, val_loss: 2.671400, val_acc: 53.26%\n",
      "Epoch [4076]/[5000], train_loss: 0.039800, train_acc: 95.02%, val_loss: 3.180200, val_acc: 54.17%\n",
      "Epoch [4077]/[5000], train_loss: 0.034300, train_acc: 95.21%, val_loss: 2.858600, val_acc: 56.64%\n",
      "Epoch [4078]/[5000], train_loss: 0.031400, train_acc: 94.87%, val_loss: 3.036400, val_acc: 55.34%\n",
      "Epoch [4079]/[5000], train_loss: 0.024500, train_acc: 95.41%, val_loss: 2.927200, val_acc: 55.34%\n",
      "Epoch [4080]/[5000], train_loss: 0.033000, train_acc: 94.87%, val_loss: 3.365400, val_acc: 54.95%\n",
      "Epoch [4081]/[5000], train_loss: 0.032300, train_acc: 95.17%, val_loss: 2.734600, val_acc: 55.34%\n",
      "Epoch [4082]/[5000], train_loss: 0.024500, train_acc: 95.17%, val_loss: 2.624100, val_acc: 55.73%\n",
      "Epoch [4083]/[5000], train_loss: 0.021100, train_acc: 95.46%, val_loss: 2.923400, val_acc: 55.08%\n",
      "Epoch [4084]/[5000], train_loss: 0.031600, train_acc: 94.97%, val_loss: 2.857400, val_acc: 52.34%\n",
      "Epoch [4085]/[5000], train_loss: 0.024400, train_acc: 95.26%, val_loss: 2.736400, val_acc: 56.64%\n",
      "Epoch [4086]/[5000], train_loss: 0.023200, train_acc: 95.26%, val_loss: 2.802700, val_acc: 54.69%\n",
      "Epoch [4087]/[5000], train_loss: 0.026600, train_acc: 95.07%, val_loss: 2.929100, val_acc: 56.12%\n",
      "Epoch [4088]/[5000], train_loss: 0.035700, train_acc: 94.92%, val_loss: 3.022200, val_acc: 56.12%\n",
      "Epoch [4089]/[5000], train_loss: 0.026400, train_acc: 95.17%, val_loss: 3.279200, val_acc: 54.95%\n",
      "Epoch [4090]/[5000], train_loss: 0.031600, train_acc: 94.97%, val_loss: 2.827500, val_acc: 53.78%\n",
      "Epoch [4091]/[5000], train_loss: 0.043700, train_acc: 94.68%, val_loss: 2.727300, val_acc: 55.21%\n",
      "Epoch [4092]/[5000], train_loss: 0.031800, train_acc: 94.68%, val_loss: 3.020100, val_acc: 55.47%\n",
      "Epoch [4093]/[5000], train_loss: 0.035100, train_acc: 95.02%, val_loss: 3.053200, val_acc: 52.73%\n",
      "Epoch [4094]/[5000], train_loss: 0.044400, train_acc: 94.53%, val_loss: 3.097100, val_acc: 54.69%\n",
      "Epoch [4095]/[5000], train_loss: 0.036700, train_acc: 94.73%, val_loss: 3.112900, val_acc: 54.04%\n",
      "Epoch [4096]/[5000], train_loss: 0.026600, train_acc: 95.12%, val_loss: 2.874300, val_acc: 55.47%\n",
      "Epoch [4097]/[5000], train_loss: 0.027600, train_acc: 95.12%, val_loss: 2.735800, val_acc: 54.43%\n",
      "Epoch [4098]/[5000], train_loss: 0.031300, train_acc: 95.17%, val_loss: 3.042300, val_acc: 56.25%\n",
      "Epoch [4099]/[5000], train_loss: 0.022600, train_acc: 95.41%, val_loss: 3.400200, val_acc: 56.77%\n",
      "Epoch [4100]/[5000], train_loss: 0.021700, train_acc: 95.21%, val_loss: 3.174400, val_acc: 54.04%\n",
      "Epoch [4101]/[5000], train_loss: 0.025600, train_acc: 95.26%, val_loss: 3.065300, val_acc: 56.64%\n",
      "Epoch [4102]/[5000], train_loss: 0.048500, train_acc: 94.58%, val_loss: 2.765600, val_acc: 52.86%\n",
      "Epoch [4103]/[5000], train_loss: 0.037800, train_acc: 94.58%, val_loss: 3.264700, val_acc: 54.82%\n",
      "Epoch [4104]/[5000], train_loss: 0.041500, train_acc: 94.58%, val_loss: 3.203000, val_acc: 52.47%\n",
      "Epoch [4105]/[5000], train_loss: 0.043300, train_acc: 94.78%, val_loss: 3.366900, val_acc: 56.51%\n",
      "Epoch [4106]/[5000], train_loss: 0.030800, train_acc: 95.31%, val_loss: 2.935600, val_acc: 56.51%\n",
      "Epoch [4107]/[5000], train_loss: 0.021200, train_acc: 95.36%, val_loss: 3.325400, val_acc: 54.69%\n",
      "Epoch [4108]/[5000], train_loss: 0.016800, train_acc: 95.36%, val_loss: 3.066100, val_acc: 54.43%\n",
      "Epoch [4109]/[5000], train_loss: 0.019300, train_acc: 95.51%, val_loss: 2.638600, val_acc: 56.38%\n",
      "Epoch [4110]/[5000], train_loss: 0.021900, train_acc: 95.36%, val_loss: 2.989900, val_acc: 56.64%\n",
      "Epoch [4111]/[5000], train_loss: 0.026400, train_acc: 95.07%, val_loss: 3.340100, val_acc: 56.51%\n",
      "Epoch [4112]/[5000], train_loss: 0.050000, train_acc: 94.53%, val_loss: 2.780800, val_acc: 55.34%\n",
      "Epoch [4113]/[5000], train_loss: 0.029000, train_acc: 95.12%, val_loss: 3.025400, val_acc: 55.21%\n",
      "Epoch [4114]/[5000], train_loss: 0.037500, train_acc: 94.97%, val_loss: 2.814600, val_acc: 54.95%\n",
      "Epoch [4115]/[5000], train_loss: 0.029600, train_acc: 95.12%, val_loss: 3.002900, val_acc: 54.56%\n",
      "Epoch [4116]/[5000], train_loss: 0.035500, train_acc: 94.78%, val_loss: 2.820600, val_acc: 53.26%\n",
      "Epoch [4117]/[5000], train_loss: 0.028000, train_acc: 95.17%, val_loss: 3.507900, val_acc: 55.34%\n",
      "Epoch [4118]/[5000], train_loss: 0.036400, train_acc: 94.63%, val_loss: 3.028600, val_acc: 54.69%\n",
      "Epoch [4119]/[5000], train_loss: 0.053700, train_acc: 94.14%, val_loss: 2.888100, val_acc: 52.99%\n",
      "Epoch [4120]/[5000], train_loss: 0.063400, train_acc: 94.29%, val_loss: 3.206100, val_acc: 54.69%\n",
      "Epoch [4121]/[5000], train_loss: 0.046200, train_acc: 94.53%, val_loss: 3.088900, val_acc: 56.77%\n",
      "Epoch [4122]/[5000], train_loss: 0.026300, train_acc: 94.92%, val_loss: 3.053400, val_acc: 56.90%\n",
      "Epoch [4123]/[5000], train_loss: 0.029000, train_acc: 95.26%, val_loss: 2.760300, val_acc: 55.47%\n",
      "Epoch [4124]/[5000], train_loss: 0.030100, train_acc: 95.21%, val_loss: 3.430000, val_acc: 54.17%\n",
      "Epoch [4125]/[5000], train_loss: 0.030000, train_acc: 94.92%, val_loss: 2.947700, val_acc: 54.04%\n",
      "Epoch [4126]/[5000], train_loss: 0.029400, train_acc: 95.21%, val_loss: 3.707600, val_acc: 54.95%\n",
      "Epoch [4127]/[5000], train_loss: 0.031700, train_acc: 95.12%, val_loss: 3.353300, val_acc: 55.08%\n",
      "Epoch [4128]/[5000], train_loss: 0.023800, train_acc: 95.21%, val_loss: 2.787000, val_acc: 55.21%\n",
      "Epoch [4129]/[5000], train_loss: 0.033800, train_acc: 94.87%, val_loss: 2.837800, val_acc: 55.86%\n",
      "Epoch [4130]/[5000], train_loss: 0.022200, train_acc: 95.26%, val_loss: 3.099800, val_acc: 54.30%\n",
      "Epoch [4131]/[5000], train_loss: 0.024100, train_acc: 95.21%, val_loss: 3.166900, val_acc: 55.47%\n",
      "Epoch [4132]/[5000], train_loss: 0.036600, train_acc: 95.02%, val_loss: 3.178600, val_acc: 55.73%\n",
      "Epoch [4133]/[5000], train_loss: 0.033100, train_acc: 94.82%, val_loss: 3.111900, val_acc: 54.43%\n",
      "Epoch [4134]/[5000], train_loss: 0.031200, train_acc: 94.82%, val_loss: 2.690000, val_acc: 55.34%\n",
      "Epoch [4135]/[5000], train_loss: 0.027800, train_acc: 95.36%, val_loss: 2.742900, val_acc: 54.69%\n",
      "Epoch [4136]/[5000], train_loss: 0.026100, train_acc: 95.12%, val_loss: 3.114500, val_acc: 55.08%\n",
      "Epoch [4137]/[5000], train_loss: 0.042000, train_acc: 94.92%, val_loss: 3.516400, val_acc: 53.65%\n",
      "Epoch [4138]/[5000], train_loss: 0.035100, train_acc: 94.87%, val_loss: 2.733900, val_acc: 54.04%\n",
      "Epoch [4139]/[5000], train_loss: 0.035700, train_acc: 94.92%, val_loss: 3.065600, val_acc: 53.78%\n",
      "Epoch [4140]/[5000], train_loss: 0.055500, train_acc: 94.34%, val_loss: 3.201300, val_acc: 54.43%\n",
      "Epoch [4141]/[5000], train_loss: 0.047700, train_acc: 94.53%, val_loss: 2.922400, val_acc: 54.82%\n",
      "Epoch [4142]/[5000], train_loss: 0.037600, train_acc: 94.82%, val_loss: 3.231200, val_acc: 53.26%\n",
      "Epoch [4143]/[5000], train_loss: 0.028600, train_acc: 94.92%, val_loss: 3.064800, val_acc: 55.47%\n",
      "Epoch [4144]/[5000], train_loss: 0.049800, train_acc: 94.53%, val_loss: 2.750400, val_acc: 55.73%\n",
      "Epoch [4145]/[5000], train_loss: 0.039100, train_acc: 94.97%, val_loss: 3.227900, val_acc: 55.08%\n",
      "Epoch [4146]/[5000], train_loss: 0.038300, train_acc: 95.21%, val_loss: 2.809900, val_acc: 55.08%\n",
      "Epoch [4147]/[5000], train_loss: 0.031300, train_acc: 94.97%, val_loss: 3.318100, val_acc: 54.04%\n",
      "Epoch [4148]/[5000], train_loss: 0.054800, train_acc: 94.24%, val_loss: 3.441500, val_acc: 53.52%\n",
      "Epoch [4149]/[5000], train_loss: 0.036200, train_acc: 94.82%, val_loss: 3.145900, val_acc: 56.12%\n",
      "Epoch [4150]/[5000], train_loss: 0.054300, train_acc: 94.48%, val_loss: 2.933300, val_acc: 57.55%\n",
      "Epoch [4151]/[5000], train_loss: 0.042700, train_acc: 94.43%, val_loss: 2.878500, val_acc: 55.34%\n",
      "Epoch [4152]/[5000], train_loss: 0.036100, train_acc: 94.82%, val_loss: 2.911200, val_acc: 53.52%\n",
      "Epoch [4153]/[5000], train_loss: 0.031600, train_acc: 94.82%, val_loss: 2.737800, val_acc: 56.51%\n",
      "Epoch [4154]/[5000], train_loss: 0.033100, train_acc: 95.02%, val_loss: 3.198800, val_acc: 54.95%\n",
      "Epoch [4155]/[5000], train_loss: 0.048100, train_acc: 94.38%, val_loss: 3.074300, val_acc: 52.86%\n",
      "Epoch [4156]/[5000], train_loss: 0.029800, train_acc: 95.02%, val_loss: 2.685500, val_acc: 56.12%\n",
      "Epoch [4157]/[5000], train_loss: 0.031100, train_acc: 94.92%, val_loss: 2.663800, val_acc: 57.29%\n",
      "Epoch [4158]/[5000], train_loss: 0.022600, train_acc: 95.46%, val_loss: 2.699500, val_acc: 56.25%\n",
      "Epoch [4159]/[5000], train_loss: 0.025000, train_acc: 95.12%, val_loss: 3.115400, val_acc: 54.56%\n",
      "Epoch [4160]/[5000], train_loss: 0.016100, train_acc: 95.61%, val_loss: 3.406100, val_acc: 54.95%\n",
      "Epoch [4161]/[5000], train_loss: 0.031300, train_acc: 95.07%, val_loss: 2.789400, val_acc: 55.21%\n",
      "Epoch [4162]/[5000], train_loss: 0.031200, train_acc: 94.78%, val_loss: 3.257700, val_acc: 56.25%\n",
      "Epoch [4163]/[5000], train_loss: 0.025300, train_acc: 95.21%, val_loss: 3.014000, val_acc: 54.95%\n",
      "Epoch [4164]/[5000], train_loss: 0.024000, train_acc: 95.31%, val_loss: 3.033500, val_acc: 53.39%\n",
      "Epoch [4165]/[5000], train_loss: 0.027900, train_acc: 95.12%, val_loss: 2.783800, val_acc: 55.21%\n",
      "Epoch [4166]/[5000], train_loss: 0.025400, train_acc: 95.21%, val_loss: 3.463800, val_acc: 54.17%\n",
      "Epoch [4167]/[5000], train_loss: 0.026000, train_acc: 95.12%, val_loss: 2.962400, val_acc: 53.78%\n",
      "Epoch [4168]/[5000], train_loss: 0.027400, train_acc: 95.26%, val_loss: 3.204200, val_acc: 52.86%\n",
      "Epoch [4169]/[5000], train_loss: 0.031800, train_acc: 94.97%, val_loss: 2.961200, val_acc: 54.17%\n",
      "Epoch [4170]/[5000], train_loss: 0.016800, train_acc: 95.61%, val_loss: 3.058300, val_acc: 54.69%\n",
      "Epoch [4171]/[5000], train_loss: 0.023500, train_acc: 95.31%, val_loss: 3.146700, val_acc: 55.34%\n",
      "Epoch [4172]/[5000], train_loss: 0.025400, train_acc: 95.26%, val_loss: 2.766700, val_acc: 55.60%\n",
      "Epoch [4173]/[5000], train_loss: 0.031200, train_acc: 95.26%, val_loss: 3.286800, val_acc: 54.43%\n",
      "Epoch [4174]/[5000], train_loss: 0.039500, train_acc: 94.78%, val_loss: 2.992400, val_acc: 54.82%\n",
      "Epoch [4175]/[5000], train_loss: 0.036300, train_acc: 94.97%, val_loss: 3.023500, val_acc: 54.17%\n",
      "Epoch [4176]/[5000], train_loss: 0.028100, train_acc: 95.17%, val_loss: 3.013500, val_acc: 53.78%\n",
      "Epoch [4177]/[5000], train_loss: 0.035000, train_acc: 94.97%, val_loss: 3.180000, val_acc: 55.47%\n",
      "Epoch [4178]/[5000], train_loss: 0.028500, train_acc: 95.12%, val_loss: 3.256300, val_acc: 56.25%\n",
      "Epoch [4179]/[5000], train_loss: 0.020500, train_acc: 95.56%, val_loss: 2.833600, val_acc: 55.73%\n",
      "Epoch [4180]/[5000], train_loss: 0.025300, train_acc: 95.21%, val_loss: 3.320100, val_acc: 54.30%\n",
      "Epoch [4181]/[5000], train_loss: 0.029100, train_acc: 95.46%, val_loss: 3.145900, val_acc: 56.51%\n",
      "Epoch [4182]/[5000], train_loss: 0.037500, train_acc: 94.92%, val_loss: 3.149900, val_acc: 55.86%\n",
      "Epoch [4183]/[5000], train_loss: 0.046700, train_acc: 94.58%, val_loss: 2.847800, val_acc: 53.65%\n",
      "Epoch [4184]/[5000], train_loss: 0.038700, train_acc: 94.68%, val_loss: 3.071700, val_acc: 53.26%\n",
      "Epoch [4185]/[5000], train_loss: 0.048100, train_acc: 94.43%, val_loss: 3.327900, val_acc: 53.52%\n",
      "Epoch [4186]/[5000], train_loss: 0.051700, train_acc: 94.68%, val_loss: 3.369800, val_acc: 52.99%\n",
      "Epoch [4187]/[5000], train_loss: 0.037900, train_acc: 95.02%, val_loss: 3.134400, val_acc: 55.21%\n",
      "Epoch [4188]/[5000], train_loss: 0.052400, train_acc: 94.43%, val_loss: 3.038900, val_acc: 55.47%\n",
      "Epoch [4189]/[5000], train_loss: 0.059100, train_acc: 93.99%, val_loss: 3.344900, val_acc: 53.39%\n",
      "Epoch [4190]/[5000], train_loss: 0.050600, train_acc: 94.34%, val_loss: 3.515400, val_acc: 52.34%\n",
      "Epoch [4191]/[5000], train_loss: 0.055700, train_acc: 94.24%, val_loss: 2.692400, val_acc: 54.82%\n",
      "Epoch [4192]/[5000], train_loss: 0.055900, train_acc: 94.19%, val_loss: 3.152900, val_acc: 55.21%\n",
      "Epoch [4193]/[5000], train_loss: 0.033600, train_acc: 94.82%, val_loss: 3.511800, val_acc: 54.56%\n",
      "Epoch [4194]/[5000], train_loss: 0.033800, train_acc: 94.97%, val_loss: 3.119800, val_acc: 53.52%\n",
      "Epoch [4195]/[5000], train_loss: 0.034500, train_acc: 95.17%, val_loss: 2.935300, val_acc: 54.30%\n",
      "Epoch [4196]/[5000], train_loss: 0.046200, train_acc: 94.43%, val_loss: 3.171500, val_acc: 53.12%\n",
      "Epoch [4197]/[5000], train_loss: 0.039500, train_acc: 94.53%, val_loss: 3.201200, val_acc: 56.64%\n",
      "Epoch [4198]/[5000], train_loss: 0.048000, train_acc: 94.48%, val_loss: 3.059700, val_acc: 50.78%\n",
      "Epoch [4199]/[5000], train_loss: 0.036100, train_acc: 94.68%, val_loss: 2.866800, val_acc: 55.08%\n",
      "Epoch [4200]/[5000], train_loss: 0.037800, train_acc: 94.92%, val_loss: 3.303100, val_acc: 51.30%\n",
      "Epoch [4201]/[5000], train_loss: 0.054700, train_acc: 94.53%, val_loss: 3.143400, val_acc: 55.60%\n",
      "Epoch [4202]/[5000], train_loss: 0.039300, train_acc: 94.53%, val_loss: 2.930100, val_acc: 56.12%\n",
      "Epoch [4203]/[5000], train_loss: 0.047000, train_acc: 94.78%, val_loss: 3.015100, val_acc: 53.39%\n",
      "Epoch [4204]/[5000], train_loss: 0.044400, train_acc: 94.29%, val_loss: 2.798800, val_acc: 54.04%\n",
      "Epoch [4205]/[5000], train_loss: 0.045400, train_acc: 94.58%, val_loss: 2.941100, val_acc: 52.21%\n",
      "Epoch [4206]/[5000], train_loss: 0.026100, train_acc: 95.21%, val_loss: 3.148800, val_acc: 54.43%\n",
      "Epoch [4207]/[5000], train_loss: 0.019800, train_acc: 95.51%, val_loss: 3.990200, val_acc: 54.82%\n",
      "Epoch [4208]/[5000], train_loss: 0.024800, train_acc: 95.26%, val_loss: 3.196000, val_acc: 54.82%\n",
      "Epoch [4209]/[5000], train_loss: 0.021100, train_acc: 95.41%, val_loss: 3.198900, val_acc: 55.60%\n",
      "Epoch [4210]/[5000], train_loss: 0.029200, train_acc: 95.02%, val_loss: 3.066200, val_acc: 53.52%\n",
      "Epoch [4211]/[5000], train_loss: 0.036500, train_acc: 94.87%, val_loss: 2.820500, val_acc: 53.78%\n",
      "Epoch [4212]/[5000], train_loss: 0.030800, train_acc: 94.73%, val_loss: 3.658200, val_acc: 54.95%\n",
      "Epoch [4213]/[5000], train_loss: 0.024000, train_acc: 95.51%, val_loss: 2.854500, val_acc: 53.39%\n",
      "Epoch [4214]/[5000], train_loss: 0.036500, train_acc: 94.92%, val_loss: 2.989500, val_acc: 55.60%\n",
      "Epoch [4215]/[5000], train_loss: 0.073000, train_acc: 93.85%, val_loss: 2.797800, val_acc: 55.73%\n",
      "Epoch [4216]/[5000], train_loss: 0.080300, train_acc: 93.55%, val_loss: 3.158800, val_acc: 53.78%\n",
      "Epoch [4217]/[5000], train_loss: 0.057100, train_acc: 94.43%, val_loss: 3.198300, val_acc: 54.69%\n",
      "Epoch [4218]/[5000], train_loss: 0.066300, train_acc: 93.99%, val_loss: 2.742300, val_acc: 53.65%\n",
      "Epoch [4219]/[5000], train_loss: 0.064600, train_acc: 93.85%, val_loss: 3.095600, val_acc: 54.69%\n",
      "Epoch [4220]/[5000], train_loss: 0.052000, train_acc: 94.29%, val_loss: 3.054900, val_acc: 54.43%\n",
      "Epoch [4221]/[5000], train_loss: 0.050600, train_acc: 94.19%, val_loss: 3.162600, val_acc: 53.52%\n",
      "Epoch [4222]/[5000], train_loss: 0.030500, train_acc: 95.12%, val_loss: 2.743600, val_acc: 52.47%\n",
      "Epoch [4223]/[5000], train_loss: 0.020400, train_acc: 95.46%, val_loss: 2.946300, val_acc: 54.30%\n",
      "Epoch [4224]/[5000], train_loss: 0.020700, train_acc: 95.41%, val_loss: 3.388300, val_acc: 54.69%\n",
      "Epoch [4225]/[5000], train_loss: 0.021500, train_acc: 95.46%, val_loss: 3.298200, val_acc: 54.82%\n",
      "Epoch [4226]/[5000], train_loss: 0.016800, train_acc: 95.65%, val_loss: 2.961500, val_acc: 53.91%\n",
      "Epoch [4227]/[5000], train_loss: 0.020600, train_acc: 95.41%, val_loss: 2.998100, val_acc: 55.47%\n",
      "Epoch [4228]/[5000], train_loss: 0.031100, train_acc: 95.36%, val_loss: 3.101400, val_acc: 54.30%\n",
      "Epoch [4229]/[5000], train_loss: 0.032600, train_acc: 95.02%, val_loss: 3.085200, val_acc: 56.38%\n",
      "Epoch [4230]/[5000], train_loss: 0.030800, train_acc: 94.97%, val_loss: 3.135900, val_acc: 54.30%\n",
      "Epoch [4231]/[5000], train_loss: 0.022400, train_acc: 95.46%, val_loss: 3.031100, val_acc: 56.64%\n",
      "Epoch [4232]/[5000], train_loss: 0.020300, train_acc: 95.41%, val_loss: 3.092000, val_acc: 54.56%\n",
      "Epoch [4233]/[5000], train_loss: 0.019200, train_acc: 95.51%, val_loss: 3.163700, val_acc: 56.25%\n",
      "Epoch [4234]/[5000], train_loss: 0.023700, train_acc: 95.36%, val_loss: 3.204100, val_acc: 55.86%\n",
      "Epoch [4235]/[5000], train_loss: 0.020600, train_acc: 95.36%, val_loss: 3.050200, val_acc: 53.91%\n",
      "Epoch [4236]/[5000], train_loss: 0.027700, train_acc: 95.17%, val_loss: 3.195400, val_acc: 55.34%\n",
      "Epoch [4237]/[5000], train_loss: 0.019300, train_acc: 95.36%, val_loss: 2.785000, val_acc: 54.43%\n",
      "Epoch [4238]/[5000], train_loss: 0.037600, train_acc: 95.26%, val_loss: 3.167700, val_acc: 54.04%\n",
      "Epoch [4239]/[5000], train_loss: 0.021500, train_acc: 95.21%, val_loss: 3.092400, val_acc: 54.30%\n",
      "Epoch [4240]/[5000], train_loss: 0.029200, train_acc: 94.87%, val_loss: 2.688300, val_acc: 54.17%\n",
      "Epoch [4241]/[5000], train_loss: 0.041200, train_acc: 94.63%, val_loss: 3.019400, val_acc: 56.77%\n",
      "Epoch [4242]/[5000], train_loss: 0.067800, train_acc: 94.14%, val_loss: 3.167100, val_acc: 56.77%\n",
      "Epoch [4243]/[5000], train_loss: 0.050300, train_acc: 94.34%, val_loss: 2.978300, val_acc: 54.30%\n",
      "Epoch [4244]/[5000], train_loss: 0.030200, train_acc: 94.87%, val_loss: 2.671000, val_acc: 57.29%\n",
      "Epoch [4245]/[5000], train_loss: 0.021800, train_acc: 95.46%, val_loss: 3.264800, val_acc: 54.43%\n",
      "Epoch [4246]/[5000], train_loss: 0.030500, train_acc: 95.12%, val_loss: 2.696300, val_acc: 55.34%\n",
      "Epoch [4247]/[5000], train_loss: 0.022300, train_acc: 95.56%, val_loss: 2.870200, val_acc: 55.08%\n",
      "Epoch [4248]/[5000], train_loss: 0.028000, train_acc: 95.12%, val_loss: 2.660900, val_acc: 55.08%\n",
      "Epoch [4249]/[5000], train_loss: 0.021900, train_acc: 95.46%, val_loss: 2.942900, val_acc: 56.77%\n",
      "Epoch [4250]/[5000], train_loss: 0.026600, train_acc: 95.17%, val_loss: 2.484000, val_acc: 54.82%\n",
      "Epoch [4251]/[5000], train_loss: 0.022400, train_acc: 95.26%, val_loss: 2.930400, val_acc: 53.12%\n",
      "Epoch [4252]/[5000], train_loss: 0.018500, train_acc: 95.36%, val_loss: 2.758400, val_acc: 55.60%\n",
      "Epoch [4253]/[5000], train_loss: 0.019000, train_acc: 95.46%, val_loss: 3.301500, val_acc: 55.99%\n",
      "Epoch [4254]/[5000], train_loss: 0.052500, train_acc: 94.38%, val_loss: 2.699500, val_acc: 54.04%\n",
      "Epoch [4255]/[5000], train_loss: 0.050300, train_acc: 94.53%, val_loss: 3.735600, val_acc: 52.73%\n",
      "Epoch [4256]/[5000], train_loss: 0.058700, train_acc: 94.29%, val_loss: 3.323800, val_acc: 54.17%\n",
      "Epoch [4257]/[5000], train_loss: 0.044300, train_acc: 94.34%, val_loss: 3.121700, val_acc: 56.90%\n",
      "Epoch [4258]/[5000], train_loss: 0.036300, train_acc: 95.07%, val_loss: 3.183900, val_acc: 56.77%\n",
      "Epoch [4259]/[5000], train_loss: 0.031800, train_acc: 94.82%, val_loss: 3.235500, val_acc: 52.86%\n",
      "Epoch [4260]/[5000], train_loss: 0.029800, train_acc: 94.82%, val_loss: 2.808900, val_acc: 54.95%\n",
      "Epoch [4261]/[5000], train_loss: 0.027300, train_acc: 95.12%, val_loss: 3.019500, val_acc: 57.55%\n",
      "Epoch [4262]/[5000], train_loss: 0.032000, train_acc: 94.97%, val_loss: 2.666500, val_acc: 56.25%\n",
      "Epoch [4263]/[5000], train_loss: 0.033600, train_acc: 94.78%, val_loss: 2.906800, val_acc: 55.99%\n",
      "Epoch [4264]/[5000], train_loss: 0.034300, train_acc: 94.68%, val_loss: 2.805200, val_acc: 54.56%\n",
      "Epoch [4265]/[5000], train_loss: 0.020300, train_acc: 95.31%, val_loss: 3.450400, val_acc: 56.64%\n",
      "Epoch [4266]/[5000], train_loss: 0.024400, train_acc: 95.31%, val_loss: 3.261500, val_acc: 57.03%\n",
      "Epoch [4267]/[5000], train_loss: 0.017300, train_acc: 95.51%, val_loss: 3.224300, val_acc: 55.99%\n",
      "Epoch [4268]/[5000], train_loss: 0.023600, train_acc: 95.12%, val_loss: 2.572900, val_acc: 55.60%\n",
      "Epoch [4269]/[5000], train_loss: 0.026400, train_acc: 95.21%, val_loss: 3.242500, val_acc: 54.04%\n",
      "Epoch [4270]/[5000], train_loss: 0.035700, train_acc: 95.02%, val_loss: 3.505200, val_acc: 56.51%\n",
      "Epoch [4271]/[5000], train_loss: 0.044000, train_acc: 94.63%, val_loss: 3.526100, val_acc: 52.99%\n",
      "Epoch [4272]/[5000], train_loss: 0.032600, train_acc: 95.17%, val_loss: 3.071100, val_acc: 54.43%\n",
      "Epoch [4273]/[5000], train_loss: 0.043500, train_acc: 95.02%, val_loss: 2.970000, val_acc: 56.12%\n",
      "Epoch [4274]/[5000], train_loss: 0.047100, train_acc: 94.73%, val_loss: 2.873500, val_acc: 55.86%\n",
      "Epoch [4275]/[5000], train_loss: 0.019900, train_acc: 95.51%, val_loss: 3.424900, val_acc: 56.25%\n",
      "Epoch [4276]/[5000], train_loss: 0.030700, train_acc: 95.17%, val_loss: 2.916700, val_acc: 54.04%\n",
      "Epoch [4277]/[5000], train_loss: 0.030300, train_acc: 94.92%, val_loss: 3.273900, val_acc: 54.30%\n",
      "Epoch [4278]/[5000], train_loss: 0.023000, train_acc: 95.36%, val_loss: 3.013600, val_acc: 55.08%\n",
      "Epoch [4279]/[5000], train_loss: 0.023900, train_acc: 95.21%, val_loss: 3.181000, val_acc: 54.95%\n",
      "Epoch [4280]/[5000], train_loss: 0.014400, train_acc: 95.51%, val_loss: 3.564000, val_acc: 55.21%\n",
      "Epoch [4281]/[5000], train_loss: 0.015100, train_acc: 95.46%, val_loss: 3.032100, val_acc: 56.12%\n",
      "Epoch [4282]/[5000], train_loss: 0.020800, train_acc: 95.26%, val_loss: 2.793500, val_acc: 55.08%\n",
      "Epoch [4283]/[5000], train_loss: 0.016800, train_acc: 95.41%, val_loss: 3.700300, val_acc: 54.43%\n",
      "Epoch [4284]/[5000], train_loss: 0.022900, train_acc: 95.41%, val_loss: 2.910900, val_acc: 56.77%\n",
      "Epoch [4285]/[5000], train_loss: 0.021700, train_acc: 95.46%, val_loss: 3.499100, val_acc: 54.30%\n",
      "Epoch [4286]/[5000], train_loss: 0.017500, train_acc: 95.51%, val_loss: 3.334700, val_acc: 53.78%\n",
      "Epoch [4287]/[5000], train_loss: 0.022800, train_acc: 95.46%, val_loss: 3.518800, val_acc: 55.21%\n",
      "Epoch [4288]/[5000], train_loss: 0.032200, train_acc: 94.82%, val_loss: 3.441300, val_acc: 52.08%\n",
      "Epoch [4289]/[5000], train_loss: 0.036700, train_acc: 94.87%, val_loss: 3.280700, val_acc: 52.73%\n",
      "Epoch [4290]/[5000], train_loss: 0.045600, train_acc: 94.63%, val_loss: 3.042600, val_acc: 53.78%\n",
      "Epoch [4291]/[5000], train_loss: 0.033100, train_acc: 94.87%, val_loss: 3.034300, val_acc: 52.08%\n",
      "Epoch [4292]/[5000], train_loss: 0.038800, train_acc: 94.78%, val_loss: 3.768200, val_acc: 54.82%\n",
      "Epoch [4293]/[5000], train_loss: 0.050700, train_acc: 94.19%, val_loss: 3.203400, val_acc: 53.65%\n",
      "Epoch [4294]/[5000], train_loss: 0.037600, train_acc: 94.82%, val_loss: 2.650800, val_acc: 53.52%\n",
      "Epoch [4295]/[5000], train_loss: 0.069500, train_acc: 93.95%, val_loss: 2.696400, val_acc: 52.47%\n",
      "Epoch [4296]/[5000], train_loss: 0.051800, train_acc: 94.63%, val_loss: 3.548200, val_acc: 54.69%\n",
      "Epoch [4297]/[5000], train_loss: 0.034400, train_acc: 95.07%, val_loss: 3.014600, val_acc: 55.73%\n",
      "Epoch [4298]/[5000], train_loss: 0.029000, train_acc: 95.02%, val_loss: 3.013900, val_acc: 53.52%\n",
      "Epoch [4299]/[5000], train_loss: 0.030700, train_acc: 94.92%, val_loss: 2.706000, val_acc: 57.29%\n",
      "Epoch [4300]/[5000], train_loss: 0.042600, train_acc: 94.73%, val_loss: 2.671700, val_acc: 54.95%\n",
      "Epoch [4301]/[5000], train_loss: 0.035600, train_acc: 94.68%, val_loss: 3.288300, val_acc: 53.52%\n",
      "Epoch [4302]/[5000], train_loss: 0.032500, train_acc: 95.07%, val_loss: 2.955200, val_acc: 53.65%\n",
      "Epoch [4303]/[5000], train_loss: 0.027200, train_acc: 95.26%, val_loss: 2.894400, val_acc: 55.60%\n",
      "Epoch [4304]/[5000], train_loss: 0.032900, train_acc: 94.92%, val_loss: 3.073400, val_acc: 54.04%\n",
      "Epoch [4305]/[5000], train_loss: 0.052600, train_acc: 94.38%, val_loss: 3.269000, val_acc: 57.03%\n",
      "Epoch [4306]/[5000], train_loss: 0.060200, train_acc: 94.73%, val_loss: 2.876500, val_acc: 54.17%\n",
      "Epoch [4307]/[5000], train_loss: 0.040900, train_acc: 94.73%, val_loss: 2.938000, val_acc: 54.69%\n",
      "Epoch [4308]/[5000], train_loss: 0.025900, train_acc: 95.61%, val_loss: 2.895400, val_acc: 55.86%\n",
      "Epoch [4309]/[5000], train_loss: 0.031300, train_acc: 95.12%, val_loss: 2.832300, val_acc: 55.99%\n",
      "Epoch [4310]/[5000], train_loss: 0.037600, train_acc: 94.87%, val_loss: 2.756000, val_acc: 55.60%\n",
      "Epoch [4311]/[5000], train_loss: 0.038400, train_acc: 94.63%, val_loss: 3.321300, val_acc: 54.04%\n",
      "Epoch [4312]/[5000], train_loss: 0.033100, train_acc: 94.97%, val_loss: 3.114500, val_acc: 54.95%\n",
      "Epoch [4313]/[5000], train_loss: 0.034300, train_acc: 94.73%, val_loss: 2.946800, val_acc: 55.21%\n",
      "Epoch [4314]/[5000], train_loss: 0.026300, train_acc: 95.07%, val_loss: 2.974300, val_acc: 53.26%\n",
      "Epoch [4315]/[5000], train_loss: 0.022600, train_acc: 95.36%, val_loss: 2.950800, val_acc: 54.95%\n",
      "Epoch [4316]/[5000], train_loss: 0.033100, train_acc: 94.97%, val_loss: 2.811100, val_acc: 55.47%\n",
      "Epoch [4317]/[5000], train_loss: 0.030400, train_acc: 94.87%, val_loss: 2.985200, val_acc: 55.60%\n",
      "Epoch [4318]/[5000], train_loss: 0.036300, train_acc: 94.73%, val_loss: 3.305300, val_acc: 52.08%\n",
      "Epoch [4319]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 3.151900, val_acc: 52.99%\n",
      "Epoch [4320]/[5000], train_loss: 0.020600, train_acc: 95.21%, val_loss: 2.554900, val_acc: 55.21%\n",
      "Epoch [4321]/[5000], train_loss: 0.035000, train_acc: 94.92%, val_loss: 3.020700, val_acc: 56.51%\n",
      "Epoch [4322]/[5000], train_loss: 0.036000, train_acc: 94.82%, val_loss: 3.028600, val_acc: 57.55%\n",
      "Epoch [4323]/[5000], train_loss: 0.049600, train_acc: 94.04%, val_loss: 3.511500, val_acc: 55.73%\n",
      "Epoch [4324]/[5000], train_loss: 0.038700, train_acc: 94.68%, val_loss: 3.469000, val_acc: 50.78%\n",
      "Epoch [4325]/[5000], train_loss: 0.033800, train_acc: 95.21%, val_loss: 3.168200, val_acc: 56.25%\n",
      "Epoch [4326]/[5000], train_loss: 0.043500, train_acc: 94.87%, val_loss: 3.061600, val_acc: 55.73%\n",
      "Epoch [4327]/[5000], train_loss: 0.032400, train_acc: 95.12%, val_loss: 3.193300, val_acc: 54.69%\n",
      "Epoch [4328]/[5000], train_loss: 0.038000, train_acc: 94.87%, val_loss: 2.787100, val_acc: 56.38%\n",
      "Epoch [4329]/[5000], train_loss: 0.029400, train_acc: 95.12%, val_loss: 3.113100, val_acc: 54.69%\n",
      "Epoch [4330]/[5000], train_loss: 0.033700, train_acc: 95.26%, val_loss: 3.238200, val_acc: 57.16%\n",
      "Epoch [4331]/[5000], train_loss: 0.044600, train_acc: 94.92%, val_loss: 3.418700, val_acc: 53.65%\n",
      "Epoch [4332]/[5000], train_loss: 0.084100, train_acc: 94.09%, val_loss: 3.167200, val_acc: 51.95%\n",
      "Epoch [4333]/[5000], train_loss: 0.068100, train_acc: 93.80%, val_loss: 2.828000, val_acc: 56.64%\n",
      "Epoch [4334]/[5000], train_loss: 0.045500, train_acc: 94.53%, val_loss: 2.550600, val_acc: 54.69%\n",
      "Epoch [4335]/[5000], train_loss: 0.035600, train_acc: 94.73%, val_loss: 2.779900, val_acc: 54.82%\n",
      "Epoch [4336]/[5000], train_loss: 0.052400, train_acc: 94.53%, val_loss: 2.677800, val_acc: 56.25%\n",
      "Epoch [4337]/[5000], train_loss: 0.042900, train_acc: 94.34%, val_loss: 3.303400, val_acc: 53.39%\n",
      "Epoch [4338]/[5000], train_loss: 0.027800, train_acc: 95.07%, val_loss: 3.187300, val_acc: 54.43%\n",
      "Epoch [4339]/[5000], train_loss: 0.026300, train_acc: 95.31%, val_loss: 2.806700, val_acc: 50.26%\n",
      "Epoch [4340]/[5000], train_loss: 0.042300, train_acc: 94.97%, val_loss: 2.655700, val_acc: 55.21%\n",
      "Epoch [4341]/[5000], train_loss: 0.018600, train_acc: 95.51%, val_loss: 3.001400, val_acc: 55.21%\n",
      "Epoch [4342]/[5000], train_loss: 0.032300, train_acc: 95.02%, val_loss: 2.941600, val_acc: 57.42%\n",
      "Epoch [4343]/[5000], train_loss: 0.028900, train_acc: 94.97%, val_loss: 3.176100, val_acc: 52.73%\n",
      "Epoch [4344]/[5000], train_loss: 0.023900, train_acc: 95.12%, val_loss: 3.143900, val_acc: 56.77%\n",
      "Epoch [4345]/[5000], train_loss: 0.016000, train_acc: 95.31%, val_loss: 3.080200, val_acc: 54.56%\n",
      "Epoch [4346]/[5000], train_loss: 0.026300, train_acc: 95.31%, val_loss: 2.775100, val_acc: 54.82%\n",
      "Epoch [4347]/[5000], train_loss: 0.026900, train_acc: 95.12%, val_loss: 2.714300, val_acc: 56.12%\n",
      "Epoch [4348]/[5000], train_loss: 0.028900, train_acc: 95.12%, val_loss: 2.990600, val_acc: 54.95%\n",
      "Epoch [4349]/[5000], train_loss: 0.026300, train_acc: 95.17%, val_loss: 2.961100, val_acc: 56.64%\n",
      "Epoch [4350]/[5000], train_loss: 0.021200, train_acc: 95.17%, val_loss: 2.759800, val_acc: 57.81%\n",
      "Epoch [4351]/[5000], train_loss: 0.054800, train_acc: 94.63%, val_loss: 3.060400, val_acc: 55.99%\n",
      "Epoch [4352]/[5000], train_loss: 0.048000, train_acc: 94.29%, val_loss: 3.113700, val_acc: 54.95%\n",
      "Epoch [4353]/[5000], train_loss: 0.026400, train_acc: 95.17%, val_loss: 2.911700, val_acc: 55.21%\n",
      "Epoch [4354]/[5000], train_loss: 0.025400, train_acc: 95.26%, val_loss: 3.188200, val_acc: 55.73%\n",
      "Epoch [4355]/[5000], train_loss: 0.035000, train_acc: 94.78%, val_loss: 2.767900, val_acc: 54.30%\n",
      "Epoch [4356]/[5000], train_loss: 0.032100, train_acc: 94.82%, val_loss: 3.457400, val_acc: 54.95%\n",
      "Epoch [4357]/[5000], train_loss: 0.035200, train_acc: 95.12%, val_loss: 2.966400, val_acc: 55.99%\n",
      "Epoch [4358]/[5000], train_loss: 0.025700, train_acc: 95.21%, val_loss: 3.136200, val_acc: 55.99%\n",
      "Epoch [4359]/[5000], train_loss: 0.024100, train_acc: 95.31%, val_loss: 2.770800, val_acc: 55.86%\n",
      "Epoch [4360]/[5000], train_loss: 0.039700, train_acc: 94.73%, val_loss: 3.188300, val_acc: 52.21%\n",
      "Epoch [4361]/[5000], train_loss: 0.031500, train_acc: 94.97%, val_loss: 3.050500, val_acc: 56.51%\n",
      "Epoch [4362]/[5000], train_loss: 0.013200, train_acc: 95.61%, val_loss: 2.835900, val_acc: 55.21%\n",
      "Epoch [4363]/[5000], train_loss: 0.031400, train_acc: 94.97%, val_loss: 2.580200, val_acc: 56.51%\n",
      "Epoch [4364]/[5000], train_loss: 0.013000, train_acc: 95.90%, val_loss: 2.816200, val_acc: 57.68%\n",
      "Epoch [4365]/[5000], train_loss: 0.031800, train_acc: 94.92%, val_loss: 3.001200, val_acc: 53.65%\n",
      "Epoch [4366]/[5000], train_loss: 0.033000, train_acc: 95.02%, val_loss: 3.111200, val_acc: 57.29%\n",
      "Epoch [4367]/[5000], train_loss: 0.029200, train_acc: 95.12%, val_loss: 2.851000, val_acc: 55.21%\n",
      "Epoch [4368]/[5000], train_loss: 0.027600, train_acc: 95.07%, val_loss: 2.857000, val_acc: 52.60%\n",
      "Epoch [4369]/[5000], train_loss: 0.016600, train_acc: 95.61%, val_loss: 2.960600, val_acc: 54.17%\n",
      "Epoch [4370]/[5000], train_loss: 0.025700, train_acc: 95.41%, val_loss: 3.101900, val_acc: 56.25%\n",
      "Epoch [4371]/[5000], train_loss: 0.025800, train_acc: 95.21%, val_loss: 2.916700, val_acc: 55.34%\n",
      "Epoch [4372]/[5000], train_loss: 0.028300, train_acc: 94.97%, val_loss: 3.124500, val_acc: 54.95%\n",
      "Epoch [4373]/[5000], train_loss: 0.022600, train_acc: 95.41%, val_loss: 2.845100, val_acc: 57.81%\n",
      "Epoch [4374]/[5000], train_loss: 0.025800, train_acc: 95.17%, val_loss: 3.320600, val_acc: 56.25%\n",
      "Epoch [4375]/[5000], train_loss: 0.030300, train_acc: 95.31%, val_loss: 2.991600, val_acc: 55.60%\n",
      "Epoch [4376]/[5000], train_loss: 0.026100, train_acc: 95.02%, val_loss: 3.010300, val_acc: 54.43%\n",
      "Epoch [4377]/[5000], train_loss: 0.025200, train_acc: 95.26%, val_loss: 2.962600, val_acc: 56.38%\n",
      "Epoch [4378]/[5000], train_loss: 0.018800, train_acc: 95.51%, val_loss: 3.001800, val_acc: 52.86%\n",
      "Epoch [4379]/[5000], train_loss: 0.031500, train_acc: 95.17%, val_loss: 2.981800, val_acc: 53.39%\n",
      "Epoch [4380]/[5000], train_loss: 0.027400, train_acc: 95.02%, val_loss: 3.121200, val_acc: 54.17%\n",
      "Epoch [4381]/[5000], train_loss: 0.046800, train_acc: 94.53%, val_loss: 2.471300, val_acc: 56.77%\n",
      "Epoch [4382]/[5000], train_loss: 0.038200, train_acc: 94.73%, val_loss: 3.143100, val_acc: 52.99%\n",
      "Epoch [4383]/[5000], train_loss: 0.021800, train_acc: 95.31%, val_loss: 3.186400, val_acc: 55.47%\n",
      "Epoch [4384]/[5000], train_loss: 0.050000, train_acc: 94.53%, val_loss: 2.680100, val_acc: 58.07%\n",
      "Epoch [4385]/[5000], train_loss: 0.036100, train_acc: 95.07%, val_loss: 2.754300, val_acc: 52.47%\n",
      "Epoch [4386]/[5000], train_loss: 0.038500, train_acc: 94.82%, val_loss: 3.501900, val_acc: 56.12%\n",
      "Epoch [4387]/[5000], train_loss: 0.031200, train_acc: 94.58%, val_loss: 3.057700, val_acc: 54.69%\n",
      "Epoch [4388]/[5000], train_loss: 0.018600, train_acc: 95.46%, val_loss: 3.001400, val_acc: 55.47%\n",
      "Epoch [4389]/[5000], train_loss: 0.014500, train_acc: 95.56%, val_loss: 3.135800, val_acc: 55.99%\n",
      "Epoch [4390]/[5000], train_loss: 0.019700, train_acc: 95.41%, val_loss: 2.982700, val_acc: 56.51%\n",
      "Epoch [4391]/[5000], train_loss: 0.023900, train_acc: 95.21%, val_loss: 3.160500, val_acc: 54.82%\n",
      "Epoch [4392]/[5000], train_loss: 0.025000, train_acc: 95.51%, val_loss: 3.172000, val_acc: 55.47%\n",
      "Epoch [4393]/[5000], train_loss: 0.061400, train_acc: 94.14%, val_loss: 3.307600, val_acc: 55.21%\n",
      "Epoch [4394]/[5000], train_loss: 0.045500, train_acc: 94.68%, val_loss: 2.856000, val_acc: 54.30%\n",
      "Epoch [4395]/[5000], train_loss: 0.028200, train_acc: 94.97%, val_loss: 3.254800, val_acc: 53.91%\n",
      "Epoch [4396]/[5000], train_loss: 0.030000, train_acc: 94.97%, val_loss: 2.863100, val_acc: 55.73%\n",
      "Epoch [4397]/[5000], train_loss: 0.035300, train_acc: 94.97%, val_loss: 3.448300, val_acc: 52.99%\n",
      "Epoch [4398]/[5000], train_loss: 0.018000, train_acc: 95.61%, val_loss: 2.965200, val_acc: 57.16%\n",
      "Epoch [4399]/[5000], train_loss: 0.042000, train_acc: 94.82%, val_loss: 3.210500, val_acc: 55.86%\n",
      "Epoch [4400]/[5000], train_loss: 0.031400, train_acc: 95.17%, val_loss: 2.856200, val_acc: 53.91%\n",
      "Epoch [4401]/[5000], train_loss: 0.040800, train_acc: 95.02%, val_loss: 2.776500, val_acc: 55.86%\n",
      "Epoch [4402]/[5000], train_loss: 0.057300, train_acc: 94.09%, val_loss: 3.386100, val_acc: 55.86%\n",
      "Epoch [4403]/[5000], train_loss: 0.070700, train_acc: 94.24%, val_loss: 3.002700, val_acc: 53.52%\n",
      "Epoch [4404]/[5000], train_loss: 0.081000, train_acc: 93.65%, val_loss: 2.671400, val_acc: 52.08%\n",
      "Epoch [4405]/[5000], train_loss: 0.078600, train_acc: 93.60%, val_loss: 3.159600, val_acc: 54.30%\n",
      "Epoch [4406]/[5000], train_loss: 0.066500, train_acc: 93.75%, val_loss: 3.429200, val_acc: 53.91%\n",
      "Epoch [4407]/[5000], train_loss: 0.056100, train_acc: 94.43%, val_loss: 2.876900, val_acc: 53.65%\n",
      "Epoch [4408]/[5000], train_loss: 0.029800, train_acc: 95.12%, val_loss: 2.910000, val_acc: 53.52%\n",
      "Epoch [4409]/[5000], train_loss: 0.049700, train_acc: 94.43%, val_loss: 3.273700, val_acc: 54.82%\n",
      "Epoch [4410]/[5000], train_loss: 0.027900, train_acc: 95.12%, val_loss: 3.022200, val_acc: 55.60%\n",
      "Epoch [4411]/[5000], train_loss: 0.030400, train_acc: 95.17%, val_loss: 2.559000, val_acc: 54.69%\n",
      "Epoch [4412]/[5000], train_loss: 0.027400, train_acc: 95.12%, val_loss: 3.031400, val_acc: 58.72%\n",
      "Epoch [4413]/[5000], train_loss: 0.030700, train_acc: 95.02%, val_loss: 2.918600, val_acc: 54.43%\n",
      "Epoch [4414]/[5000], train_loss: 0.026500, train_acc: 95.21%, val_loss: 3.024100, val_acc: 52.08%\n",
      "Epoch [4415]/[5000], train_loss: 0.028200, train_acc: 95.21%, val_loss: 2.655900, val_acc: 54.95%\n",
      "Epoch [4416]/[5000], train_loss: 0.030600, train_acc: 95.12%, val_loss: 3.227100, val_acc: 54.95%\n",
      "Epoch [4417]/[5000], train_loss: 0.029000, train_acc: 95.36%, val_loss: 2.793500, val_acc: 57.29%\n",
      "Epoch [4418]/[5000], train_loss: 0.019400, train_acc: 95.65%, val_loss: 2.737200, val_acc: 55.73%\n",
      "Epoch [4419]/[5000], train_loss: 0.018900, train_acc: 95.56%, val_loss: 3.258300, val_acc: 55.60%\n",
      "Epoch [4420]/[5000], train_loss: 0.022300, train_acc: 95.46%, val_loss: 2.795400, val_acc: 57.42%\n",
      "Epoch [4421]/[5000], train_loss: 0.029600, train_acc: 95.02%, val_loss: 3.157300, val_acc: 56.77%\n",
      "Epoch [4422]/[5000], train_loss: 0.020400, train_acc: 95.41%, val_loss: 2.595100, val_acc: 54.95%\n",
      "Epoch [4423]/[5000], train_loss: 0.019600, train_acc: 95.46%, val_loss: 3.211400, val_acc: 54.95%\n",
      "Epoch [4424]/[5000], train_loss: 0.014000, train_acc: 95.75%, val_loss: 3.170700, val_acc: 54.43%\n",
      "Epoch [4425]/[5000], train_loss: 0.016300, train_acc: 95.61%, val_loss: 2.626600, val_acc: 57.55%\n",
      "Epoch [4426]/[5000], train_loss: 0.020000, train_acc: 95.56%, val_loss: 3.207700, val_acc: 55.08%\n",
      "Epoch [4427]/[5000], train_loss: 0.012500, train_acc: 95.80%, val_loss: 2.961800, val_acc: 56.64%\n",
      "Epoch [4428]/[5000], train_loss: 0.020600, train_acc: 95.46%, val_loss: 3.372800, val_acc: 53.91%\n",
      "Epoch [4429]/[5000], train_loss: 0.024700, train_acc: 95.17%, val_loss: 2.669600, val_acc: 53.78%\n",
      "Epoch [4430]/[5000], train_loss: 0.034100, train_acc: 94.63%, val_loss: 3.493500, val_acc: 54.17%\n",
      "Epoch [4431]/[5000], train_loss: 0.040600, train_acc: 95.07%, val_loss: 2.877500, val_acc: 53.91%\n",
      "Epoch [4432]/[5000], train_loss: 0.023500, train_acc: 95.17%, val_loss: 3.407900, val_acc: 57.16%\n",
      "Epoch [4433]/[5000], train_loss: 0.033900, train_acc: 94.82%, val_loss: 3.058500, val_acc: 55.21%\n",
      "Epoch [4434]/[5000], train_loss: 0.042600, train_acc: 94.82%, val_loss: 2.949200, val_acc: 55.34%\n",
      "Epoch [4435]/[5000], train_loss: 0.048500, train_acc: 94.19%, val_loss: 2.814100, val_acc: 55.60%\n",
      "Epoch [4436]/[5000], train_loss: 0.049900, train_acc: 94.63%, val_loss: 3.103100, val_acc: 55.21%\n",
      "Epoch [4437]/[5000], train_loss: 0.051900, train_acc: 94.53%, val_loss: 2.946600, val_acc: 51.69%\n",
      "Epoch [4438]/[5000], train_loss: 0.056600, train_acc: 94.29%, val_loss: 2.998300, val_acc: 53.26%\n",
      "Epoch [4439]/[5000], train_loss: 0.049900, train_acc: 94.53%, val_loss: 3.024500, val_acc: 54.69%\n",
      "Epoch [4440]/[5000], train_loss: 0.037800, train_acc: 94.92%, val_loss: 3.637600, val_acc: 55.34%\n",
      "Epoch [4441]/[5000], train_loss: 0.046200, train_acc: 94.92%, val_loss: 2.917600, val_acc: 55.86%\n",
      "Epoch [4442]/[5000], train_loss: 0.036000, train_acc: 94.82%, val_loss: 3.090500, val_acc: 55.86%\n",
      "Epoch [4443]/[5000], train_loss: 0.036500, train_acc: 95.07%, val_loss: 2.966100, val_acc: 54.04%\n",
      "Epoch [4444]/[5000], train_loss: 0.036400, train_acc: 95.07%, val_loss: 3.660300, val_acc: 54.56%\n",
      "Epoch [4445]/[5000], train_loss: 0.033000, train_acc: 95.02%, val_loss: 3.204300, val_acc: 56.64%\n",
      "Epoch [4446]/[5000], train_loss: 0.038400, train_acc: 94.63%, val_loss: 3.163400, val_acc: 55.86%\n",
      "Epoch [4447]/[5000], train_loss: 0.027600, train_acc: 95.12%, val_loss: 2.548100, val_acc: 55.86%\n",
      "Epoch [4448]/[5000], train_loss: 0.023900, train_acc: 95.41%, val_loss: 2.852300, val_acc: 57.16%\n",
      "Epoch [4449]/[5000], train_loss: 0.020800, train_acc: 95.51%, val_loss: 2.648400, val_acc: 55.60%\n",
      "Epoch [4450]/[5000], train_loss: 0.020500, train_acc: 95.36%, val_loss: 3.378900, val_acc: 54.17%\n",
      "Epoch [4451]/[5000], train_loss: 0.025000, train_acc: 95.41%, val_loss: 2.874000, val_acc: 56.64%\n",
      "Epoch [4452]/[5000], train_loss: 0.020800, train_acc: 95.31%, val_loss: 3.094400, val_acc: 54.43%\n",
      "Epoch [4453]/[5000], train_loss: 0.021900, train_acc: 95.41%, val_loss: 2.899200, val_acc: 54.56%\n",
      "Epoch [4454]/[5000], train_loss: 0.021600, train_acc: 95.26%, val_loss: 3.002100, val_acc: 56.38%\n",
      "Epoch [4455]/[5000], train_loss: 0.025200, train_acc: 95.12%, val_loss: 3.445700, val_acc: 53.65%\n",
      "Epoch [4456]/[5000], train_loss: 0.026400, train_acc: 95.31%, val_loss: 3.142400, val_acc: 53.39%\n",
      "Epoch [4457]/[5000], train_loss: 0.018300, train_acc: 95.51%, val_loss: 2.931400, val_acc: 55.21%\n",
      "Epoch [4458]/[5000], train_loss: 0.018600, train_acc: 95.61%, val_loss: 3.358500, val_acc: 55.47%\n",
      "Epoch [4459]/[5000], train_loss: 0.012300, train_acc: 95.65%, val_loss: 3.269700, val_acc: 55.73%\n",
      "Epoch [4460]/[5000], train_loss: 0.013600, train_acc: 95.80%, val_loss: 3.428500, val_acc: 55.86%\n",
      "Epoch [4461]/[5000], train_loss: 0.020900, train_acc: 95.70%, val_loss: 3.193000, val_acc: 55.86%\n",
      "Epoch [4462]/[5000], train_loss: 0.017400, train_acc: 95.56%, val_loss: 2.893600, val_acc: 56.12%\n",
      "Epoch [4463]/[5000], train_loss: 0.027500, train_acc: 95.56%, val_loss: 3.195200, val_acc: 52.34%\n",
      "Epoch [4464]/[5000], train_loss: 0.042500, train_acc: 95.07%, val_loss: 3.506100, val_acc: 56.90%\n",
      "Epoch [4465]/[5000], train_loss: 0.018700, train_acc: 95.41%, val_loss: 3.080800, val_acc: 55.21%\n",
      "Epoch [4466]/[5000], train_loss: 0.040200, train_acc: 94.92%, val_loss: 3.011900, val_acc: 55.99%\n",
      "Epoch [4467]/[5000], train_loss: 0.020300, train_acc: 95.46%, val_loss: 3.378800, val_acc: 55.99%\n",
      "Epoch [4468]/[5000], train_loss: 0.015900, train_acc: 95.65%, val_loss: 3.663600, val_acc: 55.73%\n",
      "Epoch [4469]/[5000], train_loss: 0.014700, train_acc: 95.65%, val_loss: 3.359600, val_acc: 57.42%\n",
      "Epoch [4470]/[5000], train_loss: 0.019700, train_acc: 95.61%, val_loss: 2.637100, val_acc: 55.08%\n",
      "Epoch [4471]/[5000], train_loss: 0.038300, train_acc: 94.92%, val_loss: 3.322000, val_acc: 53.78%\n",
      "Epoch [4472]/[5000], train_loss: 0.031600, train_acc: 95.17%, val_loss: 3.028500, val_acc: 55.99%\n",
      "Epoch [4473]/[5000], train_loss: 0.016400, train_acc: 95.46%, val_loss: 2.952500, val_acc: 53.65%\n",
      "Epoch [4474]/[5000], train_loss: 0.026600, train_acc: 95.07%, val_loss: 3.094500, val_acc: 54.30%\n",
      "Epoch [4475]/[5000], train_loss: 0.027300, train_acc: 95.21%, val_loss: 3.377500, val_acc: 55.21%\n",
      "Epoch [4476]/[5000], train_loss: 0.035200, train_acc: 94.68%, val_loss: 2.966800, val_acc: 55.60%\n",
      "Epoch [4477]/[5000], train_loss: 0.038300, train_acc: 94.87%, val_loss: 3.109000, val_acc: 54.95%\n",
      "Epoch [4478]/[5000], train_loss: 0.023800, train_acc: 95.31%, val_loss: 3.143600, val_acc: 54.69%\n",
      "Epoch [4479]/[5000], train_loss: 0.028700, train_acc: 95.12%, val_loss: 2.985900, val_acc: 55.73%\n",
      "Epoch [4480]/[5000], train_loss: 0.033400, train_acc: 94.97%, val_loss: 3.004300, val_acc: 56.51%\n",
      "Epoch [4481]/[5000], train_loss: 0.058200, train_acc: 93.99%, val_loss: 2.933900, val_acc: 53.26%\n",
      "Epoch [4482]/[5000], train_loss: 0.052800, train_acc: 94.29%, val_loss: 2.813100, val_acc: 54.30%\n",
      "Epoch [4483]/[5000], train_loss: 0.045100, train_acc: 94.58%, val_loss: 3.043300, val_acc: 54.69%\n",
      "Epoch [4484]/[5000], train_loss: 0.040700, train_acc: 94.58%, val_loss: 2.667900, val_acc: 56.25%\n",
      "Epoch [4485]/[5000], train_loss: 0.038800, train_acc: 94.97%, val_loss: 2.973400, val_acc: 56.25%\n",
      "Epoch [4486]/[5000], train_loss: 0.022400, train_acc: 95.31%, val_loss: 3.097900, val_acc: 55.21%\n",
      "Epoch [4487]/[5000], train_loss: 0.032600, train_acc: 94.92%, val_loss: 3.098900, val_acc: 52.47%\n",
      "Epoch [4488]/[5000], train_loss: 0.028200, train_acc: 95.21%, val_loss: 3.072200, val_acc: 54.69%\n",
      "Epoch [4489]/[5000], train_loss: 0.023600, train_acc: 95.51%, val_loss: 2.658700, val_acc: 54.82%\n",
      "Epoch [4490]/[5000], train_loss: 0.039800, train_acc: 94.87%, val_loss: 3.391900, val_acc: 54.95%\n",
      "Epoch [4491]/[5000], train_loss: 0.050900, train_acc: 94.38%, val_loss: 2.567100, val_acc: 54.43%\n",
      "Epoch [4492]/[5000], train_loss: 0.030400, train_acc: 95.26%, val_loss: 3.183000, val_acc: 54.04%\n",
      "Epoch [4493]/[5000], train_loss: 0.060200, train_acc: 94.29%, val_loss: 2.710100, val_acc: 56.38%\n",
      "Epoch [4494]/[5000], train_loss: 0.041800, train_acc: 94.73%, val_loss: 3.037400, val_acc: 54.69%\n",
      "Epoch [4495]/[5000], train_loss: 0.043200, train_acc: 94.58%, val_loss: 3.113900, val_acc: 55.47%\n",
      "Epoch [4496]/[5000], train_loss: 0.027000, train_acc: 95.21%, val_loss: 3.329600, val_acc: 52.47%\n",
      "Epoch [4497]/[5000], train_loss: 0.041300, train_acc: 94.68%, val_loss: 3.296700, val_acc: 55.34%\n",
      "Epoch [4498]/[5000], train_loss: 0.049100, train_acc: 94.43%, val_loss: 2.756300, val_acc: 53.26%\n",
      "Epoch [4499]/[5000], train_loss: 0.066200, train_acc: 93.85%, val_loss: 2.919400, val_acc: 55.99%\n",
      "Epoch [4500]/[5000], train_loss: 0.039100, train_acc: 94.53%, val_loss: 3.528400, val_acc: 52.99%\n",
      "Epoch [4501]/[5000], train_loss: 0.038000, train_acc: 94.73%, val_loss: 2.775600, val_acc: 55.73%\n",
      "Epoch [4502]/[5000], train_loss: 0.021400, train_acc: 95.26%, val_loss: 3.008600, val_acc: 55.60%\n",
      "Epoch [4503]/[5000], train_loss: 0.022200, train_acc: 95.26%, val_loss: 3.036000, val_acc: 56.64%\n",
      "Epoch [4504]/[5000], train_loss: 0.015500, train_acc: 95.51%, val_loss: 3.044100, val_acc: 57.42%\n",
      "Epoch [4505]/[5000], train_loss: 0.012400, train_acc: 95.70%, val_loss: 2.652700, val_acc: 56.64%\n",
      "Epoch [4506]/[5000], train_loss: 0.017500, train_acc: 95.65%, val_loss: 2.805000, val_acc: 55.73%\n",
      "Epoch [4507]/[5000], train_loss: 0.014800, train_acc: 95.65%, val_loss: 2.577000, val_acc: 57.29%\n",
      "Epoch [4508]/[5000], train_loss: 0.016800, train_acc: 95.41%, val_loss: 2.735400, val_acc: 56.25%\n",
      "Epoch [4509]/[5000], train_loss: 0.015900, train_acc: 95.85%, val_loss: 3.053500, val_acc: 56.38%\n",
      "Epoch [4510]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 2.889000, val_acc: 57.94%\n",
      "Epoch [4511]/[5000], train_loss: 0.017200, train_acc: 95.41%, val_loss: 2.773800, val_acc: 54.69%\n",
      "Epoch [4512]/[5000], train_loss: 0.010900, train_acc: 95.65%, val_loss: 2.883100, val_acc: 55.34%\n",
      "Epoch [4513]/[5000], train_loss: 0.013800, train_acc: 95.51%, val_loss: 2.895200, val_acc: 55.47%\n",
      "Epoch [4514]/[5000], train_loss: 0.018400, train_acc: 95.75%, val_loss: 2.834800, val_acc: 54.69%\n",
      "Epoch [4515]/[5000], train_loss: 0.015200, train_acc: 95.61%, val_loss: 2.845400, val_acc: 55.99%\n",
      "Epoch [4516]/[5000], train_loss: 0.017500, train_acc: 95.46%, val_loss: 3.181300, val_acc: 56.25%\n",
      "Epoch [4517]/[5000], train_loss: 0.017200, train_acc: 95.41%, val_loss: 3.315900, val_acc: 56.12%\n",
      "Epoch [4518]/[5000], train_loss: 0.037900, train_acc: 95.51%, val_loss: 2.952700, val_acc: 56.64%\n",
      "Epoch [4519]/[5000], train_loss: 0.029700, train_acc: 95.21%, val_loss: 2.834100, val_acc: 55.60%\n",
      "Epoch [4520]/[5000], train_loss: 0.039100, train_acc: 95.07%, val_loss: 2.863500, val_acc: 56.90%\n",
      "Epoch [4521]/[5000], train_loss: 0.041500, train_acc: 94.92%, val_loss: 3.393500, val_acc: 57.94%\n",
      "Epoch [4522]/[5000], train_loss: 0.036700, train_acc: 94.63%, val_loss: 3.054900, val_acc: 53.78%\n",
      "Epoch [4523]/[5000], train_loss: 0.024900, train_acc: 95.31%, val_loss: 3.615800, val_acc: 55.21%\n",
      "Epoch [4524]/[5000], train_loss: 0.033100, train_acc: 95.36%, val_loss: 3.152200, val_acc: 55.34%\n",
      "Epoch [4525]/[5000], train_loss: 0.033100, train_acc: 95.26%, val_loss: 3.602900, val_acc: 54.82%\n",
      "Epoch [4526]/[5000], train_loss: 0.019200, train_acc: 95.41%, val_loss: 2.897200, val_acc: 55.34%\n",
      "Epoch [4527]/[5000], train_loss: 0.032900, train_acc: 95.17%, val_loss: 3.395800, val_acc: 54.82%\n",
      "Epoch [4528]/[5000], train_loss: 0.035100, train_acc: 94.97%, val_loss: 2.701300, val_acc: 54.04%\n",
      "Epoch [4529]/[5000], train_loss: 0.033700, train_acc: 94.92%, val_loss: 3.342300, val_acc: 55.21%\n",
      "Epoch [4530]/[5000], train_loss: 0.055500, train_acc: 94.43%, val_loss: 3.144600, val_acc: 53.12%\n",
      "Epoch [4531]/[5000], train_loss: 0.040900, train_acc: 94.68%, val_loss: 2.857000, val_acc: 53.12%\n",
      "Epoch [4532]/[5000], train_loss: 0.031900, train_acc: 95.02%, val_loss: 3.067800, val_acc: 54.69%\n",
      "Epoch [4533]/[5000], train_loss: 0.035500, train_acc: 94.63%, val_loss: 2.946200, val_acc: 54.95%\n",
      "Epoch [4534]/[5000], train_loss: 0.032900, train_acc: 94.78%, val_loss: 2.956800, val_acc: 54.69%\n",
      "Epoch [4535]/[5000], train_loss: 0.036200, train_acc: 95.02%, val_loss: 3.199700, val_acc: 53.26%\n",
      "Epoch [4536]/[5000], train_loss: 0.067600, train_acc: 94.24%, val_loss: 3.277600, val_acc: 53.78%\n",
      "Epoch [4537]/[5000], train_loss: 0.047100, train_acc: 94.38%, val_loss: 3.398600, val_acc: 54.30%\n",
      "Epoch [4538]/[5000], train_loss: 0.054700, train_acc: 94.48%, val_loss: 3.363800, val_acc: 52.99%\n",
      "Epoch [4539]/[5000], train_loss: 0.051800, train_acc: 93.95%, val_loss: 3.509200, val_acc: 52.73%\n",
      "Epoch [4540]/[5000], train_loss: 0.068100, train_acc: 94.29%, val_loss: 3.032200, val_acc: 53.52%\n",
      "Epoch [4541]/[5000], train_loss: 0.103000, train_acc: 93.75%, val_loss: 2.901100, val_acc: 54.30%\n",
      "Epoch [4542]/[5000], train_loss: 0.067800, train_acc: 94.34%, val_loss: 2.828700, val_acc: 52.60%\n",
      "Epoch [4543]/[5000], train_loss: 0.113000, train_acc: 92.68%, val_loss: 3.043000, val_acc: 52.60%\n",
      "Epoch [4544]/[5000], train_loss: 0.087100, train_acc: 92.92%, val_loss: 2.853500, val_acc: 54.56%\n",
      "Epoch [4545]/[5000], train_loss: 0.059000, train_acc: 94.09%, val_loss: 2.924100, val_acc: 54.04%\n",
      "Epoch [4546]/[5000], train_loss: 0.046400, train_acc: 94.38%, val_loss: 2.865800, val_acc: 54.95%\n",
      "Epoch [4547]/[5000], train_loss: 0.034700, train_acc: 94.82%, val_loss: 2.702300, val_acc: 54.43%\n",
      "Epoch [4548]/[5000], train_loss: 0.027500, train_acc: 95.17%, val_loss: 2.784400, val_acc: 53.65%\n",
      "Epoch [4549]/[5000], train_loss: 0.033100, train_acc: 94.97%, val_loss: 3.626100, val_acc: 53.78%\n",
      "Epoch [4550]/[5000], train_loss: 0.027100, train_acc: 95.02%, val_loss: 3.226800, val_acc: 56.38%\n",
      "Epoch [4551]/[5000], train_loss: 0.026200, train_acc: 95.41%, val_loss: 2.998700, val_acc: 54.43%\n",
      "Epoch [4552]/[5000], train_loss: 0.018000, train_acc: 95.36%, val_loss: 3.041600, val_acc: 56.25%\n",
      "Epoch [4553]/[5000], train_loss: 0.023700, train_acc: 95.36%, val_loss: 3.084400, val_acc: 55.86%\n",
      "Epoch [4554]/[5000], train_loss: 0.020400, train_acc: 95.75%, val_loss: 2.611400, val_acc: 55.47%\n",
      "Epoch [4555]/[5000], train_loss: 0.024500, train_acc: 95.36%, val_loss: 3.163500, val_acc: 54.17%\n",
      "Epoch [4556]/[5000], train_loss: 0.017500, train_acc: 95.41%, val_loss: 2.880200, val_acc: 53.12%\n",
      "Epoch [4557]/[5000], train_loss: 0.031900, train_acc: 95.31%, val_loss: 3.177400, val_acc: 55.47%\n",
      "Epoch [4558]/[5000], train_loss: 0.015000, train_acc: 95.61%, val_loss: 2.912500, val_acc: 54.82%\n",
      "Epoch [4559]/[5000], train_loss: 0.017900, train_acc: 95.41%, val_loss: 2.849400, val_acc: 55.21%\n",
      "Epoch [4560]/[5000], train_loss: 0.017800, train_acc: 95.46%, val_loss: 3.346500, val_acc: 55.60%\n",
      "Epoch [4561]/[5000], train_loss: 0.032500, train_acc: 95.31%, val_loss: 2.813900, val_acc: 55.73%\n",
      "Epoch [4562]/[5000], train_loss: 0.032700, train_acc: 95.17%, val_loss: 3.229300, val_acc: 56.12%\n",
      "Epoch [4563]/[5000], train_loss: 0.028900, train_acc: 94.92%, val_loss: 3.033500, val_acc: 52.34%\n",
      "Epoch [4564]/[5000], train_loss: 0.039300, train_acc: 95.07%, val_loss: 2.980300, val_acc: 51.95%\n",
      "Epoch [4565]/[5000], train_loss: 0.025100, train_acc: 95.46%, val_loss: 2.836700, val_acc: 54.30%\n",
      "Epoch [4566]/[5000], train_loss: 0.030100, train_acc: 95.02%, val_loss: 3.336700, val_acc: 54.56%\n",
      "Epoch [4567]/[5000], train_loss: 0.017500, train_acc: 95.56%, val_loss: 2.787900, val_acc: 55.21%\n",
      "Epoch [4568]/[5000], train_loss: 0.022400, train_acc: 95.51%, val_loss: 2.689200, val_acc: 55.60%\n",
      "Epoch [4569]/[5000], train_loss: 0.023400, train_acc: 95.51%, val_loss: 3.257400, val_acc: 55.34%\n",
      "Epoch [4570]/[5000], train_loss: 0.016200, train_acc: 95.56%, val_loss: 2.928800, val_acc: 54.95%\n",
      "Epoch [4571]/[5000], train_loss: 0.023600, train_acc: 95.41%, val_loss: 3.177900, val_acc: 54.56%\n",
      "Epoch [4572]/[5000], train_loss: 0.017000, train_acc: 95.36%, val_loss: 2.965100, val_acc: 54.30%\n",
      "Epoch [4573]/[5000], train_loss: 0.028100, train_acc: 95.21%, val_loss: 3.167900, val_acc: 54.95%\n",
      "Epoch [4574]/[5000], train_loss: 0.029000, train_acc: 95.21%, val_loss: 2.728400, val_acc: 55.34%\n",
      "Epoch [4575]/[5000], train_loss: 0.038300, train_acc: 94.68%, val_loss: 2.761900, val_acc: 54.30%\n",
      "Epoch [4576]/[5000], train_loss: 0.049800, train_acc: 94.34%, val_loss: 3.123300, val_acc: 54.69%\n",
      "Epoch [4577]/[5000], train_loss: 0.026900, train_acc: 95.21%, val_loss: 3.323800, val_acc: 55.73%\n",
      "Epoch [4578]/[5000], train_loss: 0.043700, train_acc: 94.82%, val_loss: 3.203600, val_acc: 52.73%\n",
      "Epoch [4579]/[5000], train_loss: 0.027900, train_acc: 95.31%, val_loss: 3.608200, val_acc: 54.95%\n",
      "Epoch [4580]/[5000], train_loss: 0.037200, train_acc: 94.97%, val_loss: 3.056100, val_acc: 56.90%\n",
      "Epoch [4581]/[5000], train_loss: 0.031400, train_acc: 94.97%, val_loss: 3.115200, val_acc: 53.52%\n",
      "Epoch [4582]/[5000], train_loss: 0.030700, train_acc: 95.07%, val_loss: 3.142000, val_acc: 51.95%\n",
      "Epoch [4583]/[5000], train_loss: 0.038700, train_acc: 95.07%, val_loss: 3.067100, val_acc: 56.12%\n",
      "Epoch [4584]/[5000], train_loss: 0.035100, train_acc: 94.92%, val_loss: 3.213700, val_acc: 54.04%\n",
      "Epoch [4585]/[5000], train_loss: 0.058500, train_acc: 94.34%, val_loss: 2.540500, val_acc: 55.86%\n",
      "Epoch [4586]/[5000], train_loss: 0.037500, train_acc: 94.73%, val_loss: 2.994500, val_acc: 55.47%\n",
      "Epoch [4587]/[5000], train_loss: 0.032900, train_acc: 94.97%, val_loss: 3.134600, val_acc: 54.95%\n",
      "Epoch [4588]/[5000], train_loss: 0.022400, train_acc: 95.31%, val_loss: 3.345700, val_acc: 55.73%\n",
      "Epoch [4589]/[5000], train_loss: 0.018100, train_acc: 95.46%, val_loss: 3.042100, val_acc: 55.73%\n",
      "Epoch [4590]/[5000], train_loss: 0.023900, train_acc: 95.17%, val_loss: 3.214100, val_acc: 54.69%\n",
      "Epoch [4591]/[5000], train_loss: 0.019700, train_acc: 95.41%, val_loss: 3.011700, val_acc: 55.34%\n",
      "Epoch [4592]/[5000], train_loss: 0.024700, train_acc: 95.21%, val_loss: 2.682000, val_acc: 56.12%\n",
      "Epoch [4593]/[5000], train_loss: 0.014100, train_acc: 95.65%, val_loss: 3.261600, val_acc: 54.43%\n",
      "Epoch [4594]/[5000], train_loss: 0.017800, train_acc: 95.46%, val_loss: 2.879200, val_acc: 56.64%\n",
      "Epoch [4595]/[5000], train_loss: 0.024000, train_acc: 95.56%, val_loss: 3.495900, val_acc: 55.99%\n",
      "Epoch [4596]/[5000], train_loss: 0.025600, train_acc: 95.31%, val_loss: 3.003700, val_acc: 55.08%\n",
      "Epoch [4597]/[5000], train_loss: 0.026700, train_acc: 95.17%, val_loss: 3.261900, val_acc: 55.21%\n",
      "Epoch [4598]/[5000], train_loss: 0.029300, train_acc: 95.12%, val_loss: 3.316600, val_acc: 51.82%\n",
      "Epoch [4599]/[5000], train_loss: 0.027000, train_acc: 95.17%, val_loss: 3.290700, val_acc: 55.34%\n",
      "Epoch [4600]/[5000], train_loss: 0.026700, train_acc: 95.31%, val_loss: 3.175600, val_acc: 54.69%\n",
      "Epoch [4601]/[5000], train_loss: 0.026800, train_acc: 95.31%, val_loss: 2.960200, val_acc: 56.51%\n",
      "Epoch [4602]/[5000], train_loss: 0.032600, train_acc: 94.82%, val_loss: 2.652000, val_acc: 56.38%\n",
      "Epoch [4603]/[5000], train_loss: 0.036500, train_acc: 95.12%, val_loss: 3.127800, val_acc: 57.16%\n",
      "Epoch [4604]/[5000], train_loss: 0.028800, train_acc: 95.17%, val_loss: 3.042500, val_acc: 52.73%\n",
      "Epoch [4605]/[5000], train_loss: 0.022100, train_acc: 95.36%, val_loss: 2.955000, val_acc: 55.99%\n",
      "Epoch [4606]/[5000], train_loss: 0.024300, train_acc: 95.02%, val_loss: 3.008500, val_acc: 55.34%\n",
      "Epoch [4607]/[5000], train_loss: 0.029200, train_acc: 95.07%, val_loss: 3.201000, val_acc: 56.51%\n",
      "Epoch [4608]/[5000], train_loss: 0.041500, train_acc: 94.68%, val_loss: 3.069200, val_acc: 55.34%\n",
      "Epoch [4609]/[5000], train_loss: 0.037900, train_acc: 95.17%, val_loss: 3.045100, val_acc: 54.56%\n",
      "Epoch [4610]/[5000], train_loss: 0.032600, train_acc: 94.92%, val_loss: 3.031000, val_acc: 51.56%\n",
      "Epoch [4611]/[5000], train_loss: 0.038800, train_acc: 94.53%, val_loss: 2.874800, val_acc: 54.82%\n",
      "Epoch [4612]/[5000], train_loss: 0.040000, train_acc: 94.87%, val_loss: 3.069400, val_acc: 55.08%\n",
      "Epoch [4613]/[5000], train_loss: 0.053400, train_acc: 94.48%, val_loss: 3.064000, val_acc: 54.95%\n",
      "Epoch [4614]/[5000], train_loss: 0.034500, train_acc: 94.97%, val_loss: 3.033500, val_acc: 52.99%\n",
      "Epoch [4615]/[5000], train_loss: 0.020600, train_acc: 95.41%, val_loss: 2.806500, val_acc: 53.65%\n",
      "Epoch [4616]/[5000], train_loss: 0.024500, train_acc: 95.17%, val_loss: 3.102400, val_acc: 55.08%\n",
      "Epoch [4617]/[5000], train_loss: 0.020700, train_acc: 95.46%, val_loss: 2.978500, val_acc: 56.77%\n",
      "Epoch [4618]/[5000], train_loss: 0.015600, train_acc: 95.61%, val_loss: 3.154600, val_acc: 55.60%\n",
      "Epoch [4619]/[5000], train_loss: 0.018600, train_acc: 95.46%, val_loss: 2.860500, val_acc: 57.81%\n",
      "Epoch [4620]/[5000], train_loss: 0.017000, train_acc: 95.65%, val_loss: 3.122900, val_acc: 55.34%\n",
      "Epoch [4621]/[5000], train_loss: 0.029400, train_acc: 95.17%, val_loss: 3.131100, val_acc: 55.99%\n",
      "Epoch [4622]/[5000], train_loss: 0.018500, train_acc: 95.61%, val_loss: 2.993700, val_acc: 55.86%\n",
      "Epoch [4623]/[5000], train_loss: 0.022500, train_acc: 95.36%, val_loss: 3.041400, val_acc: 55.73%\n",
      "Epoch [4624]/[5000], train_loss: 0.013700, train_acc: 95.65%, val_loss: 3.080800, val_acc: 53.91%\n",
      "Epoch [4625]/[5000], train_loss: 0.025500, train_acc: 95.31%, val_loss: 3.156700, val_acc: 55.34%\n",
      "Epoch [4626]/[5000], train_loss: 0.044400, train_acc: 94.43%, val_loss: 2.653600, val_acc: 54.43%\n",
      "Epoch [4627]/[5000], train_loss: 0.048200, train_acc: 94.92%, val_loss: 2.701200, val_acc: 53.91%\n",
      "Epoch [4628]/[5000], train_loss: 0.028100, train_acc: 94.92%, val_loss: 2.953200, val_acc: 55.60%\n",
      "Epoch [4629]/[5000], train_loss: 0.036500, train_acc: 94.82%, val_loss: 3.128200, val_acc: 57.03%\n",
      "Epoch [4630]/[5000], train_loss: 0.022600, train_acc: 95.41%, val_loss: 4.039200, val_acc: 54.69%\n",
      "Epoch [4631]/[5000], train_loss: 0.027200, train_acc: 95.21%, val_loss: 3.252400, val_acc: 52.86%\n",
      "Epoch [4632]/[5000], train_loss: 0.029700, train_acc: 95.36%, val_loss: 3.153900, val_acc: 55.34%\n",
      "Epoch [4633]/[5000], train_loss: 0.028600, train_acc: 95.21%, val_loss: 2.984500, val_acc: 56.12%\n",
      "Epoch [4634]/[5000], train_loss: 0.019900, train_acc: 95.51%, val_loss: 3.129500, val_acc: 52.60%\n",
      "Epoch [4635]/[5000], train_loss: 0.029600, train_acc: 95.21%, val_loss: 3.129200, val_acc: 55.34%\n",
      "Epoch [4636]/[5000], train_loss: 0.052400, train_acc: 94.24%, val_loss: 3.056900, val_acc: 52.60%\n",
      "Epoch [4637]/[5000], train_loss: 0.041700, train_acc: 95.02%, val_loss: 2.829200, val_acc: 53.65%\n",
      "Epoch [4638]/[5000], train_loss: 0.037200, train_acc: 94.87%, val_loss: 3.328400, val_acc: 55.34%\n",
      "Epoch [4639]/[5000], train_loss: 0.029300, train_acc: 94.87%, val_loss: 3.033000, val_acc: 57.03%\n",
      "Epoch [4640]/[5000], train_loss: 0.017900, train_acc: 95.46%, val_loss: 2.903100, val_acc: 55.60%\n",
      "Epoch [4641]/[5000], train_loss: 0.012700, train_acc: 95.75%, val_loss: 2.861300, val_acc: 56.64%\n",
      "Epoch [4642]/[5000], train_loss: 0.016000, train_acc: 95.56%, val_loss: 3.157700, val_acc: 56.90%\n",
      "Epoch [4643]/[5000], train_loss: 0.017200, train_acc: 95.46%, val_loss: 3.157800, val_acc: 57.55%\n",
      "Epoch [4644]/[5000], train_loss: 0.016500, train_acc: 95.36%, val_loss: 3.210300, val_acc: 54.95%\n",
      "Epoch [4645]/[5000], train_loss: 0.019300, train_acc: 95.46%, val_loss: 3.025400, val_acc: 57.29%\n",
      "Epoch [4646]/[5000], train_loss: 0.025100, train_acc: 95.21%, val_loss: 2.843200, val_acc: 54.56%\n",
      "Epoch [4647]/[5000], train_loss: 0.023200, train_acc: 95.21%, val_loss: 2.957800, val_acc: 55.86%\n",
      "Epoch [4648]/[5000], train_loss: 0.027500, train_acc: 95.07%, val_loss: 3.402700, val_acc: 55.21%\n",
      "Epoch [4649]/[5000], train_loss: 0.027200, train_acc: 95.02%, val_loss: 3.255600, val_acc: 54.95%\n",
      "Epoch [4650]/[5000], train_loss: 0.026800, train_acc: 95.51%, val_loss: 2.833500, val_acc: 56.90%\n",
      "Epoch [4651]/[5000], train_loss: 0.043700, train_acc: 94.82%, val_loss: 3.511800, val_acc: 51.56%\n",
      "Epoch [4652]/[5000], train_loss: 0.057600, train_acc: 93.99%, val_loss: 2.913700, val_acc: 56.77%\n",
      "Epoch [4653]/[5000], train_loss: 0.027700, train_acc: 95.21%, val_loss: 3.280800, val_acc: 53.26%\n",
      "Epoch [4654]/[5000], train_loss: 0.038200, train_acc: 94.53%, val_loss: 2.848200, val_acc: 54.43%\n",
      "Epoch [4655]/[5000], train_loss: 0.026000, train_acc: 95.26%, val_loss: 2.995800, val_acc: 54.95%\n",
      "Epoch [4656]/[5000], train_loss: 0.019500, train_acc: 95.61%, val_loss: 3.644300, val_acc: 54.30%\n",
      "Epoch [4657]/[5000], train_loss: 0.020100, train_acc: 95.61%, val_loss: 3.334600, val_acc: 55.73%\n",
      "Epoch [4658]/[5000], train_loss: 0.016900, train_acc: 95.70%, val_loss: 2.850200, val_acc: 55.60%\n",
      "Epoch [4659]/[5000], train_loss: 0.019400, train_acc: 95.56%, val_loss: 3.073600, val_acc: 54.69%\n",
      "Epoch [4660]/[5000], train_loss: 0.043900, train_acc: 94.63%, val_loss: 3.123800, val_acc: 55.08%\n",
      "Epoch [4661]/[5000], train_loss: 0.035400, train_acc: 95.02%, val_loss: 3.210000, val_acc: 56.12%\n",
      "Epoch [4662]/[5000], train_loss: 0.031600, train_acc: 94.97%, val_loss: 3.297100, val_acc: 54.17%\n",
      "Epoch [4663]/[5000], train_loss: 0.049300, train_acc: 94.68%, val_loss: 3.183700, val_acc: 52.60%\n",
      "Epoch [4664]/[5000], train_loss: 0.041600, train_acc: 94.53%, val_loss: 3.243600, val_acc: 56.51%\n",
      "Epoch [4665]/[5000], train_loss: 0.039000, train_acc: 94.87%, val_loss: 3.603900, val_acc: 52.99%\n",
      "Epoch [4666]/[5000], train_loss: 0.064700, train_acc: 93.80%, val_loss: 3.139300, val_acc: 54.82%\n",
      "Epoch [4667]/[5000], train_loss: 0.044300, train_acc: 94.78%, val_loss: 2.948200, val_acc: 55.86%\n",
      "Epoch [4668]/[5000], train_loss: 0.057900, train_acc: 94.19%, val_loss: 3.225700, val_acc: 54.95%\n",
      "Epoch [4669]/[5000], train_loss: 0.058900, train_acc: 94.04%, val_loss: 3.126300, val_acc: 52.34%\n",
      "Epoch [4670]/[5000], train_loss: 0.034300, train_acc: 95.07%, val_loss: 2.872400, val_acc: 56.12%\n",
      "Epoch [4671]/[5000], train_loss: 0.043100, train_acc: 94.78%, val_loss: 2.817400, val_acc: 52.99%\n",
      "Epoch [4672]/[5000], train_loss: 0.060200, train_acc: 94.04%, val_loss: 2.829700, val_acc: 52.34%\n",
      "Epoch [4673]/[5000], train_loss: 0.042600, train_acc: 94.53%, val_loss: 3.304200, val_acc: 51.43%\n",
      "Epoch [4674]/[5000], train_loss: 0.045900, train_acc: 94.24%, val_loss: 3.000800, val_acc: 54.82%\n",
      "Epoch [4675]/[5000], train_loss: 0.045700, train_acc: 94.58%, val_loss: 3.033800, val_acc: 54.56%\n",
      "Epoch [4676]/[5000], train_loss: 0.058300, train_acc: 94.48%, val_loss: 2.920200, val_acc: 56.90%\n",
      "Epoch [4677]/[5000], train_loss: 0.049400, train_acc: 94.63%, val_loss: 3.145100, val_acc: 56.25%\n",
      "Epoch [4678]/[5000], train_loss: 0.032400, train_acc: 95.02%, val_loss: 2.959000, val_acc: 55.34%\n",
      "Epoch [4679]/[5000], train_loss: 0.026600, train_acc: 95.41%, val_loss: 2.797400, val_acc: 54.04%\n",
      "Epoch [4680]/[5000], train_loss: 0.026500, train_acc: 95.12%, val_loss: 3.247300, val_acc: 55.08%\n",
      "Epoch [4681]/[5000], train_loss: 0.028700, train_acc: 95.17%, val_loss: 3.552300, val_acc: 55.73%\n",
      "Epoch [4682]/[5000], train_loss: 0.034000, train_acc: 94.92%, val_loss: 2.751400, val_acc: 54.17%\n",
      "Epoch [4683]/[5000], train_loss: 0.028500, train_acc: 94.97%, val_loss: 3.125600, val_acc: 53.52%\n",
      "Epoch [4684]/[5000], train_loss: 0.017800, train_acc: 95.56%, val_loss: 3.250600, val_acc: 54.95%\n",
      "Epoch [4685]/[5000], train_loss: 0.016900, train_acc: 95.56%, val_loss: 3.071200, val_acc: 55.86%\n",
      "Epoch [4686]/[5000], train_loss: 0.012900, train_acc: 95.80%, val_loss: 2.895100, val_acc: 57.16%\n",
      "Epoch [4687]/[5000], train_loss: 0.020000, train_acc: 95.41%, val_loss: 2.879800, val_acc: 54.82%\n",
      "Epoch [4688]/[5000], train_loss: 0.018600, train_acc: 95.56%, val_loss: 2.933100, val_acc: 57.16%\n",
      "Epoch [4689]/[5000], train_loss: 0.027800, train_acc: 95.26%, val_loss: 3.502400, val_acc: 55.34%\n",
      "Epoch [4690]/[5000], train_loss: 0.054600, train_acc: 94.92%, val_loss: 2.746000, val_acc: 54.43%\n",
      "Epoch [4691]/[5000], train_loss: 0.040800, train_acc: 94.68%, val_loss: 2.792100, val_acc: 53.52%\n",
      "Epoch [4692]/[5000], train_loss: 0.058900, train_acc: 94.78%, val_loss: 3.011300, val_acc: 55.86%\n",
      "Epoch [4693]/[5000], train_loss: 0.054600, train_acc: 94.53%, val_loss: 3.256600, val_acc: 54.30%\n",
      "Epoch [4694]/[5000], train_loss: 0.067200, train_acc: 93.99%, val_loss: 2.881700, val_acc: 53.52%\n",
      "Epoch [4695]/[5000], train_loss: 0.051400, train_acc: 94.78%, val_loss: 2.873600, val_acc: 53.52%\n",
      "Epoch [4696]/[5000], train_loss: 0.031900, train_acc: 95.07%, val_loss: 3.368900, val_acc: 55.34%\n",
      "Epoch [4697]/[5000], train_loss: 0.022300, train_acc: 95.56%, val_loss: 3.032600, val_acc: 55.08%\n",
      "Epoch [4698]/[5000], train_loss: 0.018600, train_acc: 95.56%, val_loss: 2.965600, val_acc: 56.38%\n",
      "Epoch [4699]/[5000], train_loss: 0.029700, train_acc: 95.12%, val_loss: 2.813400, val_acc: 56.25%\n",
      "Epoch [4700]/[5000], train_loss: 0.025200, train_acc: 95.02%, val_loss: 2.982700, val_acc: 55.60%\n",
      "Epoch [4701]/[5000], train_loss: 0.023000, train_acc: 95.41%, val_loss: 2.923200, val_acc: 55.86%\n",
      "Epoch [4702]/[5000], train_loss: 0.024600, train_acc: 95.21%, val_loss: 3.109800, val_acc: 54.95%\n",
      "Epoch [4703]/[5000], train_loss: 0.018600, train_acc: 95.41%, val_loss: 3.126400, val_acc: 53.52%\n",
      "Epoch [4704]/[5000], train_loss: 0.035300, train_acc: 95.26%, val_loss: 3.447100, val_acc: 55.08%\n",
      "Epoch [4705]/[5000], train_loss: 0.020500, train_acc: 95.51%, val_loss: 3.657600, val_acc: 53.78%\n",
      "Epoch [4706]/[5000], train_loss: 0.017500, train_acc: 95.61%, val_loss: 3.321500, val_acc: 53.12%\n",
      "Epoch [4707]/[5000], train_loss: 0.028300, train_acc: 95.17%, val_loss: 3.046800, val_acc: 54.43%\n",
      "Epoch [4708]/[5000], train_loss: 0.037100, train_acc: 94.73%, val_loss: 2.821000, val_acc: 52.86%\n",
      "Epoch [4709]/[5000], train_loss: 0.025100, train_acc: 95.17%, val_loss: 2.881400, val_acc: 53.52%\n",
      "Epoch [4710]/[5000], train_loss: 0.032200, train_acc: 94.87%, val_loss: 2.720500, val_acc: 53.78%\n",
      "Epoch [4711]/[5000], train_loss: 0.025400, train_acc: 95.17%, val_loss: 3.556400, val_acc: 55.21%\n",
      "Epoch [4712]/[5000], train_loss: 0.026000, train_acc: 95.36%, val_loss: 2.866900, val_acc: 52.08%\n",
      "Epoch [4713]/[5000], train_loss: 0.022800, train_acc: 95.36%, val_loss: 3.232300, val_acc: 55.21%\n",
      "Epoch [4714]/[5000], train_loss: 0.026200, train_acc: 94.82%, val_loss: 3.326900, val_acc: 55.60%\n",
      "Epoch [4715]/[5000], train_loss: 0.019600, train_acc: 95.36%, val_loss: 3.267800, val_acc: 54.82%\n",
      "Epoch [4716]/[5000], train_loss: 0.033400, train_acc: 95.17%, val_loss: 2.918100, val_acc: 55.73%\n",
      "Epoch [4717]/[5000], train_loss: 0.033100, train_acc: 95.02%, val_loss: 2.978200, val_acc: 53.91%\n",
      "Epoch [4718]/[5000], train_loss: 0.021600, train_acc: 95.36%, val_loss: 3.294600, val_acc: 51.82%\n",
      "Epoch [4719]/[5000], train_loss: 0.019800, train_acc: 95.46%, val_loss: 3.057100, val_acc: 52.99%\n",
      "Epoch [4720]/[5000], train_loss: 0.028500, train_acc: 95.41%, val_loss: 2.959700, val_acc: 55.47%\n",
      "Epoch [4721]/[5000], train_loss: 0.045600, train_acc: 94.73%, val_loss: 3.299200, val_acc: 55.34%\n",
      "Epoch [4722]/[5000], train_loss: 0.048200, train_acc: 94.43%, val_loss: 3.255300, val_acc: 51.04%\n",
      "Epoch [4723]/[5000], train_loss: 0.031300, train_acc: 94.87%, val_loss: 3.455000, val_acc: 51.82%\n",
      "Epoch [4724]/[5000], train_loss: 0.031400, train_acc: 95.02%, val_loss: 3.232600, val_acc: 54.43%\n",
      "Epoch [4725]/[5000], train_loss: 0.031800, train_acc: 95.02%, val_loss: 3.280300, val_acc: 54.43%\n",
      "Epoch [4726]/[5000], train_loss: 0.034700, train_acc: 95.17%, val_loss: 2.842500, val_acc: 56.12%\n",
      "Epoch [4727]/[5000], train_loss: 0.033200, train_acc: 95.07%, val_loss: 2.922800, val_acc: 54.95%\n",
      "Epoch [4728]/[5000], train_loss: 0.025900, train_acc: 95.26%, val_loss: 3.437500, val_acc: 54.56%\n",
      "Epoch [4729]/[5000], train_loss: 0.023400, train_acc: 95.21%, val_loss: 2.753500, val_acc: 56.77%\n",
      "Epoch [4730]/[5000], train_loss: 0.042300, train_acc: 95.02%, val_loss: 3.186500, val_acc: 52.34%\n",
      "Epoch [4731]/[5000], train_loss: 0.034900, train_acc: 94.97%, val_loss: 2.773100, val_acc: 55.99%\n",
      "Epoch [4732]/[5000], train_loss: 0.019800, train_acc: 95.46%, val_loss: 3.160300, val_acc: 56.90%\n",
      "Epoch [4733]/[5000], train_loss: 0.020800, train_acc: 95.46%, val_loss: 3.232300, val_acc: 54.17%\n",
      "Epoch [4734]/[5000], train_loss: 0.013700, train_acc: 95.80%, val_loss: 2.867500, val_acc: 55.21%\n",
      "Epoch [4735]/[5000], train_loss: 0.023500, train_acc: 95.36%, val_loss: 3.144900, val_acc: 56.77%\n",
      "Epoch [4736]/[5000], train_loss: 0.018300, train_acc: 95.41%, val_loss: 3.235100, val_acc: 55.47%\n",
      "Epoch [4737]/[5000], train_loss: 0.023900, train_acc: 95.21%, val_loss: 3.107300, val_acc: 54.43%\n",
      "Epoch [4738]/[5000], train_loss: 0.019300, train_acc: 95.51%, val_loss: 2.678700, val_acc: 54.17%\n",
      "Epoch [4739]/[5000], train_loss: 0.030100, train_acc: 94.87%, val_loss: 3.377700, val_acc: 53.91%\n",
      "Epoch [4740]/[5000], train_loss: 0.029700, train_acc: 95.26%, val_loss: 3.433500, val_acc: 54.30%\n",
      "Epoch [4741]/[5000], train_loss: 0.015600, train_acc: 95.70%, val_loss: 2.877100, val_acc: 55.60%\n",
      "Epoch [4742]/[5000], train_loss: 0.027700, train_acc: 95.36%, val_loss: 3.109100, val_acc: 54.56%\n",
      "Epoch [4743]/[5000], train_loss: 0.015500, train_acc: 95.51%, val_loss: 2.933800, val_acc: 55.99%\n",
      "Epoch [4744]/[5000], train_loss: 0.012700, train_acc: 95.61%, val_loss: 3.040000, val_acc: 55.21%\n",
      "Epoch [4745]/[5000], train_loss: 0.015600, train_acc: 95.56%, val_loss: 2.975800, val_acc: 55.86%\n",
      "Epoch [4746]/[5000], train_loss: 0.014900, train_acc: 95.56%, val_loss: 3.445100, val_acc: 56.90%\n",
      "Epoch [4747]/[5000], train_loss: 0.011800, train_acc: 95.75%, val_loss: 3.318400, val_acc: 55.73%\n",
      "Epoch [4748]/[5000], train_loss: 0.024900, train_acc: 95.36%, val_loss: 3.840900, val_acc: 53.26%\n",
      "Epoch [4749]/[5000], train_loss: 0.054100, train_acc: 94.19%, val_loss: 3.293600, val_acc: 56.25%\n",
      "Epoch [4750]/[5000], train_loss: 0.030900, train_acc: 95.17%, val_loss: 3.767000, val_acc: 57.16%\n",
      "Epoch [4751]/[5000], train_loss: 0.024900, train_acc: 95.51%, val_loss: 3.110600, val_acc: 55.08%\n",
      "Epoch [4752]/[5000], train_loss: 0.011900, train_acc: 95.80%, val_loss: 2.800900, val_acc: 54.56%\n",
      "Epoch [4753]/[5000], train_loss: 0.018400, train_acc: 95.41%, val_loss: 2.758700, val_acc: 54.56%\n",
      "Epoch [4754]/[5000], train_loss: 0.025900, train_acc: 95.31%, val_loss: 3.086700, val_acc: 55.60%\n",
      "Epoch [4755]/[5000], train_loss: 0.029800, train_acc: 95.17%, val_loss: 3.280900, val_acc: 55.34%\n",
      "Epoch [4756]/[5000], train_loss: 0.026500, train_acc: 95.12%, val_loss: 2.738800, val_acc: 55.08%\n",
      "Epoch [4757]/[5000], train_loss: 0.045900, train_acc: 94.82%, val_loss: 3.135500, val_acc: 56.51%\n",
      "Epoch [4758]/[5000], train_loss: 0.033100, train_acc: 95.17%, val_loss: 3.052700, val_acc: 55.47%\n",
      "Epoch [4759]/[5000], train_loss: 0.042500, train_acc: 94.92%, val_loss: 2.760700, val_acc: 53.78%\n",
      "Epoch [4760]/[5000], train_loss: 0.043400, train_acc: 94.68%, val_loss: 3.090100, val_acc: 55.99%\n",
      "Epoch [4761]/[5000], train_loss: 0.049600, train_acc: 95.02%, val_loss: 3.320100, val_acc: 53.65%\n",
      "Epoch [4762]/[5000], train_loss: 0.043000, train_acc: 94.73%, val_loss: 3.375600, val_acc: 54.04%\n",
      "Epoch [4763]/[5000], train_loss: 0.049200, train_acc: 94.53%, val_loss: 3.289800, val_acc: 53.91%\n",
      "Epoch [4764]/[5000], train_loss: 0.039000, train_acc: 95.12%, val_loss: 3.177500, val_acc: 53.65%\n",
      "Epoch [4765]/[5000], train_loss: 0.044400, train_acc: 94.87%, val_loss: 3.018800, val_acc: 55.99%\n",
      "Epoch [4766]/[5000], train_loss: 0.050700, train_acc: 94.34%, val_loss: 3.450300, val_acc: 50.39%\n",
      "Epoch [4767]/[5000], train_loss: 0.053500, train_acc: 94.34%, val_loss: 2.631000, val_acc: 53.52%\n",
      "Epoch [4768]/[5000], train_loss: 0.032300, train_acc: 95.02%, val_loss: 3.106100, val_acc: 53.78%\n",
      "Epoch [4769]/[5000], train_loss: 0.024000, train_acc: 95.36%, val_loss: 2.958500, val_acc: 54.82%\n",
      "Epoch [4770]/[5000], train_loss: 0.023600, train_acc: 95.36%, val_loss: 3.360400, val_acc: 55.08%\n",
      "Epoch [4771]/[5000], train_loss: 0.023500, train_acc: 95.41%, val_loss: 3.211600, val_acc: 57.03%\n",
      "Epoch [4772]/[5000], train_loss: 0.022500, train_acc: 95.36%, val_loss: 2.853100, val_acc: 55.60%\n",
      "Epoch [4773]/[5000], train_loss: 0.029200, train_acc: 94.97%, val_loss: 2.679000, val_acc: 55.60%\n",
      "Epoch [4774]/[5000], train_loss: 0.024100, train_acc: 95.41%, val_loss: 2.862000, val_acc: 54.82%\n",
      "Epoch [4775]/[5000], train_loss: 0.018000, train_acc: 95.61%, val_loss: 3.062100, val_acc: 55.47%\n",
      "Epoch [4776]/[5000], train_loss: 0.012900, train_acc: 95.70%, val_loss: 3.017800, val_acc: 55.08%\n",
      "Epoch [4777]/[5000], train_loss: 0.010900, train_acc: 95.65%, val_loss: 3.060300, val_acc: 55.73%\n",
      "Epoch [4778]/[5000], train_loss: 0.012900, train_acc: 95.75%, val_loss: 2.915200, val_acc: 55.86%\n",
      "Epoch [4779]/[5000], train_loss: 0.023100, train_acc: 95.46%, val_loss: 2.885700, val_acc: 55.60%\n",
      "Epoch [4780]/[5000], train_loss: 0.011800, train_acc: 95.80%, val_loss: 2.953300, val_acc: 55.99%\n",
      "Epoch [4781]/[5000], train_loss: 0.016200, train_acc: 95.65%, val_loss: 2.914000, val_acc: 55.73%\n",
      "Epoch [4782]/[5000], train_loss: 0.015700, train_acc: 95.56%, val_loss: 3.103400, val_acc: 55.99%\n",
      "Epoch [4783]/[5000], train_loss: 0.021300, train_acc: 95.51%, val_loss: 3.375700, val_acc: 54.30%\n",
      "Epoch [4784]/[5000], train_loss: 0.027000, train_acc: 95.26%, val_loss: 3.130400, val_acc: 56.38%\n",
      "Epoch [4785]/[5000], train_loss: 0.021100, train_acc: 95.46%, val_loss: 2.909300, val_acc: 58.20%\n",
      "Epoch [4786]/[5000], train_loss: 0.018300, train_acc: 95.61%, val_loss: 3.223000, val_acc: 55.73%\n",
      "Epoch [4787]/[5000], train_loss: 0.015800, train_acc: 95.61%, val_loss: 3.005600, val_acc: 54.82%\n",
      "Epoch [4788]/[5000], train_loss: 0.027600, train_acc: 95.31%, val_loss: 2.978400, val_acc: 53.26%\n",
      "Epoch [4789]/[5000], train_loss: 0.022200, train_acc: 95.26%, val_loss: 3.615900, val_acc: 55.86%\n",
      "Epoch [4790]/[5000], train_loss: 0.060700, train_acc: 94.63%, val_loss: 2.970700, val_acc: 55.99%\n",
      "Epoch [4791]/[5000], train_loss: 0.077000, train_acc: 93.65%, val_loss: 3.129800, val_acc: 54.43%\n",
      "Epoch [4792]/[5000], train_loss: 0.077300, train_acc: 93.16%, val_loss: 3.301500, val_acc: 53.26%\n",
      "Epoch [4793]/[5000], train_loss: 0.054600, train_acc: 94.09%, val_loss: 2.902700, val_acc: 52.99%\n",
      "Epoch [4794]/[5000], train_loss: 0.049500, train_acc: 94.48%, val_loss: 2.867100, val_acc: 54.69%\n",
      "Epoch [4795]/[5000], train_loss: 0.042000, train_acc: 94.63%, val_loss: 2.878900, val_acc: 54.56%\n",
      "Epoch [4796]/[5000], train_loss: 0.039200, train_acc: 94.53%, val_loss: 3.025700, val_acc: 53.65%\n",
      "Epoch [4797]/[5000], train_loss: 0.040700, train_acc: 94.87%, val_loss: 3.019700, val_acc: 54.17%\n",
      "Epoch [4798]/[5000], train_loss: 0.032400, train_acc: 94.82%, val_loss: 2.499300, val_acc: 56.51%\n",
      "Epoch [4799]/[5000], train_loss: 0.031300, train_acc: 95.07%, val_loss: 2.994100, val_acc: 56.90%\n",
      "Epoch [4800]/[5000], train_loss: 0.034200, train_acc: 95.12%, val_loss: 2.603400, val_acc: 54.04%\n",
      "Epoch [4801]/[5000], train_loss: 0.029400, train_acc: 95.26%, val_loss: 3.081300, val_acc: 56.12%\n",
      "Epoch [4802]/[5000], train_loss: 0.019900, train_acc: 95.41%, val_loss: 3.064300, val_acc: 57.81%\n",
      "Epoch [4803]/[5000], train_loss: 0.016700, train_acc: 95.46%, val_loss: 2.929900, val_acc: 55.34%\n",
      "Epoch [4804]/[5000], train_loss: 0.020400, train_acc: 95.46%, val_loss: 2.790500, val_acc: 57.42%\n",
      "Epoch [4805]/[5000], train_loss: 0.018300, train_acc: 95.41%, val_loss: 2.691500, val_acc: 56.38%\n",
      "Epoch [4806]/[5000], train_loss: 0.018700, train_acc: 95.56%, val_loss: 2.593800, val_acc: 55.60%\n",
      "Epoch [4807]/[5000], train_loss: 0.017000, train_acc: 95.36%, val_loss: 2.964600, val_acc: 58.59%\n",
      "Epoch [4808]/[5000], train_loss: 0.036300, train_acc: 94.97%, val_loss: 3.316600, val_acc: 57.55%\n",
      "Epoch [4809]/[5000], train_loss: 0.036500, train_acc: 94.58%, val_loss: 3.124500, val_acc: 51.43%\n",
      "Epoch [4810]/[5000], train_loss: 0.033200, train_acc: 95.12%, val_loss: 2.798400, val_acc: 54.56%\n",
      "Epoch [4811]/[5000], train_loss: 0.033700, train_acc: 95.02%, val_loss: 2.801800, val_acc: 55.47%\n",
      "Epoch [4812]/[5000], train_loss: 0.033800, train_acc: 95.02%, val_loss: 3.160900, val_acc: 55.60%\n",
      "Epoch [4813]/[5000], train_loss: 0.029800, train_acc: 95.07%, val_loss: 3.276500, val_acc: 55.34%\n",
      "Epoch [4814]/[5000], train_loss: 0.021900, train_acc: 95.36%, val_loss: 2.603900, val_acc: 57.03%\n",
      "Epoch [4815]/[5000], train_loss: 0.031700, train_acc: 95.07%, val_loss: 3.051600, val_acc: 55.34%\n",
      "Epoch [4816]/[5000], train_loss: 0.034000, train_acc: 95.17%, val_loss: 3.390500, val_acc: 55.60%\n",
      "Epoch [4817]/[5000], train_loss: 0.022600, train_acc: 95.26%, val_loss: 3.155500, val_acc: 54.17%\n",
      "Epoch [4818]/[5000], train_loss: 0.040900, train_acc: 94.97%, val_loss: 3.761400, val_acc: 56.90%\n",
      "Epoch [4819]/[5000], train_loss: 0.035500, train_acc: 95.12%, val_loss: 3.396600, val_acc: 52.21%\n",
      "Epoch [4820]/[5000], train_loss: 0.037900, train_acc: 94.78%, val_loss: 2.849200, val_acc: 56.12%\n",
      "Epoch [4821]/[5000], train_loss: 0.035500, train_acc: 94.68%, val_loss: 3.157300, val_acc: 55.34%\n",
      "Epoch [4822]/[5000], train_loss: 0.039200, train_acc: 94.53%, val_loss: 3.453200, val_acc: 55.34%\n",
      "Epoch [4823]/[5000], train_loss: 0.023900, train_acc: 95.31%, val_loss: 3.233800, val_acc: 52.21%\n",
      "Epoch [4824]/[5000], train_loss: 0.023900, train_acc: 95.41%, val_loss: 3.062500, val_acc: 56.38%\n",
      "Epoch [4825]/[5000], train_loss: 0.031400, train_acc: 95.26%, val_loss: 3.033300, val_acc: 55.21%\n",
      "Epoch [4826]/[5000], train_loss: 0.032600, train_acc: 95.02%, val_loss: 3.453000, val_acc: 54.30%\n",
      "Epoch [4827]/[5000], train_loss: 0.037100, train_acc: 95.02%, val_loss: 2.717100, val_acc: 56.64%\n",
      "Epoch [4828]/[5000], train_loss: 0.022600, train_acc: 95.46%, val_loss: 3.530400, val_acc: 53.39%\n",
      "Epoch [4829]/[5000], train_loss: 0.016100, train_acc: 95.65%, val_loss: 3.236900, val_acc: 52.34%\n",
      "Epoch [4830]/[5000], train_loss: 0.017900, train_acc: 95.51%, val_loss: 3.070000, val_acc: 54.82%\n",
      "Epoch [4831]/[5000], train_loss: 0.020600, train_acc: 95.31%, val_loss: 3.441500, val_acc: 54.43%\n",
      "Epoch [4832]/[5000], train_loss: 0.023300, train_acc: 95.36%, val_loss: 3.097500, val_acc: 52.86%\n",
      "Epoch [4833]/[5000], train_loss: 0.014900, train_acc: 95.51%, val_loss: 3.274900, val_acc: 53.12%\n",
      "Epoch [4834]/[5000], train_loss: 0.018500, train_acc: 95.36%, val_loss: 3.273700, val_acc: 55.21%\n",
      "Epoch [4835]/[5000], train_loss: 0.029600, train_acc: 95.31%, val_loss: 2.842300, val_acc: 54.04%\n",
      "Epoch [4836]/[5000], train_loss: 0.039800, train_acc: 94.73%, val_loss: 3.382800, val_acc: 53.12%\n",
      "Epoch [4837]/[5000], train_loss: 0.028500, train_acc: 95.02%, val_loss: 3.604300, val_acc: 53.26%\n",
      "Epoch [4838]/[5000], train_loss: 0.058800, train_acc: 94.68%, val_loss: 3.335200, val_acc: 55.47%\n",
      "Epoch [4839]/[5000], train_loss: 0.046100, train_acc: 94.68%, val_loss: 3.409700, val_acc: 53.52%\n",
      "Epoch [4840]/[5000], train_loss: 0.023900, train_acc: 95.21%, val_loss: 3.202700, val_acc: 56.12%\n",
      "Epoch [4841]/[5000], train_loss: 0.021600, train_acc: 95.41%, val_loss: 2.981400, val_acc: 53.91%\n",
      "Epoch [4842]/[5000], train_loss: 0.031000, train_acc: 94.78%, val_loss: 3.026800, val_acc: 57.16%\n",
      "Epoch [4843]/[5000], train_loss: 0.039900, train_acc: 95.02%, val_loss: 3.086700, val_acc: 55.73%\n",
      "Epoch [4844]/[5000], train_loss: 0.054900, train_acc: 93.95%, val_loss: 2.682100, val_acc: 55.86%\n",
      "Epoch [4845]/[5000], train_loss: 0.041300, train_acc: 94.87%, val_loss: 3.304300, val_acc: 51.82%\n",
      "Epoch [4846]/[5000], train_loss: 0.044100, train_acc: 94.43%, val_loss: 3.603900, val_acc: 55.47%\n",
      "Epoch [4847]/[5000], train_loss: 0.037100, train_acc: 94.73%, val_loss: 3.660100, val_acc: 53.65%\n",
      "Epoch [4848]/[5000], train_loss: 0.029300, train_acc: 94.92%, val_loss: 3.382600, val_acc: 51.82%\n",
      "Epoch [4849]/[5000], train_loss: 0.018100, train_acc: 95.46%, val_loss: 3.080200, val_acc: 55.73%\n",
      "Epoch [4850]/[5000], train_loss: 0.013600, train_acc: 95.56%, val_loss: 2.982700, val_acc: 53.91%\n",
      "Epoch [4851]/[5000], train_loss: 0.016200, train_acc: 95.80%, val_loss: 3.090000, val_acc: 54.04%\n",
      "Epoch [4852]/[5000], train_loss: 0.015300, train_acc: 95.61%, val_loss: 3.221800, val_acc: 56.25%\n",
      "Epoch [4853]/[5000], train_loss: 0.028600, train_acc: 94.97%, val_loss: 3.058700, val_acc: 54.30%\n",
      "Epoch [4854]/[5000], train_loss: 0.029500, train_acc: 95.26%, val_loss: 3.212300, val_acc: 53.91%\n",
      "Epoch [4855]/[5000], train_loss: 0.019100, train_acc: 95.46%, val_loss: 3.235200, val_acc: 52.99%\n",
      "Epoch [4856]/[5000], train_loss: 0.024500, train_acc: 95.31%, val_loss: 3.545700, val_acc: 55.60%\n",
      "Epoch [4857]/[5000], train_loss: 0.022300, train_acc: 95.17%, val_loss: 3.062000, val_acc: 54.82%\n",
      "Epoch [4858]/[5000], train_loss: 0.021700, train_acc: 95.36%, val_loss: 3.056600, val_acc: 53.26%\n",
      "Epoch [4859]/[5000], train_loss: 0.028200, train_acc: 95.12%, val_loss: 3.435500, val_acc: 55.86%\n",
      "Epoch [4860]/[5000], train_loss: 0.026700, train_acc: 95.26%, val_loss: 2.951800, val_acc: 54.56%\n",
      "Epoch [4861]/[5000], train_loss: 0.024500, train_acc: 95.07%, val_loss: 3.271300, val_acc: 55.86%\n",
      "Epoch [4862]/[5000], train_loss: 0.024500, train_acc: 95.21%, val_loss: 3.354900, val_acc: 51.56%\n",
      "Epoch [4863]/[5000], train_loss: 0.021000, train_acc: 95.26%, val_loss: 2.877300, val_acc: 55.21%\n",
      "Epoch [4864]/[5000], train_loss: 0.025100, train_acc: 95.51%, val_loss: 3.205500, val_acc: 53.52%\n",
      "Epoch [4865]/[5000], train_loss: 0.033800, train_acc: 94.82%, val_loss: 3.655700, val_acc: 52.47%\n",
      "Epoch [4866]/[5000], train_loss: 0.028300, train_acc: 95.26%, val_loss: 3.551900, val_acc: 56.77%\n",
      "Epoch [4867]/[5000], train_loss: 0.025700, train_acc: 95.07%, val_loss: 2.924800, val_acc: 55.60%\n",
      "Epoch [4868]/[5000], train_loss: 0.028000, train_acc: 94.97%, val_loss: 3.113600, val_acc: 53.52%\n",
      "Epoch [4869]/[5000], train_loss: 0.029700, train_acc: 95.17%, val_loss: 3.283500, val_acc: 54.95%\n",
      "Epoch [4870]/[5000], train_loss: 0.026100, train_acc: 95.07%, val_loss: 2.896400, val_acc: 53.78%\n",
      "Epoch [4871]/[5000], train_loss: 0.027000, train_acc: 95.21%, val_loss: 2.855500, val_acc: 55.34%\n",
      "Epoch [4872]/[5000], train_loss: 0.019200, train_acc: 95.41%, val_loss: 2.981100, val_acc: 54.04%\n",
      "Epoch [4873]/[5000], train_loss: 0.021400, train_acc: 95.46%, val_loss: 3.320800, val_acc: 54.56%\n",
      "Epoch [4874]/[5000], train_loss: 0.019900, train_acc: 95.56%, val_loss: 2.880200, val_acc: 55.86%\n",
      "Epoch [4875]/[5000], train_loss: 0.032200, train_acc: 95.02%, val_loss: 2.789900, val_acc: 55.34%\n",
      "Epoch [4876]/[5000], train_loss: 0.024600, train_acc: 95.41%, val_loss: 3.282700, val_acc: 54.30%\n",
      "Epoch [4877]/[5000], train_loss: 0.029100, train_acc: 95.12%, val_loss: 3.407800, val_acc: 52.73%\n",
      "Epoch [4878]/[5000], train_loss: 0.028200, train_acc: 95.21%, val_loss: 3.135200, val_acc: 53.78%\n",
      "Epoch [4879]/[5000], train_loss: 0.024700, train_acc: 95.17%, val_loss: 2.914200, val_acc: 53.91%\n",
      "Epoch [4880]/[5000], train_loss: 0.025800, train_acc: 95.17%, val_loss: 3.032700, val_acc: 55.08%\n",
      "Epoch [4881]/[5000], train_loss: 0.033600, train_acc: 95.31%, val_loss: 3.173600, val_acc: 55.47%\n",
      "Epoch [4882]/[5000], train_loss: 0.031400, train_acc: 95.02%, val_loss: 3.304300, val_acc: 55.86%\n",
      "Epoch [4883]/[5000], train_loss: 0.042400, train_acc: 94.48%, val_loss: 3.671600, val_acc: 55.21%\n",
      "Epoch [4884]/[5000], train_loss: 0.044100, train_acc: 94.73%, val_loss: 3.048500, val_acc: 56.38%\n",
      "Epoch [4885]/[5000], train_loss: 0.025800, train_acc: 94.92%, val_loss: 3.089600, val_acc: 54.82%\n",
      "Epoch [4886]/[5000], train_loss: 0.044600, train_acc: 94.87%, val_loss: 3.259800, val_acc: 53.39%\n",
      "Epoch [4887]/[5000], train_loss: 0.032600, train_acc: 94.63%, val_loss: 2.720300, val_acc: 55.86%\n",
      "Epoch [4888]/[5000], train_loss: 0.040800, train_acc: 94.78%, val_loss: 3.040000, val_acc: 54.95%\n",
      "Epoch [4889]/[5000], train_loss: 0.044900, train_acc: 94.48%, val_loss: 3.107700, val_acc: 53.65%\n",
      "Epoch [4890]/[5000], train_loss: 0.028400, train_acc: 95.07%, val_loss: 3.053000, val_acc: 53.78%\n",
      "Epoch [4891]/[5000], train_loss: 0.031000, train_acc: 95.02%, val_loss: 2.978700, val_acc: 54.56%\n",
      "Epoch [4892]/[5000], train_loss: 0.030400, train_acc: 94.97%, val_loss: 2.790100, val_acc: 56.12%\n",
      "Epoch [4893]/[5000], train_loss: 0.035000, train_acc: 95.02%, val_loss: 3.500100, val_acc: 55.47%\n",
      "Epoch [4894]/[5000], train_loss: 0.019700, train_acc: 95.51%, val_loss: 2.674000, val_acc: 55.73%\n",
      "Epoch [4895]/[5000], train_loss: 0.029500, train_acc: 95.12%, val_loss: 3.128200, val_acc: 56.51%\n",
      "Epoch [4896]/[5000], train_loss: 0.032100, train_acc: 95.12%, val_loss: 3.226400, val_acc: 55.08%\n",
      "Epoch [4897]/[5000], train_loss: 0.035800, train_acc: 94.87%, val_loss: 3.382800, val_acc: 54.04%\n",
      "Epoch [4898]/[5000], train_loss: 0.031100, train_acc: 95.12%, val_loss: 3.585100, val_acc: 55.34%\n",
      "Epoch [4899]/[5000], train_loss: 0.033300, train_acc: 94.97%, val_loss: 2.900400, val_acc: 54.56%\n",
      "Epoch [4900]/[5000], train_loss: 0.027400, train_acc: 95.02%, val_loss: 3.161600, val_acc: 55.60%\n",
      "Epoch [4901]/[5000], train_loss: 0.029900, train_acc: 95.26%, val_loss: 3.107800, val_acc: 57.68%\n",
      "Epoch [4902]/[5000], train_loss: 0.033400, train_acc: 95.12%, val_loss: 3.318200, val_acc: 55.08%\n",
      "Epoch [4903]/[5000], train_loss: 0.027300, train_acc: 95.12%, val_loss: 3.288700, val_acc: 52.47%\n",
      "Epoch [4904]/[5000], train_loss: 0.052100, train_acc: 94.34%, val_loss: 3.122300, val_acc: 54.95%\n",
      "Epoch [4905]/[5000], train_loss: 0.052200, train_acc: 94.48%, val_loss: 3.202700, val_acc: 53.91%\n",
      "Epoch [4906]/[5000], train_loss: 0.027400, train_acc: 95.07%, val_loss: 3.293900, val_acc: 54.56%\n",
      "Epoch [4907]/[5000], train_loss: 0.041800, train_acc: 94.53%, val_loss: 3.752700, val_acc: 55.47%\n",
      "Epoch [4908]/[5000], train_loss: 0.026000, train_acc: 95.07%, val_loss: 2.823900, val_acc: 55.47%\n",
      "Epoch [4909]/[5000], train_loss: 0.022600, train_acc: 95.51%, val_loss: 2.951800, val_acc: 54.56%\n",
      "Epoch [4910]/[5000], train_loss: 0.015100, train_acc: 95.70%, val_loss: 2.985900, val_acc: 55.86%\n",
      "Epoch [4911]/[5000], train_loss: 0.025200, train_acc: 95.65%, val_loss: 2.795400, val_acc: 57.42%\n",
      "Epoch [4912]/[5000], train_loss: 0.024000, train_acc: 95.17%, val_loss: 2.692900, val_acc: 57.42%\n",
      "Epoch [4913]/[5000], train_loss: 0.024400, train_acc: 95.51%, val_loss: 2.889500, val_acc: 55.08%\n",
      "Epoch [4914]/[5000], train_loss: 0.024800, train_acc: 95.61%, val_loss: 2.869200, val_acc: 54.69%\n",
      "Epoch [4915]/[5000], train_loss: 0.025800, train_acc: 95.31%, val_loss: 2.981400, val_acc: 55.86%\n",
      "Epoch [4916]/[5000], train_loss: 0.019000, train_acc: 95.61%, val_loss: 3.199800, val_acc: 54.30%\n",
      "Epoch [4917]/[5000], train_loss: 0.020900, train_acc: 95.31%, val_loss: 2.919600, val_acc: 56.77%\n",
      "Epoch [4918]/[5000], train_loss: 0.023500, train_acc: 95.31%, val_loss: 3.230600, val_acc: 54.95%\n",
      "Epoch [4919]/[5000], train_loss: 0.048100, train_acc: 94.63%, val_loss: 2.995700, val_acc: 52.21%\n",
      "Epoch [4920]/[5000], train_loss: 0.072100, train_acc: 93.65%, val_loss: 3.089600, val_acc: 50.00%\n",
      "Epoch [4921]/[5000], train_loss: 0.057200, train_acc: 94.09%, val_loss: 3.299300, val_acc: 54.30%\n",
      "Epoch [4922]/[5000], train_loss: 0.039000, train_acc: 94.82%, val_loss: 3.364100, val_acc: 52.47%\n",
      "Epoch [4923]/[5000], train_loss: 0.046600, train_acc: 94.63%, val_loss: 3.566900, val_acc: 54.56%\n",
      "Epoch [4924]/[5000], train_loss: 0.028100, train_acc: 95.26%, val_loss: 3.100700, val_acc: 53.52%\n",
      "Epoch [4925]/[5000], train_loss: 0.032400, train_acc: 95.12%, val_loss: 3.114800, val_acc: 54.56%\n",
      "Epoch [4926]/[5000], train_loss: 0.024200, train_acc: 95.36%, val_loss: 3.002900, val_acc: 55.47%\n",
      "Epoch [4927]/[5000], train_loss: 0.016100, train_acc: 95.51%, val_loss: 3.374000, val_acc: 54.69%\n",
      "Epoch [4928]/[5000], train_loss: 0.014700, train_acc: 95.56%, val_loss: 3.129100, val_acc: 55.73%\n",
      "Epoch [4929]/[5000], train_loss: 0.011600, train_acc: 95.65%, val_loss: 3.262300, val_acc: 54.82%\n",
      "Epoch [4930]/[5000], train_loss: 0.018800, train_acc: 95.41%, val_loss: 3.170200, val_acc: 54.17%\n",
      "Epoch [4931]/[5000], train_loss: 0.031600, train_acc: 94.92%, val_loss: 3.100700, val_acc: 55.08%\n",
      "Epoch [4932]/[5000], train_loss: 0.037900, train_acc: 94.78%, val_loss: 2.954200, val_acc: 53.26%\n",
      "Epoch [4933]/[5000], train_loss: 0.028400, train_acc: 95.17%, val_loss: 3.075100, val_acc: 55.34%\n",
      "Epoch [4934]/[5000], train_loss: 0.024800, train_acc: 95.21%, val_loss: 3.157700, val_acc: 56.77%\n",
      "Epoch [4935]/[5000], train_loss: 0.020700, train_acc: 95.56%, val_loss: 3.390700, val_acc: 54.04%\n",
      "Epoch [4936]/[5000], train_loss: 0.016100, train_acc: 95.51%, val_loss: 2.866400, val_acc: 55.99%\n",
      "Epoch [4937]/[5000], train_loss: 0.020000, train_acc: 95.61%, val_loss: 3.303000, val_acc: 54.43%\n",
      "Epoch [4938]/[5000], train_loss: 0.025400, train_acc: 95.12%, val_loss: 3.188000, val_acc: 56.12%\n",
      "Epoch [4939]/[5000], train_loss: 0.031000, train_acc: 94.97%, val_loss: 2.763600, val_acc: 55.99%\n",
      "Epoch [4940]/[5000], train_loss: 0.020700, train_acc: 95.46%, val_loss: 2.665000, val_acc: 53.91%\n",
      "Epoch [4941]/[5000], train_loss: 0.041200, train_acc: 94.68%, val_loss: 3.133400, val_acc: 55.47%\n",
      "Epoch [4942]/[5000], train_loss: 0.026800, train_acc: 95.17%, val_loss: 3.112900, val_acc: 56.77%\n",
      "Epoch [4943]/[5000], train_loss: 0.024800, train_acc: 95.26%, val_loss: 2.902700, val_acc: 56.38%\n",
      "Epoch [4944]/[5000], train_loss: 0.016900, train_acc: 95.56%, val_loss: 3.267400, val_acc: 54.69%\n",
      "Epoch [4945]/[5000], train_loss: 0.019800, train_acc: 95.36%, val_loss: 3.274400, val_acc: 56.77%\n",
      "Epoch [4946]/[5000], train_loss: 0.026500, train_acc: 95.31%, val_loss: 2.912700, val_acc: 54.82%\n",
      "Epoch [4947]/[5000], train_loss: 0.023700, train_acc: 95.17%, val_loss: 2.984600, val_acc: 57.03%\n",
      "Epoch [4948]/[5000], train_loss: 0.015500, train_acc: 95.61%, val_loss: 2.974700, val_acc: 55.99%\n",
      "Epoch [4949]/[5000], train_loss: 0.014800, train_acc: 95.61%, val_loss: 3.271300, val_acc: 54.95%\n",
      "Epoch [4950]/[5000], train_loss: 0.012300, train_acc: 95.70%, val_loss: 4.291300, val_acc: 56.12%\n",
      "Epoch [4951]/[5000], train_loss: 0.039600, train_acc: 95.46%, val_loss: 3.315300, val_acc: 56.77%\n",
      "Epoch [4952]/[5000], train_loss: 0.046500, train_acc: 94.53%, val_loss: 3.473600, val_acc: 52.47%\n",
      "Epoch [4953]/[5000], train_loss: 0.054300, train_acc: 94.29%, val_loss: 3.536200, val_acc: 56.12%\n",
      "Epoch [4954]/[5000], train_loss: 0.059500, train_acc: 94.14%, val_loss: 3.174100, val_acc: 54.30%\n",
      "Epoch [4955]/[5000], train_loss: 0.046800, train_acc: 94.43%, val_loss: 3.595700, val_acc: 52.34%\n",
      "Epoch [4956]/[5000], train_loss: 0.037100, train_acc: 95.21%, val_loss: 2.877400, val_acc: 54.04%\n",
      "Epoch [4957]/[5000], train_loss: 0.046900, train_acc: 94.68%, val_loss: 2.916400, val_acc: 54.95%\n",
      "Epoch [4958]/[5000], train_loss: 0.029100, train_acc: 95.21%, val_loss: 2.973400, val_acc: 55.99%\n",
      "Epoch [4959]/[5000], train_loss: 0.021700, train_acc: 95.36%, val_loss: 2.912400, val_acc: 56.38%\n",
      "Epoch [4960]/[5000], train_loss: 0.021300, train_acc: 95.31%, val_loss: 3.242600, val_acc: 54.95%\n",
      "Epoch [4961]/[5000], train_loss: 0.015500, train_acc: 95.61%, val_loss: 2.999300, val_acc: 53.91%\n",
      "Epoch [4962]/[5000], train_loss: 0.036600, train_acc: 94.82%, val_loss: 3.014000, val_acc: 53.65%\n",
      "Epoch [4963]/[5000], train_loss: 0.029400, train_acc: 95.12%, val_loss: 3.291700, val_acc: 54.30%\n",
      "Epoch [4964]/[5000], train_loss: 0.027000, train_acc: 95.17%, val_loss: 3.210500, val_acc: 55.86%\n",
      "Epoch [4965]/[5000], train_loss: 0.017500, train_acc: 95.51%, val_loss: 3.121400, val_acc: 54.95%\n",
      "Epoch [4966]/[5000], train_loss: 0.021200, train_acc: 95.31%, val_loss: 3.069500, val_acc: 54.43%\n",
      "Epoch [4967]/[5000], train_loss: 0.025300, train_acc: 95.07%, val_loss: 2.694900, val_acc: 55.34%\n",
      "Epoch [4968]/[5000], train_loss: 0.038200, train_acc: 95.07%, val_loss: 3.265800, val_acc: 56.77%\n",
      "Epoch [4969]/[5000], train_loss: 0.044600, train_acc: 94.63%, val_loss: 3.195300, val_acc: 54.82%\n",
      "Epoch [4970]/[5000], train_loss: 0.032700, train_acc: 94.92%, val_loss: 3.461500, val_acc: 53.12%\n",
      "Epoch [4971]/[5000], train_loss: 0.051100, train_acc: 94.38%, val_loss: 3.604700, val_acc: 54.82%\n",
      "Epoch [4972]/[5000], train_loss: 0.087600, train_acc: 93.51%, val_loss: 3.177400, val_acc: 55.34%\n",
      "Epoch [4973]/[5000], train_loss: 0.067400, train_acc: 93.95%, val_loss: 3.023300, val_acc: 54.17%\n",
      "Epoch [4974]/[5000], train_loss: 0.049200, train_acc: 94.48%, val_loss: 2.753000, val_acc: 53.78%\n",
      "Epoch [4975]/[5000], train_loss: 0.039200, train_acc: 94.78%, val_loss: 2.774900, val_acc: 56.38%\n",
      "Epoch [4976]/[5000], train_loss: 0.045900, train_acc: 93.99%, val_loss: 3.009200, val_acc: 54.17%\n",
      "Epoch [4977]/[5000], train_loss: 0.036700, train_acc: 94.78%, val_loss: 2.731100, val_acc: 56.90%\n",
      "Epoch [4978]/[5000], train_loss: 0.035300, train_acc: 94.97%, val_loss: 2.993100, val_acc: 54.04%\n",
      "Epoch [4979]/[5000], train_loss: 0.029200, train_acc: 95.07%, val_loss: 3.019000, val_acc: 55.86%\n",
      "Epoch [4980]/[5000], train_loss: 0.043300, train_acc: 94.58%, val_loss: 3.148700, val_acc: 53.26%\n",
      "Epoch [4981]/[5000], train_loss: 0.022800, train_acc: 95.31%, val_loss: 3.259800, val_acc: 55.73%\n",
      "Epoch [4982]/[5000], train_loss: 0.031300, train_acc: 94.92%, val_loss: 3.122300, val_acc: 54.95%\n",
      "Epoch [4983]/[5000], train_loss: 0.022700, train_acc: 95.17%, val_loss: 3.111200, val_acc: 55.86%\n",
      "Epoch [4984]/[5000], train_loss: 0.023700, train_acc: 95.46%, val_loss: 3.143400, val_acc: 55.21%\n",
      "Epoch [4985]/[5000], train_loss: 0.015400, train_acc: 95.51%, val_loss: 3.373500, val_acc: 56.12%\n",
      "Epoch [4986]/[5000], train_loss: 0.023200, train_acc: 95.46%, val_loss: 3.064800, val_acc: 54.17%\n",
      "Epoch [4987]/[5000], train_loss: 0.017300, train_acc: 95.46%, val_loss: 2.819400, val_acc: 58.20%\n",
      "Epoch [4988]/[5000], train_loss: 0.016500, train_acc: 95.56%, val_loss: 3.194000, val_acc: 56.12%\n",
      "Epoch [4989]/[5000], train_loss: 0.019500, train_acc: 95.41%, val_loss: 3.733700, val_acc: 56.51%\n",
      "Epoch [4990]/[5000], train_loss: 0.016600, train_acc: 95.56%, val_loss: 3.421700, val_acc: 55.86%\n",
      "Epoch [4991]/[5000], train_loss: 0.016800, train_acc: 95.51%, val_loss: 2.946000, val_acc: 55.73%\n",
      "Epoch [4992]/[5000], train_loss: 0.008400, train_acc: 95.90%, val_loss: 3.023400, val_acc: 55.34%\n",
      "Epoch [4993]/[5000], train_loss: 0.020400, train_acc: 95.61%, val_loss: 2.992800, val_acc: 55.73%\n",
      "Epoch [4994]/[5000], train_loss: 0.012800, train_acc: 95.75%, val_loss: 3.098600, val_acc: 55.99%\n",
      "Epoch [4995]/[5000], train_loss: 0.012100, train_acc: 95.65%, val_loss: 3.027300, val_acc: 57.94%\n",
      "Epoch [4996]/[5000], train_loss: 0.033400, train_acc: 95.12%, val_loss: 3.106100, val_acc: 58.33%\n",
      "Epoch [4997]/[5000], train_loss: 0.028100, train_acc: 95.17%, val_loss: 3.268100, val_acc: 53.78%\n",
      "Epoch [4998]/[5000], train_loss: 0.027800, train_acc: 94.97%, val_loss: 3.650000, val_acc: 55.99%\n",
      "Epoch [4999]/[5000], train_loss: 0.021100, train_acc: 95.46%, val_loss: 3.037100, val_acc: 54.82%\n",
      "Epoch [5000]/[5000], train_loss: 0.019300, train_acc: 95.51%, val_loss: 2.993700, val_acc: 56.64%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    batch_count = 0\n",
    "    result = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "        images = transform(images)\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(images)\n",
    "        losses = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = (torch.argmax(outputs, dim=1))\n",
    "        results = predictions - labels\n",
    "        result+= len(np.where(results.cpu() == 0)[0])\n",
    "\n",
    "        loss_sum+= losses.item()\n",
    "        batch_count+=1\n",
    "\n",
    "    train_loss = round((loss_sum/batch_count),4)\n",
    "    train_accuracy = round((result/(batch_count*batch_size))*100,2)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    batch_count = 0\n",
    "    result = 0\n",
    "        \n",
    "    for i, (images, labels) in enumerate(val_dl):\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    " \n",
    "        outputs = model(images)\n",
    "        losses = loss_fn(outputs, labels)\n",
    "        predictions = (torch.argmax(outputs, dim=1))\n",
    "        results = predictions - labels\n",
    "        result+= len(np.where(results.cpu() == 0)[0])\n",
    "\n",
    "        loss_sum+= losses.item()\n",
    "        batch_count+=1\n",
    "\n",
    "    val_loss = round((loss_sum/batch_count),4)\n",
    "    val_accuracy = round((result/(batch_count*batch_size))*100,2)\n",
    "\n",
    "    history.append({'train_loss':train_loss,'train_acc':train_accuracy,'val_loss':val_loss,'val_acc':val_accuracy})\n",
    "\n",
    "    print(\"Epoch [{}]/[{}], train_loss: {:4f}, train_acc: {:.2f}%, val_loss: {:4f}, val_acc: {:.2f}%\".format(\n",
    "        epoch, num_epochs, train_loss, train_accuracy, val_loss, val_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cd52a8-51d8-48e1-94eb-d8c1aad39826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-b')\n",
    "    plt.plot(val_losses, '-r')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs VGG');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d28b4b-915c-4eb9-b1b7-4904f71b2ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    train_acc = [x['train_acc'] for x in history]\n",
    "    val_acc = [x['val_acc'] for x in history]\n",
    "    plt.plot(train_acc, '-b')\n",
    "    plt.plot(val_acc, '-r')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb30fa91-4a59-4ce3-934c-89df4a7c0002",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       374\n",
      "           1       0.38      0.38      0.38        78\n",
      "           2       0.08      0.04      0.05        28\n",
      "           3       0.62      0.60      0.61       176\n",
      "\n",
      "    accuracy                           0.65       656\n",
      "   macro avg       0.45      0.45      0.45       656\n",
      "weighted avg       0.63      0.65      0.64       656\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "model = model.to('cuda')\n",
    "\n",
    "label_list = []\n",
    "prediction_list = []\n",
    "\n",
    "data = ELPV_Dataset(transform_base)\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=False)\n",
    "\n",
    "for image, label in val_data:\n",
    "    # print(image)\n",
    "    image = torch.reshape(image, (1, np.shape(image)[0], np.shape(image)[1], np.shape(image)[2]))\n",
    "    image = image.to('cuda')\n",
    "    result = model(image)\n",
    "    result = result.to('cpu')\n",
    "    \n",
    "    prediction_list.append(torch.argmax(result).item())\n",
    "    label_list.append(label.item())\n",
    "    # print(result.item())\n",
    "\n",
    "# print((label_list))\n",
    "# print((prediction_list))\n",
    "\n",
    "print(metrics.classification_report(label_list, prediction_list))\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(label_list, prediction_list)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
